# Comparing `tmp/plaso-20230311.tar.gz` & `tmp/plaso-20230717.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "plaso-20230311.tar", last modified: Sun Mar 12 10:45:14 2023, max compression
+gzip compressed data, was "plaso-20230717.tar", last modified: Sun Jul 23 05:03:42 2023, max compression
```

## Comparing `plaso-20230311.tar` & `plaso-20230717.tar`

### file list

```diff
@@ -1,1262 +1,1289 @@
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.503977 plaso-20230311/
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.155976 plaso-20230311/.github/
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.178976 plaso-20230311/.github/ISSUE_TEMPLATE/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1826 2023-01-31 06:18:39.000000 plaso-20230311/.github/ISSUE_TEMPLATE/problem-report.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1495 2022-12-25 09:18:55.000000 plaso-20230311/.github/ISSUE_TEMPLATE/release.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      870 2023-01-07 09:50:35.000000 plaso-20230311/.github/PULL_REQUEST_TEMPLATE.md
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.193976 plaso-20230311/.github/workflows/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4606 2023-03-12 08:28:26.000000 plaso-20230311/.github/workflows/test_docker.yml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2420 2023-03-12 08:28:07.000000 plaso-20230311/.github/workflows/test_docs.yml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2721 2023-03-12 08:28:07.000000 plaso-20230311/.github/workflows/test_tox.yml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22164 2023-03-12 08:28:07.000000 plaso-20230311/.pylintrc
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      149 2022-12-25 09:18:55.000000 plaso-20230311/.yamllint.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3739 2022-12-25 09:18:55.000000 plaso-20230311/ACKNOWLEDGEMENTS
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     2171 2021-06-03 04:45:37.000000 plaso-20230311/AUTHORS
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1515 2021-06-03 04:45:37.000000 plaso-20230311/CONTRIBUTING.md
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)    11358 2021-02-05 09:03:02.000000 plaso-20230311/LICENSE
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      681 2022-12-25 09:18:55.000000 plaso-20230311/MANIFEST.in
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      601 2022-12-25 09:18:55.000000 plaso-20230311/MANIFEST.test_data.in
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      698 2023-03-12 10:45:14.503977 plaso-20230311/PKG-INFO
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1666 2022-09-18 11:21:00.000000 plaso-20230311/README
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1799 2022-09-18 11:21:00.000000 plaso-20230311/README.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1230 2023-03-12 08:28:07.000000 plaso-20230311/appveyor.yml
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.193976 plaso-20230311/config/
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.194976 plaso-20230311/config/appveyor/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1292 2023-03-12 08:28:26.000000 plaso-20230311/config/appveyor/install.ps1
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      125 2023-03-12 08:28:07.000000 plaso-20230311/config/appveyor/install.sh
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      620 2023-03-12 08:28:07.000000 plaso-20230311/config/appveyor/runtests.sh
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.194976 plaso-20230311/config/deployment/
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      258 2022-12-25 09:18:55.000000 plaso-20230311/config/deployment/build_docker.sh
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      533 2023-01-07 09:49:55.000000 plaso-20230311/config/deployment/fedora36.Dockerfile
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      990 2022-12-25 09:18:55.000000 plaso-20230311/config/deployment/ubuntu20.04.Dockerfile
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.194976 plaso-20230311/config/docker/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1352 2023-01-07 09:49:55.000000 plaso-20230311/config/docker/Dockerfile
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      445 2022-09-18 11:26:13.000000 plaso-20230311/config/docker/Windows.Dockerfile
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1071 2022-09-18 11:21:00.000000 plaso-20230311/config/docker/plaso-switch.sh
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.196976 plaso-20230311/config/dpkg/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      168 2023-03-12 10:42:34.000000 plaso-20230311/config/dpkg/changelog
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       48 2021-06-03 04:45:37.000000 plaso-20230311/config/dpkg/clean
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        2 2023-03-12 08:28:07.000000 plaso-20230311/config/dpkg/compat
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3149 2023-03-12 08:28:07.000000 plaso-20230311/config/dpkg/control
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      948 2022-12-25 09:18:55.000000 plaso-20230311/config/dpkg/copyright
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       17 2021-06-03 04:45:37.000000 plaso-20230311/config/dpkg/plaso-data.dirs
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       23 2021-06-03 04:45:37.000000 plaso-20230311/config/dpkg/plaso-data.install
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        8 2021-06-03 04:45:37.000000 plaso-20230311/config/dpkg/plaso-tools.install
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      275 2021-06-03 04:45:37.000000 plaso-20230311/config/dpkg/python3-plaso.install
--rwxrwxr-x   0 lordyesta  (1000) lordyesta  (1000)      122 2023-03-12 08:28:07.000000 plaso-20230311/config/dpkg/rules
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.196976 plaso-20230311/config/dpkg/source/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       12 2021-06-03 04:45:37.000000 plaso-20230311/config/dpkg/source/format
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10715 2023-01-07 09:50:35.000000 plaso-20230311/config/end-to-end.ini
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.197976 plaso-20230311/config/end_to_end/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      981 2022-12-25 09:18:55.000000 plaso-20230311/config/end_to_end/extract_and_output.Dockerfile
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     3514 2022-12-25 09:18:55.000000 plaso-20230311/config/end_to_end/run_tests_with_docker.sh
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.197976 plaso-20230311/config/jenkins/
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.201976 plaso-20230311/config/jenkins/greendale/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      373 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/acserver-archive-cpio.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      371 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/acserver-archive-tgz.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/acserver-archive-zip.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      356 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/acserver-mounted.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      388 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/acserver-with_archives.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      341 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/acserver.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      356 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/bchang-laptop.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      359 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/dc1-greendale3.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      359 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/dc2-greendale2.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      386 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/dean_mac-browserhistory.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      393 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/dean_mac-with_archives.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      333 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/dean_mac.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/dean_macbook.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      170 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/output_opensearch.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      114 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/output_opensearch_ts.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      149 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/psort-studentpc1-nsrlsvr.ini
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      173 2022-07-12 16:16:36.000000 plaso-20230311/config/jenkins/greendale/psort-studentpc1-sessionize-unique-domains.ini
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      165 2022-07-12 16:16:36.000000 plaso-20230311/config/jenkins/greendale/psort-studentpc1-tagging.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      409 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/registrar-with_archives.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      362 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/greendale/registrar.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      414 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/student-pc1-browserhistory.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      386 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/student-pc1.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      399 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/studentpc1-redis.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      350 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/studentpc10.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      364 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/greendale/studentpc8.ini
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.201976 plaso-20230311/config/jenkins/linux/
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1942 2023-03-12 08:28:07.000000 plaso-20230311/config/jenkins/linux/run_end_to_end_tests.sh
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.202976 plaso-20230311/config/jenkins/other/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      354 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/other/4dell_latitude.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      344 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/other/chromiumos.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      345 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/other/coreos.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      329 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/other/schardt.ini
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.204976 plaso-20230311/config/jenkins/sans/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      389 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/dade_timemachine.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      371 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/dademurphy.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/sans/drfalken.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      422 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/eugenebelford_ellingsoncorp.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      365 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/file.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      361 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/ftp.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/katelibby.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      419 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/margowallace_ellingsoncorp.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      369 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/rd-04.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      391 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/sans/win2008R2-controller.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      382 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/sans/win7-32-nromanoff.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      370 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/sans/win7-64-nfury.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      377 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/wkstn-01.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      377 2022-12-25 09:18:55.000000 plaso-20230311/config/jenkins/sans/wkstn-05.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      361 2022-09-18 11:21:00.000000 plaso-20230311/config/jenkins/sans/xp-tdungan.ini
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      372 2021-06-03 04:45:37.000000 plaso-20230311/config/jenkins/travis.ini
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.205976 plaso-20230311/config/linux/
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     6265 2023-03-12 08:28:37.000000 plaso-20230311/config/linux/gift_copr_install.sh
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1578 2022-09-18 11:26:13.000000 plaso-20230311/config/linux/ubuntu_install_nsrlsvr.sh
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      753 2022-12-25 09:18:55.000000 plaso-20230311/config/linux/ubuntu_install_opensearch.sh
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     6136 2023-03-12 08:28:07.000000 plaso-20230311/config/linux/ubuntu_install_plaso.sh
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     2680 2021-02-05 09:03:02.000000 plaso-20230311/config/logo.jpg
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.205976 plaso-20230311/config/pylint/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5840 2022-12-25 09:18:55.000000 plaso-20230311/config/pylint/spelling-private-dict
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.205976 plaso-20230311/config/tests/
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2405 2022-09-18 11:26:13.000000 plaso-20230311/config/tests/generate_test_files.sh
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.207976 plaso-20230311/data/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      119 2022-12-25 09:18:55.000000 plaso-20230311/data/filter_no_winsxs.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4085 2022-12-25 09:18:55.000000 plaso-20230311/data/filter_windows.txt
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5255 2022-12-25 09:18:55.000000 plaso-20230311/data/filter_windows.yaml
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.217976 plaso-20230311/data/formatters/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4800 2023-01-07 09:49:55.000000 plaso-20230311/data/formatters/android.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7640 2023-01-07 09:49:55.000000 plaso-20230311/data/formatters/antivirus.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16863 2023-01-08 08:58:30.000000 plaso-20230311/data/formatters/browser.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17584 2023-01-07 09:49:55.000000 plaso-20230311/data/formatters/bsm.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    24117 2023-01-11 04:51:22.000000 plaso-20230311/data/formatters/generic.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5332 2023-01-07 09:49:55.000000 plaso-20230311/data/formatters/ios.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2188 2023-01-07 09:49:55.000000 plaso-20230311/data/formatters/linux.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11820 2023-01-08 08:58:30.000000 plaso-20230311/data/formatters/macos.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    23278 2023-01-08 08:58:30.000000 plaso-20230311/data/formatters/windows.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1796 2022-12-25 09:18:55.000000 plaso-20230311/data/opensearch.mappings
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       80 2021-06-03 04:45:37.000000 plaso-20230311/data/plaso-data.README
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3665 2023-01-07 09:50:35.000000 plaso-20230311/data/presets.yaml
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1027 2021-06-03 04:45:37.000000 plaso-20230311/data/signatures.conf
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4704 2023-01-07 09:49:55.000000 plaso-20230311/data/tag_linux.txt
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1043 2023-01-07 09:49:55.000000 plaso-20230311/data/tag_macos.txt
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7937 2023-01-08 07:01:39.000000 plaso-20230311/data/tag_windows.txt
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    42204 2023-01-07 09:49:55.000000 plaso-20230311/data/timeliner.yaml
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)  6875136 2021-06-03 04:45:37.000000 plaso-20230311/data/winevt-rc.db
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10030 2023-03-12 10:42:34.000000 plaso-20230311/dependencies.ini
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.218976 plaso-20230311/docs/
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.218976 plaso-20230311/docs/_build/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        0 2022-11-21 19:42:41.000000 plaso-20230311/docs/_build/.gitkeep
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5638 2023-03-12 08:28:44.000000 plaso-20230311/docs/conf.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1097 2022-12-25 09:18:55.000000 plaso-20230311/docs/index.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      115 2023-03-12 08:28:44.000000 plaso-20230311/docs/requirements.txt
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.218976 plaso-20230311/docs/sources/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10060 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/Supported-formats.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12839 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/Troubleshooting.md
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.225976 plaso-20230311/docs/sources/api/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        0 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/.gitkeep
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       52 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/modules.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2824 2023-01-12 02:25:22.000000 plaso-20230311/docs/sources/api/plaso.analysis.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1289 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.analyzers.hashers.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1116 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.analyzers.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6420 2023-01-12 02:25:22.000000 plaso-20230311/docs/sources/api/plaso.cli.helpers.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2425 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.cli.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2238 2023-01-12 02:25:22.000000 plaso-20230311/docs/sources/api/plaso.containers.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3154 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/api/plaso.engine.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1670 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.filters.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2715 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/api/plaso.formatters.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      438 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.helpers.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1380 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/api/plaso.helpers.windows.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1878 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/api/plaso.lib.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3214 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/api/plaso.multi_process.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2773 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.multi_processing.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3418 2023-01-12 02:25:22.000000 plaso-20230311/docs/sources/api/plaso.output.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      865 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.parsers.bencode_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      844 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.parsers.cookie_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      609 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.parsers.czip_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1283 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/api/plaso.parsers.esedb_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2555 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/api/plaso.parsers.jsonl_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1066 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.parsers.olecf_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3618 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/api/plaso.parsers.plist_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9007 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/api/plaso.parsers.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      393 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.parsers.shared.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8361 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/api/plaso.parsers.sqlite_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      814 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.parsers.syslog_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7001 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/api/plaso.parsers.text_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6566 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.parsers.winreg_plugins.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1557 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/api/plaso.preprocessors.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      653 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      539 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/api/plaso.serializer.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      415 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.single_process.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      720 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.storage.fake.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      721 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.storage.redis.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1072 2023-01-12 02:25:22.000000 plaso-20230311/docs/sources/api/plaso.storage.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      733 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.storage.sqlite.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      153 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.unix.rst
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      156 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/api/plaso.winnt.rst
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.228976 plaso-20230311/docs/sources/developer/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4733 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/developer/Developers-Guide.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      871 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/developer/Developing-Fedora.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      910 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/developer/Developing-MacOS.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1868 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/developer/Developing-Ubuntu.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2072 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/developer/Developing-Virtualenv.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2016 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/developer/Developing-Windows.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4737 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/developer/Development-Dependencies.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2275 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/developer/How-to-write-a-SQLite-plugin.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6542 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/developer/How-to-write-a-parser.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1210 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/developer/How-to-write-a-tagging-rule.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1272 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/developer/How-to-write-an-analysis-plugin.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1342 2023-01-07 09:50:35.000000 plaso-20230311/docs/sources/developer/How-to-write-an-output-module.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5071 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/developer/Internals.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      258 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/developer/Packaging-with-docker.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2321 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/developer/Packaging-with-pyinstaller.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2319 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/developer/Profiling.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2257 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/developer/Style-guide.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1968 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/developer/Testing.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      502 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/developer/index.rst
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.234976 plaso-20230311/docs/sources/user/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1781 2023-01-08 16:45:00.000000 plaso-20230311/docs/sources/user/Analysis-plugin-bloom.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1540 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-browser-search.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      713 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-chrome-extension.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1264 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-nsrlsvr.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      597 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-sessionize.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1125 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-tagging.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      842 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-unique-domains-visited.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      997 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-viper.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1438 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Analysis-plugin-virustotal.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      950 2023-01-08 16:45:00.000000 plaso-20230311/docs/sources/user/Analysis-plugins.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4677 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/user/Collection-Filters.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      524 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/user/Creating-a-timeline.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4698 2023-01-08 12:31:37.000000 plaso-20230311/docs/sources/user/Event-filters.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1714 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Feature-requests-and-bug-reports.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      504 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Fedora-Packaged-Release.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2500 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Getting-started.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      670 2022-11-21 19:42:42.000000 plaso-20230311/docs/sources/user/Installation-Problems.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3423 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Installing-with-docker.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12400 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Log2Timeline-Perl-(Legacy).md
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       91 2022-11-21 19:42:42.000000 plaso-20230311/docs/sources/user/MacOS-Packaged-Release.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3916 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/user/MacOS-Source-Release.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11445 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/user/Output-and-formatting.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4067 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Output-format-l2tcsv.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16324 2023-03-11 12:55:06.000000 plaso-20230311/docs/sources/user/Parsers-and-plugins.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      143 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/user/Release-process.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1878 2023-02-01 06:26:58.000000 plaso-20230311/docs/sources/user/Releases-and-roadmap.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7709 2022-11-21 19:42:42.000000 plaso-20230311/docs/sources/user/Scribbles-about-events.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2112 2022-11-21 19:42:42.000000 plaso-20230311/docs/sources/user/Tagging-Rules.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      609 2023-01-07 09:49:55.000000 plaso-20230311/docs/sources/user/Tips-and-Tricks.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5886 2022-11-21 19:42:42.000000 plaso-20230311/docs/sources/user/Troubleshooting-installation-issues.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      844 2023-01-07 09:50:35.000000 plaso-20230311/docs/sources/user/Ubuntu-Packaged-Release.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3296 2022-11-21 19:42:42.000000 plaso-20230311/docs/sources/user/Users-Guide.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2748 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Using-image_export.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8092 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Using-log2timeline.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5287 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/user/Using-pinfo.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21784 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/Using-psort.md
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1507 2022-11-21 19:42:41.000000 plaso-20230311/docs/sources/user/Using-psteal.md
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       91 2022-11-21 19:42:42.000000 plaso-20230311/docs/sources/user/Windows-Packaged-Release.md
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      494 2022-12-25 09:18:55.000000 plaso-20230311/docs/sources/user/index.rst
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.234976 plaso-20230311/plaso/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      296 2023-03-12 10:42:34.000000 plaso-20230311/plaso/__init__.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.254976 plaso-20230311/plaso/analysis/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      518 2023-01-08 16:45:00.000000 plaso-20230311/plaso/analysis/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4096 2023-01-08 16:45:00.000000 plaso-20230311/plaso/analysis/bloom.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9546 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analysis/browser_search.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5908 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analysis/chrome_extension.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      413 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analysis/definitions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8803 2023-01-07 09:49:55.000000 plaso-20230311/plaso/analysis/hash_tagging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2952 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analysis/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      325 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analysis/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4073 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analysis/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5195 2023-01-07 09:50:35.000000 plaso-20230311/plaso/analysis/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4921 2023-01-07 09:49:55.000000 plaso-20230311/plaso/analysis/nsrlsvr.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2099 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analysis/sessionize.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2057 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analysis/tagging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1547 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analysis/test_memory.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1928 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analysis/unique_domains_visited.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4503 2023-01-07 09:49:55.000000 plaso-20230311/plaso/analysis/viper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4479 2023-01-07 09:49:55.000000 plaso-20230311/plaso/analysis/virustotal.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.255976 plaso-20230311/plaso/analyzers/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      176 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/__init__.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.256976 plaso-20230311/plaso/analyzers/hashers/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      255 2022-12-25 09:18:55.000000 plaso-20230311/plaso/analyzers/hashers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1865 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/hashers/entropy.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      962 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/hashers/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4483 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/hashers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1239 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/hashers/md5.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1254 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/hashers/sha1.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1280 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/hashers/sha256.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2636 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/hashing_analyzer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      926 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      327 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3480 2022-11-21 19:43:24.000000 plaso-20230311/plaso/analyzers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2236 2023-01-07 09:49:55.000000 plaso-20230311/plaso/analyzers/yara_analyzer.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.259976 plaso-20230311/plaso/cli/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6316 2023-01-09 23:11:07.000000 plaso-20230311/plaso/cli/analysis_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    32700 2023-01-09 23:11:07.000000 plaso-20230311/plaso/cli/extraction_tool.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.264976 plaso-20230311/plaso/cli/helpers/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1540 2023-01-08 16:45:00.000000 plaso-20230311/plaso/cli/helpers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2895 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/analysis_plugins.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2715 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/helpers/archives.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6125 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/artifact_definitions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4004 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/artifact_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3538 2023-01-11 17:57:01.000000 plaso-20230311/plaso/cli/helpers/bloom_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1830 2023-01-07 09:50:02.000000 plaso-20230311/plaso/cli/helpers/codepage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3801 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/data_location.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3970 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/date_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2043 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/dynamic_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5900 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/event_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2938 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/extraction.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2617 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/filter_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2925 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/hashers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3800 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2413 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/language.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3992 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3866 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/helpers/nsrlsvr_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7280 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/opensearch_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2464 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/opensearch_ts_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3181 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/output_modules.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2498 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/parsers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2426 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/process_resources.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4596 2023-01-07 09:50:35.000000 plaso-20230311/plaso/cli/helpers/profiling.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2206 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/sessionize_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3122 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/helpers/status_view.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3469 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/storage_format.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2822 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/tagging_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2137 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/temporary_directory.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1928 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/helpers/vfs_backend.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4010 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/helpers/viper_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3434 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/virustotal_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3704 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/workers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2759 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/helpers/xlsx_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2618 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/helpers/yara_rules.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    29746 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/image_export_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12835 2023-01-07 09:50:35.000000 plaso-20230311/plaso/cli/log2timeline_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      315 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    62114 2023-01-08 08:58:30.000000 plaso-20230311/plaso/cli/pinfo_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19543 2023-01-08 08:58:30.000000 plaso-20230311/plaso/cli/psort_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14011 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/psteal_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22810 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/status_view.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    23995 2023-01-07 09:50:35.000000 plaso-20230311/plaso/cli/storage_media_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1303 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/time_slices.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13011 2022-12-25 09:18:55.000000 plaso-20230311/plaso/cli/tool_options.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19202 2023-01-07 09:49:55.000000 plaso-20230311/plaso/cli/tools.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11522 2022-11-21 19:43:22.000000 plaso-20230311/plaso/cli/views.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.266976 plaso-20230311/plaso/containers/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      807 2023-01-07 09:49:55.000000 plaso-20230311/plaso/containers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2425 2023-01-07 09:50:35.000000 plaso-20230311/plaso/containers/analysis_results.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      983 2023-01-07 09:50:35.000000 plaso-20230311/plaso/containers/analyzer_result.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    28991 2023-01-08 08:58:30.000000 plaso-20230311/plaso/containers/artifacts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1749 2023-01-07 09:50:35.000000 plaso-20230311/plaso/containers/counts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1839 2023-01-07 09:50:35.000000 plaso-20230311/plaso/containers/event_sources.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14186 2023-01-08 12:31:37.000000 plaso-20230311/plaso/containers/events.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      639 2023-01-07 09:49:55.000000 plaso-20230311/plaso/containers/plist_event.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1671 2023-01-07 09:50:35.000000 plaso-20230311/plaso/containers/reports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12579 2023-01-08 08:58:30.000000 plaso-20230311/plaso/containers/sessions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4021 2023-01-07 09:50:35.000000 plaso-20230311/plaso/containers/tasks.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5969 2023-01-07 09:50:35.000000 plaso-20230311/plaso/containers/warnings.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4306 2023-01-07 09:49:55.000000 plaso-20230311/plaso/containers/windows_events.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8913 2023-03-12 10:42:34.000000 plaso-20230311/plaso/dependencies.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.269976 plaso-20230311/plaso/engine/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10415 2022-12-25 09:18:55.000000 plaso-20230311/plaso/engine/artifact_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8147 2023-01-07 09:50:35.000000 plaso-20230311/plaso/engine/configurations.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13348 2023-01-07 09:49:55.000000 plaso-20230311/plaso/engine/engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21363 2023-01-09 19:05:29.000000 plaso-20230311/plaso/engine/extractors.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1596 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/filter_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      784 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/filters_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14347 2023-01-08 08:58:30.000000 plaso-20230311/plaso/engine/knowledge_base.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      321 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3864 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/path_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13781 2023-01-07 09:50:35.000000 plaso-20230311/plaso/engine/path_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1156 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/process_info.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21367 2023-01-07 09:49:55.000000 plaso-20230311/plaso/engine/processing_status.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7412 2022-12-25 09:18:55.000000 plaso-20230311/plaso/engine/profilers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2373 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/tagging_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11598 2023-01-08 12:31:37.000000 plaso-20230311/plaso/engine/timeliner.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    38417 2023-01-31 06:18:33.000000 plaso-20230311/plaso/engine/worker.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3511 2022-11-21 19:43:24.000000 plaso-20230311/plaso/engine/yaml_filter_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3711 2023-01-07 09:49:55.000000 plaso-20230311/plaso/engine/yaml_timeliner_file.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.271976 plaso-20230311/plaso/filters/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1364 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/event_filter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    24528 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/expression_parser.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7105 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/expressions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12347 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/file_entry.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17265 2023-01-08 12:31:37.000000 plaso-20230311/plaso/filters/filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      323 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10167 2023-01-07 09:49:55.000000 plaso-20230311/plaso/filters/parser_filter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22284 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/path_filter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1225 2022-11-21 19:43:22.000000 plaso-20230311/plaso/filters/value_types.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.273976 plaso-20230311/plaso/formatters/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      478 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1155 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/chrome.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2206 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/chrome_preferences.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2321 2023-01-08 12:31:37.000000 plaso-20230311/plaso/formatters/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2139 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/file_system.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1545 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/firefox.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20292 2023-01-08 12:31:37.000000 plaso-20230311/plaso/formatters/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      329 2022-11-21 19:43:22.000000 plaso-20230311/plaso/formatters/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1915 2022-11-21 19:43:22.000000 plaso-20230311/plaso/formatters/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1607 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/msiecf.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      878 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/shell_items.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2333 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/winevt.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1181 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/winlnk.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2221 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/winprefetch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      782 2022-12-25 09:18:55.000000 plaso-20230311/plaso/formatters/winreg.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10121 2023-01-07 09:49:55.000000 plaso-20230311/plaso/formatters/yaml_formatters_file.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.273976 plaso-20230311/plaso/helpers/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230311/plaso/helpers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14383 2022-12-25 09:18:55.000000 plaso-20230311/plaso/helpers/language_tags.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.274976 plaso-20230311/plaso/helpers/windows/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230311/plaso/helpers/windows/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3276 2022-12-25 09:18:55.000000 plaso-20230311/plaso/helpers/windows/eventlog_providers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9071 2022-11-21 19:43:24.000000 plaso-20230311/plaso/helpers/windows/known_folders.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9663 2022-11-21 19:43:24.000000 plaso-20230311/plaso/helpers/windows/languages.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2148 2022-11-21 19:43:24.000000 plaso-20230311/plaso/helpers/windows/resource_files.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13530 2022-11-21 19:43:24.000000 plaso-20230311/plaso/helpers/windows/shell_folders.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7428 2022-11-21 19:43:24.000000 plaso-20230311/plaso/helpers/windows/time_zones.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.276976 plaso-20230311/plaso/lib/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230311/plaso/lib/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1605 2022-11-21 19:43:24.000000 plaso-20230311/plaso/lib/bufferlib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1542 2023-01-07 09:49:55.000000 plaso-20230311/plaso/lib/cookie_plugins_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      711 2022-11-21 19:43:24.000000 plaso-20230311/plaso/lib/decorators.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5725 2023-01-08 12:31:37.000000 plaso-20230311/plaso/lib/definitions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8577 2022-12-25 09:18:55.000000 plaso-20230311/plaso/lib/dtfabric_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2435 2023-01-07 09:50:35.000000 plaso-20230311/plaso/lib/errors.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6009 2022-11-21 19:43:24.000000 plaso-20230311/plaso/lib/line_reader_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2234 2022-11-21 19:43:24.000000 plaso-20230311/plaso/lib/loggers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1513 2022-11-21 19:43:24.000000 plaso-20230311/plaso/lib/plist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5388 2022-11-21 19:43:24.000000 plaso-20230311/plaso/lib/specification.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4765 2023-01-07 09:49:55.000000 plaso-20230311/plaso/lib/yearless_helper.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.279976 plaso-20230311/plaso/multi_process/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230311/plaso/multi_process/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25136 2023-01-07 09:49:55.000000 plaso-20230311/plaso/multi_process/analysis_engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9738 2023-01-07 09:50:35.000000 plaso-20230311/plaso/multi_process/analysis_process.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11068 2022-12-25 09:18:55.000000 plaso-20230311/plaso/multi_process/base_process.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14385 2023-01-07 09:49:55.000000 plaso-20230311/plaso/multi_process/engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    37757 2023-01-07 09:49:55.000000 plaso-20230311/plaso/multi_process/extraction_engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13177 2023-01-07 09:50:35.000000 plaso-20230311/plaso/multi_process/extraction_process.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      338 2022-11-21 19:43:24.000000 plaso-20230311/plaso/multi_process/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4523 2023-01-07 09:49:55.000000 plaso-20230311/plaso/multi_process/merge_helpers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18765 2023-01-08 08:58:30.000000 plaso-20230311/plaso/multi_process/output_engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1342 2022-11-21 19:43:24.000000 plaso-20230311/plaso/multi_process/plaso_queue.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4293 2022-11-21 19:43:24.000000 plaso-20230311/plaso/multi_process/plaso_xmlrpc.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1415 2022-11-21 19:43:24.000000 plaso-20230311/plaso/multi_process/rpc.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13232 2022-12-25 09:18:55.000000 plaso-20230311/plaso/multi_process/task_engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20344 2022-12-25 09:18:55.000000 plaso-20230311/plaso/multi_process/task_manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4454 2022-12-25 09:18:55.000000 plaso-20230311/plaso/multi_process/task_process.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25840 2023-02-01 06:26:58.000000 plaso-20230311/plaso/multi_process/zeromq_queue.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.282976 plaso-20230311/plaso/output/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      581 2022-12-25 09:18:55.000000 plaso-20230311/plaso/output/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5598 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/dynamic.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20138 2023-01-08 12:31:37.000000 plaso-20230311/plaso/output/formatting_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5027 2023-01-08 12:31:37.000000 plaso-20230311/plaso/output/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      974 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/json_line.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1535 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/json_out.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2708 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/kml.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12391 2023-01-08 12:31:37.000000 plaso-20230311/plaso/output/l2t_csv.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      321 2022-11-21 19:43:23.000000 plaso-20230311/plaso/output/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4305 2022-12-25 09:18:55.000000 plaso-20230311/plaso/output/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12630 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1296 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/null.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1641 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/opensearch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2744 2023-03-11 12:54:49.000000 plaso-20230311/plaso/output/opensearch_ts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6515 2023-01-08 12:31:37.000000 plaso-20230311/plaso/output/rawpy.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6476 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/shared_dsv.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5160 2023-01-08 12:31:37.000000 plaso-20230311/plaso/output/shared_json.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15748 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/shared_opensearch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7163 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/text_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5588 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/tln.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22319 2022-12-25 09:18:55.000000 plaso-20230311/plaso/output/winevt_rc.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8386 2023-01-07 09:50:35.000000 plaso-20230311/plaso/output/xlsx.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.293976 plaso-20230311/plaso/parsers/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2301 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3205 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/android_app_usage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10966 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/asl.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2716 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/asl.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6169 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/bencode_parser.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.293976 plaso-20230311/plaso/parsers/bencode_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      169 2022-11-21 19:43:22.000000 plaso-20230311/plaso/parsers/bencode_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1677 2022-11-21 19:43:22.000000 plaso-20230311/plaso/parsers/bencode_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2737 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/bencode_plugins/transmission.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3588 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/bencode_plugins/utorrent.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12778 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/bodyfile.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    29368 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/bsm.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12445 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/bsm.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16401 2023-01-09 16:09:11.000000 plaso-20230311/plaso/parsers/chrome_cache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3866 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/chrome_cache.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10690 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/chrome_preferences.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.294976 plaso-20230311/plaso/parsers/cookie_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      115 2022-11-21 19:43:23.000000 plaso-20230311/plaso/parsers/cookie_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11172 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/cookie_plugins/ganalytics.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3978 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/cookie_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2010 2022-11-21 19:43:23.000000 plaso-20230311/plaso/parsers/cookie_plugins/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14634 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/cups_ipp.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2170 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/cups_ipp.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7900 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/custom_destinations.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1641 2023-02-12 12:57:48.000000 plaso-20230311/plaso/parsers/custom_destinations.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3053 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/czip.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.294976 plaso-20230311/plaso/parsers/czip_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      112 2022-11-21 19:43:23.000000 plaso-20230311/plaso/parsers/czip_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2413 2022-11-21 19:43:23.000000 plaso-20230311/plaso/parsers/czip_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12932 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/czip_plugins/oxml.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6948 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/detection_history.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11336 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/dsv_parser.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4757 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/esedb.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.295976 plaso-20230311/plaso/parsers/esedb_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      280 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/esedb_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4191 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/esedb_plugins/file_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11957 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/esedb_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14625 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/esedb_plugins/msie_webcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19309 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/esedb_plugins/srum.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      707 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/esedb_plugins/types.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20030 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/esedb_plugins/user_access_logging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6607 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/filestat.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18222 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/firefox_cache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2941 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/firefox_cache.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3556 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/fish_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6966 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/fseventsd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1422 2023-01-01 17:41:45.000000 plaso-20230311/plaso/parsers/fseventsd.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9488 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6752 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/java_idx.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4089 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/java_idx.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2869 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/jsonl_parser.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.297976 plaso-20230311/plaso/parsers/jsonl_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      610 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4646 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/aws_cloudtrail_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5362 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/azure_activity_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9090 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/azure_application_gateway_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4653 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/docker_container_config.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3710 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/docker_container_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3407 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/docker_layer_config.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9868 2023-01-11 04:51:22.000000 plaso-20230311/plaso/parsers/jsonl_plugins/gcp_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3517 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5927 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/ios_app_privacy.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4708 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/jsonl_plugins/microsoft365_audit_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5609 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/locate.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1724 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/locate.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      323 2022-11-21 19:43:23.000000 plaso-20230311/plaso/parsers/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    32046 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/macos_keychain.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3732 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/macos_keychain.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12122 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5999 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/mcafeeav.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22441 2023-01-08 12:31:37.000000 plaso-20230311/plaso/parsers/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14939 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/msiecf.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3883 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/networkminer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17554 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/ntfs.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1364 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/ntfs.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4127 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/olecf.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.298976 plaso-20230311/plaso/parsers/olecf_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      252 2022-11-21 19:43:23.000000 plaso-20230311/plaso/parsers/olecf_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8790 2023-02-12 18:19:21.000000 plaso-20230311/plaso/parsers/olecf_plugins/automatic_destinations.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3105 2023-02-12 05:05:35.000000 plaso-20230311/plaso/parsers/olecf_plugins/automatic_destinations.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2478 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/olecf_plugins/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2314 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/olecf_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14817 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/olecf_plugins/summary.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10043 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/opera.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21953 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/pe.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3838 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/pe_resources.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7136 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/plist.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.300976 plaso-20230311/plaso/parsers/plist_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      864 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1916 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/airport.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3095 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/apple_account.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3274 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/bluetooth.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1407 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2353 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/install_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9902 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2240 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/ios_carplay.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2753 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/ipod.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2758 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/launchd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6913 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/macos_user.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2760 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/safari_downloads.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3790 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/safari_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3245 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/software_update.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2391 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/spotlight_searched_terms.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2116 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/spotlight_volume.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3556 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plist_plugins/time_machine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      717 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/plist_plugins/time_machine.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6781 2023-02-25 10:48:56.000000 plaso-20230311/plaso/parsers/pls_recall.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1081 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/pls_recall.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3860 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/plugins.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7598 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/presets.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9271 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/recycler.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2638 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/recycler.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7987 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/safari_cookies.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2063 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/safari_cookies.yaml
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.300976 plaso-20230311/plaso/parsers/shared/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:22.000000 plaso-20230311/plaso/parsers/shared/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6801 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/shared/shell_items.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    38607 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/spotlight_storedb.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5214 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/spotlight_storedb.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15848 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/sqlite.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.305976 plaso-20230311/plaso/parsers/sqlite_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2075 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9294 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/android_calls.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16836 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/android_hangouts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7153 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/android_sms.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15201 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/android_tango.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21169 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/android_twitter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4752 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/android_webview.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3520 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/android_webviewcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3665 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/chrome_autofill.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7358 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/chrome_cookies.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4725 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/chrome_extension_activity.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    51984 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/chrome_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3742 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/dropbox.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6420 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/firefox_cookies.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5102 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/firefox_downloads.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19145 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/firefox_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11043 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/gdrive.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8332 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/imessage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6909 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7030 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/ios_kik.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8564 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/ios_netusage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3949 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/ios_powerlog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6819 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/ios_screentime.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12718 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/ios_twitter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8988 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/kodi.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3932 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/ls_quarantine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9342 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/mackeeper_cache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4191 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/macos_appusage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5759 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/macos_document_versions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    31607 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/macos_knowledgec.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7734 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/macos_notes.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5456 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/macos_notification_center.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5334 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/macos_tcc.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6227 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/safari.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    37698 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/skype.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7833 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/windows_eventtranscript.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13621 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/windows_timeline.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6418 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/sqlite_plugins/zeitgeist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12222 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/symantec.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11594 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/systemd_journal.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4003 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/systemd_journal.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9865 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_parser.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.310976 plaso-20230311/plaso/parsers/text_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1684 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/text_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9362 2023-02-01 06:26:58.000000 plaso-20230311/plaso/parsers/text_plugins/android_logcat.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10452 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/apache_access.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8085 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/apt_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25144 2023-01-07 11:30:43.000000 plaso-20230311/plaso/parsers/text_plugins/aws_elb_access.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2889 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/bash_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10145 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/confluence_access.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6687 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/dpkg.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8410 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/gdrive_synclog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9756 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/google_logging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15550 2023-02-07 15:18:26.000000 plaso-20230311/plaso/parsers/text_plugins/iis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12226 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6271 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/ios_lockdownd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5087 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/ios_logd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7381 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/ios_sysdiag_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7235 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/macos_appfirewall.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7609 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/macos_securityd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9805 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/macos_wifi.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11191 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/popcontest.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9463 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/postgresql.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20313 2023-01-07 11:30:43.000000 plaso-20230311/plaso/parsers/text_plugins/santa.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7437 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/sccm.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5812 2023-01-07 11:30:43.000000 plaso-20230311/plaso/parsers/text_plugins/selinux.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10081 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/setupapi.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18650 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/skydrivelog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9211 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/snort_fastlog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4791 2023-01-07 11:30:43.000000 plaso-20230311/plaso/parsers/text_plugins/sophos_av.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25619 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/syslog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17445 2023-01-07 11:30:43.000000 plaso-20230311/plaso/parsers/text_plugins/viminfo.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4721 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/vsftpd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12679 2023-01-09 19:05:29.000000 plaso-20230311/plaso/parsers/text_plugins/winfirewall.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10596 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/xchatlog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5882 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/xchatscrollback.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4724 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/text_plugins/zsh_extended_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12398 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/trendmicroav.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6628 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/utmp.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2031 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/utmp.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6000 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/utmpx.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10808 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/windefender_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8885 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winevt.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9638 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winevtx.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10631 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winjob.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4504 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winjob.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8580 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winlnk.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6710 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winprefetch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10253 2023-01-07 09:50:35.000000 plaso-20230311/plaso/parsers/winreg_parser.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.315976 plaso-20230311/plaso/parsers/winreg_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1591 2022-11-21 19:43:23.000000 plaso-20230311/plaso/parsers/winreg_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17782 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/amcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25266 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/appcompatcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8408 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/appcompatcache.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7956 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/bagmru.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3301 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/bam.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5486 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/ccleaner.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1117 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      322 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/filetime.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12476 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4871 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/lfu.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3055 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/mountpoints.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      904 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/mru.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10688 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/mrulist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18822 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/mrulistex.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9755 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/msie_zones.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2546 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/network_drives.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6338 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/networks.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5350 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/officemru.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3382 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/outlook.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7680 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/programscache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1009 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/programscache.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3157 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/run.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6836 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/sam_users.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1824 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/sam_users.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4219 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/services.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3695 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/shutdown.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      633 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/systemtime.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6205 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/task_scheduler.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1017 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/task_scheduler.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4918 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/terminal_server.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2488 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/timezone.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2586 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/typedurls.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3034 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/usb.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7784 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/usbstor.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      527 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/usbstor.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8190 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/userassist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1622 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/userassist.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3030 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/windows_version.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4434 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/winlogon.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2619 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winreg_plugins/winrar.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3347 2023-01-07 09:49:55.000000 plaso-20230311/plaso/parsers/winrestore.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      948 2022-12-25 09:18:55.000000 plaso-20230311/plaso/parsers/winrestore.yaml
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.316976 plaso-20230311/plaso/preprocessors/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      201 2022-12-25 09:18:55.000000 plaso-20230311/plaso/preprocessors/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3399 2022-12-25 09:18:55.000000 plaso-20230311/plaso/preprocessors/generic.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11736 2022-11-21 19:43:24.000000 plaso-20230311/plaso/preprocessors/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10756 2022-12-25 09:18:55.000000 plaso-20230311/plaso/preprocessors/linux.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      335 2022-11-21 19:43:24.000000 plaso-20230311/plaso/preprocessors/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9214 2022-12-25 09:18:55.000000 plaso-20230311/plaso/preprocessors/macos.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12802 2022-12-25 09:18:55.000000 plaso-20230311/plaso/preprocessors/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6779 2023-01-07 09:49:55.000000 plaso-20230311/plaso/preprocessors/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      934 2022-12-25 09:18:55.000000 plaso-20230311/plaso/preprocessors/mounted_devices.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1156 2022-12-25 09:18:55.000000 plaso-20230311/plaso/preprocessors/time_zone_information.yaml
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    34859 2023-01-07 09:49:55.000000 plaso-20230311/plaso/preprocessors/windows.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.317976 plaso-20230311/plaso/serializer/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230311/plaso/serializer/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16991 2023-01-07 09:50:35.000000 plaso-20230311/plaso/serializer/json_serializer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      329 2022-11-21 19:43:24.000000 plaso-20230311/plaso/serializer/logger.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.317976 plaso-20230311/plaso/single_process/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230311/plaso/single_process/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16577 2023-01-07 09:50:35.000000 plaso-20230311/plaso/single_process/extraction_engine.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.318976 plaso-20230311/plaso/storage/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:23.000000 plaso-20230311/plaso/storage/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3834 2022-12-25 09:18:55.000000 plaso-20230311/plaso/storage/factory.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.318976 plaso-20230311/plaso/storage/fake/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:23.000000 plaso-20230311/plaso/storage/fake/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1198 2022-11-21 19:43:23.000000 plaso-20230311/plaso/storage/fake/event_heap.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2029 2023-01-07 09:50:35.000000 plaso-20230311/plaso/storage/fake/fake_store.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4244 2023-01-07 09:49:55.000000 plaso-20230311/plaso/storage/fake/writer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      323 2022-11-21 19:43:23.000000 plaso-20230311/plaso/storage/logger.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8786 2023-01-08 08:58:30.000000 plaso-20230311/plaso/storage/reader.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.319976 plaso-20230311/plaso/storage/redis/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:23.000000 plaso-20230311/plaso/storage/redis/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      913 2022-12-25 09:18:55.000000 plaso-20230311/plaso/storage/redis/reader.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17528 2023-01-07 09:50:35.000000 plaso-20230311/plaso/storage/redis/redis_store.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3988 2023-01-07 09:49:55.000000 plaso-20230311/plaso/storage/redis/writer.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.319976 plaso-20230311/plaso/storage/sqlite/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:23.000000 plaso-20230311/plaso/storage/sqlite/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      541 2023-01-07 11:08:44.000000 plaso-20230311/plaso/storage/sqlite/reader.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19776 2023-01-09 19:32:36.000000 plaso-20230311/plaso/storage/sqlite/sqlite_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4770 2023-01-07 09:49:55.000000 plaso-20230311/plaso/storage/sqlite/writer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1328 2022-11-21 19:43:23.000000 plaso-20230311/plaso/storage/time_range.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7028 2023-01-08 08:58:30.000000 plaso-20230311/plaso/storage/writer.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.252976 plaso-20230311/plaso.egg-info/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      698 2023-03-12 10:45:11.000000 plaso-20230311/plaso.egg-info/PKG-INFO
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)    40258 2023-03-12 10:45:14.000000 plaso-20230311/plaso.egg-info/SOURCES.txt
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        1 2023-03-12 10:45:11.000000 plaso-20230311/plaso.egg-info/dependency_links.txt
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        1 2021-02-06 07:38:13.000000 plaso-20230311/plaso.egg-info/not-zip-safe
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1294 2023-03-12 10:45:11.000000 plaso-20230311/plaso.egg-info/requires.txt
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        6 2023-03-12 10:45:11.000000 plaso-20230311/plaso.egg-info/top_level.txt
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      529 2022-09-18 11:21:00.000000 plaso-20230311/plaso.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1413 2023-03-12 10:42:34.000000 plaso-20230311/requirements.txt
--rwxrwxr-x   0 lordyesta  (1000) lordyesta  (1000)     1027 2021-06-03 04:45:37.000000 plaso-20230311/run_tests.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2189 2023-03-12 10:45:14.505977 plaso-20230311/setup.cfg
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     8223 2023-03-12 08:29:14.000000 plaso-20230311/setup.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      248 2023-01-07 09:49:55.000000 plaso-20230311/test_dependencies.ini
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       33 2023-03-12 08:28:07.000000 plaso-20230311/test_requirements.txt
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.320976 plaso-20230311/tests/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/__init__.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.321976 plaso-20230311/tests/analysis/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/analysis/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2732 2023-01-08 16:45:00.000000 plaso-20230311/tests/analysis/bloom.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1824 2022-12-25 09:18:55.000000 plaso-20230311/tests/analysis/browser_search.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6910 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/chrome_extension.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5091 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/hash_tagging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      649 2022-09-18 11:21:01.000000 plaso-20230311/tests/analysis/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2480 2022-12-25 09:18:55.000000 plaso-20230311/tests/analysis/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1766 2022-12-25 09:18:55.000000 plaso-20230311/tests/analysis/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4278 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/nsrlsvr.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2294 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/sessionize.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3241 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/tagging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7383 2023-01-07 09:49:55.000000 plaso-20230311/tests/analysis/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2553 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/unique_domains_visited.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4699 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/viper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3805 2023-01-08 12:31:37.000000 plaso-20230311/tests/analysis/virustotal.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.322976 plaso-20230311/tests/analyzers/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/analyzers/__init__.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.323976 plaso-20230311/tests/analyzers/hashers/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/analyzers/hashers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      764 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/hashers/entropy.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3680 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/hashers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      792 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/hashers/md5.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      834 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/hashers/sha1.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      913 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/hashers/sha256.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1669 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/hashers/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1661 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/hashing_analyzer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1049 2022-12-25 09:18:55.000000 plaso-20230311/tests/analyzers/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3269 2022-09-18 11:21:01.000000 plaso-20230311/tests/analyzers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1983 2023-01-07 09:49:55.000000 plaso-20230311/tests/analyzers/yara_analyzer.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.325976 plaso-20230311/tests/cli/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/cli/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13371 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/extraction_tool.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.330976 plaso-20230311/tests/cli/helpers/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/cli/helpers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2128 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/analysis_plugins.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2348 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/archives.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2676 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/artifact_definitions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3933 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/artifact_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2476 2023-01-11 17:57:01.000000 plaso-20230311/tests/cli/helpers/bloom_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1704 2023-01-07 09:50:02.000000 plaso-20230311/tests/cli/helpers/codepage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1700 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/data_location.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3739 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/date_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1658 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/dynamic_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4335 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/event_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2501 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/extraction.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2094 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/filter_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2649 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/hashers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      560 2022-09-18 11:21:01.000000 plaso-20230311/tests/cli/helpers/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2912 2022-09-18 11:21:01.000000 plaso-20230311/tests/cli/helpers/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2093 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/language.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3443 2022-09-18 11:21:01.000000 plaso-20230311/tests/cli/helpers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2763 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/helpers/nsrlsvr_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3627 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/opensearch_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4133 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/opensearch_ts_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2121 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/output_modules.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2477 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/parsers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2513 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/process_resources.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3864 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/profiling.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2258 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/sessionize_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2177 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/helpers/status_view.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2320 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/storage_format.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2725 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/tagging_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1947 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/temporary_directory.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1641 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1745 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/helpers/vfs_backend.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2428 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/viper_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2959 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/virustotal_analysis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3280 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/workers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2022 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/helpers/xlsx_output.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2550 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/helpers/yara_rules.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21706 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/image_export_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20654 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/log2timeline_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    30609 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/pinfo_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10483 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/psort_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15745 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/psteal_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7892 2023-01-07 09:49:55.000000 plaso-20230311/tests/cli/status_view.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    50309 2022-12-25 09:18:55.000000 plaso-20230311/tests/cli/storage_media_tool.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3392 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1023 2022-09-18 11:21:01.000000 plaso-20230311/tests/cli/time_slices.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10344 2023-01-07 09:50:35.000000 plaso-20230311/tests/cli/tool_options.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11524 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/tools.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6480 2022-09-18 11:26:13.000000 plaso-20230311/tests/cli/views.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.332976 plaso-20230311/tests/containers/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/containers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      753 2022-09-18 11:21:01.000000 plaso-20230311/tests/containers/analyzer_result.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8857 2023-01-08 08:58:30.000000 plaso-20230311/tests/containers/artifacts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1175 2022-12-25 09:18:55.000000 plaso-20230311/tests/containers/counts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1230 2022-09-18 11:21:01.000000 plaso-20230311/tests/containers/event_sources.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5713 2023-01-08 12:31:37.000000 plaso-20230311/tests/containers/events.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      603 2023-01-07 09:49:55.000000 plaso-20230311/tests/containers/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      861 2023-01-08 12:31:37.000000 plaso-20230311/tests/containers/plist_event.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      853 2022-12-25 09:18:55.000000 plaso-20230311/tests/containers/reports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5000 2023-01-08 08:58:30.000000 plaso-20230311/tests/containers/sessions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1829 2022-10-27 03:49:18.000000 plaso-20230311/tests/containers/tasks.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1927 2023-01-07 09:49:55.000000 plaso-20230311/tests/containers/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1882 2022-09-18 11:26:13.000000 plaso-20230311/tests/containers/warnings.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2513 2023-01-08 12:31:37.000000 plaso-20230311/tests/containers/windows_events.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.333976 plaso-20230311/tests/data/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230311/tests/data/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1164 2022-09-18 11:21:01.000000 plaso-20230311/tests/data/presets.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18796 2023-01-08 12:31:37.000000 plaso-20230311/tests/data/tag_linux.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5034 2023-01-08 12:31:37.000000 plaso-20230311/tests/data/tag_macos.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    26795 2023-01-08 12:31:37.000000 plaso-20230311/tests/data/tag_windows.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5207 2023-01-08 12:31:37.000000 plaso-20230311/tests/data/test_lib.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)    73231 2022-12-25 09:18:55.000000 plaso-20230311/tests/end-to-end.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.335976 plaso-20230311/tests/engine/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/engine/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13136 2022-09-18 11:26:13.000000 plaso-20230311/tests/engine/artifact_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3495 2023-01-07 09:50:35.000000 plaso-20230311/tests/engine/configurations.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5113 2022-12-25 09:18:55.000000 plaso-20230311/tests/engine/engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14933 2023-01-07 09:49:55.000000 plaso-20230311/tests/engine/extractors.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1321 2022-09-18 11:21:01.000000 plaso-20230311/tests/engine/filter_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      527 2022-09-18 11:21:01.000000 plaso-20230311/tests/engine/filters_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13044 2023-01-07 09:50:35.000000 plaso-20230311/tests/engine/knowledge_base.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5384 2022-09-18 11:21:01.000000 plaso-20230311/tests/engine/path_filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17353 2023-01-07 09:50:35.000000 plaso-20230311/tests/engine/path_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      796 2022-09-18 11:21:01.000000 plaso-20230311/tests/engine/process_info.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3457 2023-01-07 09:49:55.000000 plaso-20230311/tests/engine/processing_status.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6834 2022-12-25 09:18:55.000000 plaso-20230311/tests/engine/profilers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1139 2022-09-18 11:21:01.000000 plaso-20230311/tests/engine/tagging_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1292 2023-01-07 09:49:55.000000 plaso-20230311/tests/engine/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9539 2023-01-07 09:49:55.000000 plaso-20230311/tests/engine/timeliner.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25881 2023-01-08 08:58:30.000000 plaso-20230311/tests/engine/worker.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2455 2022-09-18 11:21:01.000000 plaso-20230311/tests/engine/yaml_filter_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2288 2023-01-07 09:49:55.000000 plaso-20230311/tests/engine/yaml_timeliner_file.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.336976 plaso-20230311/tests/filters/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/filters/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2168 2022-09-18 11:21:01.000000 plaso-20230311/tests/filters/event_filter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14058 2023-01-08 12:31:37.000000 plaso-20230311/tests/filters/expression_parser.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3233 2022-09-18 11:21:01.000000 plaso-20230311/tests/filters/expressions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14204 2022-09-18 11:21:01.000000 plaso-20230311/tests/filters/file_entry.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9666 2022-09-18 11:21:01.000000 plaso-20230311/tests/filters/filters.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8247 2023-01-07 09:49:55.000000 plaso-20230311/tests/filters/parser_filter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5276 2022-09-18 11:21:01.000000 plaso-20230311/tests/filters/path_filter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      555 2022-09-18 11:21:01.000000 plaso-20230311/tests/filters/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1516 2022-09-18 11:21:01.000000 plaso-20230311/tests/filters/value_types.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.338976 plaso-20230311/tests/formatters/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/formatters/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1560 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/chrome.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2602 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/chrome_preferences.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2365 2023-01-07 09:49:55.000000 plaso-20230311/tests/formatters/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2377 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/file_system.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1736 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/firefox.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      642 2022-09-18 11:26:13.000000 plaso-20230311/tests/formatters/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7643 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      507 2022-09-18 11:21:07.000000 plaso-20230311/tests/formatters/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2023 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/msiecf.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1249 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/shell_items.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1297 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2068 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/winlnk.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2779 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/winprefetch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      958 2022-12-25 09:18:55.000000 plaso-20230311/tests/formatters/winreg.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3363 2023-01-07 09:49:55.000000 plaso-20230311/tests/formatters/yaml_formatters_file.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.338976 plaso-20230311/tests/helpers/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230311/tests/helpers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      861 2022-09-18 11:26:13.000000 plaso-20230311/tests/helpers/language_tags.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.339976 plaso-20230311/tests/helpers/windows/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230311/tests/helpers/windows/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      702 2022-09-18 11:26:13.000000 plaso-20230311/tests/helpers/windows/known_folders.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1001 2022-09-18 11:26:13.000000 plaso-20230311/tests/helpers/windows/languages.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1066 2022-10-27 03:49:18.000000 plaso-20230311/tests/helpers/windows/resource_files.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      755 2022-09-18 11:26:13.000000 plaso-20230311/tests/helpers/windows/shell_folders.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.340976 plaso-20230311/tests/lib/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/lib/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1463 2022-09-18 11:21:01.000000 plaso-20230311/tests/lib/bufferlib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5865 2022-12-25 09:18:55.000000 plaso-20230311/tests/lib/dtfabric_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6772 2023-01-07 09:49:55.000000 plaso-20230311/tests/lib/line_reader_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1270 2022-09-18 11:21:01.000000 plaso-20230311/tests/lib/loggers.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1591 2022-09-18 11:21:01.000000 plaso-20230311/tests/lib/plist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      850 2022-09-18 11:21:01.000000 plaso-20230311/tests/lib/specification.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6483 2023-01-07 09:49:55.000000 plaso-20230311/tests/lib/yearless_helper.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.341977 plaso-20230311/tests/multi_process/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230311/tests/multi_process/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7146 2023-01-08 08:58:30.000000 plaso-20230311/tests/multi_process/analysis_engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4590 2022-12-25 09:18:55.000000 plaso-20230311/tests/multi_process/analysis_process.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1681 2022-09-18 11:26:13.000000 plaso-20230311/tests/multi_process/base_process.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      994 2022-09-18 11:26:13.000000 plaso-20230311/tests/multi_process/engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3382 2023-01-07 09:49:55.000000 plaso-20230311/tests/multi_process/extraction_engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7017 2023-01-07 09:49:55.000000 plaso-20230311/tests/multi_process/extraction_process.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13920 2023-01-08 12:31:37.000000 plaso-20230311/tests/multi_process/output_engine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    30387 2022-09-18 11:26:13.000000 plaso-20230311/tests/multi_process/task_manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1991 2022-12-25 09:18:55.000000 plaso-20230311/tests/multi_process/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5788 2022-09-18 11:26:13.000000 plaso-20230311/tests/multi_process/zeromq_queue.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.361976 plaso-20230311/tests/output/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/output/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10910 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/dynamic.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18475 2023-01-07 09:49:55.000000 plaso-20230311/tests/output/formatting_helper.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      723 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5676 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4108 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/json_line.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4996 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/json_out.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5814 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/kml.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10379 2023-01-08 12:31:37.000000 plaso-20230311/tests/output/l2t_csv.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4435 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4057 2023-01-07 09:49:55.000000 plaso-20230311/tests/output/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2478 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/null.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4250 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/opensearch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4347 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/opensearch_ts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4746 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/rawpy.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      463 2022-09-18 11:21:09.000000 plaso-20230311/tests/output/shared_dsv.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3766 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/shared_json.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6111 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/shared_opensearch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      820 2022-12-25 09:18:55.000000 plaso-20230311/tests/output/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1159 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/text_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10786 2023-01-07 09:50:35.000000 plaso-20230311/tests/output/tln.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2946 2022-12-25 09:18:55.000000 plaso-20230311/tests/output/winevt_rc.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6988 2023-01-08 07:20:43.000000 plaso-20230311/tests/output/xlsx.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.368976 plaso-20230311/tests/parsers/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/parsers/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1437 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/android_app_usage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14067 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/asl.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      914 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/bencode_parser.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.369976 plaso-20230311/tests/parsers/bencode_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/parsers/bencode_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      221 2022-09-18 11:21:01.000000 plaso-20230311/tests/parsers/bencode_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1438 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/bencode_plugins/transmission.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1554 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/bencode_plugins/utorrent.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3243 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/bodyfile.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2972 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/bsm.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1329 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/chrome_cache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3009 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/chrome_preferences.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.369976 plaso-20230311/tests/parsers/cookie_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/parsers/cookie_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4227 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/cookie_plugins/ganalytics.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1655 2022-09-18 11:26:13.000000 plaso-20230311/tests/parsers/cookie_plugins/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12879 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/cups_ipp.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3286 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/custom_destinations.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1951 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/czip.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.369976 plaso-20230311/tests/parsers/czip_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230311/tests/parsers/czip_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4700 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/czip_plugins/oxml.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2331 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/czip_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4257 2022-09-18 11:21:01.000000 plaso-20230311/tests/parsers/dsv_parser.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2813 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/esedb.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.370977 plaso-20230311/tests/parsers/esedb_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/parsers/esedb_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1561 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/esedb_plugins/file_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4025 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/esedb_plugins/msie_webcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2517 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/esedb_plugins/srum.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2439 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/esedb_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3495 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/esedb_plugins/user_access_logging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16135 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/filestat.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15463 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/firefox_cache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1233 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/fish_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3583 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/fseventsd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1161 2022-12-25 09:18:55.000000 plaso-20230311/tests/parsers/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1242 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2507 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/java_idx.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.371976 plaso-20230311/tests/parsers/jsonl_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-12-25 09:18:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1577 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/aws_cloudtrail_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2285 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/azure_activity_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2521 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/azure_application_gateway_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1742 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/docker_container_config.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1787 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/docker_container_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1708 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/docker_layer_config.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2351 2023-01-11 04:51:22.000000 plaso-20230311/tests/parsers/jsonl_plugins/gcp_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1863 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/ios_app_privacy.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1929 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/microsoft365_audit_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2405 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/jsonl_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2158 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/locate.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2217 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/macos_keychain.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10388 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2094 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/mcafeeav.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8644 2023-01-08 12:31:37.000000 plaso-20230311/tests/parsers/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5472 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/msiecf.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1653 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/networkminer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9408 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/ntfs.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3041 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/olecf.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.372976 plaso-20230311/tests/parsers/olecf_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/parsers/olecf_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5634 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/olecf_plugins/automatic_destinations.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1754 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/olecf_plugins/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3284 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/olecf_plugins/summary.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2415 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/olecf_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2557 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/opera.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6603 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/pe.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6622 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.374976 plaso-20230311/tests/parsers/plist_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/parsers/plist_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1424 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/airport.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1687 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/apple_account.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1582 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/bluetooth.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4000 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2133 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/install_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4674 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1441 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/ios_carplay.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1587 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/ipod.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1401 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/launchd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1966 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/macos_user.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1788 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/safari_downloads.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1448 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/safari_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1525 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/software_update.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1537 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/spotlight_searched_terms.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1553 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/spotlight_volume.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2880 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2074 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/plist_plugins/time_machine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1444 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/pls_recall.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4885 2022-12-10 18:42:49.000000 plaso-20230311/tests/parsers/presets.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3638 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/recycler.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1844 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/safari_cookies.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3392 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/spotlight_storedb.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5843 2023-01-07 09:50:35.000000 plaso-20230311/tests/parsers/sqlite.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.379976 plaso-20230311/tests/parsers/sqlite_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/parsers/sqlite_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1429 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/android_calls.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1488 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/android_hangouts.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1498 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/android_sms.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3288 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/android_tango.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3127 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/android_twitter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1506 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/android_webview.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1548 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/android_webviewcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1508 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/chrome_autofill.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3558 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/chrome_cookies.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1606 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/chrome_extension_activity.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9938 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/chrome_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1570 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/dropbox.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1635 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/firefox_cookies.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1705 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/firefox_downloads.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4569 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/firefox_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2104 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/gdrive.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1470 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/imessage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4089 2022-09-18 11:21:01.000000 plaso-20230311/tests/parsers/sqlite_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1442 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/ios_kik.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1964 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/ios_netusage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1326 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/ios_powerlog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1438 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/ios_screentime.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2560 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/ios_twitter.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1385 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/kodi.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1743 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/ls_quarantine.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1836 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/mackeeper_cache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1553 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/macos_appusage.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1705 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/macos_document_versions.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3212 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/macos_knowledgec.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1584 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/macos_notes.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1507 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/macos_notification_center.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1388 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/macos_tcc.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1454 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/safari.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3055 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/skype.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3834 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2084 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/windows_eventtranscript.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1921 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/windows_timeline.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1382 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/sqlite_plugins/zeitgeist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1577 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/symantec.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5652 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/systemd_journal.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10458 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3696 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_parser.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.383977 plaso-20230311/tests/parsers/text_plugins/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-12-25 09:18:55.000000 plaso-20230311/tests/parsers/text_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4085 2023-01-07 09:50:35.000000 plaso-20230311/tests/parsers/text_plugins/android_logcat.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4361 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/apache_access.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9005 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/apt_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2753 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/aws_elb_access.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3679 2023-01-07 09:50:35.000000 plaso-20230311/tests/parsers/text_plugins/bash_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3615 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/confluence_access.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1279 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/dpkg.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4960 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/gdrive_synclog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2670 2023-01-07 09:50:35.000000 plaso-20230311/tests/parsers/text_plugins/google_logging.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7023 2023-02-07 15:18:26.000000 plaso-20230311/tests/parsers/text_plugins/iis.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      577 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2171 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/ios_lockdownd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1393 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/ios_logd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1875 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/ios_sysdiag_log.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2344 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/macos_appfirewall.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2223 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/macos_securityd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3540 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/macos_wifi.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1912 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/popcontest.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3200 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/postgresql.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6578 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/santa.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3587 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/sccm.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2667 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/selinux.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2752 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/setupapi.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5804 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/skydrivelog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3058 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/snort_fastlog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1460 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/sophos_av.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21082 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/syslog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2596 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3674 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/viminfo.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1453 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/vsftpd.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1622 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/winfirewall.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1304 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/xchatlog.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3438 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/xchatscrollback.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2486 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/text_plugins/zsh_extended_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3154 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/trendmicroav.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2516 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/utmp.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1331 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/utmpx.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3461 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/windefender_history.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2550 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winevt.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5159 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winevtx.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2726 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winjob.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5471 2023-02-06 19:00:49.000000 plaso-20230311/tests/parsers/winlnk.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17955 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winprefetch.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6270 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_parser.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.387977 plaso-20230311/tests/parsers/winreg_plugins/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-05 07:02:50.000000 plaso-20230311/tests/parsers/winreg_plugins/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4787 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/amcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    27903 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/appcompatcache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3728 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/bagmru.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3738 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/bam.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2901 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/ccleaner.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3389 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/default.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7630 2022-09-18 11:26:13.000000 plaso-20230311/tests/parsers/winreg_plugins/interface.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8197 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/lfu.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2241 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/mountpoints.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8768 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/mrulist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15277 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/mrulistex.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16850 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/msie_zones.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6294 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/network_drives.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9248 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/networks.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4453 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/officemru.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4730 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/outlook.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5882 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/programscache.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7504 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/run.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2228 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/sam_users.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5914 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/services.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1986 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/shutdown.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2351 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/task_scheduler.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6199 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/terminal_server.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4832 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7387 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/timezone.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4268 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/typedurls.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1998 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/usb.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2384 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/usbstor.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4448 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/userassist.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6769 2023-01-08 12:31:37.000000 plaso-20230311/tests/parsers/winreg_plugins/windows_version.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12622 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/winlogon.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3200 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winreg_plugins/winrar.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1391 2023-01-07 09:49:55.000000 plaso-20230311/tests/parsers/winrestore.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.389976 plaso-20230311/tests/preprocessors/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/preprocessors/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2044 2022-12-25 09:18:55.000000 plaso-20230311/tests/preprocessors/generic.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      616 2022-09-18 11:21:01.000000 plaso-20230311/tests/preprocessors/init_imports.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16567 2022-12-25 09:18:55.000000 plaso-20230311/tests/preprocessors/linux.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8457 2022-12-25 09:18:55.000000 plaso-20230311/tests/preprocessors/macos.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2570 2022-09-18 11:21:01.000000 plaso-20230311/tests/preprocessors/manager.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      938 2022-09-18 11:26:13.000000 plaso-20230311/tests/preprocessors/mediator.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5825 2022-12-25 09:18:55.000000 plaso-20230311/tests/preprocessors/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    26720 2022-12-25 09:18:55.000000 plaso-20230311/tests/preprocessors/windows.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.389976 plaso-20230311/tests/serializer/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/serializer/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14353 2023-01-08 12:31:37.000000 plaso-20230311/tests/serializer/json_serializer.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.389976 plaso-20230311/tests/single_process/
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230311/tests/single_process/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3064 2023-01-07 09:49:55.000000 plaso-20230311/tests/single_process/extraction_engine.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.390977 plaso-20230311/tests/storage/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tests/storage/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1206 2022-09-18 11:26:13.000000 plaso-20230311/tests/storage/factory.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.390977 plaso-20230311/tests/storage/fake/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230311/tests/storage/fake/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2440 2022-09-18 11:26:13.000000 plaso-20230311/tests/storage/fake/event_heap.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4963 2022-12-25 09:18:55.000000 plaso-20230311/tests/storage/fake/writer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5045 2023-01-07 09:50:35.000000 plaso-20230311/tests/storage/reader.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.390977 plaso-20230311/tests/storage/redis/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230311/tests/storage/redis/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1537 2022-12-25 09:18:55.000000 plaso-20230311/tests/storage/redis/reader.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14595 2023-01-07 09:50:35.000000 plaso-20230311/tests/storage/redis/redis_store.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.391976 plaso-20230311/tests/storage/sqlite/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230311/tests/storage/sqlite/__init__.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      591 2022-09-18 11:26:13.000000 plaso-20230311/tests/storage/sqlite/reader.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19149 2023-01-07 09:50:35.000000 plaso-20230311/tests/storage/sqlite/sqlite_file.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5827 2022-12-25 09:18:55.000000 plaso-20230311/tests/storage/sqlite/writer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2808 2023-01-08 12:31:37.000000 plaso-20230311/tests/storage/test_lib.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1229 2023-01-07 09:50:35.000000 plaso-20230311/tests/storage/writer.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6574 2022-09-18 11:26:13.000000 plaso-20230311/tests/test_lib.py
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.409977 plaso-20230311/tools/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/tools/__init__.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2317 2022-09-18 11:21:01.000000 plaso-20230311/tools/image_export.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2419 2022-12-25 09:18:55.000000 plaso-20230311/tools/log2timeline.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2016 2022-09-18 11:26:13.000000 plaso-20230311/tools/pinfo.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2410 2022-12-25 09:18:55.000000 plaso-20230311/tools/psort.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2629 2022-12-25 09:18:55.000000 plaso-20230311/tools/psteal.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1472 2023-03-12 08:28:07.000000 plaso-20230311/tox.ini
-drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-03-12 10:45:14.503977 plaso-20230311/utils/
--rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230311/utils/__init__.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      700 2022-12-25 09:18:55.000000 plaso-20230311/utils/build_docker.sh
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      629 2023-03-12 08:28:07.000000 plaso-20230311/utils/check_dependencies.py
--rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11583 2023-03-12 08:28:07.000000 plaso-20230311/utils/dependencies.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     3089 2022-09-18 11:21:01.000000 plaso-20230311/utils/export_event_data.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)    10536 2023-01-07 09:49:55.000000 plaso-20230311/utils/export_supported_formats.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1597 2022-09-18 11:26:13.000000 plaso-20230311/utils/generate_windows_time_zones.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     3438 2022-09-18 11:26:13.000000 plaso-20230311/utils/plot_cpu_usage.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1983 2022-09-18 11:21:01.000000 plaso-20230311/utils/plot_memory_usage.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2620 2022-09-18 11:21:01.000000 plaso-20230311/utils/plot_storage.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2070 2022-09-18 11:21:01.000000 plaso-20230311/utils/plot_task_queue.py
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     6272 2022-09-18 11:21:01.000000 plaso-20230311/utils/plot_tasks.py
--rwxrwxr-x   0 lordyesta  (1000) lordyesta  (1000)      404 2021-02-05 09:03:04.000000 plaso-20230311/utils/update_authors.sh
--rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      977 2022-09-18 11:21:01.000000 plaso-20230311/utils/update_release.sh
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.164823 plaso-20230717/
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.122822 plaso-20230717/.github/
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.150822 plaso-20230717/.github/ISSUE_TEMPLATE/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1826 2023-01-31 06:18:39.000000 plaso-20230717/.github/ISSUE_TEMPLATE/problem-report.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1495 2022-12-25 09:18:55.000000 plaso-20230717/.github/ISSUE_TEMPLATE/release.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      870 2023-01-07 09:50:35.000000 plaso-20230717/.github/PULL_REQUEST_TEMPLATE.md
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.198822 plaso-20230717/.github/workflows/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4638 2023-07-17 03:17:43.000000 plaso-20230717/.github/workflows/test_docker.yml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2447 2023-07-16 11:46:11.000000 plaso-20230717/.github/workflows/test_docs.yml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7314 2023-07-16 11:46:11.000000 plaso-20230717/.github/workflows/test_tox.yml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    23262 2023-07-16 11:46:11.000000 plaso-20230717/.pylintrc
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      149 2022-12-25 09:18:55.000000 plaso-20230717/.yamllint.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3739 2022-12-25 09:18:55.000000 plaso-20230717/ACKNOWLEDGEMENTS
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     2171 2021-06-03 04:45:37.000000 plaso-20230717/AUTHORS
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1515 2021-06-03 04:45:37.000000 plaso-20230717/CONTRIBUTING.md
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)    11358 2021-02-05 09:03:02.000000 plaso-20230717/LICENSE
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      681 2022-12-25 09:18:55.000000 plaso-20230717/MANIFEST.in
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      601 2022-12-25 09:18:55.000000 plaso-20230717/MANIFEST.test_data.in
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      698 2023-07-23 05:03:42.164823 plaso-20230717/PKG-INFO
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1666 2022-09-18 11:21:00.000000 plaso-20230717/README
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1799 2022-09-18 11:21:00.000000 plaso-20230717/README.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1230 2023-07-16 11:46:11.000000 plaso-20230717/appveyor.yml
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.199822 plaso-20230717/config/
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.199822 plaso-20230717/config/appveyor/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1376 2023-07-16 11:46:39.000000 plaso-20230717/config/appveyor/install.ps1
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      125 2023-07-16 11:46:11.000000 plaso-20230717/config/appveyor/install.sh
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      620 2023-07-16 11:46:11.000000 plaso-20230717/config/appveyor/runtests.sh
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.199822 plaso-20230717/config/deployment/
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      258 2022-12-25 09:18:55.000000 plaso-20230717/config/deployment/build_docker.sh
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      533 2023-01-07 09:49:55.000000 plaso-20230717/config/deployment/fedora36.Dockerfile
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      990 2022-12-25 09:18:55.000000 plaso-20230717/config/deployment/ubuntu20.04.Dockerfile
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.200822 plaso-20230717/config/docker/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1352 2023-01-07 09:49:55.000000 plaso-20230717/config/docker/Dockerfile
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      445 2022-09-18 11:26:13.000000 plaso-20230717/config/docker/Windows.Dockerfile
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1071 2022-09-18 11:21:00.000000 plaso-20230717/config/docker/plaso-switch.sh
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.201822 plaso-20230717/config/dpkg/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      168 2023-07-17 15:31:13.000000 plaso-20230717/config/dpkg/changelog
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       48 2021-06-03 04:45:37.000000 plaso-20230717/config/dpkg/clean
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        2 2023-07-16 11:46:11.000000 plaso-20230717/config/dpkg/compat
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3180 2023-07-17 03:17:43.000000 plaso-20230717/config/dpkg/control
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      948 2022-12-25 09:18:55.000000 plaso-20230717/config/dpkg/copyright
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       17 2021-06-03 04:45:37.000000 plaso-20230717/config/dpkg/plaso-data.dirs
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       23 2021-06-03 04:45:37.000000 plaso-20230717/config/dpkg/plaso-data.install
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        8 2021-06-03 04:45:37.000000 plaso-20230717/config/dpkg/plaso-tools.install
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      275 2021-06-03 04:45:37.000000 plaso-20230717/config/dpkg/python3-plaso.install
+-rwxrwxr-x   0 lordyesta  (1000) lordyesta  (1000)      122 2023-07-16 11:46:11.000000 plaso-20230717/config/dpkg/rules
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.201822 plaso-20230717/config/dpkg/source/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       12 2021-06-03 04:45:37.000000 plaso-20230717/config/dpkg/source/format
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11049 2023-06-21 05:27:32.000000 plaso-20230717/config/end-to-end.ini
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.201822 plaso-20230717/config/end_to_end/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      981 2022-12-25 09:18:55.000000 plaso-20230717/config/end_to_end/extract_and_output.Dockerfile
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     3514 2022-12-25 09:18:55.000000 plaso-20230717/config/end_to_end/run_tests_with_docker.sh
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:40.806822 plaso-20230717/config/jenkins/
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.204822 plaso-20230717/config/jenkins/greendale/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      373 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/acserver-archive-cpio.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      371 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/acserver-archive-tgz.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/acserver-archive-zip.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      356 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/acserver-mounted.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      388 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/acserver-with_archives.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      341 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/acserver.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      356 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/bchang-laptop.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      359 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/dc1-greendale3.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      359 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/dc2-greendale2.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      386 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/dean_mac-browserhistory.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      393 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/dean_mac-with_archives.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      333 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/dean_mac.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/dean_macbook.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      170 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/output_opensearch.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      114 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/output_opensearch_ts.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      149 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/psort-studentpc1-nsrlsvr.ini
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      173 2022-07-12 16:16:36.000000 plaso-20230717/config/jenkins/greendale/psort-studentpc1-sessionize-unique-domains.ini
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      165 2022-07-12 16:16:36.000000 plaso-20230717/config/jenkins/greendale/psort-studentpc1-tagging.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      409 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/registrar-with_archives.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      362 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/greendale/registrar.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      414 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/student-pc1-browserhistory.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      386 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/student-pc1.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      399 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/studentpc1-redis.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      350 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/studentpc10.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      364 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/greendale/studentpc8.ini
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.205822 plaso-20230717/config/jenkins/linux/
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1942 2023-07-16 11:46:11.000000 plaso-20230717/config/jenkins/linux/run_end_to_end_tests.sh
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.205822 plaso-20230717/config/jenkins/other/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      354 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/other/4dell_latitude.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      344 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/other/chromiumos.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      345 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/other/coreos.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      329 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/other/schardt.ini
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.207822 plaso-20230717/config/jenkins/sans/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      389 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/dade_timemachine.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      371 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/dademurphy.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/sans/drfalken.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      422 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/eugenebelford_ellingsoncorp.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      365 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/file.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      361 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/ftp.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      368 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/katelibby.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      419 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/margowallace_ellingsoncorp.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      369 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/rd-04.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      391 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/sans/win2008R2-controller.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      382 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/sans/win7-32-nromanoff.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      370 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/sans/win7-64-nfury.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      377 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/wkstn-01.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      377 2022-12-25 09:18:55.000000 plaso-20230717/config/jenkins/sans/wkstn-05.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      361 2022-09-18 11:21:00.000000 plaso-20230717/config/jenkins/sans/xp-tdungan.ini
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.207822 plaso-20230717/config/linux/
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     6387 2023-07-16 11:46:53.000000 plaso-20230717/config/linux/gift_copr_install.sh
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1578 2022-09-18 11:26:13.000000 plaso-20230717/config/linux/ubuntu_install_nsrlsvr.sh
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      753 2022-12-25 09:18:55.000000 plaso-20230717/config/linux/ubuntu_install_opensearch.sh
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     6245 2023-07-17 03:17:43.000000 plaso-20230717/config/linux/ubuntu_install_plaso.sh
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     2680 2021-02-05 09:03:02.000000 plaso-20230717/config/logo.jpg
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.207822 plaso-20230717/config/pylint/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5840 2023-05-11 04:08:21.000000 plaso-20230717/config/pylint/spelling-private-dict
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.208822 plaso-20230717/config/tests/
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2405 2022-09-18 11:26:13.000000 plaso-20230717/config/tests/generate_test_files.sh
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.209822 plaso-20230717/data/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      119 2022-12-25 09:18:55.000000 plaso-20230717/data/filter_no_winsxs.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4085 2022-12-25 09:18:55.000000 plaso-20230717/data/filter_windows.txt
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5298 2023-03-27 03:44:12.000000 plaso-20230717/data/filter_windows.yaml
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.220822 plaso-20230717/data/formatters/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4800 2023-01-07 09:49:55.000000 plaso-20230717/data/formatters/android.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7640 2023-01-07 09:49:55.000000 plaso-20230717/data/formatters/antivirus.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17131 2023-06-18 13:42:06.000000 plaso-20230717/data/formatters/browser.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17584 2023-01-07 09:49:55.000000 plaso-20230717/data/formatters/bsm.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    24477 2023-06-19 16:09:41.000000 plaso-20230717/data/formatters/generic.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5988 2023-06-18 13:42:06.000000 plaso-20230717/data/formatters/ios.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2193 2023-06-18 13:42:06.000000 plaso-20230717/data/formatters/linux.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12579 2023-06-18 13:42:06.000000 plaso-20230717/data/formatters/macos.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    24437 2023-06-18 13:42:30.000000 plaso-20230717/data/formatters/windows.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1796 2022-12-25 09:18:55.000000 plaso-20230717/data/opensearch.mappings
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       80 2021-06-03 04:45:37.000000 plaso-20230717/data/plaso-data.README
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3779 2023-06-18 13:42:06.000000 plaso-20230717/data/presets.yaml
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1027 2021-06-03 04:45:37.000000 plaso-20230717/data/signatures.conf
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4704 2023-01-07 09:49:55.000000 plaso-20230717/data/tag_linux.txt
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1043 2023-01-07 09:49:55.000000 plaso-20230717/data/tag_macos.txt
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7937 2023-01-08 07:01:39.000000 plaso-20230717/data/tag_windows.txt
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    43533 2023-06-18 13:42:06.000000 plaso-20230717/data/timeliner.yaml
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)  6875136 2021-06-03 04:45:37.000000 plaso-20230717/data/winevt-rc.db
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10203 2023-07-17 03:17:43.000000 plaso-20230717/dependencies.ini
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.238822 plaso-20230717/docs/
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.238822 plaso-20230717/docs/_build/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        0 2022-11-21 19:42:41.000000 plaso-20230717/docs/_build/.gitkeep
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5638 2023-07-16 11:46:16.000000 plaso-20230717/docs/conf.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1097 2022-12-25 09:18:55.000000 plaso-20230717/docs/index.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      115 2023-07-16 11:46:16.000000 plaso-20230717/docs/requirements.txt
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.256822 plaso-20230717/docs/sources/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10060 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/Supported-formats.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12839 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/Troubleshooting.md
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.422822 plaso-20230717/docs/sources/api/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        0 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/.gitkeep
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       52 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/modules.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2824 2023-01-12 02:25:22.000000 plaso-20230717/docs/sources/api/plaso.analysis.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1289 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.analyzers.hashers.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1116 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.analyzers.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6420 2023-01-12 02:25:22.000000 plaso-20230717/docs/sources/api/plaso.cli.helpers.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2425 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.cli.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2238 2023-01-12 02:25:22.000000 plaso-20230717/docs/sources/api/plaso.containers.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2982 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/api/plaso.engine.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1670 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.filters.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2715 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/api/plaso.formatters.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      370 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/api/plaso.helpers.macos.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      461 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/api/plaso.helpers.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1380 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/api/plaso.helpers.windows.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1878 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/api/plaso.lib.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3214 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/api/plaso.multi_process.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2773 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.multi_processing.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3418 2023-01-12 02:25:22.000000 plaso-20230717/docs/sources/api/plaso.output.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      865 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.parsers.bencode_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      844 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.parsers.cookie_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      609 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.parsers.czip_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1283 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/api/plaso.parsers.esedb_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2555 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/api/plaso.parsers.jsonl_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1066 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.parsers.olecf_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3855 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/api/plaso.parsers.plist_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9635 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/api/plaso.parsers.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      393 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.parsers.shared.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8580 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/api/plaso.parsers.sqlite_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      814 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.parsers.syslog_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7238 2023-04-02 18:49:01.000000 plaso-20230717/docs/sources/api/plaso.parsers.text_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6566 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.parsers.winreg_plugins.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1557 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/api/plaso.preprocessors.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      653 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      539 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/api/plaso.serializer.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      415 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.single_process.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      720 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.storage.fake.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      721 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.storage.redis.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1236 2023-04-02 18:49:01.000000 plaso-20230717/docs/sources/api/plaso.storage.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      733 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.storage.sqlite.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      153 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.unix.rst
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      156 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/api/plaso.winnt.rst
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.643823 plaso-20230717/docs/sources/developer/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4733 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/developer/Developers-Guide.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      871 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/developer/Developing-Fedora.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      910 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/developer/Developing-MacOS.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1868 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/developer/Developing-Ubuntu.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2072 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/developer/Developing-Virtualenv.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2016 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/developer/Developing-Windows.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4737 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/developer/Development-Dependencies.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2275 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/developer/How-to-write-a-SQLite-plugin.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6542 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/developer/How-to-write-a-parser.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1210 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/developer/How-to-write-a-tagging-rule.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1272 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/developer/How-to-write-an-analysis-plugin.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1342 2023-01-07 09:50:35.000000 plaso-20230717/docs/sources/developer/How-to-write-an-output-module.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5071 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/developer/Internals.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      258 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/developer/Packaging-with-docker.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2470 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/developer/Packaging-with-pyinstaller.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2319 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/developer/Profiling.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2257 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/developer/Style-guide.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1968 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/developer/Testing.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      502 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/developer/index.rst
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.821823 plaso-20230717/docs/sources/user/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1781 2023-01-08 16:45:00.000000 plaso-20230717/docs/sources/user/Analysis-plugin-bloom.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1540 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-browser-search.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      713 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-chrome-extension.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1264 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-nsrlsvr.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      597 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-sessionize.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1125 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-tagging.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      842 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-unique-domains-visited.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      997 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-viper.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1438 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Analysis-plugin-virustotal.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      950 2023-01-08 16:45:00.000000 plaso-20230717/docs/sources/user/Analysis-plugins.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2935 2023-06-18 13:42:06.000000 plaso-20230717/docs/sources/user/Collection-Filters.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      524 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/user/Creating-a-timeline.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4698 2023-01-08 12:31:37.000000 plaso-20230717/docs/sources/user/Event-filters.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1714 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Feature-requests-and-bug-reports.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      504 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Fedora-Packaged-Release.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2500 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Getting-started.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      670 2022-11-21 19:42:42.000000 plaso-20230717/docs/sources/user/Installation-Problems.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3423 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Installing-with-docker.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12400 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Log2Timeline-Perl-(Legacy).md
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       91 2022-11-21 19:42:42.000000 plaso-20230717/docs/sources/user/MacOS-Packaged-Release.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3916 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/user/MacOS-Source-Release.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11445 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/user/Output-and-formatting.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4067 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Output-format-l2tcsv.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17058 2023-07-17 04:23:52.000000 plaso-20230717/docs/sources/user/Parsers-and-plugins.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      143 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/user/Release-process.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1878 2023-02-01 06:26:58.000000 plaso-20230717/docs/sources/user/Releases-and-roadmap.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7691 2023-07-08 05:08:20.000000 plaso-20230717/docs/sources/user/Scribbles-about-events.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2112 2022-11-21 19:42:42.000000 plaso-20230717/docs/sources/user/Tagging-Rules.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      609 2023-01-07 09:49:55.000000 plaso-20230717/docs/sources/user/Tips-and-Tricks.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5886 2022-11-21 19:42:42.000000 plaso-20230717/docs/sources/user/Troubleshooting-installation-issues.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      844 2023-01-07 09:50:35.000000 plaso-20230717/docs/sources/user/Ubuntu-Packaged-Release.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3296 2022-11-21 19:42:42.000000 plaso-20230717/docs/sources/user/Users-Guide.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2748 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Using-image_export.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8092 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Using-log2timeline.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5287 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/user/Using-pinfo.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21784 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/Using-psort.md
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1507 2022-11-21 19:42:41.000000 plaso-20230717/docs/sources/user/Using-psteal.md
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       91 2022-11-21 19:42:42.000000 plaso-20230717/docs/sources/user/Windows-Packaged-Release.md
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      494 2022-12-25 09:18:55.000000 plaso-20230717/docs/sources/user/index.rst
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.822823 plaso-20230717/plaso/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      296 2023-07-17 15:31:13.000000 plaso-20230717/plaso/__init__.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.837823 plaso-20230717/plaso/analysis/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      518 2023-01-08 16:45:00.000000 plaso-20230717/plaso/analysis/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4096 2023-01-08 16:45:00.000000 plaso-20230717/plaso/analysis/bloom.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9546 2022-12-25 09:18:55.000000 plaso-20230717/plaso/analysis/browser_search.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5964 2023-06-18 13:42:06.000000 plaso-20230717/plaso/analysis/chrome_extension.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      413 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analysis/definitions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8890 2023-06-18 13:42:06.000000 plaso-20230717/plaso/analysis/hash_tagging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2952 2022-12-25 09:18:55.000000 plaso-20230717/plaso/analysis/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      325 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analysis/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4073 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analysis/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5525 2023-04-03 15:50:34.000000 plaso-20230717/plaso/analysis/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4921 2023-01-07 09:49:55.000000 plaso-20230717/plaso/analysis/nsrlsvr.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2099 2022-12-25 09:18:55.000000 plaso-20230717/plaso/analysis/sessionize.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2057 2022-12-25 09:18:55.000000 plaso-20230717/plaso/analysis/tagging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1547 2022-12-25 09:18:55.000000 plaso-20230717/plaso/analysis/test_memory.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1928 2022-12-25 09:18:55.000000 plaso-20230717/plaso/analysis/unique_domains_visited.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4503 2023-01-07 09:49:55.000000 plaso-20230717/plaso/analysis/viper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4479 2023-01-07 09:49:55.000000 plaso-20230717/plaso/analysis/virustotal.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.838823 plaso-20230717/plaso/analyzers/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      176 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/__init__.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.839823 plaso-20230717/plaso/analyzers/hashers/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      255 2022-12-25 09:18:55.000000 plaso-20230717/plaso/analyzers/hashers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1865 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/hashers/entropy.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      962 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/hashers/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4483 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/hashers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1239 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/hashers/md5.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1254 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/hashers/sha1.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1280 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/hashers/sha256.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2636 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/hashing_analyzer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      926 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      327 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3480 2022-11-21 19:43:24.000000 plaso-20230717/plaso/analyzers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2236 2023-01-07 09:49:55.000000 plaso-20230717/plaso/analyzers/yara_analyzer.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.841823 plaso-20230717/plaso/cli/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5168 2023-04-03 15:50:34.000000 plaso-20230717/plaso/cli/analysis_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    32163 2023-07-17 15:31:13.000000 plaso-20230717/plaso/cli/extraction_tool.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.846823 plaso-20230717/plaso/cli/helpers/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1540 2023-06-18 14:11:18.000000 plaso-20230717/plaso/cli/helpers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2895 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/analysis_plugins.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2715 2023-01-07 09:49:55.000000 plaso-20230717/plaso/cli/helpers/archives.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6125 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/artifact_definitions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4004 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/artifact_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3538 2023-01-11 17:57:01.000000 plaso-20230717/plaso/cli/helpers/bloom_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1830 2023-01-07 09:50:02.000000 plaso-20230717/plaso/cli/helpers/codepage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3801 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/data_location.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3970 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/date_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2043 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/dynamic_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5904 2023-03-25 10:51:05.000000 plaso-20230717/plaso/cli/helpers/event_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2938 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/extraction.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2617 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/filter_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2925 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/hashers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3800 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2413 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/language.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3992 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3866 2023-01-07 09:49:55.000000 plaso-20230717/plaso/cli/helpers/nsrlsvr_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7280 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/opensearch_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2464 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/opensearch_ts_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3181 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/output_modules.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2498 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/parsers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2426 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/process_resources.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4596 2023-01-07 09:50:35.000000 plaso-20230717/plaso/cli/helpers/profiling.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2206 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/sessionize_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3122 2023-01-07 09:49:55.000000 plaso-20230717/plaso/cli/helpers/status_view.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3469 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/storage_format.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2822 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/tagging_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2137 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/temporary_directory.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1928 2023-01-07 09:49:55.000000 plaso-20230717/plaso/cli/helpers/vfs_backend.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4010 2023-01-07 09:49:55.000000 plaso-20230717/plaso/cli/helpers/viper_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3434 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/virustotal_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3704 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/workers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2759 2022-12-25 09:18:55.000000 plaso-20230717/plaso/cli/helpers/xlsx_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2618 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/helpers/yara_rules.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    30005 2023-07-18 03:09:38.000000 plaso-20230717/plaso/cli/image_export_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12835 2023-01-07 09:50:35.000000 plaso-20230717/plaso/cli/log2timeline_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      315 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    62593 2023-06-24 17:48:27.000000 plaso-20230717/plaso/cli/pinfo_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19084 2023-06-18 17:14:42.000000 plaso-20230717/plaso/cli/psort_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13823 2023-06-18 17:14:42.000000 plaso-20230717/plaso/cli/psteal_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22810 2023-01-07 09:49:55.000000 plaso-20230717/plaso/cli/status_view.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    24005 2023-04-29 12:23:04.000000 plaso-20230717/plaso/cli/storage_media_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1303 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/time_slices.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14352 2023-06-18 17:14:42.000000 plaso-20230717/plaso/cli/tool_options.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19202 2023-01-07 09:49:55.000000 plaso-20230717/plaso/cli/tools.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11522 2022-11-21 19:43:22.000000 plaso-20230717/plaso/cli/views.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.848823 plaso-20230717/plaso/containers/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      807 2023-01-07 09:49:55.000000 plaso-20230717/plaso/containers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2425 2023-01-07 09:50:35.000000 plaso-20230717/plaso/containers/analysis_results.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      983 2023-01-07 09:50:35.000000 plaso-20230717/plaso/containers/analyzer_result.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    30121 2023-06-18 13:42:06.000000 plaso-20230717/plaso/containers/artifacts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1749 2023-01-07 09:50:35.000000 plaso-20230717/plaso/containers/counts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1839 2023-01-07 09:50:35.000000 plaso-20230717/plaso/containers/event_sources.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14186 2023-01-08 12:31:37.000000 plaso-20230717/plaso/containers/events.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      639 2023-01-07 09:49:55.000000 plaso-20230717/plaso/containers/plist_event.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1671 2023-01-07 09:50:35.000000 plaso-20230717/plaso/containers/reports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12585 2023-06-18 13:42:06.000000 plaso-20230717/plaso/containers/sessions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4021 2023-01-07 09:50:35.000000 plaso-20230717/plaso/containers/tasks.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5969 2023-01-07 09:50:35.000000 plaso-20230717/plaso/containers/warnings.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4347 2023-03-13 05:42:44.000000 plaso-20230717/plaso/containers/windows_events.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8970 2023-07-17 03:17:43.000000 plaso-20230717/plaso/dependencies.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.850823 plaso-20230717/plaso/engine/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230717/plaso/engine/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10719 2023-07-17 04:18:48.000000 plaso-20230717/plaso/engine/artifact_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8669 2023-06-18 17:14:42.000000 plaso-20230717/plaso/engine/configurations.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14714 2023-07-17 15:31:13.000000 plaso-20230717/plaso/engine/engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20469 2023-06-18 13:42:06.000000 plaso-20230717/plaso/engine/extractors.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1596 2022-11-21 19:43:24.000000 plaso-20230717/plaso/engine/filter_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7014 2023-04-02 18:49:01.000000 plaso-20230717/plaso/engine/knowledge_base.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      321 2022-11-21 19:43:24.000000 plaso-20230717/plaso/engine/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4312 2023-06-18 13:42:06.000000 plaso-20230717/plaso/engine/path_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13795 2023-07-17 04:16:51.000000 plaso-20230717/plaso/engine/path_helper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1156 2022-11-21 19:43:24.000000 plaso-20230717/plaso/engine/process_info.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21367 2023-01-07 09:49:55.000000 plaso-20230717/plaso/engine/processing_status.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7412 2022-12-25 09:18:55.000000 plaso-20230717/plaso/engine/profilers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2373 2022-11-21 19:43:24.000000 plaso-20230717/plaso/engine/tagging_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14647 2023-06-18 13:42:06.000000 plaso-20230717/plaso/engine/timeliner.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    38253 2023-06-18 13:42:06.000000 plaso-20230717/plaso/engine/worker.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3511 2023-04-29 12:23:02.000000 plaso-20230717/plaso/engine/yaml_filter_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3711 2023-01-07 09:49:55.000000 plaso-20230717/plaso/engine/yaml_timeliner_file.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.851823 plaso-20230717/plaso/filters/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:22.000000 plaso-20230717/plaso/filters/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1364 2022-11-21 19:43:22.000000 plaso-20230717/plaso/filters/event_filter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    24528 2022-11-21 19:43:22.000000 plaso-20230717/plaso/filters/expression_parser.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7105 2022-11-21 19:43:22.000000 plaso-20230717/plaso/filters/expressions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12347 2022-11-21 19:43:22.000000 plaso-20230717/plaso/filters/file_entry.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17336 2023-06-18 13:42:06.000000 plaso-20230717/plaso/filters/filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      323 2022-11-21 19:43:22.000000 plaso-20230717/plaso/filters/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10167 2023-01-07 09:49:55.000000 plaso-20230717/plaso/filters/parser_filter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22284 2022-11-21 19:43:22.000000 plaso-20230717/plaso/filters/path_filter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1225 2023-05-06 07:54:02.000000 plaso-20230717/plaso/filters/value_types.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.853823 plaso-20230717/plaso/formatters/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      478 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1155 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/chrome.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2206 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/chrome_preferences.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2321 2023-01-08 12:31:37.000000 plaso-20230717/plaso/formatters/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2139 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/file_system.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1545 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/firefox.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20292 2023-01-08 12:31:37.000000 plaso-20230717/plaso/formatters/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      329 2022-11-21 19:43:22.000000 plaso-20230717/plaso/formatters/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1915 2022-11-21 19:43:22.000000 plaso-20230717/plaso/formatters/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1607 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/msiecf.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      878 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/shell_items.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2333 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/winevt.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1181 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/winlnk.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2221 2022-12-25 09:18:55.000000 plaso-20230717/plaso/formatters/winprefetch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1026 2023-03-13 05:42:44.000000 plaso-20230717/plaso/formatters/winreg.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10117 2023-03-25 12:51:33.000000 plaso-20230717/plaso/formatters/yaml_formatters_file.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.854823 plaso-20230717/plaso/helpers/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230717/plaso/helpers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14383 2022-12-25 09:18:55.000000 plaso-20230717/plaso/helpers/language_tags.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.854823 plaso-20230717/plaso/helpers/macos/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)        0 2023-06-18 13:42:06.000000 plaso-20230717/plaso/helpers/macos/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4661 2023-06-18 13:42:06.000000 plaso-20230717/plaso/helpers/macos/darwin.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.855823 plaso-20230717/plaso/helpers/windows/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230717/plaso/helpers/windows/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3276 2022-12-25 09:18:55.000000 plaso-20230717/plaso/helpers/windows/eventlog_providers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9071 2022-11-21 19:43:24.000000 plaso-20230717/plaso/helpers/windows/known_folders.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9663 2022-11-21 19:43:24.000000 plaso-20230717/plaso/helpers/windows/languages.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2148 2022-11-21 19:43:24.000000 plaso-20230717/plaso/helpers/windows/resource_files.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13530 2022-11-21 19:43:24.000000 plaso-20230717/plaso/helpers/windows/shell_folders.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7428 2022-11-21 19:43:24.000000 plaso-20230717/plaso/helpers/windows/time_zones.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.856823 plaso-20230717/plaso/lib/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230717/plaso/lib/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1605 2022-11-21 19:43:24.000000 plaso-20230717/plaso/lib/bufferlib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1542 2023-01-07 09:49:55.000000 plaso-20230717/plaso/lib/cookie_plugins_helper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      711 2022-11-21 19:43:24.000000 plaso-20230717/plaso/lib/decorators.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5725 2023-07-17 03:17:43.000000 plaso-20230717/plaso/lib/definitions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8577 2023-05-18 17:45:55.000000 plaso-20230717/plaso/lib/dtfabric_helper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2329 2023-06-18 17:14:42.000000 plaso-20230717/plaso/lib/errors.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6009 2022-11-21 19:43:24.000000 plaso-20230717/plaso/lib/line_reader_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2234 2022-11-21 19:43:24.000000 plaso-20230717/plaso/lib/loggers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1513 2022-11-21 19:43:24.000000 plaso-20230717/plaso/lib/plist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5388 2022-11-21 19:43:24.000000 plaso-20230717/plaso/lib/specification.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4765 2023-01-07 09:49:55.000000 plaso-20230717/plaso/lib/yearless_helper.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.858823 plaso-20230717/plaso/multi_process/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230717/plaso/multi_process/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25022 2023-04-03 15:50:34.000000 plaso-20230717/plaso/multi_process/analysis_engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8996 2023-04-03 15:50:34.000000 plaso-20230717/plaso/multi_process/analysis_process.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11068 2022-12-25 09:18:55.000000 plaso-20230717/plaso/multi_process/base_process.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14345 2023-06-18 13:42:07.000000 plaso-20230717/plaso/multi_process/engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    43397 2023-07-17 15:31:13.000000 plaso-20230717/plaso/multi_process/extraction_engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13077 2023-06-18 13:42:07.000000 plaso-20230717/plaso/multi_process/extraction_process.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      338 2022-11-21 19:43:24.000000 plaso-20230717/plaso/multi_process/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4523 2023-01-07 09:49:55.000000 plaso-20230717/plaso/multi_process/merge_helpers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18898 2023-06-18 17:14:42.000000 plaso-20230717/plaso/multi_process/output_engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1342 2022-11-21 19:43:24.000000 plaso-20230717/plaso/multi_process/plaso_queue.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4293 2022-11-21 19:43:24.000000 plaso-20230717/plaso/multi_process/plaso_xmlrpc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1415 2022-11-21 19:43:24.000000 plaso-20230717/plaso/multi_process/rpc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13232 2023-04-16 05:14:44.000000 plaso-20230717/plaso/multi_process/task_engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20463 2023-06-18 13:42:07.000000 plaso-20230717/plaso/multi_process/task_manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4454 2022-12-25 09:18:55.000000 plaso-20230717/plaso/multi_process/task_process.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25702 2023-06-18 13:42:07.000000 plaso-20230717/plaso/multi_process/zeromq_queue.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.861823 plaso-20230717/plaso/output/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      581 2022-12-25 09:18:55.000000 plaso-20230717/plaso/output/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5633 2023-04-03 15:50:34.000000 plaso-20230717/plaso/output/dynamic.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20622 2023-06-18 17:14:42.000000 plaso-20230717/plaso/output/formatting_helper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4772 2023-06-18 17:14:42.000000 plaso-20230717/plaso/output/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      974 2023-01-07 09:50:35.000000 plaso-20230717/plaso/output/json_line.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1535 2023-01-07 09:50:35.000000 plaso-20230717/plaso/output/json_out.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2708 2023-01-07 09:50:35.000000 plaso-20230717/plaso/output/kml.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12307 2023-06-18 17:14:42.000000 plaso-20230717/plaso/output/l2t_csv.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      321 2022-11-21 19:43:23.000000 plaso-20230717/plaso/output/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4305 2022-12-25 09:18:55.000000 plaso-20230717/plaso/output/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13671 2023-06-18 17:14:42.000000 plaso-20230717/plaso/output/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1296 2023-01-07 09:50:35.000000 plaso-20230717/plaso/output/null.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1641 2023-01-07 09:50:35.000000 plaso-20230717/plaso/output/opensearch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2744 2023-03-11 12:54:49.000000 plaso-20230717/plaso/output/opensearch_ts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6515 2023-01-08 12:31:37.000000 plaso-20230717/plaso/output/rawpy.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6476 2023-01-07 09:50:35.000000 plaso-20230717/plaso/output/shared_dsv.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7209 2023-06-18 17:14:42.000000 plaso-20230717/plaso/output/shared_json.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15840 2023-06-30 15:14:54.000000 plaso-20230717/plaso/output/shared_opensearch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7163 2023-01-07 09:50:35.000000 plaso-20230717/plaso/output/text_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5497 2023-06-18 17:14:42.000000 plaso-20230717/plaso/output/tln.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22245 2023-06-18 13:42:07.000000 plaso-20230717/plaso/output/winevt_rc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8387 2023-04-03 15:50:34.000000 plaso-20230717/plaso/output/xlsx.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.874823 plaso-20230717/plaso/parsers/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2443 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3205 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/android_app_usage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10966 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/asl.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2716 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/asl.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2635 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/aul_dsc.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1913 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/aul_timesync.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19123 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/aul_tracev3.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1608 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/aul_uuidtext.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6049 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/bencode_parser.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.874823 plaso-20230717/plaso/parsers/bencode_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      169 2022-11-21 19:43:22.000000 plaso-20230717/plaso/parsers/bencode_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1677 2022-11-21 19:43:22.000000 plaso-20230717/plaso/parsers/bencode_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2737 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/bencode_plugins/transmission.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3588 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/bencode_plugins/utorrent.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12778 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/bodyfile.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    29368 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/bsm.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12445 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/bsm.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16868 2023-06-24 05:56:24.000000 plaso-20230717/plaso/parsers/chrome_cache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3866 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/chrome_cache.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10690 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/chrome_preferences.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.875823 plaso-20230717/plaso/parsers/cookie_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      115 2022-11-21 19:43:23.000000 plaso-20230717/plaso/parsers/cookie_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11172 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/cookie_plugins/ganalytics.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3978 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/cookie_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2010 2022-11-21 19:43:23.000000 plaso-20230717/plaso/parsers/cookie_plugins/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14763 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/cups_ipp.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2170 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/cups_ipp.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7900 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/custom_destinations.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1641 2023-02-12 12:57:48.000000 plaso-20230717/plaso/parsers/custom_destinations.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2939 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/czip.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.875823 plaso-20230717/plaso/parsers/czip_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      112 2022-11-21 19:43:23.000000 plaso-20230717/plaso/parsers/czip_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2413 2022-11-21 19:43:23.000000 plaso-20230717/plaso/parsers/czip_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12932 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/czip_plugins/oxml.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11215 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/dsv_parser.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4692 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/esedb.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.876823 plaso-20230717/plaso/parsers/esedb_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      280 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/esedb_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4191 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/esedb_plugins/file_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11957 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/esedb_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18935 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/esedb_plugins/msie_webcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19309 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/esedb_plugins/srum.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      707 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/esedb_plugins/types.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20030 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/esedb_plugins/user_access_logging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6607 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/filestat.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18222 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/firefox_cache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2941 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/firefox_cache.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3556 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/fish_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6966 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/fseventsd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1422 2023-01-01 17:41:45.000000 plaso-20230717/plaso/parsers/fseventsd.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9771 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6752 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/java_idx.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4089 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/java_idx.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2925 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/jsonl_parser.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.877823 plaso-20230717/plaso/parsers/jsonl_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      610 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4646 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/aws_cloudtrail_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5362 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/azure_activity_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9090 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/azure_application_gateway_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4653 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/docker_container_config.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3710 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/docker_container_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3407 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/docker_layer_config.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9868 2023-01-11 04:51:22.000000 plaso-20230717/plaso/parsers/jsonl_plugins/gcp_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3517 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5927 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/ios_app_privacy.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4708 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/jsonl_plugins/microsoft365_audit_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5609 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/locate.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1724 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/locate.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      323 2022-11-21 19:43:23.000000 plaso-20230717/plaso/parsers/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4892 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/macos_core_location.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    32046 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/macos_keychain.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3732 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/macos_keychain.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1267 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/macos_mdns.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      962 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/macos_open_directory.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12122 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6022 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/mcafeeav.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    22923 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14972 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/msiecf.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3883 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/networkminer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17554 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/ntfs.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1364 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/ntfs.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4094 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/olecf.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.878823 plaso-20230717/plaso/parsers/olecf_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      252 2022-11-21 19:43:23.000000 plaso-20230717/plaso/parsers/olecf_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8790 2023-02-12 18:19:21.000000 plaso-20230717/plaso/parsers/olecf_plugins/automatic_destinations.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3105 2023-02-12 05:05:35.000000 plaso-20230717/plaso/parsers/olecf_plugins/automatic_destinations.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2478 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/olecf_plugins/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2314 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/olecf_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14817 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/olecf_plugins/summary.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17186 2023-04-16 05:38:30.000000 plaso-20230717/plaso/parsers/onedrive.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2235 2023-04-02 05:13:57.000000 plaso-20230717/plaso/parsers/onedrive.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10073 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/opera.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21974 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/pe.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3838 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/pe_resources.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7074 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/plist.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.881823 plaso-20230717/plaso/parsers/plist_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      925 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/plist_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1916 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/airport.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3095 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/apple_account.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3274 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/bluetooth.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1407 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2352 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/plist_plugins/install_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9902 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2240 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/ios_carplay.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2979 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/plist_plugins/ios_identityservices.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2753 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/ipod.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2758 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/launchd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6913 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/macos_user.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2760 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/safari_downloads.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3790 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/safari_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3245 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/software_update.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2391 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/spotlight_searched_terms.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2116 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/spotlight_volume.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3556 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plist_plugins/time_machine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      717 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/plist_plugins/time_machine.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6781 2023-02-25 10:48:56.000000 plaso-20230717/plaso/parsers/pls_recall.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1081 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/pls_recall.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3860 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/plugins.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7598 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/presets.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9268 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/recycler.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2638 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/recycler.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7987 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/safari_cookies.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2063 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/safari_cookies.yaml
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.881823 plaso-20230717/plaso/parsers/shared/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:22.000000 plaso-20230717/plaso/parsers/shared/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6801 2023-07-17 03:17:43.000000 plaso-20230717/plaso/parsers/shared/shell_items.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    52442 2023-06-23 03:55:15.000000 plaso-20230717/plaso/parsers/spotlight_storedb.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6580 2023-06-23 03:55:15.000000 plaso-20230717/plaso/parsers/spotlight_storedb.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15878 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/sqlite.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.927823 plaso-20230717/plaso/parsers/sqlite_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2130 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/sqlite_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9294 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/android_calls.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16836 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/android_hangouts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7153 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/android_sms.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15201 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/android_tango.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21169 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/android_twitter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4752 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/android_webview.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3520 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/android_webviewcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3665 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/chrome_autofill.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7358 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/chrome_cookies.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4725 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/chrome_extension_activity.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    52203 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/sqlite_plugins/chrome_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3742 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/dropbox.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7809 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/sqlite_plugins/firefox_cookies.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5102 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/firefox_downloads.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19145 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/firefox_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11043 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/gdrive.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6448 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/sqlite_plugins/imessage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6909 2023-05-28 05:31:32.000000 plaso-20230717/plaso/parsers/sqlite_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4379 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/sqlite_plugins/ios_datausage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7030 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/ios_kik.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8564 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/ios_netusage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3949 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/ios_powerlog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6819 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/ios_screentime.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12718 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/ios_twitter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8988 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/kodi.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3932 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/ls_quarantine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9342 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/mackeeper_cache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4191 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/macos_appusage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5759 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/macos_document_versions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    31607 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/macos_knowledgec.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7734 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/macos_notes.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5456 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/macos_notification_center.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5334 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/macos_tcc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6227 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/safari.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    37698 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/skype.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7833 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/windows_eventtranscript.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13621 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/windows_timeline.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6418 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/sqlite_plugins/zeitgeist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12222 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/symantec.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11594 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/systemd_journal.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4003 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/systemd_journal.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10352 2023-04-16 05:38:30.000000 plaso-20230717/plaso/parsers/text_parser.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.932823 plaso-20230717/plaso/parsers/text_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1745 2023-04-02 09:30:20.000000 plaso-20230717/plaso/parsers/text_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9362 2023-02-01 06:26:58.000000 plaso-20230717/plaso/parsers/text_plugins/android_logcat.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10452 2023-01-09 19:05:29.000000 plaso-20230717/plaso/parsers/text_plugins/apache_access.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8085 2023-01-09 19:05:29.000000 plaso-20230717/plaso/parsers/text_plugins/apt_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25144 2023-01-07 11:30:43.000000 plaso-20230717/plaso/parsers/text_plugins/aws_elb_access.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2889 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/bash_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10145 2023-01-09 19:05:29.000000 plaso-20230717/plaso/parsers/text_plugins/confluence_access.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6687 2023-01-09 19:05:29.000000 plaso-20230717/plaso/parsers/text_plugins/dpkg.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8410 2023-01-09 19:05:29.000000 plaso-20230717/plaso/parsers/text_plugins/gdrive_synclog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9756 2023-04-14 17:05:39.000000 plaso-20230717/plaso/parsers/text_plugins/google_logging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15550 2023-04-14 17:05:39.000000 plaso-20230717/plaso/parsers/text_plugins/iis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12271 2023-04-14 17:52:37.000000 plaso-20230717/plaso/parsers/text_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6271 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/ios_lockdownd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5087 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/ios_logd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7381 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/ios_sysdiag_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7235 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/macos_appfirewall.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7609 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/macos_securityd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9805 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/macos_wifi.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11191 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/popcontest.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9463 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/postgresql.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11222 2023-04-02 09:30:20.000000 plaso-20230717/plaso/parsers/text_plugins/powershell_transcript.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20313 2023-01-07 11:30:43.000000 plaso-20230717/plaso/parsers/text_plugins/santa.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7437 2023-01-09 19:05:29.000000 plaso-20230717/plaso/parsers/text_plugins/sccm.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5812 2023-01-07 11:30:43.000000 plaso-20230717/plaso/parsers/text_plugins/selinux.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10081 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/setupapi.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18650 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/skydrivelog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9211 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/snort_fastlog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4791 2023-01-07 11:30:43.000000 plaso-20230717/plaso/parsers/text_plugins/sophos_av.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25619 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/syslog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17445 2023-01-07 11:30:43.000000 plaso-20230717/plaso/parsers/text_plugins/viminfo.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4721 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/vsftpd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12679 2023-01-09 19:05:29.000000 plaso-20230717/plaso/parsers/text_plugins/winfirewall.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10596 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/xchatlog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5882 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/xchatscrollback.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4724 2023-01-07 09:50:35.000000 plaso-20230717/plaso/parsers/text_plugins/zsh_extended_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12398 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/trendmicroav.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)   145493 2023-06-23 03:55:15.000000 plaso-20230717/plaso/parsers/unified_logging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6626 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/utmp.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2031 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/utmp.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5999 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/utmpx.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12384 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/wincc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10810 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/windefender_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6950 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/windefender_history.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1094 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/windows_nt.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8917 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/winevt.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9670 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/winevtx.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10631 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winjob.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4504 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winjob.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8597 2023-07-17 03:17:43.000000 plaso-20230717/plaso/parsers/winlnk.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5467 2023-03-27 03:44:12.000000 plaso-20230717/plaso/parsers/winpca.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6710 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winprefetch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10215 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/winreg_parser.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.937823 plaso-20230717/plaso/parsers/winreg_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1591 2022-11-21 19:43:23.000000 plaso-20230717/plaso/parsers/winreg_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17782 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/amcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25266 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/appcompatcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8408 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/appcompatcache.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7956 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/bagmru.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3301 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/bam.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5486 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/ccleaner.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1117 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      322 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/filetime.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12330 2023-03-13 05:42:44.000000 plaso-20230717/plaso/parsers/winreg_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4871 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/lfu.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3055 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/mountpoints.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      904 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/mru.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10688 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/mrulist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18822 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/mrulistex.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9755 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/msie_zones.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2546 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/network_drives.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6338 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/networks.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5350 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/officemru.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3382 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/outlook.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7702 2023-04-02 18:49:01.000000 plaso-20230717/plaso/parsers/winreg_plugins/programscache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1009 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/programscache.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3157 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/run.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6836 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/sam_users.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1824 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/sam_users.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4192 2023-03-13 05:42:44.000000 plaso-20230717/plaso/parsers/winreg_plugins/services.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3695 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/shutdown.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      633 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/systemtime.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6205 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/task_scheduler.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1017 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/task_scheduler.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4918 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/terminal_server.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2488 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/timezone.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2586 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/typedurls.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3034 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/usb.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7784 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/usbstor.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      527 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/usbstor.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8190 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/userassist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1622 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/userassist.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3030 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/windows_version.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4434 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/winlogon.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2619 2023-01-07 09:49:55.000000 plaso-20230717/plaso/parsers/winreg_plugins/winrar.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3332 2023-06-18 13:42:07.000000 plaso-20230717/plaso/parsers/winrestore.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      948 2022-12-25 09:18:55.000000 plaso-20230717/plaso/parsers/winrestore.yaml
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.939823 plaso-20230717/plaso/preprocessors/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      201 2022-12-25 09:18:55.000000 plaso-20230717/plaso/preprocessors/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3399 2022-12-25 09:18:55.000000 plaso-20230717/plaso/preprocessors/generic.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11871 2023-06-18 13:42:07.000000 plaso-20230717/plaso/preprocessors/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10623 2023-06-18 13:42:07.000000 plaso-20230717/plaso/preprocessors/linux.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      335 2022-11-21 19:43:24.000000 plaso-20230717/plaso/preprocessors/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9081 2023-06-18 13:42:07.000000 plaso-20230717/plaso/preprocessors/macos.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12761 2023-04-02 05:13:57.000000 plaso-20230717/plaso/preprocessors/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9260 2023-07-17 15:31:13.000000 plaso-20230717/plaso/preprocessors/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      934 2022-12-25 09:18:55.000000 plaso-20230717/plaso/preprocessors/mounted_devices.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1156 2022-12-25 09:18:55.000000 plaso-20230717/plaso/preprocessors/time_zone_information.yaml
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    34521 2023-06-18 13:42:07.000000 plaso-20230717/plaso/preprocessors/windows.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.939823 plaso-20230717/plaso/serializer/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230717/plaso/serializer/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16991 2023-01-07 09:50:35.000000 plaso-20230717/plaso/serializer/json_serializer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      329 2022-11-21 19:43:24.000000 plaso-20230717/plaso/serializer/logger.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.939823 plaso-20230717/plaso/single_process/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:24.000000 plaso-20230717/plaso/single_process/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20180 2023-07-17 15:31:13.000000 plaso-20230717/plaso/single_process/extraction_engine.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.948823 plaso-20230717/plaso/storage/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      515 2023-03-27 15:25:01.000000 plaso-20230717/plaso/storage/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3834 2022-12-25 09:18:55.000000 plaso-20230717/plaso/storage/factory.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.948823 plaso-20230717/plaso/storage/fake/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:23.000000 plaso-20230717/plaso/storage/fake/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1198 2022-11-21 19:43:23.000000 plaso-20230717/plaso/storage/fake/event_heap.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2029 2023-03-26 07:06:08.000000 plaso-20230717/plaso/storage/fake/fake_store.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4244 2023-01-07 09:49:55.000000 plaso-20230717/plaso/storage/fake/writer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      323 2022-11-21 19:43:23.000000 plaso-20230717/plaso/storage/logger.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8786 2023-04-02 05:17:40.000000 plaso-20230717/plaso/storage/reader.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.949823 plaso-20230717/plaso/storage/redis/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:23.000000 plaso-20230717/plaso/storage/redis/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      913 2022-12-25 09:18:55.000000 plaso-20230717/plaso/storage/redis/reader.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17528 2023-01-07 09:50:35.000000 plaso-20230717/plaso/storage/redis/redis_store.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3494 2023-04-02 05:13:57.000000 plaso-20230717/plaso/storage/redis/writer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3370 2023-03-27 15:25:01.000000 plaso-20230717/plaso/storage/serializers.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.949823 plaso-20230717/plaso/storage/sqlite/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-11-21 19:43:23.000000 plaso-20230717/plaso/storage/sqlite/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      541 2023-01-07 11:08:44.000000 plaso-20230717/plaso/storage/sqlite/reader.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19108 2023-06-18 13:42:07.000000 plaso-20230717/plaso/storage/sqlite/sqlite_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4770 2023-01-07 09:49:55.000000 plaso-20230717/plaso/storage/sqlite/writer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1328 2022-11-21 19:43:23.000000 plaso-20230717/plaso/storage/time_range.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7028 2023-01-08 08:58:30.000000 plaso-20230717/plaso/storage/writer.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.835823 plaso-20230717/plaso.egg-info/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)      698 2023-07-23 05:03:13.000000 plaso-20230717/plaso.egg-info/PKG-INFO
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)    41138 2023-07-23 05:03:40.000000 plaso-20230717/plaso.egg-info/SOURCES.txt
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        1 2023-07-23 05:03:13.000000 plaso-20230717/plaso.egg-info/dependency_links.txt
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        1 2021-02-06 07:38:13.000000 plaso-20230717/plaso.egg-info/not-zip-safe
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)     1352 2023-07-23 05:03:13.000000 plaso-20230717/plaso.egg-info/requires.txt
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)        6 2023-07-23 05:03:13.000000 plaso-20230717/plaso.egg-info/top_level.txt
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      529 2022-09-18 11:21:00.000000 plaso-20230717/plaso.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1471 2023-07-17 03:17:43.000000 plaso-20230717/requirements.txt
+-rwxrwxr-x   0 lordyesta  (1000) lordyesta  (1000)     1027 2021-06-03 04:45:37.000000 plaso-20230717/run_tests.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2218 2023-07-23 05:03:42.166823 plaso-20230717/setup.cfg
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     8223 2023-07-16 11:46:25.000000 plaso-20230717/setup.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      248 2023-01-07 09:49:55.000000 plaso-20230717/test_dependencies.ini
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       33 2023-07-16 11:46:11.000000 plaso-20230717/test_requirements.txt
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.950823 plaso-20230717/tests/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/__init__.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.952823 plaso-20230717/tests/analysis/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/analysis/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2732 2023-01-08 16:45:00.000000 plaso-20230717/tests/analysis/bloom.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1824 2022-12-25 09:18:55.000000 plaso-20230717/tests/analysis/browser_search.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7281 2023-03-27 03:44:12.000000 plaso-20230717/tests/analysis/chrome_extension.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5091 2023-01-08 12:31:37.000000 plaso-20230717/tests/analysis/hash_tagging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      649 2022-09-18 11:21:01.000000 plaso-20230717/tests/analysis/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2480 2022-12-25 09:18:55.000000 plaso-20230717/tests/analysis/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1853 2023-04-03 15:50:34.000000 plaso-20230717/tests/analysis/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4278 2023-01-08 12:31:37.000000 plaso-20230717/tests/analysis/nsrlsvr.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2294 2023-01-08 12:31:37.000000 plaso-20230717/tests/analysis/sessionize.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3241 2023-01-08 12:31:37.000000 plaso-20230717/tests/analysis/tagging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5683 2023-04-16 05:38:30.000000 plaso-20230717/tests/analysis/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2553 2023-01-08 12:31:37.000000 plaso-20230717/tests/analysis/unique_domains_visited.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4826 2023-06-18 13:42:07.000000 plaso-20230717/tests/analysis/viper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3987 2023-06-18 13:42:07.000000 plaso-20230717/tests/analysis/virustotal.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.953823 plaso-20230717/tests/analyzers/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/analyzers/__init__.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.962823 plaso-20230717/tests/analyzers/hashers/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/analyzers/hashers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      764 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/hashers/entropy.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3680 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/hashers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      792 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/hashers/md5.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      834 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/hashers/sha1.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      913 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/hashers/sha256.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1669 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/hashers/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1661 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/hashing_analyzer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1049 2022-12-25 09:18:55.000000 plaso-20230717/tests/analyzers/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3269 2022-09-18 11:21:01.000000 plaso-20230717/tests/analyzers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1983 2023-01-07 09:49:55.000000 plaso-20230717/tests/analyzers/yara_analyzer.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.966823 plaso-20230717/tests/cli/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/cli/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    13329 2023-06-18 13:42:07.000000 plaso-20230717/tests/cli/extraction_tool.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.974823 plaso-20230717/tests/cli/helpers/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/cli/helpers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2128 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/analysis_plugins.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2348 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/archives.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2676 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/artifact_definitions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3933 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/artifact_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2476 2023-01-11 17:57:01.000000 plaso-20230717/tests/cli/helpers/bloom_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1704 2023-01-07 09:50:02.000000 plaso-20230717/tests/cli/helpers/codepage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1700 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/data_location.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3739 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/date_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1658 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/dynamic_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4335 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/event_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2501 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/extraction.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2094 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/filter_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2649 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/hashers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      560 2022-09-18 11:21:01.000000 plaso-20230717/tests/cli/helpers/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2912 2022-09-18 11:21:01.000000 plaso-20230717/tests/cli/helpers/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2093 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/language.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3443 2022-09-18 11:21:01.000000 plaso-20230717/tests/cli/helpers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2763 2023-01-07 09:49:55.000000 plaso-20230717/tests/cli/helpers/nsrlsvr_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3627 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/opensearch_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4133 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/opensearch_ts_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2121 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/output_modules.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2477 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/parsers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2513 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/process_resources.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3864 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/profiling.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2258 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/sessionize_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2177 2023-01-07 09:49:55.000000 plaso-20230717/tests/cli/helpers/status_view.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2320 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/storage_format.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2725 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/tagging_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1947 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/temporary_directory.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1641 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1745 2023-01-07 09:49:55.000000 plaso-20230717/tests/cli/helpers/vfs_backend.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2428 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/viper_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2959 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/virustotal_analysis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3280 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/workers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2022 2022-12-25 09:18:55.000000 plaso-20230717/tests/cli/helpers/xlsx_output.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2550 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/helpers/yara_rules.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21681 2023-04-02 18:49:01.000000 plaso-20230717/tests/cli/image_export_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    20654 2023-01-07 09:49:55.000000 plaso-20230717/tests/cli/log2timeline_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    30172 2023-06-24 17:48:27.000000 plaso-20230717/tests/cli/pinfo_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10500 2023-03-27 15:25:01.000000 plaso-20230717/tests/cli/psort_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15745 2023-01-07 09:49:55.000000 plaso-20230717/tests/cli/psteal_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7892 2023-01-07 09:49:55.000000 plaso-20230717/tests/cli/status_view.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    50309 2023-06-18 13:42:07.000000 plaso-20230717/tests/cli/storage_media_tool.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3392 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1023 2022-09-18 11:21:01.000000 plaso-20230717/tests/cli/time_slices.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10815 2023-06-18 17:14:42.000000 plaso-20230717/tests/cli/tool_options.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11524 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/tools.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6480 2022-09-18 11:26:13.000000 plaso-20230717/tests/cli/views.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.976823 plaso-20230717/tests/containers/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/containers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      753 2022-09-18 11:21:01.000000 plaso-20230717/tests/containers/analyzer_result.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8964 2023-06-18 13:42:07.000000 plaso-20230717/tests/containers/artifacts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1175 2022-12-25 09:18:55.000000 plaso-20230717/tests/containers/counts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1230 2022-09-18 11:21:01.000000 plaso-20230717/tests/containers/event_sources.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5713 2023-01-08 12:31:37.000000 plaso-20230717/tests/containers/events.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      603 2023-01-07 09:49:55.000000 plaso-20230717/tests/containers/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      861 2023-01-08 12:31:37.000000 plaso-20230717/tests/containers/plist_event.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      853 2022-12-25 09:18:55.000000 plaso-20230717/tests/containers/reports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5000 2023-04-02 05:17:40.000000 plaso-20230717/tests/containers/sessions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1829 2022-10-27 03:49:18.000000 plaso-20230717/tests/containers/tasks.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1927 2023-01-07 09:49:55.000000 plaso-20230717/tests/containers/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1882 2022-09-18 11:26:13.000000 plaso-20230717/tests/containers/warnings.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2513 2023-01-08 12:31:37.000000 plaso-20230717/tests/containers/windows_events.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.978823 plaso-20230717/tests/data/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230717/tests/data/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1164 2022-09-18 11:21:01.000000 plaso-20230717/tests/data/presets.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18796 2023-01-08 12:31:37.000000 plaso-20230717/tests/data/tag_linux.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5034 2023-01-08 12:31:37.000000 plaso-20230717/tests/data/tag_macos.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    26795 2023-01-08 12:31:37.000000 plaso-20230717/tests/data/tag_windows.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4996 2023-04-03 15:50:34.000000 plaso-20230717/tests/data/test_lib.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)    72601 2023-06-21 05:27:32.000000 plaso-20230717/tests/end-to-end.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.982823 plaso-20230717/tests/engine/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/engine/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12414 2023-06-18 13:42:07.000000 plaso-20230717/tests/engine/artifact_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3495 2023-01-07 09:50:35.000000 plaso-20230717/tests/engine/configurations.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5567 2023-06-18 13:42:07.000000 plaso-20230717/tests/engine/engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14491 2023-06-18 13:42:07.000000 plaso-20230717/tests/engine/extractors.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1321 2022-09-18 11:21:01.000000 plaso-20230717/tests/engine/filter_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5928 2023-04-16 06:55:05.000000 plaso-20230717/tests/engine/knowledge_base.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5384 2023-04-16 06:54:56.000000 plaso-20230717/tests/engine/path_filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    17353 2023-04-16 06:54:51.000000 plaso-20230717/tests/engine/path_helper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      796 2022-09-18 11:21:01.000000 plaso-20230717/tests/engine/process_info.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3457 2023-01-07 09:49:55.000000 plaso-20230717/tests/engine/processing_status.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6856 2023-06-18 13:42:07.000000 plaso-20230717/tests/engine/profilers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1139 2022-09-18 11:21:01.000000 plaso-20230717/tests/engine/tagging_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      504 2023-04-02 05:13:57.000000 plaso-20230717/tests/engine/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9237 2023-04-16 05:38:30.000000 plaso-20230717/tests/engine/timeliner.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    25091 2023-04-02 05:13:57.000000 plaso-20230717/tests/engine/worker.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2455 2022-09-18 11:21:01.000000 plaso-20230717/tests/engine/yaml_filter_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2288 2023-01-07 09:49:55.000000 plaso-20230717/tests/engine/yaml_timeliner_file.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.984823 plaso-20230717/tests/filters/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/filters/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2168 2022-09-18 11:21:01.000000 plaso-20230717/tests/filters/event_filter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14058 2023-01-08 12:31:37.000000 plaso-20230717/tests/filters/expression_parser.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3233 2022-09-18 11:21:01.000000 plaso-20230717/tests/filters/expressions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14204 2022-09-18 11:21:01.000000 plaso-20230717/tests/filters/file_entry.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9666 2022-09-18 11:21:01.000000 plaso-20230717/tests/filters/filters.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8247 2023-01-07 09:49:55.000000 plaso-20230717/tests/filters/parser_filter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5276 2022-09-18 11:21:01.000000 plaso-20230717/tests/filters/path_filter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      555 2022-09-18 11:21:01.000000 plaso-20230717/tests/filters/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1516 2022-09-18 11:21:01.000000 plaso-20230717/tests/filters/value_types.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.990823 plaso-20230717/tests/formatters/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/formatters/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1560 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/chrome.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2602 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/chrome_preferences.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2365 2023-01-07 09:49:55.000000 plaso-20230717/tests/formatters/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2377 2023-04-02 12:10:49.000000 plaso-20230717/tests/formatters/file_system.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1736 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/firefox.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      642 2022-09-18 11:26:13.000000 plaso-20230717/tests/formatters/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7643 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      507 2022-09-18 11:21:07.000000 plaso-20230717/tests/formatters/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2023 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/msiecf.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1249 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/shell_items.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1323 2023-04-03 15:50:34.000000 plaso-20230717/tests/formatters/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2068 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/winlnk.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2779 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/winprefetch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      958 2022-12-25 09:18:55.000000 plaso-20230717/tests/formatters/winreg.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3363 2023-01-07 09:49:55.000000 plaso-20230717/tests/formatters/yaml_formatters_file.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.991823 plaso-20230717/tests/helpers/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230717/tests/helpers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      861 2022-09-18 11:26:13.000000 plaso-20230717/tests/helpers/language_tags.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.992823 plaso-20230717/tests/helpers/windows/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230717/tests/helpers/windows/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      702 2022-09-18 11:26:13.000000 plaso-20230717/tests/helpers/windows/known_folders.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1001 2022-09-18 11:26:13.000000 plaso-20230717/tests/helpers/windows/languages.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1066 2022-10-27 03:49:18.000000 plaso-20230717/tests/helpers/windows/resource_files.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      755 2022-09-18 11:26:13.000000 plaso-20230717/tests/helpers/windows/shell_folders.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:41.993823 plaso-20230717/tests/lib/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/lib/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1463 2022-09-18 11:21:01.000000 plaso-20230717/tests/lib/bufferlib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5865 2022-12-25 09:18:55.000000 plaso-20230717/tests/lib/dtfabric_helper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6772 2023-01-07 09:49:55.000000 plaso-20230717/tests/lib/line_reader_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1270 2022-09-18 11:21:01.000000 plaso-20230717/tests/lib/loggers.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1591 2022-09-18 11:21:01.000000 plaso-20230717/tests/lib/plist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      850 2022-09-18 11:21:01.000000 plaso-20230717/tests/lib/specification.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6354 2023-04-02 05:13:57.000000 plaso-20230717/tests/lib/yearless_helper.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.005823 plaso-20230717/tests/multi_process/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230717/tests/multi_process/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5979 2023-04-03 15:50:34.000000 plaso-20230717/tests/multi_process/analysis_engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4496 2023-06-18 13:42:07.000000 plaso-20230717/tests/multi_process/analysis_process.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1681 2022-09-18 11:26:13.000000 plaso-20230717/tests/multi_process/base_process.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      994 2022-09-18 11:26:13.000000 plaso-20230717/tests/multi_process/engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3573 2023-06-18 13:42:07.000000 plaso-20230717/tests/multi_process/extraction_engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7026 2023-06-18 13:42:07.000000 plaso-20230717/tests/multi_process/extraction_process.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11977 2023-04-03 15:50:34.000000 plaso-20230717/tests/multi_process/output_engine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    30931 2023-06-18 13:42:07.000000 plaso-20230717/tests/multi_process/task_manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1266 2023-04-02 05:13:57.000000 plaso-20230717/tests/multi_process/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5788 2022-09-18 11:26:13.000000 plaso-20230717/tests/multi_process/zeromq_queue.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.009823 plaso-20230717/tests/output/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/output/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10910 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/dynamic.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    18475 2023-01-07 09:49:55.000000 plaso-20230717/tests/output/formatting_helper.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      723 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5676 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4108 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/json_line.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4996 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/json_out.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5814 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/kml.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10379 2023-01-08 12:31:37.000000 plaso-20230717/tests/output/l2t_csv.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4435 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5762 2023-06-18 17:14:42.000000 plaso-20230717/tests/output/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2478 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/null.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4250 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/opensearch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4347 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/opensearch_ts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4746 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/rawpy.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      463 2022-09-18 11:21:09.000000 plaso-20230717/tests/output/shared_dsv.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3766 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/shared_json.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6111 2023-06-30 15:14:54.000000 plaso-20230717/tests/output/shared_opensearch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      846 2023-04-03 15:50:34.000000 plaso-20230717/tests/output/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1159 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/text_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10786 2023-01-07 09:50:35.000000 plaso-20230717/tests/output/tln.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2938 2023-04-02 05:13:57.000000 plaso-20230717/tests/output/winevt_rc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6988 2023-01-08 07:20:43.000000 plaso-20230717/tests/output/xlsx.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.017823 plaso-20230717/tests/parsers/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/parsers/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1437 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/android_app_usage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14067 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/asl.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      914 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/bencode_parser.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.018823 plaso-20230717/tests/parsers/bencode_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/parsers/bencode_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      221 2022-09-18 11:21:01.000000 plaso-20230717/tests/parsers/bencode_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1438 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/bencode_plugins/transmission.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1554 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/bencode_plugins/utorrent.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3243 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/bodyfile.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2972 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/bsm.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2423 2023-06-24 05:56:25.000000 plaso-20230717/tests/parsers/chrome_cache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3009 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/chrome_preferences.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.018823 plaso-20230717/tests/parsers/cookie_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/parsers/cookie_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4228 2023-06-18 13:42:07.000000 plaso-20230717/tests/parsers/cookie_plugins/ganalytics.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1655 2022-09-18 11:26:13.000000 plaso-20230717/tests/parsers/cookie_plugins/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12879 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/cups_ipp.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3286 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/custom_destinations.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1951 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/czip.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.018823 plaso-20230717/tests/parsers/czip_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230717/tests/parsers/czip_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4700 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/czip_plugins/oxml.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1874 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/czip_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4257 2022-09-18 11:21:01.000000 plaso-20230717/tests/parsers/dsv_parser.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2813 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/esedb.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.019823 plaso-20230717/tests/parsers/esedb_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/parsers/esedb_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1561 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/esedb_plugins/file_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5391 2023-06-18 13:42:07.000000 plaso-20230717/tests/parsers/esedb_plugins/msie_webcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2517 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/esedb_plugins/srum.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1982 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/esedb_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3495 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/esedb_plugins/user_access_logging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16135 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/filestat.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15463 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/firefox_cache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1233 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/fish_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3583 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/fseventsd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1161 2022-12-25 09:18:55.000000 plaso-20230717/tests/parsers/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1242 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2507 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/java_idx.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.020823 plaso-20230717/tests/parsers/jsonl_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-12-25 09:18:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1577 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/aws_cloudtrail_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2285 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/azure_activity_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2521 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/azure_application_gateway_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1742 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/docker_container_config.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1787 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/docker_container_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1708 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/docker_layer_config.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2351 2023-01-11 04:51:22.000000 plaso-20230717/tests/parsers/jsonl_plugins/gcp_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1863 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/ios_app_privacy.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1929 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/jsonl_plugins/microsoft365_audit_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1948 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/jsonl_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2158 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/locate.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2217 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/macos_keychain.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10388 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2094 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/mcafeeav.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8228 2023-04-02 18:49:01.000000 plaso-20230717/tests/parsers/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5472 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/msiecf.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1653 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/networkminer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9408 2023-07-07 18:21:24.000000 plaso-20230717/tests/parsers/ntfs.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3041 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/olecf.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.021823 plaso-20230717/tests/parsers/olecf_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/parsers/olecf_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5634 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/olecf_plugins/automatic_destinations.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1754 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/olecf_plugins/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3284 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/olecf_plugins/summary.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2009 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/olecf_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4523 2023-04-16 05:38:30.000000 plaso-20230717/tests/parsers/onedrive.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2557 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/opera.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6525 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/pe.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6622 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.023823 plaso-20230717/tests/parsers/plist_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/parsers/plist_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1424 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/airport.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1687 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/apple_account.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1582 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/bluetooth.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4000 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2133 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/install_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4674 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1441 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/ios_carplay.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1349 2023-06-18 13:42:07.000000 plaso-20230717/tests/parsers/plist_plugins/ios_identityservices.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1587 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/ipod.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1401 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/launchd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1966 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/macos_user.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1788 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/safari_downloads.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1448 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/safari_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1525 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/software_update.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1537 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/spotlight_searched_terms.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1553 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/spotlight_volume.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2234 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/plist_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2074 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/plist_plugins/time_machine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1444 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/pls_recall.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4885 2022-12-10 18:42:49.000000 plaso-20230717/tests/parsers/presets.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3638 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/recycler.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1844 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/safari_cookies.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.024823 plaso-20230717/tests/parsers/shared/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2023-06-18 13:42:07.000000 plaso-20230717/tests/parsers/shared/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6752 2023-06-23 03:55:15.000000 plaso-20230717/tests/parsers/spotlight_storedb.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5843 2023-01-07 09:50:35.000000 plaso-20230717/tests/parsers/sqlite.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.035823 plaso-20230717/tests/parsers/sqlite_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/parsers/sqlite_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1429 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/android_calls.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1488 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/android_hangouts.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1498 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/android_sms.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3288 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/android_tango.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3127 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/android_twitter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1506 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/android_webview.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1548 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/android_webviewcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1508 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/chrome_autofill.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3558 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/chrome_cookies.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1606 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/chrome_extension_activity.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    10068 2023-06-18 13:42:08.000000 plaso-20230717/tests/parsers/sqlite_plugins/chrome_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1570 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/dropbox.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2963 2023-06-18 13:42:08.000000 plaso-20230717/tests/parsers/sqlite_plugins/firefox_cookies.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1705 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/firefox_downloads.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4569 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/firefox_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2104 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/gdrive.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1470 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/imessage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4089 2022-09-18 11:21:01.000000 plaso-20230717/tests/parsers/sqlite_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1785 2023-06-18 13:42:08.000000 plaso-20230717/tests/parsers/sqlite_plugins/ios_datausage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1442 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/ios_kik.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1964 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/ios_netusage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1326 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/ios_powerlog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1438 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/ios_screentime.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2560 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/ios_twitter.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1385 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/kodi.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1743 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/ls_quarantine.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1836 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/mackeeper_cache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1553 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/macos_appusage.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1705 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/macos_document_versions.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3212 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/macos_knowledgec.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1584 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/macos_notes.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1507 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/macos_notification_center.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1388 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/macos_tcc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1454 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/safari.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3055 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/skype.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3384 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/sqlite_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2084 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/windows_eventtranscript.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1921 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/windows_timeline.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1382 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/sqlite_plugins/zeitgeist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1577 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/symantec.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5652 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/systemd_journal.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8118 2023-07-07 19:18:41.000000 plaso-20230717/tests/parsers/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3696 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_parser.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.040823 plaso-20230717/tests/parsers/text_plugins/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-12-25 09:18:55.000000 plaso-20230717/tests/parsers/text_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4085 2023-01-07 09:50:35.000000 plaso-20230717/tests/parsers/text_plugins/android_logcat.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4361 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/apache_access.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9005 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/apt_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2753 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/aws_elb_access.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3679 2023-01-07 09:50:35.000000 plaso-20230717/tests/parsers/text_plugins/bash_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3615 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/confluence_access.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1279 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/dpkg.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4960 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/gdrive_synclog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2670 2023-01-07 09:50:35.000000 plaso-20230717/tests/parsers/text_plugins/google_logging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7023 2023-02-07 15:18:26.000000 plaso-20230717/tests/parsers/text_plugins/iis.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      577 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2171 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/ios_lockdownd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1393 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/ios_logd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1875 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/ios_sysdiag_log.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2344 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/macos_appfirewall.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2223 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/macos_securityd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3540 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/macos_wifi.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1912 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/popcontest.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3200 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/postgresql.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6349 2023-04-02 09:30:20.000000 plaso-20230717/tests/parsers/text_plugins/powershell_transcript.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6578 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/santa.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3587 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/sccm.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2667 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/selinux.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2752 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/setupapi.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5804 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/skydrivelog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3058 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/snort_fastlog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1460 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/sophos_av.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    21082 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/syslog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2194 2023-04-02 18:49:01.000000 plaso-20230717/tests/parsers/text_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3674 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/viminfo.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1453 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/vsftpd.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1622 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/winfirewall.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1304 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/xchatlog.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3438 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/xchatscrollback.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2486 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/text_plugins/zsh_extended_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3154 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/trendmicroav.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    93324 2023-06-18 13:42:08.000000 plaso-20230717/tests/parsers/unified_logging.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2516 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/utmp.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1331 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/utmpx.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2531 2023-06-18 13:42:08.000000 plaso-20230717/tests/parsers/wincc.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3461 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/windefender_history.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2550 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winevt.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5159 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winevtx.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2726 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winjob.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5471 2023-07-17 03:17:43.000000 plaso-20230717/tests/parsers/winlnk.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2801 2023-03-27 03:44:12.000000 plaso-20230717/tests/parsers/winpca.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19690 2023-07-08 05:08:20.000000 plaso-20230717/tests/parsers/winprefetch.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6102 2023-06-18 13:42:08.000000 plaso-20230717/tests/parsers/winreg_parser.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.044823 plaso-20230717/tests/parsers/winreg_plugins/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-05 07:02:50.000000 plaso-20230717/tests/parsers/winreg_plugins/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4787 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/amcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    27903 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/appcompatcache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3728 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/bagmru.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3738 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/bam.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2901 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/ccleaner.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3409 2023-03-13 05:42:44.000000 plaso-20230717/tests/parsers/winreg_plugins/default.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7609 2023-03-13 05:42:44.000000 plaso-20230717/tests/parsers/winreg_plugins/interface.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8230 2023-03-13 05:42:44.000000 plaso-20230717/tests/parsers/winreg_plugins/lfu.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2241 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/mountpoints.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8768 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/mrulist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    15277 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/mrulistex.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16850 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/msie_zones.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6294 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/network_drives.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     9248 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/networks.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4453 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/officemru.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4730 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/outlook.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5907 2023-03-13 05:42:44.000000 plaso-20230717/tests/parsers/winreg_plugins/programscache.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7504 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/run.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2228 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/sam_users.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5915 2023-03-13 05:42:44.000000 plaso-20230717/tests/parsers/winreg_plugins/services.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1986 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/shutdown.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2351 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/task_scheduler.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6199 2023-03-12 13:56:34.000000 plaso-20230717/tests/parsers/winreg_plugins/terminal_server.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4387 2023-04-02 05:13:57.000000 plaso-20230717/tests/parsers/winreg_plugins/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     7387 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/timezone.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4268 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/typedurls.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1998 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/usb.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2384 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/usbstor.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4448 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/userassist.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6789 2023-03-13 05:42:44.000000 plaso-20230717/tests/parsers/winreg_plugins/windows_version.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    12622 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/winlogon.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     3200 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winreg_plugins/winrar.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1391 2023-01-07 09:49:55.000000 plaso-20230717/tests/parsers/winrestore.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.045823 plaso-20230717/tests/preprocessors/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/preprocessors/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1822 2023-04-02 05:13:57.000000 plaso-20230717/tests/preprocessors/generic.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      616 2022-09-18 11:21:01.000000 plaso-20230717/tests/preprocessors/init_imports.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    16385 2023-04-02 05:13:57.000000 plaso-20230717/tests/preprocessors/linux.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     8362 2023-04-02 05:13:57.000000 plaso-20230717/tests/preprocessors/macos.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2288 2023-04-02 05:13:57.000000 plaso-20230717/tests/preprocessors/manager.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2731 2023-04-02 05:13:57.000000 plaso-20230717/tests/preprocessors/mediator.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5489 2023-04-16 06:54:43.000000 plaso-20230717/tests/preprocessors/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    27973 2023-04-16 06:54:37.000000 plaso-20230717/tests/preprocessors/windows.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.046823 plaso-20230717/tests/serializer/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/serializer/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14353 2023-04-02 05:17:40.000000 plaso-20230717/tests/serializer/json_serializer.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.046823 plaso-20230717/tests/single_process/
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)       24 2022-09-18 11:26:13.000000 plaso-20230717/tests/single_process/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2975 2023-06-18 13:42:08.000000 plaso-20230717/tests/single_process/extraction_engine.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.046823 plaso-20230717/tests/storage/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tests/storage/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1206 2022-09-18 11:26:13.000000 plaso-20230717/tests/storage/factory.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.047823 plaso-20230717/tests/storage/fake/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230717/tests/storage/fake/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2440 2022-09-18 11:26:13.000000 plaso-20230717/tests/storage/fake/event_heap.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     4963 2022-12-25 09:18:55.000000 plaso-20230717/tests/storage/fake/writer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5045 2023-01-07 09:50:35.000000 plaso-20230717/tests/storage/reader.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.047823 plaso-20230717/tests/storage/redis/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230717/tests/storage/redis/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1537 2022-12-25 09:18:55.000000 plaso-20230717/tests/storage/redis/reader.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    14595 2023-01-07 09:50:35.000000 plaso-20230717/tests/storage/redis/redis_store.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.048823 plaso-20230717/tests/storage/sqlite/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-06-03 04:45:38.000000 plaso-20230717/tests/storage/sqlite/__init__.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)      591 2022-09-18 11:26:13.000000 plaso-20230717/tests/storage/sqlite/reader.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    19148 2023-06-18 13:42:08.000000 plaso-20230717/tests/storage/sqlite/sqlite_file.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     5827 2022-12-25 09:18:55.000000 plaso-20230717/tests/storage/sqlite/writer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     2808 2023-01-08 12:31:37.000000 plaso-20230717/tests/storage/test_lib.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1229 2023-01-07 09:50:35.000000 plaso-20230717/tests/storage/writer.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     6574 2022-09-18 11:26:13.000000 plaso-20230717/tests/test_lib.py
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.058823 plaso-20230717/tools/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/tools/__init__.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2317 2023-04-02 18:49:01.000000 plaso-20230717/tools/image_export.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2419 2022-12-25 09:18:55.000000 plaso-20230717/tools/log2timeline.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2016 2022-09-18 11:26:13.000000 plaso-20230717/tools/pinfo.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2410 2022-12-25 09:18:55.000000 plaso-20230717/tools/psort.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2629 2022-12-25 09:18:55.000000 plaso-20230717/tools/psteal.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)     1255 2023-07-16 11:46:11.000000 plaso-20230717/tox.ini
+drwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)        0 2023-07-23 05:03:42.163823 plaso-20230717/utils/
+-rw-rw-r--   0 lordyesta  (1000) lordyesta  (1000)       24 2021-02-05 09:03:04.000000 plaso-20230717/utils/__init__.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      700 2022-12-25 09:18:55.000000 plaso-20230717/utils/build_docker.sh
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      629 2023-07-16 11:46:11.000000 plaso-20230717/utils/check_dependencies.py
+-rw-r--r--   0 lordyesta  (1000) lordyesta  (1000)    11583 2023-07-16 11:46:11.000000 plaso-20230717/utils/dependencies.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     3089 2022-09-18 11:21:01.000000 plaso-20230717/utils/export_event_data.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)    10536 2023-01-07 09:49:55.000000 plaso-20230717/utils/export_supported_formats.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1597 2022-09-18 11:26:13.000000 plaso-20230717/utils/generate_windows_time_zones.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     3438 2022-09-18 11:26:13.000000 plaso-20230717/utils/plot_cpu_usage.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     1983 2022-09-18 11:21:01.000000 plaso-20230717/utils/plot_memory_usage.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2620 2022-09-18 11:21:01.000000 plaso-20230717/utils/plot_storage.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     2070 2022-09-18 11:21:01.000000 plaso-20230717/utils/plot_task_queue.py
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)     6272 2022-09-18 11:21:01.000000 plaso-20230717/utils/plot_tasks.py
+-rwxrwxr-x   0 lordyesta  (1000) lordyesta  (1000)      404 2021-02-05 09:03:04.000000 plaso-20230717/utils/update_authors.sh
+-rwxr-xr-x   0 lordyesta  (1000) lordyesta  (1000)      977 2022-09-18 11:21:01.000000 plaso-20230717/utils/update_release.sh
```

### Comparing `plaso-20230311/.github/ISSUE_TEMPLATE/problem-report.md` & `plaso-20230717/.github/ISSUE_TEMPLATE/problem-report.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/.github/ISSUE_TEMPLATE/release.md` & `plaso-20230717/.github/ISSUE_TEMPLATE/release.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/.github/PULL_REQUEST_TEMPLATE.md` & `plaso-20230717/.github/PULL_REQUEST_TEMPLATE.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/.github/workflows/test_docker.yml` & `plaso-20230717/.github/workflows/test_docker.yml`

 * *Files 2% similar despite different names*

```diff
@@ -3,26 +3,26 @@
 on: [push]
 permissions: read-all
 jobs:
   test_fedora:
     runs-on: ubuntu-latest
     strategy:
       matrix:
-        version: ['37']
+        version: ['38']
     container:
       image: registry.fedoraproject.org/fedora:${{ matrix.version }}
     steps:
-    - uses: actions/checkout@v2
+    - uses: actions/checkout@v3
     - name: Set up container
       run: |
         dnf install -y dnf-plugins-core langpacks-en
     - name: Install dependencies
       run: |
         dnf copr -y enable @gift/dev
-        dnf install -y @development-tools python3 python3-devel libbde-python3 libcreg-python3 libesedb-python3 libevt-python3 libevtx-python3 libewf-python3 libfsapfs-python3 libfsext-python3 libfsfat-python3 libfshfs-python3 libfsntfs-python3 libfsxfs-python3 libfvde-python3 libfwnt-python3 libfwsi-python3 liblnk-python3 libluksde-python3 libmodi-python3 libmsiecf-python3 libolecf-python3 libphdi-python3 libqcow-python3 libregf-python3 libscca-python3 libsigscan-python3 libsmdev-python3 libsmraw-python3 libvhdi-python3 libvmdk-python3 libvsgpt-python3 libvshadow-python3 libvslvm-python3 python3-XlsxWriter python3-acstore python3-artifacts python3-bencode python3-certifi python3-cffi python3-chardet python3-cryptography python3-dateutil python3-defusedxml python3-dfdatetime python3-dfvfs python3-dfwinreg python3-dtfabric python3-fakeredis python3-future python3-idna python3-lz4 python3-mock python3-opensearch python3-pefile python3-psutil python3-pyparsing python3-pytsk3 python3-pytz python3-pyxattr python3-pyyaml python3-redis python3-requests python3-setuptools python3-six python3-urllib3 python3-yara python3-zmq
+        dnf install -y @development-tools python3 python3-devel libbde-python3 libcaes-python3 libcreg-python3 libesedb-python3 libevt-python3 libevtx-python3 libewf-python3 libfsapfs-python3 libfsext-python3 libfsfat-python3 libfshfs-python3 libfsntfs-python3 libfsxfs-python3 libfvde-python3 libfwnt-python3 libfwsi-python3 liblnk-python3 libluksde-python3 libmodi-python3 libmsiecf-python3 libolecf-python3 libphdi-python3 libqcow-python3 libregf-python3 libscca-python3 libsigscan-python3 libsmdev-python3 libsmraw-python3 libvhdi-python3 libvmdk-python3 libvsgpt-python3 libvshadow-python3 libvslvm-python3 python3-XlsxWriter python3-acstore python3-artifacts python3-bencode python3-certifi python3-cffi python3-chardet python3-cryptography python3-dateutil python3-defusedxml python3-dfdatetime python3-dfvfs python3-dfwinreg python3-dtfabric python3-fakeredis python3-future python3-idna python3-lz4 python3-mock python3-opensearch python3-pefile python3-psutil python3-pyparsing python3-pytsk3 python3-pytz python3-pyxattr python3-pyyaml python3-redis python3-requests python3-setuptools python3-six python3-urllib3 python3-yara python3-zmq
     - name: Run tests
       env:
         LANG: C.utf8
       run: |
         python3 ./run_tests.py
     - name: Run end-to-end tests
       run: |
@@ -41,28 +41,28 @@
     runs-on: ubuntu-latest
     strategy:
       matrix:
         version: ['22.04']
     container:
       image: ubuntu:${{ matrix.version }}
     steps:
-    - uses: actions/checkout@v2
+    - uses: actions/checkout@v3
     - name: Set up container
       env:
         DEBIAN_FRONTEND: noninteractive
       run: |
         apt-get update -q
         apt-get install -y libterm-readline-gnu-perl locales software-properties-common
         locale-gen en_US.UTF-8
         ln -f -s /usr/share/zoneinfo/UTC /etc/localtime
     - name: Install dependencies
       run: |
         add-apt-repository -y ppa:gift/dev
         apt-get update -q
-        apt-get install -y build-essential python3 python3-dev libbde-python3 libcreg-python3 libesedb-python3 libevt-python3 libevtx-python3 libewf-python3 libfsapfs-python3 libfsext-python3 libfsfat-python3 libfshfs-python3 libfsntfs-python3 libfsxfs-python3 libfvde-python3 libfwnt-python3 libfwsi-python3 liblnk-python3 libluksde-python3 libmodi-python3 libmsiecf-python3 libolecf-python3 libphdi-python3 libqcow-python3 libregf-python3 libscca-python3 libsigscan-python3 libsmdev-python3 libsmraw-python3 libvhdi-python3 libvmdk-python3 libvsgpt-python3 libvshadow-python3 libvslvm-python3 python3-acstore python3-artifacts python3-bencode python3-certifi python3-cffi-backend python3-chardet python3-cryptography python3-dateutil python3-defusedxml python3-dfdatetime python3-dfvfs python3-dfwinreg python3-distutils python3-dtfabric python3-fakeredis python3-flor python3-future python3-idna python3-lz4 python3-mock python3-opensearch python3-pefile python3-psutil python3-pyparsing python3-pytsk3 python3-pyxattr python3-redis python3-requests python3-setuptools python3-six python3-tz python3-urllib3 python3-xlsxwriter python3-yaml python3-yara python3-zmq
+        apt-get install -y build-essential python3 python3-dev libbde-python3 libcaes-python3 libcreg-python3 libesedb-python3 libevt-python3 libevtx-python3 libewf-python3 libfsapfs-python3 libfsext-python3 libfsfat-python3 libfshfs-python3 libfsntfs-python3 libfsxfs-python3 libfvde-python3 libfwnt-python3 libfwsi-python3 liblnk-python3 libluksde-python3 libmodi-python3 libmsiecf-python3 libolecf-python3 libphdi-python3 libqcow-python3 libregf-python3 libscca-python3 libsigscan-python3 libsmdev-python3 libsmraw-python3 libvhdi-python3 libvmdk-python3 libvsgpt-python3 libvshadow-python3 libvslvm-python3 python3-acstore python3-artifacts python3-bencode python3-certifi python3-cffi-backend python3-chardet python3-cryptography python3-dateutil python3-defusedxml python3-dfdatetime python3-dfvfs python3-dfwinreg python3-distutils python3-dtfabric python3-fakeredis python3-flor python3-future python3-idna python3-lz4 python3-mock python3-opensearch python3-pefile python3-psutil python3-pyparsing python3-pytsk3 python3-pyxattr python3-redis python3-requests python3-setuptools python3-six python3-tz python3-urllib3 python3-xlsxwriter python3-yaml python3-yara python3-zmq
     - name: Run tests
       env:
         LANG: en_US.UTF-8
       run: |
         python3 ./run_tests.py
     - name: Run end-to-end tests
       env:
```

### Comparing `plaso-20230311/.github/workflows/test_docs.yml` & `plaso-20230717/.github/workflows/test_docs.yml`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
       matrix:
         include:
         - python-version: '3.8'
           toxenv: 'docs'
     container:
       image: ubuntu:22.04
     steps:
-    - uses: actions/checkout@v2
+    - uses: actions/checkout@v3
     - name: Set up container
       env:
         DEBIAN_FRONTEND: noninteractive
       run: |
         apt-get update -q
         apt-get install -y libterm-readline-gnu-perl locales software-properties-common
         locale-gen en_US.UTF-8
@@ -32,15 +32,15 @@
       env:
         DEBIAN_FRONTEND: noninteractive
       run: |
         add-apt-repository -y universe
         add-apt-repository -y ppa:deadsnakes/ppa
         add-apt-repository -y ppa:gift/dev
         apt-get update -q
-        apt-get install -y build-essential git libffi-dev python${{ matrix.python-version }} python${{ matrix.python-version }}-dev python${{ matrix.python-version }}-venv libbde-python3 libcreg-python3 libesedb-python3 libevt-python3 libevtx-python3 libewf-python3 libfsapfs-python3 libfsext-python3 libfsfat-python3 libfshfs-python3 libfsntfs-python3 libfsxfs-python3 libfvde-python3 libfwnt-python3 libfwsi-python3 liblnk-python3 libluksde-python3 libmodi-python3 libmsiecf-python3 libolecf-python3 libphdi-python3 libqcow-python3 libregf-python3 libscca-python3 libsigscan-python3 libsmdev-python3 libsmraw-python3 libvhdi-python3 libvmdk-python3 libvsgpt-python3 libvshadow-python3 libvslvm-python3 python3-acstore python3-artifacts python3-bencode python3-certifi python3-cffi-backend python3-chardet python3-cryptography python3-dateutil python3-defusedxml python3-dfdatetime python3-dfvfs python3-dfwinreg python3-distutils python3-dtfabric python3-fakeredis python3-flor python3-future python3-idna python3-lz4 python3-mock python3-opensearch python3-pefile python3-pip python3-psutil python3-pyparsing python3-pytsk3 python3-pyxattr python3-redis python3-requests python3-setuptools python3-six python3-tz python3-urllib3 python3-xlsxwriter python3-yaml python3-yara python3-zmq
+        apt-get install -y build-essential git libffi-dev python${{ matrix.python-version }} python${{ matrix.python-version }}-dev python${{ matrix.python-version }}-venv libbde-python3 libcaes-python3 libcreg-python3 libesedb-python3 libevt-python3 libevtx-python3 libewf-python3 libfsapfs-python3 libfsext-python3 libfsfat-python3 libfshfs-python3 libfsntfs-python3 libfsxfs-python3 libfvde-python3 libfwnt-python3 libfwsi-python3 liblnk-python3 libluksde-python3 libmodi-python3 libmsiecf-python3 libolecf-python3 libphdi-python3 libqcow-python3 libregf-python3 libscca-python3 libsigscan-python3 libsmdev-python3 libsmraw-python3 libssl-dev libvhdi-python3 libvmdk-python3 libvsgpt-python3 libvshadow-python3 libvslvm-python3 python3-acstore python3-artifacts python3-bencode python3-certifi python3-cffi-backend python3-chardet python3-cryptography python3-dateutil python3-defusedxml python3-dfdatetime python3-dfvfs python3-dfwinreg python3-distutils python3-dtfabric python3-fakeredis python3-flor python3-future python3-idna python3-lz4 python3-mock python3-opensearch python3-pefile python3-pip python3-psutil python3-pyparsing python3-pytsk3 python3-pyxattr python3-redis python3-requests python3-setuptools python3-six python3-tz python3-urllib3 python3-xlsxwriter python3-yaml python3-yara python3-zmq
     - name: Install tox
       run: |
         python3 -m pip install tox
     - name: Run tests
       env:
         LANG: en_US.UTF-8
       run: |
```

### Comparing `plaso-20230311/.pylintrc` & `plaso-20230717/.pylintrc`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,22 @@
-# Pylint 2.14.x configuration file
+# Pylint 2.17.x configuration file
 #
 # This file is generated by l2tdevtools update-dependencies.py, any dependency
 # related changes should be made in dependencies.ini.
 [MAIN]
 
 # Analyse import fallback blocks. This can be used to support both Python 2 and
 # 3 compatible code, which means that the block might have code that exists
 # only in one or another interpreter, leading to false positives when analysed.
 analyse-fallback-blocks=no
 
+# Clear in-memory caches upon conclusion of linting. Useful if running pylint
+# in a server-like mode.
+clear-cache-post-run=no
+
 # Load and enable all available extensions. Use --list-extensions to see a list
 # all available extensions.
 #enable-all-extensions=
 
 # In error mode, messages with a category besides ERROR or FATAL are
 # suppressed, and no reports are done by default. Error mode is compatible with
 # disabling specific errors.
@@ -21,44 +25,46 @@
 # Always return a 0 (non-error) status code, even if lint errors are found.
 # This is primarily useful in continuous integration scripts.
 #exit-zero=
 
 # A comma-separated list of package or module names from where C extensions may
 # be loaded. Extensions are loading into the active Python interpreter and may
 # run arbitrary code.
-extension-pkg-allow-list=pybde,pycreg,pyesedb,pyevt,pyevtx,pyewf,pyfsapfs,pyfsext,pyfshfs,pyfsntfs,pyfsxfs,pyfvde,pyfwnt,pyfwsi,pylnk,pyluksde,pymodi,pymsiecf,pyolecf,pyphdi,pyqcow,pyregf,pyscca,pysigscan,pysmdev,pysmraw,pytsk3,pyvhdi,pyvmdk,pyvsgpt,pyvshadow,pyvslvm,xattr,yara
+extension-pkg-allow-list=pybde,pycaes,pycreg,pyesedb,pyevt,pyevtx,pyewf,pyfsapfs,pyfsext,pyfsfat,pyfshfs,pyfsntfs,pyfsxfs,pyfvde,pyfwnt,pyfwsi,pylnk,pyluksde,pymodi,pymsiecf,pyolecf,pyphdi,pyqcow,pyregf,pyscca,pysigscan,pysmdev,pysmraw,pytsk3,pyvhdi,pyvmdk,pyvsgpt,pyvshadow,pyvslvm,xattr,yara
 
 # A comma-separated list of package or module names from where C extensions may
 # be loaded. Extensions are loading into the active Python interpreter and may
 # run arbitrary code. (This is an alternative name to extension-pkg-allow-list
 # for backward compatibility.)
 extension-pkg-whitelist=
 
 # Return non-zero exit code if any of these messages/categories are detected,
 # even if score is above --fail-under value. Syntax same as enable. Messages
 # specified are enabled, while categories only check already-enabled messages.
 fail-on=
 
-# Specify a score threshold to be exceeded before program exits with error.
+# Specify a score threshold under which the program will exit with error.
 fail-under=10
 
 # Interpret the stdin as a python script, whose filename needs to be passed as
 # the module_or_package argument.
 #from-stdin=
 
 # Files or directories to be skipped. They should be base names, not paths.
 ignore=CVS
 
-# Add files or directories matching the regex patterns to the ignore-list. The
-# regex matches against paths and can be in Posix or Windows format.
+# Add files or directories matching the regular expressions patterns to the
+# ignore-list. The regex matches against paths and can be in Posix or Windows
+# format. Because '\\' represents the directory delimiter on Windows systems,
+# it can't be used as an escape character.
 ignore-paths=
 
-# Files or directories matching the regex patterns are skipped. The regex
-# matches against base names, not paths. The default value ignores Emacs file
-# locks
+# Files or directories matching the regular expression patterns are skipped.
+# The regex matches against base names, not paths. The default value ignores
+# Emacs file locks
 ignore-patterns=^\.#
 
 # List of module names for which member attributes should not be checked
 # (useful for modules/projects where namespaces are manipulated during runtime
 # and thus existing member attributes cannot be deduced by static analysis). It
 # supports qualified module names, as well as Unix pattern matching.
 ignored-modules=
@@ -89,249 +95,32 @@
 # the version used to run pylint.
 py-version=3.11
 
 # Discover python modules and packages in the file system subtree.
 # recursive=no
 recursive=yes
 
+# Add paths to the list of the source roots. Supports globbing patterns. The
+# source root is an absolute path or a path relative to the current working
+# directory used to determine a package namespace for modules located under the
+# source root.
+source-roots=
+
 # When enabled, pylint would attempt to guess common misconfiguration and emit
 # user-friendly hints instead of false-positive error messages.
 suggestion-mode=yes
 
 # Allow loading of arbitrary C extensions. Extensions are imported into the
 # active Python interpreter and may run arbitrary code.
 unsafe-load-any-extension=no
 
 # In verbose mode, extra non-checker-related info will be displayed.
 #verbose=
 
 
-[REPORTS]
-
-# Python expression which should return a score less than or equal to 10. You
-# have access to the variables 'fatal', 'error', 'warning', 'refactor',
-# 'convention', and 'info' which contain the number of messages in each
-# category, as well as 'statement' which is the total number of statements
-# analyzed. This score is used by the global evaluation report (RP0004).
-evaluation=max(0, 0 if fatal else 10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10))
-
-# Template used to display messages. This is a python new-style format string
-# used to format the message information. See doc for all details.
-msg-template=
-
-# Set the output format. Available formats are text, parseable, colorized, json
-# and msvs (visual studio). You can also give a reporter class, e.g.
-# mypackage.mymodule.MyReporterClass.
-#output-format=
-
-# Tells whether to display a full report or only the messages.
-reports=no
-
-# Activate the evaluation score.
-# score=yes
-score=no
-
-
-[MESSAGES CONTROL]
-
-# Only show warnings with the listed confidence levels. Leave empty to show
-# all. Valid levels: HIGH, CONTROL_FLOW, INFERENCE, INFERENCE_FAILURE,
-# UNDEFINED.
-confidence=HIGH,
-           CONTROL_FLOW,
-           INFERENCE,
-           INFERENCE_FAILURE,
-           UNDEFINED
-
-# Disable the message, report, category or checker with the given id(s). You
-# can either give multiple identifiers separated by comma (,) or put this
-# option multiple times (only on the command line, not in the configuration
-# file where it should appear only once). You can also use "--disable=all" to
-# disable everything first and then re-enable specific checks. For example, if
-# you want to run only the similarities checker, you can use "--disable=all
-# --enable=similarities". If you want to run only the classes checker, but have
-# no Warning level messages displayed, use "--disable=all --enable=classes
-# --disable=W".
-disable=assignment-from-none,
-        bad-inline-option,
-        consider-using-f-string,
-        deprecated-pragma,
-        duplicate-code,
-        file-ignored,
-        fixme,
-        locally-disabled,
-        logging-format-interpolation,
-        logging-fstring-interpolation,
-        missing-param-doc,
-        raise-missing-from,
-        raw-checker-failed,
-        super-with-arguments,
-        suppressed-message,
-        too-few-public-methods,
-        too-many-ancestors,
-        too-many-boolean-expressions,
-        too-many-branches,
-        too-many-instance-attributes,
-        too-many-lines,
-        too-many-locals,
-        too-many-nested-blocks,
-        too-many-public-methods,
-        too-many-return-statements,
-        too-many-statements,
-        unsubscriptable-object,
-        useless-object-inheritance,
-        useless-suppression
-
-# Enable the message, report, category or checker with the given id(s). You can
-# either give multiple identifier separated by comma (,) or put this option
-# multiple time (only on the command line, not in the configuration file where
-# it should appear only once). See also the "--disable" option for examples.
-enable=c-extension-no-member
-
-
-[VARIABLES]
-
-# List of additional names supposed to be defined in builtins. Remember that
-# you should avoid defining new builtins when possible.
-additional-builtins=
-
-# Tells whether unused global variables should be treated as a violation.
-allow-global-unused-variables=yes
-
-# List of names allowed to shadow builtins
-allowed-redefined-builtins=
-
-# List of strings which can identify a callback function by name. A callback
-# name must start or end with one of those strings.
-callbacks=cb_,
-          _cb
-
-# A regular expression matching the name of dummy variables (i.e. expected to
-# not be used).
-dummy-variables-rgx=_+$|(_[a-zA-Z0-9_]*[a-zA-Z0-9]+?$)|dummy|^ignored_|^unused_
-
-# Argument names that match this expression will be ignored. Default to name
-# with leading underscore.
-ignored-argument-names=_.*|^ignored_|^unused_
-
-# Tells whether we should check for unused import in __init__ files.
-init-import=no
-
-# List of qualified module names which can have objects that can redefine
-# builtins.
-redefining-builtins-modules=six.moves,past.builtins,future.builtins,builtins,io
-
-
-[TYPECHECK]
-
-# List of decorators that produce context managers, such as
-# contextlib.contextmanager. Add to this list to register other decorators that
-# produce valid context managers.
-contextmanager-decorators=contextlib.contextmanager
-
-# List of members which are set dynamically and missed by pylint inference
-# system, and so shouldn't trigger E1101 when accessed. Python regular
-# expressions are accepted.
-generated-members=
-
-# Tells whether to warn about missing members when the owner of the attribute
-# is inferred to be None.
-ignore-none=yes
-
-# This flag controls whether pylint should warn about no-member and similar
-# checks whenever an opaque object is returned when inferring. The inference
-# can return multiple potential results while evaluating a Python object, but
-# some branches might not be evaluated, which results in partial inference. In
-# that case, it might be useful to still emit no-member and other checks for
-# the rest of the inferred objects.
-ignore-on-opaque-inference=yes
-
-# List of symbolic message names to ignore for Mixin members.
-ignored-checks-for-mixins=no-member,
-                          not-async-context-manager,
-                          not-context-manager,
-                          attribute-defined-outside-init
-
-# List of class names for which member attributes should not be checked (useful
-# for classes with dynamically set attributes). This supports the use of
-# qualified names.
-ignored-classes=optparse.Values,thread._local,_thread._local,argparse.Namespace
-
-# Show a hint with possible names when a member name was not found. The aspect
-# of finding the hint is based on edit distance.
-missing-member-hint=yes
-
-# The minimum edit distance a name should have in order to be considered a
-# similar match for a missing member name.
-missing-member-hint-distance=1
-
-# The total number of similar names that should be taken in consideration when
-# showing a hint for a missing member.
-missing-member-max-choices=1
-
-# Regex pattern to define which classes are considered mixins.
-mixin-class-rgx=.*[Mm]ixin
-
-# List of decorators that change the signature of a decorated function.
-signature-mutators=
-
-
-[LOGGING]
-
-# The type of string formatting that logging methods do. `old` means using %
-# formatting, `new` is for `{}` formatting.
-logging-format-style=old
-
-# Logging modules to check that the string format arguments are in logging
-# function parameter format.
-logging-modules=logging
-
-
-[DESIGN]
-
-# List of regular expressions of class ancestor names to ignore when counting
-# public methods (see R0903)
-exclude-too-few-public-methods=
-
-# List of qualified class names to ignore when counting class parents (see
-# R0901)
-ignored-parents=
-
-# Maximum number of arguments for function / method.
-# max-args=5
-max-args=10
-
-# Maximum number of attributes for a class (see R0902).
-max-attributes=7
-
-# Maximum number of boolean expressions in an if statement (see R0916).
-max-bool-expr=5
-
-# Maximum number of branch for function / method body.
-max-branches=12
-
-# Maximum number of locals for function / method body.
-max-locals=15
-
-# Maximum number of parents for a class (see R0901).
-max-parents=7
-
-# Maximum number of public methods for a class (see R0904).
-max-public-methods=20
-
-# Maximum number of return / yield for function / method body.
-max-returns=6
-
-# Maximum number of statements in function / method body.
-max-statements=50
-
-# Minimum number of public methods for a class (see R0903).
-min-public-methods=2
-
-
 [BASIC]
 
 # Naming style matching correct argument names.
 argument-naming-style=snake_case
 
 # Regular expression matching correct argument names. Overrides argument-
 # naming-style. If left empty, argument names will be checked with the set
@@ -456,70 +245,102 @@
 no-docstring-rgx=^_
 
 # List of decorators that produce properties, such as abc.abstractproperty. Add
 # to this list to register other decorators that produce valid properties.
 # These decorators are taken in consideration only for invalid-name.
 property-classes=abc.abstractproperty
 
+# Regular expression matching correct type alias names. If left empty, type
+# alias names will be checked with the set naming style.
+#typealias-rgx=
+
 # Regular expression matching correct type variable names. If left empty, type
 # variable names will be checked with the set naming style.
 #typevar-rgx=
 
 # Naming style matching correct variable names.
 variable-naming-style=snake_case
 
 # Regular expression matching correct variable names. Overrides variable-
 # naming-style. If left empty, variable names will be checked with the set
 # naming style.
 #variable-rgx=
 variable-rgx=(([a-z][a-z0-9_]*)|(_[a-z0-9_]*))$
 
 
-[EXCEPTIONS]
-
-# Exceptions that will emit a warning when caught.
-overgeneral-exceptions=BaseException,
-                       Exception
-
-
 [CLASSES]
 
 # Warn about protected attribute access inside special methods
 check-protected-access-in-special-methods=no
 
 # List of method names used to declare (i.e. assign) instance attributes.
 defining-attr-methods=__init__,
                       __new__,
                       setUp,
+                      asyncSetUp,
                       __post_init__
 
 # List of member names, which should be excluded from the protected access
 # warning.
-exclude-protected=_asdict,
-                  _fields,
-                  _replace,
-                  _source,
-                  _make
+exclude-protected=_asdict,_fields,_replace,_source,_make,os._exit
 
 # List of valid names for the first argument in a class method.
 valid-classmethod-first-arg=cls
 
 # List of valid names for the first argument in a metaclass class method.
+# valid-metaclass-classmethod-first-arg=mcs
 valid-metaclass-classmethod-first-arg=cls
 
 
-[MISCELLANEOUS]
+[DESIGN]
 
-# List of note tags to take in consideration, separated by a comma.
-notes=FIXME,
-      XXX,
-      TODO
+# List of regular expressions of class ancestor names to ignore when counting
+# public methods (see R0903)
+exclude-too-few-public-methods=
 
-# Regular expression of note tags to take in consideration.
-notes-rgx=
+# List of qualified class names to ignore when counting class parents (see
+# R0901)
+ignored-parents=
+
+# Maximum number of arguments for function / method.
+# max-args=5
+max-args=10
+
+# Maximum number of attributes for a class (see R0902).
+max-attributes=7
+
+# Maximum number of boolean expressions in an if statement (see R0916).
+max-bool-expr=5
+
+# Maximum number of branch for function / method body.
+max-branches=12
+
+# Maximum number of locals for function / method body.
+max-locals=15
+
+# Maximum number of parents for a class (see R0901).
+max-parents=7
+
+# Maximum number of public methods for a class (see R0904).
+max-public-methods=20
+
+# Maximum number of return / yield for function / method body.
+max-returns=6
+
+# Maximum number of statements in function / method body.
+max-statements=50
+
+# Minimum number of public methods for a class (see R0903).
+min-public-methods=2
+
+
+[EXCEPTIONS]
+
+# Exceptions that will emit a warning when caught.
+overgeneral-exceptions=builtins.BaseException,builtins.Exception
 
 
 [FORMAT]
 
 # Expected format of line ending, e.g. empty (any line ending), LF or CRLF.
 expected-line-ending-format=
 
@@ -546,14 +367,196 @@
 single-line-class-stmt=no
 
 # Allow the body of an if to be on the same line as the test if there is no
 # else.
 single-line-if-stmt=no
 
 
+[IMPORTS]
+
+# List of modules that can be imported at any level, not just the top level
+# one.
+allow-any-import-level=
+
+# Allow explicit reexports by alias from a package __init__.
+allow-reexport-from-package=no
+
+# Allow wildcard imports from modules that define __all__.
+allow-wildcard-with-all=no
+
+# Deprecated modules which should not be used, separated by a comma.
+deprecated-modules=
+
+# Output a graph (.gv or any supported image format) of external dependencies
+# to the given file (report RP0402 must not be disabled).
+ext-import-graph=
+
+# Output a graph (.gv or any supported image format) of all (i.e. internal and
+# external) dependencies to the given file (report RP0402 must not be
+# disabled).
+import-graph=
+
+# Output a graph (.gv or any supported image format) of internal dependencies
+# to the given file (report RP0402 must not be disabled).
+int-import-graph=
+
+# Force import order to recognize a module as part of the standard
+# compatibility libraries.
+known-standard-library=
+
+# Force import order to recognize a module as part of a third party library.
+known-third-party=enchant
+
+# Couples of modules and preferred modules, separated by a comma.
+preferred-modules=
+
+
+[LOGGING]
+
+# The type of string formatting that logging methods do. `old` means using %
+# formatting, `new` is for `{}` formatting.
+logging-format-style=old
+
+# Logging modules to check that the string format arguments are in logging
+# function parameter format.
+logging-modules=logging
+
+
+[MESSAGES CONTROL]
+
+# Only show warnings with the listed confidence levels. Leave empty to show
+# all. Valid levels: HIGH, CONTROL_FLOW, INFERENCE, INFERENCE_FAILURE,
+# UNDEFINED.
+confidence=HIGH,
+           CONTROL_FLOW,
+           INFERENCE,
+           INFERENCE_FAILURE,
+           UNDEFINED
+
+# Disable the message, report, category or checker with the given id(s). You
+# can either give multiple identifiers separated by comma (,) or put this
+# option multiple times (only on the command line, not in the configuration
+# file where it should appear only once). You can also use "--disable=all" to
+# disable everything first and then re-enable specific checks. For example, if
+# you want to run only the similarities checker, you can use "--disable=all
+# --enable=similarities". If you want to run only the classes checker, but have
+# no Warning level messages displayed, use "--disable=all --enable=classes
+# --disable=W".
+disable=assignment-from-none,
+        bad-inline-option,
+        consider-using-f-string,
+        deprecated-pragma,
+        duplicate-code,
+        file-ignored,
+        fixme,
+        locally-disabled,
+        logging-format-interpolation,
+        logging-fstring-interpolation,
+        missing-param-doc,
+        raise-missing-from,
+        raw-checker-failed,
+        super-with-arguments,
+        suppressed-message,
+        too-few-public-methods,
+        too-many-ancestors,
+        too-many-boolean-expressions,
+        too-many-branches,
+        too-many-instance-attributes,
+        too-many-lines,
+        too-many-locals,
+        too-many-nested-blocks,
+        too-many-public-methods,
+        too-many-return-statements,
+        too-many-statements,
+        unsubscriptable-object,
+        useless-object-inheritance,
+        useless-suppression,
+        use-symbolic-message-instead
+
+# Enable the message, report, category or checker with the given id(s). You can
+# either give multiple identifier separated by comma (,) or put this option
+# multiple time (only on the command line, not in the configuration file where
+# it should appear only once). See also the "--disable" option for examples.
+enable=c-extension-no-member
+
+
+[METHOD_ARGS]
+
+# List of qualified names (i.e., library.method) which require a timeout
+# parameter e.g. 'requests.api.get,requests.api.post'
+timeout-methods=requests.api.delete,requests.api.get,requests.api.head,requests.api.options,requests.api.patch,requests.api.post,requests.api.put,requests.api.request
+
+
+[MISCELLANEOUS]
+
+# List of note tags to take in consideration, separated by a comma.
+notes=FIXME,
+      XXX,
+      TODO
+
+# Regular expression of note tags to take in consideration.
+notes-rgx=
+
+
+[REFACTORING]
+
+# Maximum number of nested blocks for function / method body
+max-nested-blocks=5
+
+# Complete name of functions that never returns. When checking for
+# inconsistent-return-statements if a never returning function is called then
+# it will be considered as an explicit return statement and no message will be
+# printed.
+never-returning-functions=sys.exit,argparse.parse_error
+
+
+[REPORTS]
+
+# Python expression which should return a score less than or equal to 10. You
+# have access to the variables 'fatal', 'error', 'warning', 'refactor',
+# 'convention', and 'info' which contain the number of messages in each
+# category, as well as 'statement' which is the total number of statements
+# analyzed. This score is used by the global evaluation report (RP0004).
+evaluation=max(0, 0 if fatal else 10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10))
+
+# Template used to display messages. This is a python new-style format string
+# used to format the message information. See doc for all details.
+msg-template=
+
+# Set the output format. Available formats are text, parseable, colorized, json
+# and msvs (visual studio). You can also give a reporter class, e.g.
+# mypackage.mymodule.MyReporterClass.
+#output-format=
+
+# Tells whether to display a full report or only the messages.
+reports=no
+
+# Activate the evaluation score.
+# score=yes
+score=no
+
+
+[SIMILARITIES]
+
+# Comments are removed from the similarity computation
+ignore-comments=yes
+
+# Docstrings are removed from the similarity computation
+ignore-docstrings=yes
+
+# Imports are removed from the similarity computation
+ignore-imports=yes
+
+# Signatures are removed from the similarity computation
+ignore-signatures=yes
+
+# Minimum lines number of a similarity.
+min-similarity-lines=4
+
+
 [SPELLING]
 
 # Limits count of emitted suggestions for spelling mistakes.
 max-spelling-suggestions=4
 
 # Spelling dictionary name. Available dictionaries: en_AG (hunspell), en_AU
 # (hunspell), en_BS (hunspell), en_BW (hunspell), en_BZ (hunspell), en_CA
@@ -575,82 +578,102 @@
 spelling-private-dict-file=
 
 # Tells whether to store unknown words to the private dictionary (see the
 # --spelling-private-dict-file option) instead of raising a message.
 spelling-store-unknown-words=no
 
 
-[SIMILARITIES]
-
-# Comments are removed from the similarity computation
-ignore-comments=yes
-
-# Docstrings are removed from the similarity computation
-ignore-docstrings=yes
-
-# Imports are removed from the similarity computation
-ignore-imports=yes
-
-# Signatures are removed from the similarity computation
-ignore-signatures=yes
-
-# Minimum lines number of a similarity.
-min-similarity-lines=4
-
-
 [STRING]
 
 # This flag controls whether inconsistent-quotes generates a warning when the
 # character used as a quote delimiter is used inconsistently within a module.
 check-quote-consistency=no
 
 # This flag controls whether the implicit-str-concat should generate a warning
 # on implicit string concatenation in sequences defined over several lines.
 check-str-concat-over-line-jumps=no
 
 
-[IMPORTS]
+[TYPECHECK]
 
-# List of modules that can be imported at any level, not just the top level
-# one.
-allow-any-import-level=
+# List of decorators that produce context managers, such as
+# contextlib.contextmanager. Add to this list to register other decorators that
+# produce valid context managers.
+contextmanager-decorators=contextlib.contextmanager
 
-# Allow wildcard imports from modules that define __all__.
-allow-wildcard-with-all=no
+# List of members which are set dynamically and missed by pylint inference
+# system, and so shouldn't trigger E1101 when accessed. Python regular
+# expressions are accepted.
+generated-members=
 
-# Deprecated modules which should not be used, separated by a comma.
-deprecated-modules=
+# Tells whether to warn about missing members when the owner of the attribute
+# is inferred to be None.
+ignore-none=yes
 
-# Output a graph (.gv or any supported image format) of external dependencies
-# to the given file (report RP0402 must not be disabled).
-ext-import-graph=
+# This flag controls whether pylint should warn about no-member and similar
+# checks whenever an opaque object is returned when inferring. The inference
+# can return multiple potential results while evaluating a Python object, but
+# some branches might not be evaluated, which results in partial inference. In
+# that case, it might be useful to still emit no-member and other checks for
+# the rest of the inferred objects.
+ignore-on-opaque-inference=yes
 
-# Output a graph (.gv or any supported image format) of all (i.e. internal and
-# external) dependencies to the given file (report RP0402 must not be
-# disabled).
-import-graph=
+# List of symbolic message names to ignore for Mixin members.
+ignored-checks-for-mixins=no-member,
+                          not-async-context-manager,
+                          not-context-manager,
+                          attribute-defined-outside-init
 
-# Output a graph (.gv or any supported image format) of internal dependencies
-# to the given file (report RP0402 must not be disabled).
-int-import-graph=
+# List of class names for which member attributes should not be checked (useful
+# for classes with dynamically set attributes). This supports the use of
+# qualified names.
+ignored-classes=optparse.Values,thread._local,_thread._local,argparse.Namespace
 
-# Force import order to recognize a module as part of the standard
-# compatibility libraries.
-known-standard-library=
+# Show a hint with possible names when a member name was not found. The aspect
+# of finding the hint is based on edit distance.
+missing-member-hint=yes
 
-# Force import order to recognize a module as part of a third party library.
-known-third-party=enchant
+# The minimum edit distance a name should have in order to be considered a
+# similar match for a missing member name.
+missing-member-hint-distance=1
 
-# Couples of modules and preferred modules, separated by a comma.
-preferred-modules=
+# The total number of similar names that should be taken in consideration when
+# showing a hint for a missing member.
+missing-member-max-choices=1
 
+# Regex pattern to define which classes are considered mixins.
+mixin-class-rgx=.*[Mm]ixin
 
-[REFACTORING]
+# List of decorators that change the signature of a decorated function.
+signature-mutators=
 
-# Maximum number of nested blocks for function / method body
-max-nested-blocks=5
 
-# Complete name of functions that never returns. When checking for
-# inconsistent-return-statements if a never returning function is called then
-# it will be considered as an explicit return statement and no message will be
-# printed.
-never-returning-functions=sys.exit,argparse.parse_error
+[VARIABLES]
+
+# List of additional names supposed to be defined in builtins. Remember that
+# you should avoid defining new builtins when possible.
+additional-builtins=
+
+# Tells whether unused global variables should be treated as a violation.
+allow-global-unused-variables=yes
+
+# List of names allowed to shadow builtins
+allowed-redefined-builtins=
+
+# List of strings which can identify a callback function by name. A callback
+# name must start or end with one of those strings.
+callbacks=cb_,
+          _cb
+
+# A regular expression matching the name of dummy variables (i.e. expected to
+# not be used).
+dummy-variables-rgx=_+$|(_[a-zA-Z0-9_]*[a-zA-Z0-9]+?$)|dummy|^ignored_|^unused_
+
+# Argument names that match this expression will be ignored.
+ignored-argument-names=_.*|^ignored_|^unused_
+
+# Tells whether we should check for unused import in __init__ files.
+init-import=no
+
+# List of qualified module names which can have objects that can redefine
+# builtins.
+redefining-builtins-modules=six.moves,past.builtins,future.builtins,builtins,io
```

### Comparing `plaso-20230311/ACKNOWLEDGEMENTS` & `plaso-20230717/ACKNOWLEDGEMENTS`

 * *Files identical despite different names*

### Comparing `plaso-20230311/AUTHORS` & `plaso-20230717/AUTHORS`

 * *Files identical despite different names*

### Comparing `plaso-20230311/CONTRIBUTING.md` & `plaso-20230717/CONTRIBUTING.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/LICENSE` & `plaso-20230717/LICENSE`

 * *Files identical despite different names*

### Comparing `plaso-20230311/MANIFEST.in` & `plaso-20230717/MANIFEST.in`

 * *Files identical despite different names*

### Comparing `plaso-20230311/MANIFEST.test_data.in` & `plaso-20230717/MANIFEST.test_data.in`

 * *Files identical despite different names*

### Comparing `plaso-20230311/PKG-INFO` & `plaso-20230717/PKG-INFO`

 * *Files 19% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: plaso
-Version: 20230311
+Version: 20230717
 Summary: Plaso (log2timeline) - Super timeline all the things
 Home-page: https://github.com/log2timeline/plaso
 Maintainer: Log2Timeline maintainers
 Maintainer-email: log2timeline-maintainers@googlegroups.com
 License: Apache License, Version 2.0
 Classifier: Development Status :: 4 - Beta
 Classifier: Environment :: Console
```

### Comparing `plaso-20230311/README` & `plaso-20230717/README`

 * *Files identical despite different names*

### Comparing `plaso-20230311/README.md` & `plaso-20230717/README.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/appveyor.yml` & `plaso-20230717/appveyor.yml`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 environment:
   matrix:
-  - DESCRIPTION: "Windows with 32-bit Python 3.10"
+  - DESCRIPTION: "Windows with 32-bit Python 3.11"
     MACHINE_TYPE: "x86"
-    APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019
-    PYTHON: "C:\\Python310"
-    PYTHON_VERSION: "3.10"
+    APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2022
+    PYTHON: "C:\\Python311"
+    PYTHON_VERSION: "3.11"
     L2TBINARIES_TRACK: "dev"
-  - DESCRIPTION: "Windows with 64-bit Python 3.10"
+  - DESCRIPTION: "Windows with 64-bit Python 3.11"
     MACHINE_TYPE: "amd64"
-    APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2019
-    PYTHON: "C:\\Python310-x64"
-    PYTHON_VERSION: "3.10"
+    APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2022
+    PYTHON: "C:\\Python311-x64"
+    PYTHON_VERSION: "3.11"
     L2TBINARIES_TRACK: "dev"
   - DESCRIPTION: "Mac OS with Python 3.11"
     APPVEYOR_BUILD_WORKER_IMAGE: macos-monterey
     HOMEBREW_NO_INSTALL_CLEANUP: 1
 
 install:
 - cmd: "%PYTHON%\\python.exe -m pip install -U pip setuptools twine wheel"
```

### Comparing `plaso-20230311/config/appveyor/install.ps1` & `plaso-20230717/config/appveyor/install.ps1`

 * *Files 19% similar despite different names*

```diff
@@ -1,23 +1,27 @@
 # Script to set up tests on AppVeyor Windows.
 
-$Dependencies = "PyYAML XlsxWriter acstore artifacts bencode certifi cffi chardet cryptography dateutil defusedxml dfdatetime dfvfs dfwinreg dtfabric fakeredis future idna libbde libcreg libesedb libevt libevtx libewf libfsapfs libfsext libfsfat libfshfs libfsntfs libfsxfs libfvde libfwnt libfwsi liblnk libluksde libmodi libmsiecf libolecf libphdi libqcow libregf libscca libsigscan libsmdev libsmraw libvhdi libvmdk libvsgpt libvshadow libvslvm lz4 mock opensearch-py pefile psutil pyparsing pytsk3 pytz pyzmq redis requests six urllib3 xattr yara-python"
-$Dependencies = ${Dependencies} -split " "
+$Dependencies = "PyYAML XlsxWriter acstore artifacts bencode certifi cffi chardet cryptography dateutil defusedxml dfdatetime dfvfs dfwinreg dtfabric fakeredis future idna libbde libcaes libcreg libesedb libevt libevtx libewf libfsapfs libfsext libfsfat libfshfs libfsntfs libfsxfs libfvde libfwnt libfwsi liblnk libluksde libmodi libmsiecf libolecf libphdi libqcow libregf libscca libsigscan libsmdev libsmraw libvhdi libvmdk libvsgpt libvshadow libvslvm lz4 mock opensearch-py pefile psutil pyparsing pytsk3 pytz pyzmq redis requests six urllib3 xattr yara-python"
 
-$Output = Invoke-Expression -Command "git clone https://github.com/log2timeline/l2tdevtools.git ..\l2tdevtools 2>&1"
-Write-Host (${Output} | Out-String)
-
-If ($env:APPVEYOR_REPO_BRANCH -eq "main")
-{
-	$Track = "stable"
-}
-Else
+If ($Dependencies.Length -gt 0)
 {
-	$Track = $env:APPVEYOR_REPO_BRANCH
-}
-New-Item -ItemType "directory" -Name "dependencies"
+	$Dependencies = ${Dependencies} -split " "
 
-$env:PYTHONPATH = "..\l2tdevtools"
+	$Output = Invoke-Expression -Command "git clone https://github.com/log2timeline/l2tdevtools.git ..\l2tdevtools 2>&1" | %{ "$_" }
+	Write-Host (${Output} | Out-String)
 
-$Output = Invoke-Expression -Command "& '${env:PYTHON}\python.exe' ..\l2tdevtools\tools\update.py --download-directory dependencies --machine-type ${env:MACHINE_TYPE} --msi-targetdir ${env:PYTHON} --track ${env:L2TBINARIES_TRACK} ${Dependencies} 2>&1"
-Write-Host (${Output} | Out-String)
+	If ($env:APPVEYOR_REPO_BRANCH -eq "main")
+	{
+		$Track = "stable"
+	}
+	Else
+	{
+		$Track = $env:APPVEYOR_REPO_BRANCH
+	}
+	New-Item -ItemType "directory" -Name "dependencies"
+
+	$env:PYTHONPATH = "..\l2tdevtools"
+
+	$Output = Invoke-Expression -Command "& '${env:PYTHON}\python.exe' ..\l2tdevtools\tools\update.py --download-directory dependencies --machine-type ${env:MACHINE_TYPE} --msi-targetdir ${env:PYTHON} --track ${env:L2TBINARIES_TRACK} ${Dependencies} 2>&1" | %{ "$_" }
+	Write-Host (${Output} | Out-String)
+}
```

### Comparing `plaso-20230311/config/appveyor/runtests.sh` & `plaso-20230717/config/appveyor/runtests.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/deployment/fedora36.Dockerfile` & `plaso-20230717/config/deployment/fedora36.Dockerfile`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/deployment/ubuntu20.04.Dockerfile` & `plaso-20230717/config/deployment/ubuntu20.04.Dockerfile`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/docker/Dockerfile` & `plaso-20230717/config/docker/Dockerfile`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/docker/plaso-switch.sh` & `plaso-20230717/config/docker/plaso-switch.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/dpkg/control` & `plaso-20230717/config/dpkg/control`

 * *Files 5% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 Description: Data files for plaso (log2timeline)
  Plaso (log2timeline) is a framework to create super timelines. Its
  purpose is to extract timestamps from various files found on typical
  computer systems and aggregate them.
 
 Package: python3-plaso
 Architecture: all
-Depends: plaso-data (>= ${binary:Version}), libbde-python3 (>= 20220121), libcreg-python3 (>= 20200725), libesedb-python3 (>= 20220806), libevt-python3 (>= 20191104), libevtx-python3 (>= 20220724), libewf-python3 (>= 20131210), libfsapfs-python3 (>= 20201107), libfsext-python3 (>= 20220112), libfsfat-python3 (>= 20220816), libfshfs-python3 (>= 20220115), libfsntfs-python3 (>= 20211229), libfsxfs-python3 (>= 20220113), libfvde-python3 (>= 20220121), libfwnt-python3 (>= 20210717), libfwsi-python3 (>= 20150606), liblnk-python3 (>= 20230205), libluksde-python3 (>= 20220121), libmodi-python3 (>= 20210405), libmsiecf-python3 (>= 20150314), libolecf-python3 (>= 20151223), libphdi-python3 (>= 20220110), libqcow-python3 (>= 20201213), libregf-python3 (>= 20201002), libscca-python3 (>= 20190605), libsigscan-python3 (>= 20230109), libsmdev-python3 (>= 20140529), libsmraw-python3 (>= 20140612), libvhdi-python3 (>= 20201014), libvmdk-python3 (>= 20140421), libvsgpt-python3 (>= 20211115), libvshadow-python3 (>= 20160109), libvslvm-python3 (>= 20160109), python3-acstore (>= 20230101), python3-artifacts (>= 20220219), python3-bencode, python3-certifi (>= 2016.9.26), python3-cffi-backend (>= 1.9.1), python3-chardet (>= 2.0.1), python3-cryptography (>= 2.0.2), python3-dateutil (>= 1.5), python3-defusedxml (>= 0.5.0), python3-dfdatetime (>= 20221112), python3-dfvfs (>= 20221224), python3-dfwinreg (>= 20211207), python3-dtfabric (>= 20220219), python3-flor (>= 1.1.3), python3-future (>= 0.16.0), python3-idna (>= 2.5), python3-lz4 (>= 0.10.0), python3-opensearch, python3-pefile (>= 2021.5.24), python3-psutil (>= 5.4.3), python3-pyparsing (>= 2.4.2), python3-pytsk3 (>= 20210419), python3-pyxattr (>= 0.7.2), python3-redis (>= 3.4), python3-requests (>= 2.18.0), python3-six (>= 1.1.0), python3-tz, python3-urllib3 (>= 1.21.1), python3-xlsxwriter (>= 0.9.3), python3-yaml (>= 3.10), python3-yara (>= 3.4.0), python3-zmq (>= 2.1.11), ${misc:Depends}
+Depends: plaso-data (>= ${binary:Version}), libbde-python3 (>= 20220121), libcaes-python3 (>= 20221127), libcreg-python3 (>= 20200725), libesedb-python3 (>= 20220806), libevt-python3 (>= 20191104), libevtx-python3 (>= 20220724), libewf-python3 (>= 20131210), libfsapfs-python3 (>= 20201107), libfsext-python3 (>= 20220112), libfsfat-python3 (>= 20220816), libfshfs-python3 (>= 20220115), libfsntfs-python3 (>= 20211229), libfsxfs-python3 (>= 20220113), libfvde-python3 (>= 20220121), libfwnt-python3 (>= 20210717), libfwsi-python3 (>= 20150606), liblnk-python3 (>= 20230205), libluksde-python3 (>= 20220121), libmodi-python3 (>= 20210405), libmsiecf-python3 (>= 20150314), libolecf-python3 (>= 20151223), libphdi-python3 (>= 20220110), libqcow-python3 (>= 20201213), libregf-python3 (>= 20201002), libscca-python3 (>= 20190605), libsigscan-python3 (>= 20230109), libsmdev-python3 (>= 20140529), libsmraw-python3 (>= 20140612), libvhdi-python3 (>= 20201014), libvmdk-python3 (>= 20140421), libvsgpt-python3 (>= 20211115), libvshadow-python3 (>= 20160109), libvslvm-python3 (>= 20160109), python3-acstore (>= 20230519), python3-artifacts (>= 20220219), python3-bencode, python3-certifi (>= 2016.9.26), python3-cffi-backend (>= 1.9.1), python3-chardet (>= 2.0.1), python3-cryptography (>= 2.0.2), python3-dateutil (>= 1.5), python3-defusedxml (>= 0.5.0), python3-dfdatetime (>= 20221112), python3-dfvfs (>= 20230407), python3-dfwinreg (>= 20211207), python3-dtfabric (>= 20230518), python3-flor (>= 1.1.3), python3-future (>= 0.16.0), python3-idna (>= 2.5), python3-lz4 (>= 0.10.0), python3-opensearch, python3-pefile (>= 2021.5.24), python3-psutil (>= 5.4.3), python3-pyparsing (>= 2.4.2), python3-pytsk3 (>= 20210419), python3-pyxattr (>= 0.7.2), python3-redis (>= 3.4), python3-requests (>= 2.18.0), python3-six (>= 1.1.0), python3-tz, python3-urllib3 (>= 1.21.1), python3-xlsxwriter (>= 0.9.3), python3-yaml (>= 3.10), python3-yara (>= 3.4.0), python3-zmq (>= 2.1.11), ${misc:Depends}
 Description: Python 3 module of plaso (log2timeline)
  Plaso (log2timeline) is a framework to create super timelines. Its
  purpose is to extract timestamps from various files found on typical
  computer systems and aggregate them.
 
 Package: plaso-tools
 Architecture: all
```

### Comparing `plaso-20230311/config/dpkg/copyright` & `plaso-20230717/config/dpkg/copyright`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/end-to-end.ini` & `plaso-20230717/config/end-to-end.ini`

 * *Files 1% similar despite different names*

```diff
@@ -48,14 +48,24 @@
 extract_options=--no-vss
 output_file=extract_and_output4.log
 output_format=dynamic
 output_options=--dynamic-time
 reference_output_file=test_data/end_to_end/extract_and_output.log
 source=test_data/vsstest.qcow2
 
+[extract_and_output5]
+case=extract_and_output
+extract_options=--no-vss
+output_file=extract_and_output5.log
+output_format=dynamic
+output_options=--dynamic-time
+custom_formatter_file=test_data/custom_formatters.yaml
+reference_output_file=test_data/end_to_end/extract_and_output_with_custom_formatter.log
+source=test_data/vsstest.qcow2
+
 [extract_and_output_empty]
 case=extract_and_output
 extract_options=--no-vss --parsers=bodyfile
 output_file=extract_and_output_empty.log
 output_format=dynamic
 output_options=--dynamic-time
 reference_output_file=test_data/end_to_end/extract_and_output_empty.log
```

### Comparing `plaso-20230311/config/end_to_end/extract_and_output.Dockerfile` & `plaso-20230717/config/end_to_end/extract_and_output.Dockerfile`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/end_to_end/run_tests_with_docker.sh` & `plaso-20230717/config/end_to_end/run_tests_with_docker.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/jenkins/linux/run_end_to_end_tests.sh` & `plaso-20230717/config/jenkins/linux/run_end_to_end_tests.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/linux/gift_copr_install.sh` & `plaso-20230717/config/linux/gift_copr_install.sh`

 * *Files 0% similar despite different names*

```diff
@@ -5,14 +5,15 @@
 
 # Exit on error.
 set -e
 
 # Dependencies for running plaso, alphabetized, one per line.
 # This should not include packages only required for testing or development.
 PYTHON3_DEPENDENCIES="libbde-python3
+                      libcaes-python3
                       libcreg-python3
                       libesedb-python3
                       libevt-python3
                       libevtx-python3
                       libewf-python3
                       libfsapfs-python3
                       libfsext-python3
@@ -80,14 +81,16 @@
 # Additional dependencies for development, alphabetized, one per line.
 DEVELOPMENT_DEPENDENCIES="pylint
                           python-sphinx";
 
 # Additional dependencies for debugging, alphabetized, one per line.
 DEBUG_DEPENDENCIES="libbde-debuginfo
                     libbde-python3-debuginfo
+                    libcaes-debuginfo
+                    libcaes-python3-debuginfo
                     libcreg-debuginfo
                     libcreg-python3-debuginfo
                     libesedb-debuginfo
                     libesedb-python3-debuginfo
                     libevt-debuginfo
                     libevt-python3-debuginfo
                     libevtx-debuginfo
```

### Comparing `plaso-20230311/config/linux/ubuntu_install_nsrlsvr.sh` & `plaso-20230717/config/linux/ubuntu_install_nsrlsvr.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/linux/ubuntu_install_opensearch.sh` & `plaso-20230717/config/linux/ubuntu_install_opensearch.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/linux/ubuntu_install_plaso.sh` & `plaso-20230717/config/linux/ubuntu_install_plaso.sh`

 * *Files 5% similar despite different names*

```diff
@@ -12,14 +12,15 @@
 GIFT_PPA_TRACK=${GIFT_PPA_TRACK:-dev}
 
 export DEBIAN_FRONTEND=noninteractive
 
 # Dependencies for running plaso, alphabetized, one per line.
 # This should not include packages only required for testing or development.
 PYTHON_DEPENDENCIES="libbde-python3
+                     libcaes-python3
                      libcreg-python3
                      libesedb-python3
                      libevt-python3
                      libevtx-python3
                      libewf-python3
                      libfsapfs-python3
                      libfsext-python3
@@ -89,14 +90,16 @@
 # Additional dependencies for development, alphabetized, one per line.
 DEVELOPMENT_DEPENDENCIES="pylint
                           python-sphinx";
 
 # Additional dependencies for debugging, alphabetized, one per line.
 DEBUG_DEPENDENCIES="libbde-dbg
                     libbde-python3-dbg
+                    libcaes-dbg
+                    libcaes-python3-dbg
                     libcreg-dbg
                     libcreg-python3-dbg
                     libesedb-dbg
                     libesedb-python3-dbg
                     libevt-dbg
                     libevt-python3-dbg
                     libevtx-dbg
```

### Comparing `plaso-20230311/config/logo.jpg` & `plaso-20230717/config/logo.jpg`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/pylint/spelling-private-dict` & `plaso-20230717/config/pylint/spelling-private-dict`

 * *Files identical despite different names*

### Comparing `plaso-20230311/config/tests/generate_test_files.sh` & `plaso-20230717/config/tests/generate_test_files.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/filter_windows.txt` & `plaso-20230717/data/filter_windows.txt`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/filter_windows.yaml` & `plaso-20230717/data/filter_windows.yaml`

 * *Files 1% similar despite different names*

```diff
@@ -67,14 +67,15 @@
 - '%SystemRoot%\\System32\\winevt\\Logs\\.+[.]evtx'
 - '%SystemRoot%\\System32\\config\\.+[.]evt'
 ---
 description: Various log files.
 type: include
 path_separator: '\'
 paths:
+- '%SystemRoot%\\appcompat\\pca\\.+[.]txt'
 - '%SystemRoot%\\inf\\setupapi[.].+[.]log'
 - '%SystemRoot%\\setupapi.log'
 - '%SystemRoot%\\System32\\LogFiles\\.+\\.+[.]txt'
 ---
 description: Windows User Access Logging (UAL) database files.
 type: include
 path_separator: '\'
```

### Comparing `plaso-20230311/data/formatters/android.yaml` & `plaso-20230717/data/formatters/android.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/formatters/antivirus.yaml` & `plaso-20230717/data/formatters/antivirus.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/formatters/browser.yaml` & `plaso-20230717/data/formatters/browser.yaml`

 * *Files 0% similar despite different names*

```diff
@@ -189,15 +189,16 @@
     4: 'SOURCE_IE_IMPORTED'
     5: 'SOURCE_SAFARI_IMPORTED'
 message:
 - '{url}'
 - '({title})'
 - '[count: {typed_count}]'
 - 'Visit from: {from_visit}'
-- 'Visit Source: [{visit_source}]'
+- 'Visit source: [{visit_source}]'
+- 'Visit count: {visit_count}'
 - 'Type: [{page_transition}]'
 - '{url_hidden_string}'
 - '{url_typed_string}'
 short_message:
 - '{url}'
 - '({title})'
 short_source: 'WEBHIST'
@@ -487,14 +488,27 @@
 - 'Set identifier: {set_identifier}'
 short_message:
 - 'Directory: {directory}'
 short_source: 'WEBHIST'
 source: 'MSIE WebCache containers record'
 ---
 type: 'conditional'
+data_type: 'msie:webcache:cookie'
+message:
+- '{url}'
+- '<{path}>'
+- '({cookie_name})'
+- 'Flags: {flags}'
+short_message:
+- '{url}'
+- '({cookie_name})'
+short_source: 'WEBHIST'
+source: 'MSIE WebCache cookies record'
+---
+type: 'conditional'
 data_type: 'msie:webcache:leak_file'
 message:
 - 'Filename: {cached_filename}'
 - 'Leak identifier: {leak_identifier}'
 short_message:
 - 'Filename: {cached_filename}'
 short_source: 'WEBHIST'
```

### Comparing `plaso-20230311/data/formatters/bsm.yaml` & `plaso-20230717/data/formatters/bsm.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/formatters/generic.yaml` & `plaso-20230717/data/formatters/generic.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -691,14 +691,27 @@
 short_message:
 - '{severity}'
 - '{log_line}'
 short_source: 'LOG'
 source: 'PostgreSQL Log'
 ---
 type: 'conditional'
+data_type: 'powershell:transcript_log:entry'
+message:
+- '{commands} executed'
+- 'by host application {host_application}'
+- 'as user {runas_user}'
+- 'in process {process_identifier}'
+short_message:
+- '{host_application} executed: '
+- '{commands}'
+short_source: 'LOG'
+source: 'PowerShell Transcript Event'
+---
+type: 'conditional'
 data_type: 'santa:diskmount'
 message:
 - 'Santa {action}'
 - 'on ({mount})'
 - 'serial: ({serial})'
 - 'for ({dmg_path})'
 short_message:
@@ -952,22 +965,22 @@
 short_source: 'LOG'
 source: 'Text File'
 ---
 type: 'conditional'
 data_type: 'viminfo:history'
 message:
 - '['
-- 'History type: {type}'
+- 'History type: {history_type}'
 - 'item number: {item_number}'
 - ']'
-- 'value: {value}'
+- 'value: {history_value}'
 - 'filename: {filename}'
 short_message:
-- '[{type}]'
-- '{value}'
+- '[{history_type}]'
+- '{history_value}'
 - '{filename}'
 short_source: 'HISTORY'
 source: 'viminfo'
 ---
 type: 'conditional'
 data_type: 'vsftpd:log'
 message:
```

### Comparing `plaso-20230311/data/formatters/ios.yaml` & `plaso-20230717/data/formatters/ios.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -29,14 +29,38 @@
 - 'Application identifier: {application_identifier}'
 short_message:
 - 'Application identifier: {application_identifier}'
 short_source: 'PLIST'
 source: 'Apple iOS Car Play application plist'
 ---
 type: 'conditional'
+data_type: 'ios:idstatuscache:lookup'
+message:
+- 'Process Name: {process_name}'
+- 'Apple Identifier: {apple_identifier}'
+short_message:
+- 'Apple Identifier: {apple_identifier}'
+short_source: 'PLIST'
+source: 'Apple iOS identity services status cache plist'
+---
+type: 'conditional'
+data_type: 'ios:datausage:event'
+message:
+- 'Bundle Identifier: {bundle_identifier}'
+- 'Process Name: {process_name}'
+- 'Wifi In: {wifi_in}'
+- 'Wifi Out: {wifi_out}'
+- 'Wireless Wan In: {wireless_wan_in}'
+- 'Wireless Wan Out: {wireless_wan_out}'
+short_message:
+- 'Process Name: {process_name}'
+short_source: 'HISTORY'
+source: 'iOS data usage database'
+---
+type: 'conditional'
 data_type: 'ios:kik:messaging'
 enumeration_helpers:
 - input_attribute: 'message_status'
   output_attribute: 'message_status'
   default_value: 'UNKNOWN'
   values:
     0: 'unread'
```

### Comparing `plaso-20230311/data/formatters/linux.yaml` & `plaso-20230717/data/formatters/linux.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 - '{body}'
 short_message:
 - '{body}'
 short_source: 'LOG'
 source: 'dpkg log file'
 ---
 # TODO: paths is kept for backwards compatibility
-type: 'basic'
+type: 'conditional'
 data_type: 'linux:locate_database:entry'
 message:
 - 'Folder Path: {path}'
 - 'Folder Paths: {paths}'
 - 'Entries: {entries}'
 short_message:
 - '{path}'
@@ -48,15 +48,15 @@
 short_source: 'LOG'
 source: 'Popularity Contest Log'
 ---
 type: 'conditional'
 data_type: 'linux:popularity_contest_log:session'
 message:
 - 'Session {session}'
-- 'Host identifier: {host_indentifier}'
+- 'Host identifier: {host_identifier}'
 - '[{details}]'
 short_message:
 - 'Session {session}'
 short_source: 'LOG'
 source: 'Popularity Contest Log'
 ---
 type: 'conditional'
```

### Comparing `plaso-20230311/data/formatters/macos.yaml` & `plaso-20230717/data/formatters/macos.yaml`

 * *Files 6% similar despite different names*

```diff
@@ -140,14 +140,37 @@
 - 'Host: {host}'
 - 'Sender: {sender}'
 - 'Facility: {facility}'
 short_source: 'LOG'
 source: 'MacOS ASL Log'
 ---
 type: 'conditional'
+data_type: 'macos:unified_logging:event'
+message:
+- 'Subsystem: {subsystem}'
+- 'Thread Identifier: 0x{thread_identifier:x}'
+- 'Process Identifier: {process_identifier}'
+- 'Effective User Identifier: {euid}'
+- 'Boot Identifier: {boot_identifier}'
+- 'Time To Live: {ttl}'
+- 'Process image identifier: {process_image_identifier}'
+- 'Process image path: {process_image_path}'
+- 'Sender image identifier: {sender_image_identifier}'
+- 'Sender image path: {sender_image_path}'
+- 'Activity identifier: {activity_identifier}'
+- 'Category: {category}'
+- 'Event type: {event_type}'
+- 'Event message: {event_message}'
+short_message:
+- 'Subsystem: {subsystem}'
+- 'Event messaeg: {event_message}'
+short_source: 'LOG'
+source: 'Apple Unified Logging'
+---
+type: 'conditional'
 data_type: 'macos:asl:file'
 boolean_helpers:
 - input_attribute: 'is_dirty'
   output_attribute: 'is_dirty_string'
   value_if_true: '(Is dirty)'
 message:
 - 'Format version: {format_version}'
```

### Comparing `plaso-20230311/data/formatters/windows.yaml` & `plaso-20230717/data/formatters/windows.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -77,14 +77,35 @@
 - '[Identifier: {task_identifier}]'
 short_message:
 - 'Task: {task_name}'
 short_source: 'REG'
 source: 'Task Cache Registry Key'
 ---
 type: 'conditional'
+data_type: 'wincc:simatic_s7:entry'
+message:
+- '{body}'
+short_message:
+- '{body}'
+short_source: 'LOG'
+source: 'SIMATIC S7 log'
+---
+type: 'conditional'
+data_type: 'wincc:sys_log:entry'
+message:
+- 'Hostname: {log_hostname}'
+- 'Source: {source_device}'
+- '{body}'
+short_message:
+- '{source_device}'
+- '{body}'
+short_source: 'LOG'
+source: 'WinCC Sys Log'
+---
+type: 'conditional'
 data_type: 'windows:diagnosis:eventtranscript'
 message:
 - 'Event: {event_name}'
 - 'Binary: {logging_binary_name}'
 - '[{friendly_logging_binary_name}]'
 - 'version: {version}'
 - 'name: {name}'
@@ -290,14 +311,40 @@
 - '(from drive: {drive_letter})'
 short_message:
 - 'Deleted file: {original_filename}'
 short_source: 'RECBIN'
 source: 'Recycle Bin'
 ---
 type: 'conditional'
+data_type: 'windows:pca_log:entry'
+message:
+- '[{executable}] was executed - '
+- 'Description: {description}'
+- 'Version: {version}'
+- 'Vendor: {vendor}'
+- 'Exit code: {exit_code}'
+short_message:
+- '{executable} was run'
+short_source: 'LOG'
+source: 'Program Compatibility Assistant (PCA) Log'
+---
+type: 'conditional'
+data_type: 'windows:onedrive:log'
+message:
+- 'Code filename: {code_filename}'
+- 'Code function name: {code_function_name}'
+- 'Decoded parameters: {decoded_parameters}'
+- 'Raw Parameters: {raw_parameters}'
+short_message:
+- 'Code function name: {code_function_name}'
+- 'Decoded parameters: {decoded_parameters}'
+short_source: 'LOG'
+source: 'OneDrive Log file'
+---
+type: 'conditional'
 data_type: 'windows:prefetch:execution'
 custom_helpers:
 - identifier: 'windows_prefetch_path_hints'
   output_attribute: 'path_hints'
 - identifier: 'windows_prefetch_volumes_string'
   output_attribute: 'volumes_string'
 message:
@@ -586,14 +633,17 @@
 - 'RID: {account_rid}'
 - 'Login count: {login_count}'
 short_source: 'REG'
 source: 'User Account Information Registry Key'
 ---
 type: 'conditional'
 data_type: 'windows:registry:service'
+custom_helpers:
+- identifier: 'windows_registry_values'
+  output_attribute: 'values'
 enumeration_helpers:
 - input_attribute: 'error_control'
   output_attribute: 'error_control'
   default_value: 'UNKNOWN'
   values:
     0: 'Ignore (0)'
     1: 'Normal (1)'
```

### Comparing `plaso-20230311/data/opensearch.mappings` & `plaso-20230717/data/opensearch.mappings`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/presets.yaml` & `plaso-20230717/data/presets.yaml`

 * *Files 3% similar despite different names*

```diff
@@ -16,14 +16,15 @@
 - sqlite/chrome_66_cookies
 - sqlite/skype
 ---
 name: ios
 description: Preset for iOS.
 parsers:
 - jsonl/ios_application_privacy
+- plist/ios_identityservices
 - sqlite/imessage
 - sqlite/ios_netusage
 - sqlite/ios_powerlog
 - sqlite/ios_screentime
 - sqlite/kik_ios
 - sqlite/twitter_ios
 - text/ios_lockdownd
@@ -120,15 +121,16 @@
 - plist/safari_history
 - sqlite/chrome_8_history
 - sqlite/chrome_17_cookies
 - sqlite/chrome_27_history
 - sqlite/chrome_66_cookies
 - sqlite/chrome_autofill
 - sqlite/chrome_extension_activity
-- sqlite/firefox_cookies
+- sqlite/firefox_2_cookies
+- sqlite/firefox_10_cookies
 - sqlite/firefox_downloads
 - sqlite/firefox_history
 - sqlite/safari_historydb
 ---
 name: win_gen
 description: Preset for generic Windows, intended as template for other Windows presets.
 parsers:
@@ -160,16 +162,19 @@
 - {family: Windows NT}
 parsers:
 - custom_destinations
 - esedb/file_history
 - esedb/user_access_logging
 - olecf/olecf_automatic_destinations
 - recycle_bin
+- text/powershell_transcript
 - winevtx
 - win_gen
+- winpca_db0
+- winpca_dic
 ---
 name: win7_slow
 description: Preset for Windows 7 and later including parsers that require more processing time.
 parsers:
 - esedb
 - mft
 - win7
```

### Comparing `plaso-20230311/data/signatures.conf` & `plaso-20230717/data/signatures.conf`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/tag_linux.txt` & `plaso-20230717/data/tag_linux.txt`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/tag_macos.txt` & `plaso-20230717/data/tag_macos.txt`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/tag_windows.txt` & `plaso-20230717/data/tag_windows.txt`

 * *Files identical despite different names*

### Comparing `plaso-20230311/data/timeliner.yaml` & `plaso-20230717/data/timeliner.yaml`

 * *Files 0% similar despite different names*

```diff
@@ -477,14 +477,26 @@
 ---
 data_type: 'ios:carplay:history:entry'
 attribute_mappings:
 - name: 'last_run_time'
   description: 'Last Time Executed'
 place_holder_event: false
 ---
+data_type: 'ios:idstatuscache:lookup'
+attribute_mappings:
+- name: 'lookup_time'
+  description: 'Lookup Time'
+place_holder_event: true
+---
+data_type: 'ios:datausage:event'
+attribute_mappings:
+- name: 'start_time'
+  description: 'Start Time'
+place_holder_event: true
+---
 data_type: 'ios:kik:messaging'
 attribute_mappings:
 - name: 'received_time'
   description: 'Received Time'
 place_holder_event: true
 ---
 data_type: 'ios:lockdownd_log:entry'
@@ -650,14 +662,20 @@
 ---
 data_type: 'macos:asl:file'
 attribute_mappings:
 - name: 'creation_time'
   description: 'Creation Time'
 place_holder_event: true
 ---
+data_type: 'macos:unified_logging:event'
+attribute_mappings:
+- name: 'recorded_time'
+  description: 'Recorded Time'
+place_holder_event: true
+---
 data_type: 'macos:bluetooth:entry'
 attribute_mappings:
 - name: 'inquiry_time'
   description: 'Last Inquiry Update Time'
 - name: 'name_update_time'
   description: 'Last Name Update Time'
 - name: 'services_update_time'
@@ -831,14 +849,22 @@
 ---
 data_type: 'msie:webcache:partitions'
 attribute_mappings:
 - name: 'scavenge_time'
   description: 'Last Scavenge Time'
 place_holder_event: false
 ---
+data_type: 'msie:webcache:cookie'
+attribute_mappings:
+- name: 'expiration_time'
+  description: 'Expiration Time'
+- name: 'modification_time'
+  description: 'Modification Time'
+place_holder_event: true
+---
 data_type: 'msiecf:leak'
 place_holder_event: true
 ---
 data_type: 'msiecf:redirected'
 place_holder_event: true
 ---
 data_type: 'msiecf:url'
@@ -981,14 +1007,20 @@
 ---
 data_type: 'postgresql:application_log:entry'
 attribute_mappings:
 - name: 'recorded_time'
   description: 'Recorded Time'
 place_holder_event: true
 ---
+data_type: 'powershell:transcript_log:entry'
+attribute_mappings:
+- name: 'start_time'
+  description: 'Start Time'
+place_holder_event: true
+---
 data_type: 'safari:cookie:entry'
 attribute_mappings:
 - name: 'creation_time'
   description: 'Creation Time'
 - name: 'expiration_time'
   description: 'Expiration Time'
 place_holder_event: true
@@ -1232,14 +1264,26 @@
 ---
 data_type: 'windows:diagnosis:eventtranscript'
 attribute_mappings:
 - name: 'recorded_time'
   description: 'Recorded Time'
 place_holder_event: true
 ---
+data_type: 'wincc:simatic_s7:entry'
+attribute_mappings:
+- name: 'creation_time'
+  description: 'Creation Time'
+place_holder_event: true
+---
+data_type: 'wincc:sys_log:entry'
+attribute_mappings:
+- name: 'creation_time'
+  description: 'Creation Time'
+place_holder_event: true
+---
 data_type: 'windows:distributed_link_tracking:creation'
 attribute_mappings:
 - name: 'creation_time'
   description: 'Creation Time'
 place_holder_event: true
 ---
 data_type: 'windows:firewall_log:entry'
@@ -1284,14 +1328,26 @@
 ---
 data_type: 'windows:metadata:deleted_item'
 attribute_mappings:
 - name: 'deletion_time'
   description: 'Content Deletion Time'
 place_holder_event: true
 ---
+data_type: 'windows:pca_log:entry'
+attribute_mappings:
+- name: 'last_execution_time'
+  description: 'Last Time Executed'
+place_holder_event: false
+---
+data_type: 'windows:onedrive:log'
+attribute_mappings:
+- name: 'recorded_time'
+  description: 'Recorded Time'
+place_holder_event: false
+---
 data_type: 'windows:prefetch:execution'
 attribute_mappings:
 - name: 'last_run_time'
   description: 'Last Time Executed'
 - name: 'previous_run_times'
   description: 'Previous Last Time Executed'
 place_holder_event: true
```

### Comparing `plaso-20230311/data/winevt-rc.db` & `plaso-20230717/data/winevt-rc.db`

 * *Files identical despite different names*

### Comparing `plaso-20230311/dependencies.ini` & `plaso-20230717/dependencies.ini`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [acstore]
 dpkg_name: python3-acstore
-minimum_version: 20230101
+minimum_version: 20230519
 rpm_name: python3-acstore
 version_property: __version__
 
 [artifacts]
 dpkg_name: python3-artifacts
 minimum_version: 20220219
 rpm_name: python3-artifacts
@@ -60,27 +60,27 @@
 dpkg_name: python3-dfdatetime
 minimum_version: 20221112
 rpm_name: python3-dfdatetime
 version_property: __version__
 
 [dfvfs]
 dpkg_name: python3-dfvfs
-minimum_version: 20221224
+minimum_version: 20230407
 rpm_name: python3-dfvfs
 version_property: __version__
 
 [dfwinreg]
 dpkg_name: python3-dfwinreg
 minimum_version: 20211207
 rpm_name: python3-dfwinreg
 version_property: __version__
 
 [dtfabric]
 dpkg_name: python3-dtfabric
-minimum_version: 20220219
+minimum_version: 20230518
 rpm_name: python3-dtfabric
 version_property: __version__
 
 [flor]
 dpkg_name: python3-flor
 is_optional: true
 minimum_version: 1.1.3
@@ -113,14 +113,22 @@
 dpkg_name: python3-opensearch
 is_optional: true
 l2tbinaries_name: opensearch-py
 pypi_name: opensearch-py
 rpm_name: python3-opensearch
 version_property: __versionstr__
 
+[pycaes]
+dpkg_name: libcaes-python3
+l2tbinaries_name: libcaes
+minimum_version: 20221127
+pypi_name: libcaes-python
+rpm_name: libcaes-python3
+version_property: get_version()
+
 [pefile]
 dpkg_name: python3-pefile
 minimum_version: 2021.5.24
 rpm_name: python3-pefile
 version_property: __version__
 
 [psutil]
```

### Comparing `plaso-20230311/docs/conf.py` & `plaso-20230717/docs/conf.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/index.rst` & `plaso-20230717/docs/index.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/Supported-formats.md` & `plaso-20230717/docs/sources/Supported-formats.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/Troubleshooting.md` & `plaso-20230717/docs/sources/Troubleshooting.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.analysis.rst` & `plaso-20230717/docs/sources/api/plaso.analysis.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.analyzers.hashers.rst` & `plaso-20230717/docs/sources/api/plaso.analyzers.hashers.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.analyzers.rst` & `plaso-20230717/docs/sources/api/plaso.analyzers.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.cli.helpers.rst` & `plaso-20230717/docs/sources/api/plaso.cli.helpers.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.cli.rst` & `plaso-20230717/docs/sources/api/plaso.cli.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.containers.rst` & `plaso-20230717/docs/sources/api/plaso.containers.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.engine.rst` & `plaso-20230717/docs/sources/api/plaso.engine.rst`

 * *Files 4% similar despite different names*

```diff
@@ -40,22 +40,14 @@
 --------------------------------
 
 .. automodule:: plaso.engine.filter_file
    :members:
    :undoc-members:
    :show-inheritance:
 
-plaso.engine.filters\_helper module
------------------------------------
-
-.. automodule:: plaso.engine.filters_helper
-   :members:
-   :undoc-members:
-   :show-inheritance:
-
 plaso.engine.knowledge\_base module
 -----------------------------------
 
 .. automodule:: plaso.engine.knowledge_base
    :members:
    :undoc-members:
    :show-inheritance:
```

### Comparing `plaso-20230311/docs/sources/api/plaso.filters.rst` & `plaso-20230717/docs/sources/api/plaso.filters.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.formatters.rst` & `plaso-20230717/docs/sources/api/plaso.formatters.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.helpers.windows.rst` & `plaso-20230717/docs/sources/api/plaso.helpers.windows.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.lib.rst` & `plaso-20230717/docs/sources/api/plaso.lib.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.multi_process.rst` & `plaso-20230717/docs/sources/api/plaso.multi_process.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.multi_processing.rst` & `plaso-20230717/docs/sources/api/plaso.multi_processing.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.output.rst` & `plaso-20230717/docs/sources/api/plaso.output.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.bencode_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.bencode_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.cookie_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.cookie_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.czip_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.czip_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.esedb_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.esedb_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.jsonl_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.jsonl_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.olecf_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.olecf_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.plist_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.plist_plugins.rst`

 * *Files 5% similar despite different names*

```diff
@@ -56,14 +56,22 @@
 ------------------------------------------------
 
 .. automodule:: plaso.parsers.plist_plugins.ios_carplay
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.parsers.plist\_plugins.ios\_identityservices module
+---------------------------------------------------------
+
+.. automodule:: plaso.parsers.plist_plugins.ios_identityservices
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.parsers.plist\_plugins.ipod module
 ----------------------------------------
 
 .. automodule:: plaso.parsers.plist_plugins.ipod
    :members:
    :undoc-members:
    :show-inheritance:
```

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.rst`

 * *Files 4% similar despite different names*

```diff
@@ -250,14 +250,22 @@
 --------------------------
 
 .. automodule:: plaso.parsers.olecf
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.parsers.onedrive module
+-----------------------------
+
+.. automodule:: plaso.parsers.onedrive
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.parsers.opera module
 --------------------------
 
 .. automodule:: plaso.parsers.opera
    :members:
    :undoc-members:
    :show-inheritance:
@@ -362,14 +370,22 @@
 ---------------------------------
 
 .. automodule:: plaso.parsers.trendmicroav
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.parsers.unified\_logging module
+-------------------------------------
+
+.. automodule:: plaso.parsers.unified_logging
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.parsers.utmp module
 -------------------------
 
 .. automodule:: plaso.parsers.utmp
    :members:
    :undoc-members:
    :show-inheritance:
@@ -378,14 +394,22 @@
 --------------------------
 
 .. automodule:: plaso.parsers.utmpx
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.parsers.wincc module
+--------------------------
+
+.. automodule:: plaso.parsers.wincc
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.parsers.windefender\_history module
 -----------------------------------------
 
 .. automodule:: plaso.parsers.windefender_history
    :members:
    :undoc-members:
    :show-inheritance:
@@ -418,14 +442,22 @@
 ---------------------------
 
 .. automodule:: plaso.parsers.winlnk
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.parsers.winpca module
+---------------------------
+
+.. automodule:: plaso.parsers.winpca
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.parsers.winprefetch module
 --------------------------------
 
 .. automodule:: plaso.parsers.winprefetch
    :members:
    :undoc-members:
    :show-inheritance:
```

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.sqlite_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.sqlite_plugins.rst`

 * *Files 1% similar despite different names*

```diff
@@ -144,14 +144,22 @@
 ----------------------------------------------
 
 .. automodule:: plaso.parsers.sqlite_plugins.interface
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.parsers.sqlite\_plugins.ios\_datausage module
+---------------------------------------------------
+
+.. automodule:: plaso.parsers.sqlite_plugins.ios_datausage
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.parsers.sqlite\_plugins.ios\_kik module
 ---------------------------------------------
 
 .. automodule:: plaso.parsers.sqlite_plugins.ios_kik
    :members:
    :undoc-members:
    :show-inheritance:
```

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.syslog_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.syslog_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.text_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.text_plugins.rst`

 * *Files 1% similar despite different names*

```diff
@@ -152,14 +152,22 @@
 ---------------------------------------------
 
 .. automodule:: plaso.parsers.text_plugins.postgresql
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.parsers.text\_plugins.powershell\_transcript module
+---------------------------------------------------------
+
+.. automodule:: plaso.parsers.text_plugins.powershell_transcript
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.parsers.text\_plugins.santa module
 ----------------------------------------
 
 .. automodule:: plaso.parsers.text_plugins.santa
    :members:
    :undoc-members:
    :show-inheritance:
```

### Comparing `plaso-20230311/docs/sources/api/plaso.parsers.winreg_plugins.rst` & `plaso-20230717/docs/sources/api/plaso.parsers.winreg_plugins.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.preprocessors.rst` & `plaso-20230717/docs/sources/api/plaso.preprocessors.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.rst` & `plaso-20230717/docs/sources/api/plaso.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.serializer.rst` & `plaso-20230717/docs/sources/api/plaso.serializer.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.storage.fake.rst` & `plaso-20230717/docs/sources/api/plaso.storage.fake.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.storage.redis.rst` & `plaso-20230717/docs/sources/api/plaso.storage.redis.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/api/plaso.storage.rst` & `plaso-20230717/docs/sources/api/plaso.storage.rst`

 * *Files 11% similar despite different names*

```diff
@@ -34,14 +34,22 @@
 ---------------------------
 
 .. automodule:: plaso.storage.reader
    :members:
    :undoc-members:
    :show-inheritance:
 
+plaso.storage.serializers module
+--------------------------------
+
+.. automodule:: plaso.storage.serializers
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
 plaso.storage.time\_range module
 --------------------------------
 
 .. automodule:: plaso.storage.time_range
    :members:
    :undoc-members:
    :show-inheritance:
```

### Comparing `plaso-20230311/docs/sources/api/plaso.storage.sqlite.rst` & `plaso-20230717/docs/sources/api/plaso.storage.sqlite.rst`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Developers-Guide.md` & `plaso-20230717/docs/sources/developer/Developers-Guide.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Developing-Fedora.md` & `plaso-20230717/docs/sources/developer/Developing-Fedora.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Developing-MacOS.md` & `plaso-20230717/docs/sources/developer/Developing-MacOS.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Developing-Ubuntu.md` & `plaso-20230717/docs/sources/developer/Developing-Ubuntu.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Developing-Virtualenv.md` & `plaso-20230717/docs/sources/developer/Developing-Virtualenv.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Developing-Windows.md` & `plaso-20230717/docs/sources/developer/Developing-Windows.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Development-Dependencies.md` & `plaso-20230717/docs/sources/developer/Development-Dependencies.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/How-to-write-a-SQLite-plugin.md` & `plaso-20230717/docs/sources/developer/How-to-write-a-SQLite-plugin.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/How-to-write-a-parser.md` & `plaso-20230717/docs/sources/developer/How-to-write-a-parser.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/How-to-write-a-tagging-rule.md` & `plaso-20230717/docs/sources/developer/How-to-write-a-tagging-rule.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/How-to-write-an-analysis-plugin.md` & `plaso-20230717/docs/sources/developer/How-to-write-an-analysis-plugin.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/How-to-write-an-output-module.md` & `plaso-20230717/docs/sources/developer/How-to-write-an-output-module.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Internals.md` & `plaso-20230717/docs/sources/developer/Internals.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Packaging-with-pyinstaller.md` & `plaso-20230717/docs/sources/developer/Packaging-with-pyinstaller.md`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,12 @@
 ## Packaging with PyInstaller
 
+**Note that packaging with PyInstaller is no longer a supported build method.
+You are expected to be able to debug and fix build issues yourself.**
+
 To create a Windows packaged release from the development release you also need:
 
 * PyInstaller
 
 ### PyInstaller
 
 Download the latest source from:
```

### Comparing `plaso-20230311/docs/sources/developer/Profiling.md` & `plaso-20230717/docs/sources/developer/Profiling.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Style-guide.md` & `plaso-20230717/docs/sources/developer/Style-guide.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/developer/Testing.md` & `plaso-20230717/docs/sources/developer/Testing.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-bloom.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-bloom.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-browser-search.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-browser-search.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-chrome-extension.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-chrome-extension.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-nsrlsvr.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-nsrlsvr.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-sessionize.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-sessionize.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-tagging.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-tagging.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-unique-domains-visited.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-unique-domains-visited.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-viper.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-viper.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugin-virustotal.md` & `plaso-20230717/docs/sources/user/Analysis-plugin-virustotal.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Analysis-plugins.md` & `plaso-20230717/docs/sources/user/Analysis-plugins.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Creating-a-timeline.md` & `plaso-20230717/docs/sources/user/Creating-a-timeline.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Event-filters.md` & `plaso-20230717/docs/sources/user/Event-filters.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Feature-requests-and-bug-reports.md` & `plaso-20230717/docs/sources/user/Feature-requests-and-bug-reports.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Getting-started.md` & `plaso-20230717/docs/sources/user/Getting-started.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Installation-Problems.md` & `plaso-20230717/docs/sources/user/Installation-Problems.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Installing-with-docker.md` & `plaso-20230717/docs/sources/user/Installing-with-docker.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Log2Timeline-Perl-(Legacy).md` & `plaso-20230717/docs/sources/user/Log2Timeline-Perl-(Legacy).md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/MacOS-Source-Release.md` & `plaso-20230717/docs/sources/user/MacOS-Source-Release.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Output-and-formatting.md` & `plaso-20230717/docs/sources/user/Output-and-formatting.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Output-format-l2tcsv.md` & `plaso-20230717/docs/sources/user/Output-format-l2tcsv.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Parsers-and-plugins.md` & `plaso-20230717/docs/sources/user/Parsers-and-plugins.md`

 * *Files 2% similar despite different names*

```diff
@@ -25,37 +25,43 @@
 locate_database | Parser for Locate database file (updatedb).
 mac_keychain | Parser for MacOS keychain database files.
 mcafee_protection | Parser for McAfee Anti-Virus access protection log files.
 mft | Parser for NTFS $MFT metadata files.
 msiecf | Parser for Microsoft Internet Explorer (MSIE) 4 - 9 cache (index.dat) files.
 networkminer_fileinfo | Parser for NetworkMiner .fileinfos files.
 olecf | Parser for OLE Compound File (OLECF) format.
+onedrive_log | Parser for OneDrive Log files.
 opera_global | Parser for Opera global history (global_history.dat) files.
 opera_typed_history | Parser for Opera typed history (typed_history.xml) files.
 pe | Parser for Portable Executable (PE) files.
 plist | Parser for Property list (plist) files.
 pls_recall | Parser for PL SQL cache file (PL-SQL developer recall file) format.
 prefetch | Parser for Windows Prefetch File (PF).
 recycle_bin | Parser for Windows $Recycle.Bin $I files.
 recycle_bin_info2 | Parser for Windows Recycler INFO2 files.
 rplog | Parser for Windows Restore Point log (rp.log) files.
+simatic_s7 | Parser for SIMATIC S7 Log files.
 spotlight_storedb | Parser for Apple Spotlight store database (store.db) files.
 sqlite | Parser for SQLite database files.
 symantec_scanlog | Parser for Symantec AV Corporate Edition and Endpoint Protection log files.
 systemd_journal | Parser for Systemd journal files.
 text | Parser for text-based log files.
 trendmicro_url | Parser for Trend Micro Office Web Reputation log files.
 trendmicro_vd | Parser for Trend Micro Office Scan Virus Detection log files.
+unified_logging | Parser for Apple Unified Logging (AUL) 64-bit tracev3 files.
 usnjrnl | Parser for NTFS USN change journal ($UsnJrnl:$J) file system metadata files.
 utmp | Parser for Linux libc6 utmp files.
 utmpx | Parser for Mac OS X 10.5 utmpx files.
+wincc_sys | Parser for WinCC Sys Log files.
 windefender_history | Parser for Windows Defender scan DetectionHistory files.
 winevt | Parser for Windows EventLog (EVT) files.
 winevtx | Parser for Windows XML EventLog (EVTX) files.
 winjob | Parser for Windows Scheduled Task job (or at-job) files.
+winpca_db0 | Parser for Windows PCA DB0 log files.
+winpca_dic | Parser for Windows PCA DIC log files.
 winreg | Parser for Windows NT Registry (REGF) files.
 
 ### Parser plugins: bencode
 
 Name | Description
 --- | ---
 bencode_transmission | Parser for Transmission BitTorrent activity files.
@@ -102,14 +108,15 @@
 ### Parser plugins: plist
 
 Name | Description
 --- | ---
 airport | Parser for Airport plist files.
 apple_id | Parser for Apple account information plist files.
 ios_carplay | Parser for Apple iOS Car Play application plist files.
+ios_identityservices | Parser for Idstatuscache plist files.
 ipod_device | Parser for iPod, iPad and iPhone plist files.
 launchd_plist | Parser for Launchd plist files.
 macos_bluetooth | Parser for MacOS Bluetooth plist files.
 macos_software_update | Parser for MacOS software update plist files.
 macosx_install_history | Parser for MacOS installation history plist files.
 macuser | Parser for MacOS user plist files.
 plist_default | Parser for plist files.
@@ -131,20 +138,22 @@
 chrome_17_cookies | Parser for Google Chrome 17 - 65 cookies SQLite database files.
 chrome_27_history | Parser for Google Chrome 27 and later history SQLite database files.
 chrome_66_cookies | Parser for Google Chrome 66 and later cookies SQLite database files.
 chrome_8_history | Parser for Google Chrome 8 - 25 history SQLite database files.
 chrome_autofill | Parser for Google Chrome autofill SQLite database (Web Data) files.
 chrome_extension_activity | Parser for Google Chrome extension activity SQLite database files.
 dropbox | Parser for Dropbox sync history database (sync_history.db) files.
-firefox_cookies | Parser for Mozilla Firefox cookies SQLite database files.
+firefox_10_cookies | Parser for Mozilla Firefox cookies SQLite database file version 10.
+firefox_2_cookies | Parser for Mozilla Firefox cookies SQLite database file version 2.
 firefox_downloads | Parser for Mozilla Firefox downloads SQLite database (downloads.sqlite) files.
 firefox_history | Parser for Mozilla Firefox history SQLite database (places.sqlite) files.
 google_drive | Parser for Google Drive snapshot SQLite database (snapshot.db) files.
 hangouts_messages | Parser for Google Hangouts conversations SQLite database (babel.db) files.
 imessage | Parser for MacOS and iOS iMessage database (chat.db, sms.db) files.
+ios_datausage | Parser for iOS data usage SQLite databse (DataUsage.sqlite) file..
 ios_netusage | Parser for iOS network usage SQLite database (netusage.sqlite) files.
 ios_powerlog | Parser for iOS powerlog SQLite database (CurrentPowerlog.PLSQL) files.
 ios_screentime | Parser for iOS Screen Time SQLite database (RMAdminStore-Local.sqlite).
 kik_ios | Parser for iOS Kik messenger SQLite database (kik.sqlite) files.
 kodi | Parser for Kodi videos SQLite database (MyVideos.db) files.
 ls_quarantine | Parser for MacOS launch services quarantine events database SQLite database files.
 mac_document_versions | Parser for MacOS document revisions SQLite database files.
@@ -180,14 +189,15 @@
 ios_logd | Parser for iOS sysdiagnose logd files.
 ios_sysdiag_log | Parser for iOS sysdiag log.
 mac_appfirewall_log | Parser for MacOS Application firewall log (appfirewall.log) files.
 mac_securityd | Parser for MacOS security daemon (securityd) log files.
 mac_wifi | Parser for MacOS Wi-Fi log (wifi.log) files.
 popularity_contest | Parser for Popularity Contest log files.
 postgresql | Parser for PostgreSQL application log files.
+powershell_transcript | Parser for PowerShell transcript event.
 santa | Parser for Santa log (santa.log) files.
 sccm | Parser for System Center Configuration Manager (SCCM) client log files.
 selinux | Parser for SELinux audit log (audit.log) files.
 setupapi | Parser for Windows SetupAPI log files.
 skydrive_log_v1 | Parser for OneDrive (or SkyDrive) version 1 log files.
 skydrive_log_v2 | Parser for OneDrive (or SkyDrive) version 2 log files.
 snort_fastlog | Parser for Snort3/Suricata fast-log alert log (fast.log) files.
@@ -244,18 +254,18 @@
 winreg_default | Parser for Windows Registry data.
 
 ### Parser presets (data/presets.yaml)
 
 Name | Parsers and plugins
 --- | ---
 android | android_app_usage, chrome_cache, filestat, sqlite/android_calls, sqlite/android_sms, sqlite/android_webview, sqlite/android_webviewcache, sqlite/chrome_8_history, sqlite/chrome_17_cookies, sqlite/chrome_27_history, sqlite/chrome_66_cookies, sqlite/skype
-ios | jsonl/ios_application_privacy, sqlite/imessage, sqlite/ios_netusage, sqlite/ios_powerlog, sqlite/ios_screentime, sqlite/kik_ios, sqlite/twitter_ios, text/ios_lockdownd, text/ios_logd, text/ios_sysdiag_log
+ios | jsonl/ios_application_privacy, plist/ios_identityservices, sqlite/imessage, sqlite/ios_netusage, sqlite/ios_powerlog, sqlite/ios_screentime, sqlite/kik_ios, sqlite/twitter_ios, text/ios_lockdownd, text/ios_logd, text/ios_sysdiag_log
 linux | bencode, czip/oxml, jsonl/docker_container_config, jsonl/docker_container_log, jsonl/docker_layer_config, filestat, olecf, pls_recall, sqlite/google_drive, sqlite/skype, sqlite/zeitgeist, systemd_journal, text/apt_history, text/bash_history, text/dpkg, text/gdrive_synclog, text/googlelog, text/popularity_contest, text/selinux, text/syslog, text/syslog_traditional, text/vsftpd, text/xchatlog, text/xchatscrollback, text/zsh_extended_history, utmp, webhist
 macos | asl_log, bencode, bsm_log, cups_ipp, czip/oxml, filestat, fseventsd, mac_keychain, olecf, plist, spotlight_storedb, sqlite/appusage, sqlite/google_drive, sqlite/imessage, sqlite/ls_quarantine, sqlite/mac_document_versions, sqlite/mac_notes, sqlite/mackeeper_cache, sqlite/mac_knowledgec, sqlite/skype, text/bash_history, text/gdrive_synclog, text/mac_appfirewall_log, text/mac_securityd, text/mac_wifi, text/syslog, text/syslog_traditional, text/zsh_extended_history, utmpx, webhist
 mactime | bodyfile
-webhist | binary_cookies, chrome_cache, chrome_preferences, esedb/msie_webcache, firefox_cache, java_idx, msiecf, opera_global, opera_typed_history, plist/safari_history, sqlite/chrome_8_history, sqlite/chrome_17_cookies, sqlite/chrome_27_history, sqlite/chrome_66_cookies, sqlite/chrome_autofill, sqlite/chrome_extension_activity, sqlite/firefox_cookies, sqlite/firefox_downloads, sqlite/firefox_history, sqlite/safari_historydb
-win7 | custom_destinations, esedb/file_history, esedb/user_access_logging, olecf/olecf_automatic_destinations, recycle_bin, winevtx, win_gen
+webhist | binary_cookies, chrome_cache, chrome_preferences, esedb/msie_webcache, firefox_cache, java_idx, msiecf, opera_global, opera_typed_history, plist/safari_history, sqlite/chrome_8_history, sqlite/chrome_17_cookies, sqlite/chrome_27_history, sqlite/chrome_66_cookies, sqlite/chrome_autofill, sqlite/chrome_extension_activity, sqlite/firefox_2_cookies, sqlite/firefox_10_cookies, sqlite/firefox_downloads, sqlite/firefox_history, sqlite/safari_historydb
+win7 | custom_destinations, esedb/file_history, esedb/user_access_logging, olecf/olecf_automatic_destinations, recycle_bin, text/powershell_transcript, winevtx, win_gen, winpca_db0, winpca_dic
 win7_slow | esedb, mft, win7
 win_gen | bencode, czip/oxml, filestat, lnk, mcafee_protection, olecf, pe, prefetch, sqlite/google_drive, sqlite/skype, symantec_scanlog, text/gdrive_synclog, text/sccm, text/setupapi, text/skydrive_log_v1, text/skydrive_log_v2, text/winfirewall, usnjrnl, webhist, winjob, winreg
 winxp | recycle_bin_info2, rplog, win_gen, winevt
 winxp_slow | esedb, mft, winxp
```

### Comparing `plaso-20230311/docs/sources/user/Releases-and-roadmap.md` & `plaso-20230717/docs/sources/user/Releases-and-roadmap.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Scribbles-about-events.md` & `plaso-20230717/docs/sources/user/Scribbles-about-events.md`

 * *Files 1% similar despite different names*

```diff
@@ -69,18 +69,18 @@
 * system-level event; operating system events that can be derived from source-level events;
 * user-level event; user attributable events that can be derived from system-level or source-level events.
 
 ## How are events defined in Plaso?
 
 Events in Plaso consist of multiple parts:
 
-* [event data](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py#L10)
-* [event data stream](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py#L90)
-* [event](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py#L118)
-* [event tag](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py#L185)
+* [event data](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py)
+* [event data stream](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py)
+* [event](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py)
+* [event tag](https://github.com/log2timeline/plaso/blob/main/plaso/containers/events.py)
 
 ### Event (object)
 
 Originally Plaso's event (object) also contained the event data and event
 data stream information. This information was moved to separate attribute
 containers (object) to reduce duplication of information across multiple
 events. An event (object) typically has:
```

### Comparing `plaso-20230311/docs/sources/user/Tagging-Rules.md` & `plaso-20230717/docs/sources/user/Tagging-Rules.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Tips-and-Tricks.md` & `plaso-20230717/docs/sources/user/Tips-and-Tricks.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Troubleshooting-installation-issues.md` & `plaso-20230717/docs/sources/user/Troubleshooting-installation-issues.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Ubuntu-Packaged-Release.md` & `plaso-20230717/docs/sources/user/Ubuntu-Packaged-Release.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Users-Guide.md` & `plaso-20230717/docs/sources/user/Users-Guide.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Using-image_export.md` & `plaso-20230717/docs/sources/user/Using-image_export.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Using-log2timeline.md` & `plaso-20230717/docs/sources/user/Using-log2timeline.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Using-pinfo.md` & `plaso-20230717/docs/sources/user/Using-pinfo.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Using-psort.md` & `plaso-20230717/docs/sources/user/Using-psort.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/docs/sources/user/Using-psteal.md` & `plaso-20230717/docs/sources/user/Using-psteal.md`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/__init__.py` & `plaso-20230717/plaso/analysis/__init__.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/bloom.py` & `plaso-20230717/plaso/analysis/bloom.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/browser_search.py` & `plaso-20230717/plaso/analysis/browser_search.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/chrome_extension.py` & `plaso-20230717/plaso/analysis/chrome_extension.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,14 +18,16 @@
 
   _SUPPORTED_EVENT_DATA_TYPES = frozenset([
       'fs:stat'])
 
   _TITLE_RE = re.compile(r'<title>([^<]+)</title>')
   _WEB_STORE_URL = 'https://chrome.google.com/webstore/detail/{xid}?hl=en-US'
 
+  _REQUEST_TIMEOUT = 60
+
   def __init__(self):
     """Initializes an Chrome extension analysis plugin."""
     super(ChromeExtensionPlugin, self).__init__()
 
     # Saved list of already looked up extensions.
     self._extensions = {}
     self._extensions_per_user = {}
@@ -37,15 +39,15 @@
       extension_identifier (str): Chrome extension identifier.
 
     Returns:
       str: page content or None.
     """
     web_store_url = self._WEB_STORE_URL.format(xid=extension_identifier)
     try:
-      response = requests.get(web_store_url)
+      response = requests.get(web_store_url, timeout=self._REQUEST_TIMEOUT)
 
     except (requests.ConnectionError, requests.HTTPError) as exception:
       logger.warning((
           '[{0:s}] unable to retrieve URL: {1:s} with error: {2!s}').format(
               self.NAME, web_store_url, exception))
       return None
```

### Comparing `plaso-20230311/plaso/analysis/hash_tagging.py` & `plaso-20230717/plaso/analysis/hash_tagging.py`

 * *Files 2% similar despite different names*

```diff
@@ -44,14 +44,16 @@
   # Lookup hashes supported by the hash tagging analysis plugin.
   SUPPORTED_HASHES = frozenset([])
 
   _DEFAULT_HASHES_PER_BATCH = 1
   _DEFAULT_LOOKUP_HASH = 'sha256'
   _DEFAULT_WAIT_AFTER_ANALYSIS = 0.0
 
+  _REQUEST_TIMEOUT = 60
+
   def __init__(self):
     """Initializes a hash tagging analysis plugin."""
     super(HashTaggingAnalysisPlugin, self).__init__()
     self._batch_of_lookup_hashes = []
     self._data_stream_identifiers = set()
     self._data_streams_by_hash = collections.defaultdict(set)
     self._event_identifiers_by_data_stream = collections.defaultdict(set)
@@ -102,18 +104,18 @@
     """
     method_upper = method.upper()
     if method_upper not in ('GET', 'POST'):
       raise ValueError('Method {0:s} is not supported')
 
     try:
       if method_upper == 'GET':
-        response = requests.get(url, **kwargs)
+        response = requests.get(url, timeout=self._REQUEST_TIMEOUT, **kwargs)
 
       elif method_upper == 'POST':
-        response = requests.post(url, **kwargs)
+        response = requests.post(url, timeout=self._REQUEST_TIMEOUT, **kwargs)
 
       response.raise_for_status()
 
     except requests.ConnectionError as exception:
       error_string = 'Unable to connect to {0:s} with error: {1!s}'.format(
           url, exception)
       raise errors.ConnectionError(error_string)
```

### Comparing `plaso-20230311/plaso/analysis/interface.py` & `plaso-20230717/plaso/analysis/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/manager.py` & `plaso-20230717/plaso/analysis/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/mediator.py` & `plaso-20230717/plaso/analysis/mediator.py`

 * *Files 7% similar despite different names*

```diff
@@ -23,32 +23,30 @@
         information is then used by the foreman to detect workers that are
         not responding (stalled).
     number_of_produced_analysis_reports (int): number of produced analysis
         reports.
     number_of_produced_event_tags (int): number of produced event tags.
   """
 
-  def __init__(self, session, knowledge_base, data_location=None):
+  def __init__(self, data_location=None, user_accounts=None):
     """Initializes an analysis plugin mediator.
 
     Args:
-      session (Session): session the analysis is part of.
-      knowledge_base (KnowledgeBase): contains information from the source
-          data needed for analysis.
       data_location (Optional[str]): location of data files used during
           analysis.
+      user_accounts (Optional[list[UserAccountArtifact]]): user accounts.
     """
     super(AnalysisMediator, self).__init__()
     self._abort = False
     self._data_location = data_location
     self._event_filter_expression = None
-    self._knowledge_base = knowledge_base
     self._number_of_warnings = 0
-    self._session = session
     self._storage_writer = None
+    self._user_accounts = user_accounts
+    self._username_by_user_directory = {}
 
     self.analysis_reports_counter = collections.Counter()
     self.event_labels_counter = collections.Counter()
     self.last_activity_timestamp = 0.0
     self.number_of_produced_analysis_reports = 0
     self.number_of_produced_event_tags = 0
 
@@ -82,15 +80,27 @@
     Args:
       path (str): path.
 
     Returns:
       str: username or None if the path does not appear to be within a user's
           directory.
     """
-    return self._knowledge_base.GetUsernameForPath(path)
+    path = path.lower()
+
+    username = self._username_by_user_directory.get(path, None)
+    if not username and self._user_accounts:
+      for user_account in self._user_accounts:
+        if user_account.user_directory:
+          user_directory = user_account.user_directory.lower()
+          if path.startswith(user_directory):
+            username = user_account.username
+            self._username_by_user_directory[path] = username
+            break
+
+    return username
 
   def ProduceAnalysisResult(self, analysis_result):
     """Produces an analysis result attribute.
 
     Args:
       analysis_result (AttributeContainer): analysis result.
     """
@@ -126,15 +136,15 @@
     Args:
       message (str): message of the warning.
       plugin_name (str): name of the analysis plugin to which the warning
           applies.
     """
     if self._storage_writer:
       warning = warnings.AnalysisWarning(
-          message=message, plugin_name=plugin_name)
+         message=message, plugin_name=plugin_name)
       self._storage_writer.AddAttributeContainer(warning)
 
     self._number_of_warnings += 1
 
     self.last_activity_timestamp = time.time()
 
   def ProduceEventTag(self, event_tag):
```

### Comparing `plaso-20230311/plaso/analysis/nsrlsvr.py` & `plaso-20230717/plaso/analysis/nsrlsvr.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/sessionize.py` & `plaso-20230717/plaso/analysis/sessionize.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/tagging.py` & `plaso-20230717/plaso/analysis/tagging.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/test_memory.py` & `plaso-20230717/plaso/analysis/test_memory.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/unique_domains_visited.py` & `plaso-20230717/plaso/analysis/unique_domains_visited.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/viper.py` & `plaso-20230717/plaso/analysis/viper.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analysis/virustotal.py` & `plaso-20230717/plaso/analysis/virustotal.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/hashers/entropy.py` & `plaso-20230717/plaso/analyzers/hashers/entropy.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/hashers/interface.py` & `plaso-20230717/plaso/analyzers/hashers/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/hashers/manager.py` & `plaso-20230717/plaso/analyzers/hashers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/hashers/md5.py` & `plaso-20230717/plaso/analyzers/hashers/md5.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/hashers/sha1.py` & `plaso-20230717/plaso/analyzers/hashers/sha1.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/hashers/sha256.py` & `plaso-20230717/plaso/analyzers/hashers/sha256.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/hashing_analyzer.py` & `plaso-20230717/plaso/analyzers/hashing_analyzer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/interface.py` & `plaso-20230717/plaso/analyzers/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/manager.py` & `plaso-20230717/plaso/analyzers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/analyzers/yara_analyzer.py` & `plaso-20230717/plaso/analyzers/yara_analyzer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/analysis_tool.py` & `plaso-20230717/plaso/cli/analysis_tool.py`

 * *Files 23% similar despite different names*

```diff
@@ -6,16 +6,14 @@
 from dfdatetime import posix_time as dfdatetime_posix_time
 
 from plaso.analysis import manager as analysis_manager
 from plaso.cli import tool_options
 from plaso.cli import tools
 from plaso.cli import views
 from plaso.containers import reports
-from plaso.containers import sessions
-from plaso.engine import knowledge_base
 from plaso.multi_process import analysis_engine as multi_analysis_engine
 from plaso.storage import factory as storage_factory
 
 
 class AnalysisTool(
     tools.CLITool,
     tool_options.AnalysisPluginOptions,
@@ -43,15 +41,14 @@
         input_reader=input_reader, output_writer=output_writer)
     self._analysis_manager = analysis_manager.AnalysisPluginManager
     self._analysis_plugins = None
     self._analysis_plugins_output_format = None
     self._command_line_arguments = None
     self._event_filter_expression = None
     self._event_filter = None
-    self._knowledge_base = knowledge_base.KnowledgeBase()
     self._number_of_stored_analysis_reports = 0
     self._status_view_interval = 0.5
     self._storage_file_path = None
     self._worker_memory_limit = None
     self._worker_timeout = None
 
     self.list_analysis_plugins = False
@@ -87,50 +84,29 @@
 
     processing_status = None
 
     session.command_line_arguments = self._command_line_arguments
     session.debug_mode = self._debug_mode
 
     try:
-      # Writing a separate session start is kept for backwards compatibility.
-      if storage_writer.HasAttributeContainers(
-          sessions.SessionStart.CONTAINER_TYPE):
-        session_start = session.CreateSessionStart()
-        storage_writer.AddAttributeContainer(session_start)
-      else:
-        storage_writer.AddAttributeContainer(session)
+      storage_writer.AddAttributeContainer(session)
 
       try:
-        # Writing a separate session configuration is kept for backwards
-        # compatibility.
-        if storage_writer.HasAttributeContainers(
-            sessions.SessionStart.CONTAINER_TYPE):
-          session_configuration = session.CreateSessionConfiguration()
-          storage_writer.AddAttributeContainer(session_configuration)
-
         processing_status = analysis_engine.AnalyzeEvents(
-            session, self._knowledge_base, storage_writer, self._data_location,
+            session, storage_writer, self._data_location,
             self._analysis_plugins, configuration,
             event_filter=self._event_filter,
             event_filter_expression=self._event_filter_expression,
             status_update_callback=status_update_callback,
             storage_file_path=self._storage_file_path)
 
       finally:
         session.aborted = getattr(processing_status, 'aborted', True)
-
-        # Writing a separate session completion is kept for backwards
-        # compatibility.
-        if storage_writer.HasAttributeContainers(
-            sessions.SessionStart.CONTAINER_TYPE):
-          session_completion = session.CreateSessionCompletion()
-          storage_writer.AddAttributeContainer(session_completion)
-        else:
-          session.completion_time = int(time.time() * 1000000)
-          storage_writer.UpdateAttributeContainer(session)
+        session.completion_time = int(time.time() * 1000000)
+        storage_writer.UpdateAttributeContainer(session)
 
     finally:
       storage_writer.Close()
 
     return processing_status
 
   def _PrintAnalysisReportsDetails(self, storage_reader):
```

### Comparing `plaso-20230311/plaso/cli/extraction_tool.py` & `plaso-20230717/plaso/cli/extraction_tool.py`

 * *Files 7% similar despite different names*

```diff
@@ -22,15 +22,14 @@
 from plaso.cli import logger
 from plaso.cli import status_view
 from plaso.cli import storage_media_tool
 from plaso.cli import tool_options
 from plaso.cli import views
 from plaso.cli.helpers import manager as helpers_manager
 from plaso.containers import artifacts
-from plaso.containers import sessions
 from plaso.engine import configurations
 from plaso.engine import engine
 from plaso.single_process import extraction_engine as single_extraction_engine
 from plaso.filters import parser_filter
 from plaso.helpers import language_tags
 from plaso.lib import definitions
 from plaso.lib import errors
@@ -146,21 +145,50 @@
     # TODO: add a more thorough check to see if the storage file really is
     # a plaso storage file.
 
     if not os.access(dirname, os.W_OK):
       raise errors.BadConfigOption(
           'Unable to write to storage file: {0:s}'.format(storage_file_path))
 
+  def _CreateExtractionEngine(self, single_process_mode):
+    """Creates an extraction engine.
+
+    Args:
+      single_process_mode (bool): True if the engine should use single process
+          mode.
+
+    Returns:
+      BaseEngine: extraction engine.
+    """
+    status_update_callback = (
+        self._status_view.GetExtractionStatusUpdateCallback())
+
+    if single_process_mode:
+      extraction_engine = single_extraction_engine.SingleProcessEngine(
+          status_update_callback=status_update_callback)
+    else:
+      extraction_engine = multi_extraction_engine.ExtractionMultiProcessEngine(
+          number_of_worker_processes=self._number_of_extraction_workers,
+          status_update_callback=status_update_callback,
+          worker_memory_limit=self._worker_memory_limit,
+          worker_timeout=self._worker_timeout)
+
+    extraction_engine.SetStatusUpdateInterval(self._status_view_interval)
+
+    return extraction_engine
+
   def _CreateExtractionProcessingConfiguration(self):
     """Creates an extraction processing configuration.
 
     Returns:
       ProcessingConfiguration: extraction processing configuration.
     """
     configuration = configurations.ProcessingConfiguration()
+    configuration.artifact_definitions_path = self._artifact_definitions_path
+    configuration.custom_artifacts_path = self._custom_artifacts_path
     configuration.data_location = self._data_location
     configuration.extraction.archive_types_string = self._archive_types_string
     configuration.artifact_filters = self._artifact_filters
     configuration.credentials = self._credential_configurations
     configuration.debug_output = self._debug_mode
     configuration.extraction.hasher_file_size_limit = (
         self._hasher_file_size_limit)
@@ -212,39 +240,33 @@
 
     if not source_name or source_name in ('/', '\\'):
       # The user passed the filesystem's root as source
       source_name = 'ROOT'
 
     return '{0:s}-{1:s}.plaso'.format(datetime_string, source_name)
 
-  def _GetExpandedParserFilterExpression(self, knowledge_base):
+  def _GetExpandedParserFilterExpression(self, system_configuration):
     """Determines the expanded parser filter expression.
 
     Args:
-      knowledge_base (KnowledgeBase): contains information from the source
-          data needed for parsing.
+      system_configuration (SystemConfigurationArtifact): system configuration.
 
     Returns:
       str: expanded parser filter expression.
 
     Raises:
       BadConfigOption: if presets in the parser filter expression could not
           be expanded or if an invalid parser or plugin name is specified.
     """
     parser_filter_expression = self._parser_filter_expression
-    if not parser_filter_expression:
-      operating_system_family = knowledge_base.GetValue('operating_system')
-      operating_system_product = knowledge_base.GetValue(
-          'operating_system_product')
-      operating_system_version = knowledge_base.GetValue(
-          'operating_system_version')
-
+    if not parser_filter_expression and system_configuration:
       operating_system_artifact = artifacts.OperatingSystemArtifact(
-          family=operating_system_family, product=operating_system_product,
-          version=operating_system_version)
+          family=system_configuration.operating_system,
+          product=system_configuration.operating_system_product,
+          version=system_configuration.operating_system_version)
 
       preset_definitions = self._presets_manager.GetPresetsByOperatingSystem(
           operating_system_artifact)
       if preset_definitions:
         self._parser_filter_expression = ','.join([
             preset_definition.name
             for preset_definition in preset_definitions])
@@ -388,71 +410,70 @@
       dfvfs_definitions.PREFERRED_NTFS_BACK_END = (
           dfvfs_definitions.TYPE_INDICATOR_TSK)
 
     elif self._vfs_back_end == 'vsgpt':
       dfvfs_definitions.PREFERRED_GPT_BACK_END = (
           dfvfs_definitions.TYPE_INDICATOR_GPT)
 
-  def _PreprocessSources(self, extraction_engine, session, storage_writer):
-    """Preprocesses the sources.
-
-    Args:
-      extraction_engine (BaseEngine): extraction engine to preprocess
-          the sources.
-      session (Session): session in which the sources are processed.
-      storage_writer (StorageWriter): storage writer.
-    """
-    logger.debug('Starting preprocessing.')
-
-    try:
-      extraction_engine.PreprocessSources(
-          self._artifact_definitions_path, self._custom_artifacts_path,
-          self._source_path_specs, session, storage_writer,
-          resolver_context=self._resolver_context)
-
-    except IOError as exception:
-      logger.error('Unable to preprocess with error: {0!s}'.format(exception))
-
-    logger.debug('Preprocessing done.')
-
-  def _ProcessSources(self, session, storage_writer):
-    """Processes the sources and extract events.
+  def _ProcessSource(self, session, storage_writer):
+    """Processes the source and extract events.
 
     Args:
-      session (Session): session in which the sources are processed.
-      storage_writer (StorageWriter): storage writer for a session storage.
+      session (Session): session in which the source is processed.
+      storage_writer (StorageWriter): storage writer to store extracted events.
 
     Returns:
       ProcessingStatus: processing status.
 
     Raises:
       BadConfigOption: if an invalid collection filter was specified.
     """
     single_process_mode = self._single_process_mode
     if self._source_type == dfvfs_definitions.SOURCE_TYPE_FILE:
       single_process_mode = True
 
-    if single_process_mode:
-      extraction_engine = single_extraction_engine.SingleProcessEngine()
-    else:
-      extraction_engine = multi_extraction_engine.ExtractionMultiProcessEngine(
-          number_of_worker_processes=self._number_of_extraction_workers,
-          worker_memory_limit=self._worker_memory_limit,
-          worker_timeout=self._worker_timeout)
+    extraction_engine = self._CreateExtractionEngine(single_process_mode)
 
-    extraction_engine.SetStatusUpdateInterval(self._status_view_interval)
+    extraction_engine.BuildArtifactsRegistry(
+        self._artifact_definitions_path, self._custom_artifacts_path)
+
+    source_configuration = artifacts.SourceConfigurationArtifact(
+        path=self._source_path, source_type=self._source_type)
+
+    # TODO: check if the source was processed previously.
+    # TODO: add check for modification time of source.
 
-    # If the source is a directory or a storage media image
-    # run pre-processing.
+    # If the source is a directory or a storage media image run pre-processing.
+
+    system_configurations = []
     if self._source_type in self._SOURCE_TYPES_TO_PREPROCESS:
-      self._PreprocessSources(extraction_engine, session, storage_writer)
+      try:
+        logger.debug('Starting preprocessing.')
+
+        system_configurations = extraction_engine.PreprocessSource(
+            self._file_system_path_specs, storage_writer,
+            resolver_context=self._resolver_context)
+
+        logger.debug('Preprocessing done.')
+
+      except IOError as exception:
+        system_configurations = []
+
+        logger.error('Unable to preprocess with error: {0!s}'.format(exception))
 
+      # TODO: check if the source was processed previously and if system
+      # configuration differs.
+
+    system_configuration = None
+    if system_configurations:
+      system_configuration = system_configurations[0]
+
+    # TODO: add support for more than 1 system configuration.
     self._expanded_parser_filter_expression = (
-        self._GetExpandedParserFilterExpression(
-            extraction_engine.knowledge_base))
+        self._GetExpandedParserFilterExpression(system_configuration))
 
     enabled_parser_names = self._expanded_parser_filter_expression.split(',')
 
     number_of_enabled_parsers = len(enabled_parser_names)
 
     force_parser = False
     if (self._source_type == dfvfs_definitions.SOURCE_TYPE_FILE and
@@ -471,21 +492,27 @@
           'A Windows EventLog parser is enabled in combination with '
           'extraction of Windows EventLog resources, but the Portable '
           'Executable (PE) parser is disabled. Therefore Windows EventLog '
           'resources cannot be extracted.')
 
       self._extract_winevt_resources = False
 
-    configuration = self._CreateExtractionProcessingConfiguration()
+    processing_configuration = (
+        self._CreateExtractionProcessingConfiguration())
+    processing_configuration.force_parser = force_parser
+
+    environment_variables = (
+        extraction_engine.knowledge_base.GetEnvironmentVariables())
+    user_accounts = list(storage_writer.GetAttributeContainers('user_account'))
 
     try:
       extraction_engine.BuildCollectionFilters(
-          self._artifact_definitions_path, self._custom_artifacts_path,
-          extraction_engine.knowledge_base, self._artifact_filters,
-          self._filter_file)
+          environment_variables, user_accounts,
+          artifact_filter_names=self._artifact_filters,
+          filter_file_path=self._filter_file)
     except errors.InvalidFilter as exception:
       raise errors.BadConfigOption(
           'Unable to build collection filters with error: {0!s}'.format(
               exception))
 
     session.artifact_filters = self._artifact_filters
     session.command_line_arguments = self._command_line_arguments
@@ -496,79 +523,47 @@
     session.parser_filter_expression = self._parser_filter_expression
     session.preferred_codepage = self._preferred_codepage
     session.preferred_encoding = self.preferred_encoding
     session.preferred_language = self._preferred_language or 'en-US'
     session.preferred_time_zone = self._preferred_time_zone
     session.preferred_year = self._preferred_year
 
-    # Writing a separate session start is kept for backwards compatibility.
-    if storage_writer.HasAttributeContainers(
-        sessions.SessionStart.CONTAINER_TYPE):
-      session_start = session.CreateSessionStart()
-      storage_writer.AddAttributeContainer(session_start)
-    else:
-      storage_writer.AddAttributeContainer(session)
+    storage_writer.AddAttributeContainer(session)
 
     processing_status = None
 
     try:
-      # Writing a separate session configuration is kept for backwards
-      # compatibility.
-      if storage_writer.HasAttributeContainers(
-          sessions.SessionStart.CONTAINER_TYPE):
-        session_configuration = session.CreateSessionConfiguration()
-        storage_writer.AddAttributeContainer(session_configuration)
-
-      source_configurations = []
-      for path_spec in self._source_path_specs:
-        source_configuration = artifacts.SourceConfigurationArtifact(
-            path_spec=path_spec)
-        source_configurations.append(source_configuration)
-
-      # TODO: improve to detect more than 1 system configurations.
-      # TODO: improve to add volumes to system configuration.
-      system_configuration = (
-          extraction_engine.knowledge_base.GetSystemConfigurationArtifact())
-      storage_writer.AddAttributeContainer(system_configuration)
+      storage_writer.AddAttributeContainer(source_configuration)
 
-      status_update_callback = (
-          self._status_view.GetExtractionStatusUpdateCallback())
+      for system_configuration in system_configurations:
+        storage_writer.AddAttributeContainer(system_configuration)
 
       if single_process_mode:
         logger.debug('Starting extraction in single process mode.')
 
-        processing_status = extraction_engine.ProcessSources(
-            source_configurations, storage_writer, self._resolver_context,
-            configuration, force_parser=force_parser,
-            status_update_callback=status_update_callback)
+        processing_status = extraction_engine.ProcessSource(
+            storage_writer, self._resolver_context, processing_configuration,
+            system_configurations, self._file_system_path_specs)
 
       else:
         logger.debug('Starting extraction in multi process mode.')
 
-        # The following overrides are needed because pylint 2.6.0 gets confused
-        # about which ProcessSources to check against.
-        # pylint: disable=no-value-for-parameter,unexpected-keyword-arg
-        processing_status = extraction_engine.ProcessSources(
-            source_configurations, storage_writer, session.identifier,
-            configuration, enable_sigsegv_handler=self._enable_sigsegv_handler,
-            status_update_callback=status_update_callback,
+        # The method is named ProcessSourceMulti because pylint 2.6.0 and
+        # later gets confused about keyword arguments when ProcessSource
+        # is used.
+        processing_status = extraction_engine.ProcessSourceMulti(
+            storage_writer, session.identifier, processing_configuration,
+            system_configurations, self._file_system_path_specs,
+            enable_sigsegv_handler=self._enable_sigsegv_handler,
             storage_file_path=self._storage_file_path)
 
     finally:
       session.aborted = getattr(processing_status, 'aborted', True)
-
-      # Writing a separate session completion is kept for backwards
-      # compatibility.
-      if storage_writer.HasAttributeContainers(
-          sessions.SessionStart.CONTAINER_TYPE):
-        session_completion = session.CreateSessionCompletion()
-        storage_writer.AddAttributeContainer(session_completion)
-      else:
-        session.completion_time = int(time.time() * 1000000)
-        storage_writer.UpdateAttributeContainer(session)
+      session.completion_time = int(time.time() * 1000000)
+      storage_writer.UpdateAttributeContainer(session)
 
     return processing_status
 
   def _ReadParserPresetsFromFile(self):
     """Reads the parser presets from the presets.yaml file.
 
     Raises:
@@ -722,17 +717,17 @@
     try:
       self.ScanSource(self._source_path)
     except dfvfs_errors.UserAbort as exception:
       raise errors.UserAbort(exception)
 
     if self._source_type == dfvfs_definitions.SOURCE_TYPE_FILE:
       archive_path_spec = self._ScanSourceForArchive(
-          self._source_path_specs[0])
+          self._file_system_path_specs[0])
       if archive_path_spec:
-        self._source_path_specs = [archive_path_spec]
+        self._file_system_path_specs = [archive_path_spec]
         self._source_type = definitions.SOURCE_TYPE_ARCHIVE
 
     self._status_view.SetMode(self._status_view_mode)
     self._status_view.SetStatusFile(self._status_view_file)
     self._status_view.SetSourceInformation(
         self._source_path, self._source_type,
         artifact_filters=self._artifact_filters,
@@ -761,15 +756,15 @@
     number_of_extraction_warnings = 0
 
     try:
       stored_number_of_extraction_warnings = (
           storage_writer.GetNumberOfAttributeContainers('extraction_warning'))
 
       try:
-        processing_status = self._ProcessSources(session, storage_writer)
+        processing_status = self._ProcessSource(session, storage_writer)
 
       finally:
         number_of_extraction_warnings = (
             storage_writer.GetNumberOfAttributeContainers(
                 'extraction_warning') - stored_number_of_extraction_warnings)
 
     except IOError as exception:
```

### Comparing `plaso-20230311/plaso/cli/helpers/__init__.py` & `plaso-20230717/plaso/cli/helpers/__init__.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/analysis_plugins.py` & `plaso-20230717/plaso/cli/helpers/analysis_plugins.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/archives.py` & `plaso-20230717/plaso/cli/helpers/archives.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/artifact_definitions.py` & `plaso-20230717/plaso/cli/helpers/artifact_definitions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/artifact_filters.py` & `plaso-20230717/plaso/cli/helpers/artifact_filters.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/bloom_analysis.py` & `plaso-20230717/plaso/cli/helpers/bloom_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/codepage.py` & `plaso-20230717/plaso/cli/helpers/codepage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/data_location.py` & `plaso-20230717/plaso/cli/helpers/data_location.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/date_filters.py` & `plaso-20230717/plaso/cli/helpers/date_filters.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/dynamic_output.py` & `plaso-20230717/plaso/cli/helpers/dynamic_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/event_filters.py` & `plaso-20230717/plaso/cli/helpers/event_filters.py`

 * *Files 1% similar despite different names*

```diff
@@ -106,25 +106,25 @@
           'Time slice and slicer cannot be used at the same time.')
 
     time_slice_event_timestamp = None
     if time_slice_event_time_string:
       if ' ' in time_slice_event_time_string:
         raise errors.BadConfigOption(
             'Time slice date and time must be defined in ISO 8601 format, '
-            'for example: 20200619T20:09:23+02:00.')
+            'for example: 2020-06-19T20:09:23+02:00.')
 
       date_time = dfdatetime_time_elements.TimeElements()
 
       try:
         date_time.CopyFromStringISO8601(time_slice_event_time_string)
       except ValueError:
         raise errors.BadConfigOption((
             'Unsupported time slice date and time: {0:s}. The date and time '
             'must be defined in ISO 8601 format, for example: '
-            '20200619T20:09:23+02:00').format(time_slice_event_time_string))
+            '2020-06-19T20:09:23+02:00').format(time_slice_event_time_string))
 
       # TODO: directly use dfDateTime objects in time slice.
       time_slice_event_timestamp = date_time.GetPlasoTimestamp()
 
     setattr(configuration_object, '_event_filter_expression', filter_expression)
 
     if filter_object:
```

### Comparing `plaso-20230311/plaso/cli/helpers/extraction.py` & `plaso-20230717/plaso/cli/helpers/extraction.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/filter_file.py` & `plaso-20230717/plaso/cli/helpers/filter_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/hashers.py` & `plaso-20230717/plaso/cli/helpers/hashers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/interface.py` & `plaso-20230717/plaso/cli/helpers/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/language.py` & `plaso-20230717/plaso/cli/helpers/language.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/manager.py` & `plaso-20230717/plaso/cli/helpers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/nsrlsvr_analysis.py` & `plaso-20230717/plaso/cli/helpers/nsrlsvr_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/opensearch_output.py` & `plaso-20230717/plaso/cli/helpers/opensearch_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/opensearch_ts_output.py` & `plaso-20230717/plaso/cli/helpers/opensearch_ts_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/output_modules.py` & `plaso-20230717/plaso/cli/helpers/output_modules.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/parsers.py` & `plaso-20230717/plaso/cli/helpers/parsers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/process_resources.py` & `plaso-20230717/plaso/cli/helpers/process_resources.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/profiling.py` & `plaso-20230717/plaso/cli/helpers/profiling.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/sessionize_analysis.py` & `plaso-20230717/plaso/cli/helpers/sessionize_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/status_view.py` & `plaso-20230717/plaso/cli/helpers/status_view.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/storage_format.py` & `plaso-20230717/plaso/cli/helpers/storage_format.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/tagging_analysis.py` & `plaso-20230717/plaso/cli/helpers/tagging_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/temporary_directory.py` & `plaso-20230717/plaso/cli/helpers/temporary_directory.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/vfs_backend.py` & `plaso-20230717/plaso/cli/helpers/vfs_backend.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/viper_analysis.py` & `plaso-20230717/plaso/cli/helpers/viper_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/virustotal_analysis.py` & `plaso-20230717/plaso/cli/helpers/virustotal_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/workers.py` & `plaso-20230717/plaso/cli/helpers/workers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/xlsx_output.py` & `plaso-20230717/plaso/cli/helpers/xlsx_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/helpers/yara_rules.py` & `plaso-20230717/plaso/cli/helpers/yara_rules.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/image_export_tool.py` & `plaso-20230717/plaso/cli/image_export_tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,22 +14,22 @@
 from dfvfs.resolver import context
 from dfvfs.resolver import resolver as path_spec_resolver
 
 from plaso.analyzers.hashers import manager as hashers_manager
 from plaso.cli import logger
 from plaso.cli import storage_media_tool
 from plaso.cli.helpers import manager as helpers_manager
-from plaso.containers import sessions
 from plaso.engine import engine
 from plaso.engine import extractors
 from plaso.engine import path_helper
 from plaso.filters import file_entry as file_entry_filters
 from plaso.lib import errors
 from plaso.lib import loggers
 from plaso.lib import specification
+from plaso.storage.fake import writer as fake_writer
 
 
 class ImageExportTool(storage_media_tool.StorageMediaTool):
   """Class that implements the image export CLI tool.
 
   Attributes:
     has_filters (bool): True if filters have been specified via the options.
@@ -124,34 +124,35 @@
     while data:
       hasher_object.Update(data)
       data = file_object.read(self._READ_BUFFER_SIZE)
 
     return hasher_object.GetStringDigest()
 
   def _CreateSanitizedDestination(
-      self, source_file_entry, source_path_spec, source_data_stream_name,
+      self, source_file_entry, file_system_path_spec, source_data_stream_name,
       destination_path):
     """Creates a sanitized path of both destination directory and filename.
 
     This function replaces non-printable and other characters defined in
      _DIRTY_CHARACTERS with an underscore "_".
 
     Args:
       source_file_entry (dfvfs.FileEntry): file entry of the source file.
-      source_path_spec (dfvfs.PathSpec): path specification of the source file.
+      file_system_path_spec (dfvfs.PathSpec): path specifications of the source
+          file system to process.
       source_data_stream_name (str): name of the data stream of the source file
           entry.
       destination_path (str): path of the destination directory.
 
     Returns:
       tuple[str, str]: sanitized paths of both destination directory and
           filename.
     """
     file_system = source_file_entry.GetFileSystem()
-    path = getattr(source_path_spec, 'location', None)
+    path = getattr(file_system_path_spec, 'location', None)
     path_segments = file_system.SplitPath(path)
 
     # Sanitize each path segment.
     for index, path_segment in enumerate(path_segments):
       path_segments[index] = ''.join([
           character if character not in self._DIRTY_CHARACTERS else '_'
           for character in path_segment])
@@ -283,24 +284,25 @@
 
     if not file_entry_processed:
       self._ExtractDataStream(
           file_entry, '', destination_path, skip_duplicates=skip_duplicates)
 
   # TODO: merge with collector and/or engine.
   def _Extract(
-      self, source_path_specs, destination_path, output_writer,
+      self, file_system_path_specs, destination_path, output_writer,
       artifact_filters, filter_file, artifact_definitions_path,
       custom_artifacts_path, skip_duplicates=True):
     """Extracts files.
 
     This method runs the file extraction process on the image and
     potentially on every VSS if that is wanted.
 
     Args:
-      source_path_specs (list[dfvfs.PathSpec]): path specifications to extract.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
       destination_path (str): path where the extracted files should be stored.
       output_writer (CLIOutputWriter): output writer.
       artifact_definitions_path (str): path to artifact definitions file.
       custom_artifacts_path (str): path to custom artifact definitions file.
       artifact_filters (list[str]): names of artifact definitions that are
           used for filtering file system and Windows Registry key paths.
       filter_file (str): path of the file that contains the filter file path
@@ -309,65 +311,89 @@
           should be skipped.
 
     Raises:
       BadConfigOption: if an invalid collection filter was specified.
     """
     extraction_engine = engine.BaseEngine()
 
-    # If the source is a directory or a storage media image
-    # run pre-processing.
+    extraction_engine.BuildArtifactsRegistry(
+        artifact_definitions_path, custom_artifacts_path)
+
+    storage_writer = fake_writer.FakeStorageWriter()
+    storage_writer.Open()
+
+    # If the source is a directory or a storage media image run pre-processing.
+
+    system_configurations = []
     if self._source_type in self._SOURCE_TYPES_TO_PREPROCESS:
-      self._PreprocessSources(extraction_engine)
+      try:
+        logger.debug('Starting preprocessing.')
+
+        # Setting storage writer to None here since we do not want to store
+        # preprocessing information.
+        system_configurations = extraction_engine.PreprocessSource(
+            self._file_system_path_specs, storage_writer,
+            resolver_context=self._resolver_context)
+
+        logger.debug('Preprocessing done.')
+
+      except IOError as exception:
+        logger.error('Unable to preprocess with error: {0!s}'.format(exception))
+
+    # TODO: use system_configurations instead of knowledge base
+    _ = system_configurations
+
+    environment_variables = (
+        extraction_engine.knowledge_base.GetEnvironmentVariables())
+    user_accounts = list(storage_writer.GetAttributeContainers('user_account'))
 
     try:
       extraction_engine.BuildCollectionFilters(
-          artifact_definitions_path, custom_artifacts_path,
-          extraction_engine.knowledge_base, artifact_filters, filter_file)
+          environment_variables, user_accounts,
+          artifact_filter_names=artifact_filters,
+          filter_file_path=filter_file)
     except errors.InvalidFilter as exception:
       raise errors.BadConfigOption(
           'Unable to build collection filters with error: {0!s}'.format(
               exception))
 
-    filters_helper = extraction_engine.collection_filters_helper
-
-    excluded_find_specs = None
-    included_find_specs = None
-    if filters_helper:
-      excluded_find_specs = filters_helper.excluded_file_system_find_specs
-      included_find_specs = filters_helper.included_file_system_find_specs
+    excluded_find_specs = extraction_engine.GetCollectionExcludedFindSpecs()
+    included_find_specs = extraction_engine.GetCollectionIncludedFindSpecs()
 
     output_writer.Write('Extracting file entries.\n')
-    path_spec_generator = self._path_spec_extractor.ExtractPathSpecs(
-        source_path_specs, find_specs=included_find_specs,
-        resolver_context=self._resolver_context)
-
-    for path_spec in path_spec_generator:
-      file_entry = path_spec_resolver.Resolver.OpenFileEntry(
-          path_spec, resolver_context=self._resolver_context)
-
-      if not file_entry:
-        path_spec_string = self._GetPathSpecificationString(path_spec)
-        logger.warning(
-            'Unable to open file entry for path specfication: {0:s}'.format(
-                path_spec_string))
-        continue
-
-      skip_file_entry = False
-      for find_spec in excluded_find_specs or []:
-        skip_file_entry = find_spec.CompareLocation(file_entry)
-        if skip_file_entry:
-          break
 
-      if skip_file_entry:
-        logger.info('Skipped: {0:s} because of exclusion filter.'.format(
-            file_entry.path_spec.location))
-        continue
+    for file_system_path_spec in file_system_path_specs:
+      path_spec_generator = self._path_spec_extractor.ExtractPathSpecs(
+          file_system_path_spec, find_specs=included_find_specs,
+          resolver_context=self._resolver_context)
 
-      self._ExtractFileEntry(
-          file_entry, destination_path, skip_duplicates=skip_duplicates)
+      for path_spec in path_spec_generator:
+        file_entry = path_spec_resolver.Resolver.OpenFileEntry(
+            path_spec, resolver_context=self._resolver_context)
+
+        if not file_entry:
+          path_spec_string = self._GetPathSpecificationString(path_spec)
+          logger.warning(
+              'Unable to open file entry for path specfication: {0:s}'.format(
+                  path_spec_string))
+          continue
+
+        skip_file_entry = False
+        for find_spec in excluded_find_specs or []:
+          skip_file_entry = find_spec.CompareLocation(file_entry)
+          if skip_file_entry:
+            break
+
+        if skip_file_entry:
+          logger.info('Skipped: {0:s} because of exclusion filter.'.format(
+              file_entry.path_spec.location))
+          continue
+
+        self._ExtractFileEntry(
+            file_entry, destination_path, skip_duplicates=skip_duplicates)
 
   def _ParseExtensionsString(self, extensions_string):
     """Parses the extensions string.
 
     Args:
       extensions_string (str): comma separated extensions to filter.
     """
@@ -461,38 +487,14 @@
     signature_identifiers = signature_identifiers.lower()
     signature_identifiers = [
         identifier.strip() for identifier in signature_identifiers.split(',')]
     file_entry_filter = file_entry_filters.SignaturesFileEntryFilter(
         specification_store, signature_identifiers)
     self._filter_collection.AddFilter(file_entry_filter)
 
-  def _PreprocessSources(self, extraction_engine):
-    """Preprocesses the sources.
-
-    Args:
-      extraction_engine (BaseEngine): extraction engine to preprocess
-          the sources.
-    """
-    logger.debug('Starting preprocessing.')
-
-    session = sessions.Session()
-
-    try:
-      # Setting storage writer to None here since we do not want to store
-      # preprocessing information.
-      extraction_engine.PreprocessSources(
-          self._artifact_definitions_path, self._custom_artifacts_path,
-          self._source_path_specs, session, None,
-          resolver_context=self._resolver_context)
-
-    except IOError as exception:
-      logger.error('Unable to preprocess with error: {0!s}'.format(exception))
-
-    logger.debug('Preprocessing done.')
-
   def _ReadSpecificationFile(self, path):
     """Reads the format specification file.
 
     Args:
       path (str): path of the format specification file.
 
     Returns:
@@ -785,16 +787,16 @@
 
     self._EnforceProcessMemoryLimit(self._process_memory_limit)
 
   def PrintFilterCollection(self):
     """Prints the filter collection."""
     self._filter_collection.Print(self._output_writer)
 
-  def ProcessSources(self):
-    """Processes the sources.
+  def ProcessSource(self):
+    """Processes the source.
 
     Raises:
       SourceScannerError: if the source scanner could not find a supported
           file system.
       UserAbort: if the user initiated an abort.
     """
     try:
@@ -804,15 +806,15 @@
 
     self._output_writer.Write('Export started.\n')
 
     if not os.path.isdir(self._destination_path):
       os.makedirs(self._destination_path)
 
     self._Extract(
-        self._source_path_specs, self._destination_path,
+        self._file_system_path_specs, self._destination_path,
         self._output_writer, self._artifact_filters, self._filter_file,
         self._artifact_definitions_path, self._custom_artifacts_path,
         skip_duplicates=self._skip_duplicates)
 
     json_data = []
 
     if not self._no_hashes:
```

### Comparing `plaso-20230311/plaso/cli/log2timeline_tool.py` & `plaso-20230717/plaso/cli/log2timeline_tool.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/pinfo_tool.py` & `plaso-20230717/plaso/cli/pinfo_tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -359,15 +359,15 @@
       stores_are_identical = False
 
       self._PrintCounterDifferences(
           differences,
           column_names=['Parser (plugin) name', 'Number of warnings'],
           title='Timelining warnings generated per parser')
 
-    # Compare timelining warnings by path specification
+    # Compare timelining warnings by path specification.
     warnings_counter = storage_counters.get(
         'timelining_warnings_by_path_spec', collections.Counter())
     compare_warnings_counter = compare_storage_counters.get(
         'timelining_warnings_by_path_spec', collections.Counter())
     differences = self._CompareCounter(
         warnings_counter, compare_warnings_counter)
 
@@ -902,14 +902,15 @@
     enabled_parser_names = 'N/A'
     if session.enabled_parser_names:
       enabled_parser_names = ', '.join(sorted(session.enabled_parser_names))
 
     command_line_arguments = session.command_line_arguments or 'N/A'
     parser_filter_expression = session.parser_filter_expression or 'N/A'
     preferred_encoding = session.preferred_encoding or 'N/A'
+    preferred_time_zone = session.preferred_time_zone or 'N/A'
 
     if session.artifact_filters:
       artifact_filters_string = ', '.join(session.artifact_filters)
     else:
       artifact_filters_string = 'N/A'
     filter_file = session.filter_file or 'N/A'
 
@@ -921,14 +922,15 @@
     table_view.AddRow(['Completion time', completion_time])
     table_view.AddRow(['Product name', session.product_name])
     table_view.AddRow(['Product version', session.product_version])
     table_view.AddRow(['Command line arguments', command_line_arguments])
     table_view.AddRow(['Parser filter expression', parser_filter_expression])
     table_view.AddRow(['Enabled parser and plugins', enabled_parser_names])
     table_view.AddRow(['Preferred encoding', preferred_encoding])
+    table_view.AddRow(['Preferred time zone', preferred_time_zone])
     table_view.AddRow(['Debug mode', session.debug_mode])
     table_view.AddRow(['Artifact filters', artifact_filters_string])
     table_view.AddRow(['Filter file', filter_file])
 
     table_view.Write(self._output_writer)
 
   def _PrintSessionsDetails(self, storage_reader):
@@ -954,15 +956,16 @@
         self._PrintSessionDetailsAsTable(session, session_identifier)
 
       if self._verbose:
         system_configuration = storage_reader.GetAttributeContainerByIndex(
             'system_configuration', session_index)
         if system_configuration:
           self._PrintSystemConfigurations(
-              [system_configuration], session_identifier=session_identifier)
+              storage_reader, [system_configuration],
+              session_identifier=session_identifier)
 
     if self._output_format == 'json':
       self._output_writer.Write('}')
 
   def _PrintSessionsOverview(self, storage_reader):
     """Prints a sessions overview.
 
@@ -993,18 +996,19 @@
       self._PrintSessionsOverview(storage_reader)
 
     if (self._output_format == 'json' or self._verbose or
         'sessions' in self._sections):
       self._PrintSessionsDetails(storage_reader)
 
   def _PrintSystemConfiguration(
-      self, system_configuration, session_identifier=None):
+      self, storage_reader, system_configuration, session_identifier=None):
     """Prints the details of a system configuration.
 
     Args:
+      storage_reader (StorageReader): storage reader.
       system_configuration (SystemConfiguration): system configuration.
       session_identifier (Optional[str]): session identifier, formatted as
           a UUID.
     """
     if not system_configuration:
       return
 
@@ -1044,46 +1048,49 @@
     if session_identifier:
       title = '{0:s}: {1:s}'.format(title, session_identifier)
 
     table_view = views.ViewsFactory.GetTableView(
         self._views_format_type,
         column_names=['Name', 'Offset from UTC'], title=title)
 
-    for time_zone in system_configuration.available_time_zones:
+    # TODO: filter time zones on specific system configuration.
+    for time_zone in storage_reader.GetAttributeContainers('time_zone'):
       hours_from_utc, minutes_from_utc = divmod(time_zone.offset, 60)
       if hours_from_utc < 0:
         sign = '+'
         hours_from_utc *= -1
       else:
         sign = '-'
+
       time_zone_offset = '{0:s}{1:02d}:{2:02d}'.format(
           sign, hours_from_utc, minutes_from_utc)
       table_view.AddRow([time_zone.name, time_zone_offset])
 
     table_view.Write(self._output_writer)
 
     title = 'User accounts'
     if session_identifier:
       title = '{0:s}: {1:s}'.format(title, session_identifier)
 
     table_view = views.ViewsFactory.GetTableView(
         self._views_format_type,
         column_names=['Username', 'User directory'], title=title)
 
-    for user_account in system_configuration.user_accounts:
-      table_view.AddRow([
-          user_account.username, user_account.user_directory])
+    # TODO: filter user accounts on specific system configuration.
+    for user_account in storage_reader.GetAttributeContainers('user_account'):
+      table_view.AddRow([user_account.username, user_account.user_directory])
 
     table_view.Write(self._output_writer)
 
   def _PrintSystemConfigurations(
-      self, system_configurations, session_identifier=None):
+      self, storage_reader, system_configurations, session_identifier=None):
     """Prints the details of system configurations.
 
     Args:
+      storage_reader (StorageReader): storage reader.
       system_configurations (list[SystemConfiguration]): system configurations.
       session_identifier (Optional[str]): session identifier, formatted as
           a UUID.
     """
     if self._output_format == 'json':
       self._output_writer.Write(', "system_configurations": {')
 
@@ -1096,15 +1103,16 @@
             json_serializer.JSONAttributeContainerSerializer.WriteSerialized(
                 configuration.system_configuration))
         self._output_writer.Write(
             '"system_configuration": {0:s}'.format(json_string))
 
       elif self._output_format in ('markdown', 'text'):
         self._PrintSystemConfiguration(
-            configuration, session_identifier=session_identifier)
+            storage_reader, configuration,
+            session_identifier=session_identifier)
 
     if self._output_format == 'json':
       self._output_writer.Write('}')
 
   def _PrintStorageInformation(self, storage_reader):
     """Prints information about the store.
```

### Comparing `plaso-20230311/plaso/cli/psort_tool.py` & `plaso-20230717/plaso/cli/psort_tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -121,25 +121,21 @@
 
   def _CreateOutputAndFormattingProcessingConfiguration(self):
     """Creates an output and formatting processing configuration.
 
     Returns:
       ProcessingConfiguration: output and formatting processing configuration.
     """
-    if self._preferred_language:
-      preferred_language = self._preferred_language
-    else:
-      preferred_language = self._knowledge_base.language
-
     configuration = configurations.ProcessingConfiguration()
+    configuration.custom_formatters_path = self._output_custom_formatters_path
     configuration.data_location = self._data_location
     configuration.debug_output = self._debug_mode
     configuration.dynamic_time = self._output_dynamic_time
     configuration.log_filename = self._log_file
-    configuration.preferred_language = preferred_language
+    configuration.preferred_language = self._preferred_language
     configuration.preferred_time_zone = self._output_time_zone
     configuration.profiling.directory = self._profiling_directory
     configuration.profiling.profilers = self._profilers
     configuration.profiling.sample_rate = self._profiling_sample_rate
 
     return configuration
 
@@ -477,26 +473,17 @@
 
     storage_reader = storage_factory.StorageFactory.CreateStorageReaderForFile(
         self._storage_file_path)
     if not storage_reader:
       raise RuntimeError('Unable to create storage reader.')
 
     try:
-      for session_index, session in enumerate(storage_reader.GetSessions()):
-        self._knowledge_base.SetActiveSession(session.identifier)
-
-        system_configuration = storage_reader.GetAttributeContainerByIndex(
-            'system_configuration', session_index)
-        self._knowledge_base.ReadSystemConfigurationArtifact(
-            system_configuration)
-
       self._number_of_stored_analysis_reports = (
           storage_reader.GetNumberOfAttributeContainers(
               self._CONTAINER_TYPE_ANALYSIS_REPORT))
-
     finally:
       storage_reader.Close()
 
     session = engine.BaseEngine.CreateSession()
 
     configuration = self._CreateOutputAndFormattingProcessingConfiguration()
 
@@ -516,16 +503,16 @@
       # TODO: add single process output and formatting engine support.
       output_engine = (
           multi_output_engine.OutputAndFormattingMultiProcessEngine())
 
       output_engine.SetStatusUpdateInterval(self._status_view_interval)
 
       output_engine.ExportEvents(
-          self._knowledge_base, storage_reader, self._output_module,
-          configuration, deduplicate_events=self._deduplicate_events,
+          storage_reader, self._output_module, configuration,
+          deduplicate_events=self._deduplicate_events,
           event_filter=self._event_filter,
           status_update_callback=status_update_callback,
           time_slice=self._time_slice, use_time_slicer=self._use_time_slicer)
 
       self._output_module.Close()
       self._output_module = None
```

### Comparing `plaso-20230311/plaso/cli/psteal_tool.py` & `plaso-20230717/plaso/cli/psteal_tool.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,14 @@
 
 from plaso.cli import extraction_tool
 from plaso.cli import tool_options
 from plaso.cli.helpers import manager as helpers_manager
 from plaso.containers import reports
 from plaso.engine import configurations
 from plaso.engine import engine
-from plaso.engine import knowledge_base
 from plaso.lib import errors
 from plaso.lib import loggers
 from plaso.multi_process import output_engine as multi_output_engine
 from plaso.parsers import manager as parsers_manager
 from plaso.storage import factory as storage_factory
 
 
@@ -83,15 +82,14 @@
       output_writer (Optional[OutputWriter]): output writer, where None
           indicates that the stdout output writer should be used.
     """
     super(PstealTool, self).__init__(
         input_reader=input_reader, output_writer=output_writer)
     self._artifacts_registry = None
     self._deduplicate_events = True
-    self._knowledge_base = knowledge_base.KnowledgeBase()
     self._number_of_analysis_reports = 0
     self._output_format = None
     self._parsers_manager = parsers_manager.ParsersManager
     self._preferred_year = None
     self._time_slice = None
     self._use_time_slicer = False
 
@@ -103,25 +101,21 @@
 
   def _CreateOutputAndFormattingProcessingConfiguration(self):
     """Creates an output and formatting processing configuration.
 
     Returns:
       ProcessingConfiguration: output and formatting processing configuration.
     """
-    if self._preferred_language:
-      preferred_language = self._preferred_language
-    else:
-      preferred_language = self._knowledge_base.language
-
     configuration = configurations.ProcessingConfiguration()
+    configuration.custom_formatters_path = self._output_custom_formatters_path
     configuration.data_location = self._data_location
     configuration.debug_output = self._debug_mode
     configuration.dynamic_time = self._output_dynamic_time
     configuration.log_filename = self._log_file
-    configuration.preferred_language = preferred_language
+    configuration.preferred_language = self._preferred_language
     configuration.preferred_time_zone = self._output_time_zone
     configuration.profiling.directory = self._profiling_directory
     configuration.profiling.profilers = self._profilers
     configuration.profiling.sample_rate = self._profiling_sample_rate
 
     return configuration
 
@@ -363,16 +357,16 @@
               self._storage_file_path))
 
       # TODO: add single process output and formatting engine support.
       output_engine = (
           multi_output_engine.OutputAndFormattingMultiProcessEngine())
 
       output_engine.ExportEvents(
-          self._knowledge_base, storage_reader, self._output_module,
-          configuration, deduplicate_events=self._deduplicate_events,
+          storage_reader, self._output_module, configuration,
+          deduplicate_events=self._deduplicate_events,
           status_update_callback=status_update_callback,
           time_slice=self._time_slice, use_time_slicer=self._use_time_slicer)
 
       self._output_module.Close()
       self._output_module = None
 
     if self._quiet_mode:
```

### Comparing `plaso-20230311/plaso/cli/status_view.py` & `plaso-20230717/plaso/cli/status_view.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/storage_media_tool.py` & `plaso-20230717/plaso/cli/storage_media_tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -389,20 +389,20 @@
     super(StorageMediaTool, self).__init__(
         input_reader=input_reader, output_writer=output_writer)
     self._custom_artifacts_path = None
     self._artifact_definitions_path = None
     self._artifact_filters = None
     self._credentials = []
     self._credential_configurations = []
+    self._file_system_path_specs = []
     self._filter_file = None
     self._mediator = StorageMediaToolMediator(
         input_reader=input_reader, output_writer=output_writer)
     self._partitions = None
     self._source_path = None
-    self._source_path_specs = []
     self._source_type = None
     self._volumes = None
     self._vss_only = False
     self._vss_stores = None
 
   def _ParseCredentialOptions(self, options):
     """Parses the credential options.
@@ -652,9 +652,9 @@
 
     if not base_path_specs:
       raise errors.SourceScannerError(
           'No supported file system found in source.')
 
     # pylint: disable=protected-access
     self._credential_configurations = volume_scanner._credential_configurations
-    self._source_path_specs = base_path_specs
+    self._file_system_path_specs = base_path_specs
     self._source_type = volume_scanner.source_type
```

### Comparing `plaso-20230311/plaso/cli/time_slices.py` & `plaso-20230717/plaso/cli/time_slices.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/tool_options.py` & `plaso-20230717/plaso/cli/tool_options.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,20 @@
 # -*- coding: utf-8 -*-
 """The CLI tool options mix-ins."""
 
 import os
 import pytz
 
 from plaso.analysis import manager as analysis_manager
+from plaso.analyzers.hashers import manager as hashers_manager
+from plaso.cli import logger
 from plaso.cli import views
 from plaso.cli.helpers import manager as helpers_manager
 from plaso.cli.helpers import profiling
-from plaso.analyzers.hashers import manager as hashers_manager
+from plaso.formatters import yaml_formatters_file
 from plaso.lib import errors
 from plaso.output import manager as output_manager
 
 
 # TODO: pass argument_parser instead of argument_group and add groups
 # in mix-ins.
 
@@ -102,14 +104,15 @@
   _DEPRECATED_OUTPUT_FORMATS = frozenset(['l2tcsv', 'l2ttln', 'tln'])
 
   def __init__(self):
     """Initializes output module options."""
     super(OutputModuleOptions, self).__init__()
     self._output_additional_fields = []
     self._output_custom_fields = []
+    self._output_custom_formatters_path = None
     self._output_dynamic_time = None
     self._output_filename = None
     self._output_format = None
     self._output_module = None
     self._output_time_zone = None
 
     self.list_time_zones = False
@@ -225,14 +228,32 @@
           name, value = custom_field.split(':')
         except ValueError:
           raise errors.BadConfigOption(
               'Unsupported custom field: {0:s}'.format(custom_field))
 
         self._output_custom_fields.append((name, value))
 
+    custom_formatters_path = self.ParseStringOption(
+        options, 'custom_formatter_definitions_path')
+
+    if custom_formatters_path and not os.path.isfile(custom_formatters_path):
+      raise errors.BadConfigOption((
+          'Unable to determine path to custom formatter definitions: '
+          '{0:s}.').format(custom_formatters_path))
+
+    if custom_formatters_path:
+      logger.info('Custom formatter definitions path: {0:s}'.format(
+          custom_formatters_path))
+
+    if custom_formatters_path:
+      message_formatters_file = yaml_formatters_file.YAMLFormattersFile()
+      message_formatters_file.ReadFromFile(custom_formatters_path)
+
+    self._output_custom_formatters_path = custom_formatters_path
+
     self._output_dynamic_time = getattr(options, 'dynamic_time', False)
 
     time_zone_string = self.ParseStringOption(options, 'output_time_zone')
     if isinstance(time_zone_string, str):
       if time_zone_string.lower() == 'list':
         self.list_time_zones = True
 
@@ -282,14 +303,23 @@
             'the default fields. A custom field is defined as "name:value". '
             'Multiple custom field names can be defined as list of comma '
             'separated values. Note that regular fields will are favoured '
             'above custom fields with same name. Output formats that support '
             'this are: dynamic, opensearch and xlsx.'))
 
     argument_group.add_argument(
+        '--custom_formatter_definitions', '--custom-formatter-definitions',
+        dest='custom_formatter_definitions_path', type=str, metavar='PATH',
+        action='store', help=(
+            'Path to a file containing custom event formatter definitions, '
+            'which is a .yaml file. Custom event formatter definitions can '
+            'be used to customize event messages and override the built-in '
+            'event formatter definitions.'))
+
+    argument_group.add_argument(
         '--dynamic_time', '--dynamic-time', dest='dynamic_time',
         action='store_true', default=False, help=(
             'Indicate that the output should use dynamic time. Output formats '
             'that support dynamic time are: dynamic'))
 
     # Note the default here is None so we can determine if the time zone
     # option was set.
```

### Comparing `plaso-20230311/plaso/cli/tools.py` & `plaso-20230717/plaso/cli/tools.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/cli/views.py` & `plaso-20230717/plaso/cli/views.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/__init__.py` & `plaso-20230717/plaso/containers/__init__.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/analysis_results.py` & `plaso-20230717/plaso/containers/analysis_results.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/analyzer_result.py` & `plaso-20230717/plaso/containers/analyzer_result.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/artifacts.py` & `plaso-20230717/plaso/containers/artifacts.py`

 * *Files 4% similar despite different names*

```diff
@@ -57,14 +57,18 @@
   Attributes:
     name (str): name of the host according to the naming schema.
     schema (str): naming schema such as "DNS", "NIS", "SMB/NetBIOS".
   """
 
   CONTAINER_TYPE = 'hostname'
 
+  SCHEMA = {
+      'name': 'str',
+      'schema': 'str'}
+
   def __init__(self, name=None, schema='DNS'):
     """Initializes a hostname artifact.
 
     Args:
       name (Optional[str]): name of the host according to the naming schema.
       schema (Optional[str]): naming schema.
     """
@@ -88,14 +92,20 @@
         Professional XP". This value is typically obtained from the source data.
     version (str): version, such as "10.14.1" or "5.1". This value is typically
         obtained from the source data.
   """
 
   CONTAINER_TYPE = 'operating_system'
 
+  SCHEMA = {
+      'family': 'str',
+      'name': 'str',
+      'product': 'str',
+      'version': 'str'}
+
   _DEFAULT_FAMILY_AND_VERSION = (
       definitions.OPERATING_SYSTEM_FAMILY_UNKNOWN, (0, 0))
 
   _FAMILY_AND_VERSION_PER_NAME = {
       'Windows 2000': (definitions.OPERATING_SYSTEM_FAMILY_WINDOWS_NT, (5, 0)),
       'Windows 2003': (definitions.OPERATING_SYSTEM_FAMILY_WINDOWS_NT, (5, 2)),
       'Windows 2003 R2': (
@@ -234,14 +244,19 @@
     data_stream (str): name of a data stream.
     path_segment_separator (str): path segment separator.
     path_segments (list[str]): path segments.
   """
 
   CONTAINER_TYPE = 'path'
 
+  SCHEMA = {
+      'data_stream': 'str',
+      'path_segment_separator': 'str',
+      'path_segments': 'List[str]'}
+
   def __init__(self, data_stream=None, path=None, path_segment_separator='/'):
     """Initializes a path artifact.
 
     Args:
       data_stream (Optional[str]): name of a data stream.
       path (Optional[str]): a path.
       path_segment_separator (Optional[str]): path segment separator.
@@ -398,81 +413,102 @@
     return False
 
 
 class SourceConfigurationArtifact(ArtifactAttributeContainer):
   """Source configuration artifact attribute container.
 
   The source configuration contains the configuration data of a source
-  that is (or going to be) processed such as volume in a storage media
-  image or a mounted directory.
+  that is (or going to be) processed such storage media image or a mounted
+  directory.
 
   Attributes:
-    mount_path (str): path of a "mounted" directory input source.
-    path_spec (dfvfs.PathSpec): path specification of the source that is
-        processed.
-    system_configuration (SystemConfigurationArtifact): system configuration of
-        a specific system installation, such as Windows or Linux, detected by
-        the pre-processing on the source.
+    path (str): path of the source.
+    source_type (str): type of source.
   """
 
   CONTAINER_TYPE = 'source_configuration'
 
-  def __init__(self, path_spec=None):
+  SCHEMA = {
+      'path': 'str',
+      'source_type': 'str'}
+
+  def __init__(self, path=None, source_type=None):
     """Initializes a source configuration artifact.
 
     Args:
-      path_spec (Optional[dfvfs.PathSpec]): path specification of the source
-          that is processed.
+      path (Optional[str]): path of the source.
+      source_type (Optional[str]): type of source.
     """
     super(SourceConfigurationArtifact, self).__init__()
-    self.mount_path = None
-    self.path_spec = path_spec
+    self.path = path
+    self.source_type = source_type
 
 
 class SystemConfigurationArtifact(ArtifactAttributeContainer):
   """System configuration artifact attribute container.
 
   The system configuration contains the configuration data of a specific
   system installation such as Windows or Linux.
 
   Attributes:
     available_time_zones (list[TimeZone]): available time zones.
     code_page (str): system code page.
+    environment_variables (list[EnvironmentVariableArtifact]): environment
+        variables.
     hostname (HostnameArtifact): hostname.
     keyboard_layout (str): keyboard layout.
     language (str): system language.
     operating_system (str): operating system for example "MacOS" or "Windows".
     operating_system_product (str): operating system product for example
         "Windows XP".
     operating_system_version (str): operating system version for example
         "10.9.2" or "8.1".
+    path_specs (list[dfvfs.PathSpec]): path specifications of the file systems
+        the system configuration was retrieved from.
     time_zone (str): system time zone.
     user_accounts (list[UserAccountArtifact]): user accounts.
   """
 
   CONTAINER_TYPE = 'system_configuration'
 
+  # TODO: add SCHEMA
+  # SCHEMA = {
+  #     'code_page': 'str',
+  #     'environment_variables': Llist[EnvironmentVariableArtifact]',
+  #     'keyboard_layout': 'str',
+  #     'hostname': 'HostnameArtifact',
+  #     'language': 'str',
+  #     'operating_system': 'str',
+  #     'operating_system_product': 'str',
+  #     'operating_system_version': 'str',
+  #     'path_specs': 'List[dfvfs.PathSpec]',
+  #     'time_zone': 'str'}
+
   def __init__(self, code_page=None, language=None, time_zone=None):
     """Initializes a system configuration artifact.
 
     Args:
       code_page (Optional[str]): system code page.
       language (Optional[str]): system language.
       time_zone (Optional[str]): system time zone.
     """
     super(SystemConfigurationArtifact, self).__init__()
+    # TODO: kept for backwards compatibility.
     self.available_time_zones = []
     self.code_page = code_page
+    self.environment_variables = []
     self.hostname = None
     self.keyboard_layout = None
     self.language = language
     self.operating_system = None
     self.operating_system_product = None
     self.operating_system_version = None
+    self.path_specs = []
     self.time_zone = time_zone
+    # TODO: kept for backwards compatibility.
     self.user_accounts = []
 
 
 class TimeZoneArtifact(ArtifactAttributeContainer):
   """Time zone artifact attribute container.
 
   Attributes:
@@ -483,14 +519,20 @@
     name (str): name describing the time zone for example "Greenwich Standard
         Time".
     offset (int): time zone offset in number of minutes from UTC.
   """
 
   CONTAINER_TYPE = 'time_zone'
 
+  SCHEMA = {
+      'localized_name': 'str',
+      'mui_form': 'str',
+      'name': 'str',
+      'offset': 'int'}
+
   def __init__(
       self, localized_name=None, mui_form=None, name=None, offset=None):
     """Initializes a time zone artifact.
 
     Args:
       localized_name (Optional[str]): name describing the time zone in localized
           language for example "Greenwich (standaardtijd)".
@@ -519,14 +561,21 @@
     identifier (str): user identifier.
     user_directory (str): path of the user (or home or profile) directory.
     username (str): name uniquely identifying the user.
   """
 
   CONTAINER_TYPE = 'user_account'
 
+  SCHEMA = {
+      'full_name': 'str',
+      'group_identifier': 'str',
+      'identifier': 'str',
+      'user_directory': 'str',
+      'username': 'str'}
+
   def __init__(
       self, full_name=None, group_identifier=None, identifier=None,
       path_separator='/', user_directory=None, username=None):
     """Initializes a user account artifact.
 
     Args:
       full_name (Optional[str]): name describing the user.
```

### Comparing `plaso-20230311/plaso/containers/counts.py` & `plaso-20230717/plaso/containers/counts.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/event_sources.py` & `plaso-20230717/plaso/containers/event_sources.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/events.py` & `plaso-20230717/plaso/containers/events.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/plist_event.py` & `plaso-20230717/plaso/containers/plist_event.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/reports.py` & `plaso-20230717/plaso/containers/reports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/sessions.py` & `plaso-20230717/plaso/containers/sessions.py`

 * *Files 0% similar despite different names*

```diff
@@ -39,15 +39,15 @@
   """
 
   CONTAINER_TYPE = 'session'
 
   SCHEMA = {
       'file_entropy': 'str',
       'aborted': 'bool',
-      'artifact_filters': 'str',
+      'artifact_filters': 'List[str]',
       'command_line_arguments': 'str',
       'completion_time': 'int',
       'debug_mode': 'bool',
       'enabled_parser_names': 'List[str]',
       'filter_file': 'str',
       'identifier': 'str',
       'parser_filter_expression': 'str',
```

### Comparing `plaso-20230311/plaso/containers/tasks.py` & `plaso-20230717/plaso/containers/tasks.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/warnings.py` & `plaso-20230717/plaso/containers/warnings.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/containers/windows_events.py` & `plaso-20230717/plaso/containers/windows_events.py`

 * *Files 3% similar despite different names*

```diff
@@ -52,15 +52,16 @@
 class WindowsRegistryEventData(events.EventData):
   """Windows Registry event data attribute container.
 
   Attributes:
     key_path (str): Windows Registry key path.
     last_written_time (dfdatetime.DateTimeValues): key last written date and
         time.
-    values (str): names and data of the values in the key.
+    values (list[tuple[str, str, str]]): name, data type and data of the values
+        in the key.
   """
 
   DATA_TYPE = 'windows:registry:key_value'
 
   def __init__(self):
     """Initializes event data."""
     super(WindowsRegistryEventData, self).__init__(data_type=self.DATA_TYPE)
```

### Comparing `plaso-20230311/plaso/dependencies.py` & `plaso-20230717/plaso/dependencies.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,32 +12,33 @@
 #
 # A version tuple consists of:
 # (version_attribute_name, minimum_version, maximum_version, is_required)
 #
 # Where version_attribute_name is either a name of an attribute,
 # property or method.
 PYTHON_DEPENDENCIES = {
-    'acstore': ('__version__', '20230101', None, True),
+    'acstore': ('__version__', '20230519', None, True),
     'artifacts': ('__version__', '20220219', None, True),
     'bencode': ('', '', None, True),
     'certifi': ('__version__', '2016.9.26', None, True),
     'cryptography': ('__version__', '2.0.2', None, True),
     'dateutil': ('__version__', '1.5', None, True),
     'defusedxml': ('__version__', '0.5.0', None, True),
     'dfdatetime': ('__version__', '20221112', None, True),
-    'dfvfs': ('__version__', '20221224', None, True),
+    'dfvfs': ('__version__', '20230407', None, True),
     'dfwinreg': ('__version__', '20211207', None, True),
-    'dtfabric': ('__version__', '20220219', None, True),
+    'dtfabric': ('__version__', '20230518', None, True),
     'flor': ('__version__', '1.1.3', None, False),
     'future': ('__version__', '0.16.0', None, True),
     'lz4': ('__version__', '0.10.0', None, True),
     'opensearchpy': ('__versionstr__', '', None, False),
     'pefile': ('__version__', '2021.5.24', None, True),
     'psutil': ('__version__', '5.4.3', None, True),
     'pybde': ('get_version()', '20220121', None, True),
+    'pycaes': ('get_version()', '20221127', None, True),
     'pycreg': ('get_version()', '20200725', None, True),
     'pyesedb': ('get_version()', '20220806', None, True),
     'pyevt': ('get_version()', '20191104', None, True),
     'pyevtx': ('get_version()', '20220724', None, True),
     'pyewf': ('get_version()', '20131210', None, True),
     'pyfsapfs': ('get_version()', '20201107', None, True),
     'pyfsext': ('get_version()', '20220112', None, True),
```

### Comparing `plaso-20230311/plaso/engine/artifact_filters.py` & `plaso-20230717/plaso/engine/artifact_filters.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,79 +1,83 @@
 # -*- coding: utf-8 -*-
 """Helper to create filters based on forensic artifact definitions."""
 
 from artifacts import definitions as artifact_types
 
-from dfwinreg import registry_searcher
+from dfvfs.helpers import file_system_searcher as dfvfs_file_system_searcher
 
-from dfvfs.helpers import file_system_searcher
+from dfwinreg import registry_searcher as dfwinreg_registry_searcher
 
-from plaso.engine import filters_helper
 from plaso.engine import logger
 from plaso.engine import path_helper
 
 
-class ArtifactDefinitionsFiltersHelper(filters_helper.CollectionFiltersHelper):
+class ArtifactDefinitionsFiltersHelper(object):
   """Helper to create collection filters based on artifact definitions.
 
   Builds collection filters from forensic artifact definitions.
 
   For more information about Forensic Artifacts see:
   https://github.com/ForensicArtifacts/artifacts/blob/main/docs/Artifacts%20definition%20format%20and%20style%20guide.asciidoc
 
   Attributes:
     file_system_artifact_names (set[str]): names of artifacts definitions that
         generated file system find specifications.
+    file_system_find_specs (list[dfvfs.FindSpec]): file system find
+        specifications of paths to include in the collection.
     registry_artifact_names (set[str]): names of artifacts definitions that
         generated Windows Registry find specifications.
+    registry_find_specs (list[dfwinreg.FindSpec]): Windows Registry find
+        specifications.
   """
 
   _COMPATIBLE_REGISTRY_KEY_PATH_PREFIXES = frozenset([
       'HKEY_CURRENT_USER',
       'HKEY_LOCAL_MACHINE\\SYSTEM',
       'HKEY_LOCAL_MACHINE\\SOFTWARE',
       'HKEY_LOCAL_MACHINE\\SAM',
       'HKEY_LOCAL_MACHINE\\SECURITY',
       'HKEY_USERS'])
 
-  def __init__(self, artifacts_registry, knowledge_base):
+  def __init__(self, artifacts_registry):
     """Initializes an artifact definitions filters helper.
 
     Args:
       artifacts_registry (artifacts.ArtifactDefinitionsRegistry): artifact
           definitions registry.
-      knowledge_base (KnowledgeBase): contains information from the source
-          data needed for filtering.
     """
     super(ArtifactDefinitionsFiltersHelper, self).__init__()
     self._artifacts_registry = artifacts_registry
-    self._knowledge_base = knowledge_base
 
     self.file_system_artifact_names = set()
+    self.file_system_find_specs = []
     self.registry_artifact_names = set()
+    self.registry_find_specs = []
 
-  def _BuildFindSpecsFromArtifact(self, definition, environment_variables):
+  def _BuildFindSpecsFromArtifact(
+      self, definition, environment_variables, user_accounts):
     """Builds find specifications from an artifact definition.
 
     Args:
       definition (artifacts.ArtifactDefinition): artifact definition.
       environment_variables (list[EnvironmentVariableArtifact]):
           environment variables.
+      user_accounts (list[UserAccountArtifact]): user accounts.
 
     Returns:
       list[dfvfs.FindSpec|dfwinreg.FindSpec]: dfVFS or dfWinReg find
           specifications.
     """
     find_specs = []
     for source in definition.sources:
       if source.type_indicator == artifact_types.TYPE_INDICATOR_FILE:
         for path_entry in set(source.paths):
           specifications = self._BuildFindSpecsFromFileSourcePath(
               path_entry, source.separator, environment_variables,
-              self._knowledge_base.user_accounts)
+              user_accounts)
           find_specs.extend(specifications)
           self.file_system_artifact_names.add(definition.name)
 
       elif (source.type_indicator ==
             artifact_types.TYPE_INDICATOR_WINDOWS_REGISTRY_KEY):
         for key_path in set(source.keys):
           if ArtifactDefinitionsFiltersHelper.CheckKeyCompatibility(key_path):
@@ -100,44 +104,46 @@
             find_specs.extend(specifications)
             self.registry_artifact_names.add(definition.name)
 
       elif (source.type_indicator ==
             artifact_types.TYPE_INDICATOR_ARTIFACT_GROUP):
         for name in source.names:
           specifications = self._BuildFindSpecsFromGroupName(
-              name, environment_variables)
+              name, environment_variables, user_accounts)
           find_specs.extend(specifications)
 
       else:
         logger.warning(
             'Unsupported artifact definition source type: "{0:s}"'.format(
                 source.type_indicator))
 
     return find_specs
 
-  def _BuildFindSpecsFromGroupName(self, group_name, environment_variables):
+  def _BuildFindSpecsFromGroupName(
+      self, group_name, environment_variables, user_accounts):
     """Builds find specifications from a artifact group name.
 
     Args:
       group_name (str): artifact group name.
-      environment_variables (list[str]): environment variable attributes used to
-          dynamically populate environment variables in file and registry
-          artifacts.
+      environment_variables (list[EnvironmentVariableArtifact]):
+          environment variables.
+      user_accounts (list[UserAccountArtifact]): user accounts.
 
     Returns:
       list[dfwinreg.FindSpec|dfvfs.FindSpec]: find specifications or None if no
           artifact with the given name can be retrieved.
     """
     definition = self._artifacts_registry.GetDefinitionByName(group_name)
     if not definition:
       definition = self._artifacts_registry.GetDefinitionByAlias(group_name)
     if not definition:
       return None
 
-    return self._BuildFindSpecsFromArtifact(definition, environment_variables)
+    return self._BuildFindSpecsFromArtifact(
+        definition, environment_variables, user_accounts)
 
   def _BuildFindSpecsFromRegistrySourceKey(self, key_path):
     """Build find specifications from a Windows Registry source type.
 
     Args:
       key_path (str): Windows Registry key path defined by the source.
 
@@ -156,30 +162,30 @@
         # Rewrite CurrentControlSet to ControlSet* for Windows NT.
         key_path_glob = 'HKEY_LOCAL_MACHINE\\System\\ControlSet*{0:s}'.format(
             key_path_glob[43:])
 
       elif key_path_glob_upper.startswith('HKEY_USERS\\%%USERS.SID%%'):
         key_path_glob = 'HKEY_CURRENT_USER{0:s}'.format(key_path_glob[26:])
 
-      find_spec = registry_searcher.FindSpec(key_path_glob=key_path_glob)
+      find_spec = dfwinreg_registry_searcher.FindSpec(
+          key_path_glob=key_path_glob)
       find_specs.append(find_spec)
 
     return find_specs
 
   def _BuildFindSpecsFromFileSourcePath(
       self, source_path, path_separator, environment_variables, user_accounts):
     """Builds find specifications from a file source type.
 
     Args:
       source_path (str): file system path defined by the source.
       path_separator (str): file system path segment separator.
-      environment_variables (list[str]): environment variable attributes used to
-          dynamically populate environment variables in key.
-      user_accounts (list[str]): identified user accounts stored in the
-          knowledge base.
+      environment_variables (list[EnvironmentVariableArtifact]):
+          environment variables.
+      user_accounts (list[UserAccountArtifact]): user accounts.
 
     Returns:
       list[dfvfs.FindSpec]: find specifications for the file source type.
     """
     find_specs = []
     for path_glob in path_helper.PathHelper.ExpandGlobStars(
         source_path, path_separator):
@@ -199,56 +205,59 @@
         if not path.startswith(path_separator):
           logger.warning((
               'The path filter must be defined as an absolute path: '
               '"{0:s}"').format(path))
           continue
 
         try:
-          find_spec = file_system_searcher.FindSpec(
+          find_spec = dfvfs_file_system_searcher.FindSpec(
               case_sensitive=False, location_glob=path,
               location_separator=path_separator)
         except ValueError as exception:
           logger.error((
               'Unable to build find specification for path: "{0:s}" with '
               'error: {1!s}').format(path, exception))
           continue
 
         find_specs.append(find_spec)
 
     return find_specs
 
-  def BuildFindSpecs(self, artifact_filter_names, environment_variables=None):
+  def BuildFindSpecs(
+      self, artifact_filter_names, environment_variables=None,
+      user_accounts=None):
     """Builds find specifications from artifact definitions.
 
     Args:
       artifact_filter_names (list[str]): names of artifact definitions that are
           used for filtering file system and Windows Registry key paths.
       environment_variables (Optional[list[EnvironmentVariableArtifact]]):
           environment variables.
+      user_accounts (Optional[list[UserAccountArtifact]]): user accounts.
     """
     find_specs = []
     for name in artifact_filter_names:
       definition = self._artifacts_registry.GetDefinitionByName(name)
       if not definition:
         definition = self._artifacts_registry.GetDefinitionByAlias(name)
       if not definition:
         logger.debug('undefined artifact definition: {0:s}'.format(name))
         continue
 
       logger.debug('building find spec from artifact definition: {0:s}'.format(
           name))
       artifact_find_specs = self._BuildFindSpecsFromArtifact(
-          definition, environment_variables)
+          definition, environment_variables, user_accounts)
       find_specs.extend(artifact_find_specs)
 
     for find_spec in find_specs:
-      if isinstance(find_spec, file_system_searcher.FindSpec):
-        self.included_file_system_find_specs.append(find_spec)
+      if isinstance(find_spec, dfvfs_file_system_searcher.FindSpec):
+        self.file_system_find_specs.append(find_spec)
 
-      elif isinstance(find_spec, registry_searcher.FindSpec):
+      elif isinstance(find_spec, dfwinreg_registry_searcher.FindSpec):
         self.registry_find_specs.append(find_spec)
 
       else:
         logger.warning('Unsupported find specification type: {0!s}'.format(
             type(find_spec)))
 
   @classmethod
```

### Comparing `plaso-20230311/plaso/engine/configurations.py` & `plaso-20230717/plaso/engine/configurations.py`

 * *Files 10% similar despite different names*

```diff
@@ -179,26 +179,33 @@
     return 'tasks' in self.profilers
 
 
 class ProcessingConfiguration(interface.AttributeContainer):
   """Configuration settings for processing.
 
   Attributes:
+    artifact_definitions_path (str): path to artifact definitions directory
+        or file.
     artifact_filters (Optional list[str]): names of artifact
           definitions that are used for filtering file system and Windows
           Registry key paths.
     credentials (list[CredentialConfiguration]): credential configurations.
+    custom_artifacts_path (str): path to custom artifact definitions
+        directory or file.
+    custom_formatters_path (str): path to custom formatter definitions file.
     data_location (str): path to the data files.
     debug_output (bool): True if debug output should be enabled.
     dynamic_time (bool): True if date and time values should be represented
         in their granularity or semantically.
     event_extraction (EventExtractionConfiguration): event extraction
         configuration.
     extraction (ExtractionConfiguration): extraction configuration.
     filter_file (str): path to a file with find specifications.
+    force_parser (bool): True if a specified parser should be forced to be used
+        to extract events.
     log_filename (str): name of the log file.
     parser_filter_expression (str): parser filter expression,
         where None represents all parsers and plugins.
     preferred_codepage (str): preferred codepage.
     preferred_encoding (str): preferred output encoding.
     preferred_language (str): preferred language.
     preferred_time_zone (str): preferred time zone.
@@ -206,27 +213,32 @@
         time values.
     profiling (ProfilingConfiguration): profiling configuration.
     task_storage_format (str): format to use for storing task results.
     task_storage_path (str): path of the directory containing SQLite task
         storage files.
     temporary_directory (str): path of the directory for temporary files.
   """
+
   CONTAINER_TYPE = 'processing_configuration'
 
   def __init__(self):
     """Initializes a process configuration object."""
     super(ProcessingConfiguration, self).__init__()
+    self.artifact_definitions_path = None
     self.artifact_filters = None
     self.credentials = []
+    self.custom_artifacts_path = None
+    self.custom_formatters_path = None
     self.data_location = None
     self.debug_output = False
     self.dynamic_time = False
     self.event_extraction = EventExtractionConfiguration()
     self.extraction = ExtractionConfiguration()
     self.filter_file = None
+    self.force_parser = None
     self.log_filename = None
     self.parser_filter_expression = None
     self.preferred_codepage = None
     self.preferred_encoding = None
     self.preferred_language = None
     self.preferred_time_zone = None
     self.preferred_year = None
```

### Comparing `plaso-20230311/plaso/engine/engine.py` & `plaso-20230717/plaso/engine/engine.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 from artifacts import reader as artifacts_reader
 from artifacts import registry as artifacts_registry
 
 from dfvfs.lib import errors as dfvfs_errors
 from dfvfs.path import factory as path_spec_factory
 from dfvfs.resolver import resolver as path_spec_resolver
 
+from plaso.containers import artifacts
 from plaso.containers import sessions
 from plaso.engine import artifact_filters
 from plaso.engine import filter_file
 from plaso.engine import knowledge_base
 from plaso.engine import logger
 from plaso.engine import path_filters
 from plaso.engine import processing_status
@@ -25,89 +26,41 @@
 from plaso.preprocessors import mediator as preprocess_mediator
 
 
 class BaseEngine(object):
   """Processing engine interface.
 
   Attributes:
-    collection_filters_helper (CollectionFiltersHelper): collection filters
-        helper.
     knowledge_base (KnowledgeBase): knowledge base.
   """
 
   _WINDOWS_REGISTRY_FILES_ARTIFACT_NAMES = [
       'WindowsSystemRegistryFiles', 'WindowsUserRegistryFiles']
 
   def __init__(self):
     """Initializes an engine."""
     super(BaseEngine, self).__init__()
     self._abort = False
     self._analyzers_profiler = None
+    self._artifacts_registry = None
+    self._excluded_file_system_find_specs = None
+    self._included_file_system_find_specs = None
     self._memory_profiler = None
     self._name = 'Main'
     self._processing_status = processing_status.ProcessingStatus()
     self._processing_profiler = None
+    self._registry_find_specs = None
     self._serializers_profiler = None
     # The interval of status updates in number of seconds.
     self._status_update_interval = 0.5
     self._storage_profiler = None
     self._task_queue_profiler = None
 
-    self.collection_filters_helper = None
     self.knowledge_base = knowledge_base.KnowledgeBase()
 
-  def _BuildArtifactsRegistry(
-      self, artifact_definitions_path, custom_artifacts_path):
-    """Build Find Specs from artifacts or filter file if available.
-
-    Args:
-      artifact_definitions_path (str): path to artifact definitions directory
-          or file.
-      custom_artifacts_path (str): path to custom artifact definitions
-          directory or file.
-
-    Returns:
-      artifacts.ArtifactDefinitionsRegistry: artifact definitions registry.
-
-    Raises:
-      BadConfigOption: if artifact definitions cannot be read.
-    """
-    if not artifact_definitions_path:
-      raise errors.BadConfigOption(
-          'No such artifact definitions: {0:s}.'.format(
-              artifact_definitions_path))
-
-    registry = artifacts_registry.ArtifactDefinitionsRegistry()
-    reader = artifacts_reader.YamlArtifactsReader()
-
-    try:
-      if os.path.isdir(artifact_definitions_path):
-        registry.ReadFromDirectory(reader, artifact_definitions_path)
-      else:
-        registry.ReadFromFile(reader, artifact_definitions_path)
-
-    except (KeyError, artifacts_errors.FormatError) as exception:
-      raise errors.BadConfigOption((
-          'Unable to read artifact definitions from: {0:s} with error: '
-          '{1!s}').format(artifact_definitions_path, exception))
-
-    if custom_artifacts_path:
-      try:
-        if os.path.isdir(custom_artifacts_path):
-          registry.ReadFromDirectory(reader, custom_artifacts_path)
-        else:
-          registry.ReadFromFile(reader, custom_artifacts_path)
-
-      except (KeyError, artifacts_errors.FormatError) as exception:
-        raise errors.BadConfigOption((
-            'Unable to read custom artifact definitions from: {0:s} with '
-            'error: {1!s}').format(custom_artifacts_path, exception))
-
-    return registry
-
   def _StartProfiling(self, configuration):
     """Starts profiling.
 
     Args:
       configuration (ProfilingConfiguration): profiling configuration.
     """
     if not configuration:
@@ -168,14 +121,135 @@
       self._storage_profiler.Stop()
       self._storage_profiler = None
 
     if self._task_queue_profiler:
       self._task_queue_profiler.Stop()
       self._task_queue_profiler = None
 
+  def BuildArtifactsRegistry(
+      self, artifact_definitions_path, custom_artifacts_path):
+    """Builds an artificats definition registry.
+
+    Args:
+      artifact_definitions_path (str): path to artifact definitions directory
+          or file.
+      custom_artifacts_path (str): path to custom artifact definitions
+          directory or file.
+
+    Raises:
+      BadConfigOption: if artifact definitions cannot be read.
+    """
+    if not artifact_definitions_path:
+      raise errors.BadConfigOption('Missing artifact definitions path.')
+
+    registry = artifacts_registry.ArtifactDefinitionsRegistry()
+    reader = artifacts_reader.YamlArtifactsReader()
+
+    try:
+      if os.path.isdir(artifact_definitions_path):
+        registry.ReadFromDirectory(reader, artifact_definitions_path)
+      else:
+        registry.ReadFromFile(reader, artifact_definitions_path)
+
+    except (KeyError, artifacts_errors.FormatError) as exception:
+      raise errors.BadConfigOption((
+          'Unable to read artifact definitions from: {0:s} with error: '
+          '{1!s}').format(artifact_definitions_path, exception))
+
+    if custom_artifacts_path:
+      try:
+        if os.path.isdir(custom_artifacts_path):
+          registry.ReadFromDirectory(reader, custom_artifacts_path)
+        else:
+          registry.ReadFromFile(reader, custom_artifacts_path)
+
+      except (KeyError, artifacts_errors.FormatError) as exception:
+        raise errors.BadConfigOption((
+            'Unable to read custom artifact definitions from: {0:s} with '
+            'error: {1!s}').format(custom_artifacts_path, exception))
+
+    self._artifacts_registry = registry
+
+  def BuildCollectionFilters(
+      self, environment_variables, user_accounts, artifact_filter_names=None,
+      filter_file_path=None):
+    """Builds collection filters from artifacts or filter file if available.
+
+    Args:
+      environment_variables (list[EnvironmentVariableArtifact]):
+          environment variables.
+      user_accounts (list[UserAccountArtifact]): user accounts.
+      artifact_filter_names (Optional[list[str]]): names of artifact
+          definitions that are used for filtering file system and Windows
+          Registry key paths.
+      filter_file_path (Optional[str]): path of filter file.
+
+    Raises:
+      InvalidFilter: if no valid file system find specifications are built.
+    """
+    filters_helper = None
+
+    if artifact_filter_names:
+      logger.debug(
+          'building find specification based on artifacts: {0:s}'.format(
+              ', '.join(artifact_filter_names)))
+
+      filters_helper = artifact_filters.ArtifactDefinitionsFiltersHelper(
+          self._artifacts_registry)
+      filters_helper.BuildFindSpecs(
+          artifact_filter_names, environment_variables=environment_variables,
+          user_accounts=user_accounts)
+
+      # If the user selected Windows Registry artifacts we have to ensure
+      # the Windows Registry files are parsed.
+      if filters_helper.registry_find_specs:
+        filters_helper.BuildFindSpecs(
+            self._WINDOWS_REGISTRY_FILES_ARTIFACT_NAMES,
+            environment_variables=environment_variables,
+            user_accounts=user_accounts)
+
+      if not filters_helper.file_system_find_specs:
+        raise errors.InvalidFilter(
+            'No valid file system find specifications were built from '
+            'artifacts.')
+
+      self._included_file_system_find_specs = (
+          filters_helper.file_system_find_specs)
+      self._registry_find_specs = filters_helper.registry_find_specs
+
+    elif filter_file_path:
+      logger.debug(
+          'building find specification based on filter file: {0:s}'.format(
+              filter_file_path))
+
+      filter_file_path_lower = filter_file_path.lower()
+      if (filter_file_path_lower.endswith('.yaml') or
+          filter_file_path_lower.endswith('.yml')):
+        filter_file_object = yaml_filter_file.YAMLFilterFile()
+      else:
+        filter_file_object = filter_file.FilterFile()
+
+      filter_file_path_filters = filter_file_object.ReadFromFile(
+          filter_file_path)
+
+      filters_helper = path_filters.PathCollectionFiltersHelper()
+      filters_helper.BuildFindSpecs(
+          filter_file_path_filters, environment_variables=environment_variables)
+
+      if (not filters_helper.excluded_file_system_find_specs and
+          not filters_helper.included_file_system_find_specs):
+        raise errors.InvalidFilter((
+            'No valid file system find specifications were built from filter '
+            'file: {0:s}.').format(filter_file_path))
+
+      self._excluded_file_system_find_specs = (
+          filters_helper.excluded_file_system_find_specs)
+      self._included_file_system_find_specs = (
+          filters_helper.included_file_system_find_specs)
+
   # pylint: disable=too-many-arguments
   @classmethod
   def CreateSession(
       cls, artifact_filter_names=None, command_line_arguments=None,
       debug_mode=False, filter_file_path=None, preferred_encoding='utf-8'):
     """Creates a session attribute container.
 
@@ -197,160 +271,132 @@
     session.command_line_arguments = command_line_arguments
     session.debug_mode = debug_mode
     session.filter_file = filter_file_path
     session.preferred_encoding = preferred_encoding
 
     return session
 
-  def GetSourceFileSystem(self, source_path_spec, resolver_context=None):
+  def GetCollectionExcludedFindSpecs(self):
+    """Retrieves find specifications to exclude from collection.
+
+    Returns:
+      list[dfvfs.FindSpec]: find specifications to exclude from collection.
+    """
+    return self._excluded_file_system_find_specs or []
+
+  def GetCollectionIncludedFindSpecs(self):
+    """Retrieves find specifications to include in collection.
+
+    Returns:
+      list[dfvfs.FindSpec]: find specifications to include in collection.
+    """
+    return self._included_file_system_find_specs or []
+
+  def GetSourceFileSystem(self, file_system_path_spec, resolver_context=None):
     """Retrieves the file system of the source.
 
     Args:
-      source_path_spec (dfvfs.PathSpec): path specifications of the sources
-          to process.
+      file_system_path_spec (dfvfs.PathSpec): path specifications of
+          the source file system to process.
       resolver_context (dfvfs.Context): resolver context.
 
     Returns:
       tuple: containing:
 
         dfvfs.FileSystem: file system
         path.PathSpec: mount point path specification. The mount point path
             specification refers to either a directory or a volume on a storage
             media device or image. It is needed by the dfVFS file system
             to indicate the base location of the file system.
 
     Raises:
       RuntimeError: if source file system path specification is not set.
     """
-    if not source_path_spec:
-      raise RuntimeError('Missing source path specification.')
+    if not file_system_path_spec:
+      raise RuntimeError('Missing source file system path specification.')
 
     file_system = path_spec_resolver.Resolver.OpenFileSystem(
-        source_path_spec, resolver_context=resolver_context)
+        file_system_path_spec, resolver_context=resolver_context)
 
-    type_indicator = source_path_spec.type_indicator
+    type_indicator = file_system_path_spec.type_indicator
     if path_spec_factory.Factory.IsSystemLevelTypeIndicator(type_indicator):
-      mount_point = source_path_spec
+      mount_point = file_system_path_spec
     else:
-      mount_point = source_path_spec.parent
+      mount_point = file_system_path_spec.parent
 
     return file_system, mount_point
 
-  def PreprocessSources(
-      self, artifact_definitions_path, custom_artifacts_path,
-      source_path_specs, session, storage_writer, resolver_context=None):
-    """Preprocesses the sources.
+  def PreprocessSource(
+      self, file_system_path_specs, storage_writer, resolver_context=None):
+    """Preprocesses a source.
 
     Args:
-      artifact_definitions_path (str): path to artifact definitions directory
-          or file.
-      custom_artifacts_path (str): path to custom artifact definitions
-          directory or file.
-      source_path_specs (list[dfvfs.PathSpec]): path specifications of
-          the sources to process.
-      session (Session): session the preprocessing is part of.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
       storage_writer (StorageWriter): storage writer.
       resolver_context (Optional[dfvfs.Context]): resolver context.
-    """
-    artifacts_registry_object = self._BuildArtifactsRegistry(
-        artifact_definitions_path, custom_artifacts_path)
 
-    mediator = preprocess_mediator.PreprocessMediator(
-        session, storage_writer, self.knowledge_base)
+    Returns:
+      list[SystemConfigurationArtifact]: system configurations found in
+          the source.
+    """
+    mediator = preprocess_mediator.PreprocessMediator(storage_writer)
 
     detected_operating_systems = []
-    for source_path_spec in source_path_specs:
+    system_configurations = []
+    for path_spec in file_system_path_specs:
       try:
         file_system, mount_point = self.GetSourceFileSystem(
-            source_path_spec, resolver_context=resolver_context)
+            path_spec, resolver_context=resolver_context)
       except (RuntimeError, dfvfs_errors.BackEndError) as exception:
         logger.error(exception)
         continue
 
       preprocess_manager.PreprocessPluginsManager.RunPlugins(
-          artifacts_registry_object, file_system, mount_point, mediator)
-
-      operating_system = self.knowledge_base.GetValue('operating_system')
-      if operating_system:
-        detected_operating_systems.append(operating_system)
-
-    if detected_operating_systems:
-      logger.info('Preprocessing detected operating systems: {0:s}'.format(
-          ', '.join(detected_operating_systems)))
-      self.knowledge_base.SetValue(
-          'operating_system', detected_operating_systems[0])
-
-  def BuildCollectionFilters(
-      self, artifact_definitions_path, custom_artifacts_path,
-      knowledge_base_object, artifact_filter_names=None, filter_file_path=None):
-    """Builds collection filters from artifacts or filter file if available.
-
-    Args:
-      artifact_definitions_path (str): path to artifact definitions file.
-      custom_artifacts_path (str): path to custom artifact definitions file.
-      knowledge_base_object (KnowledgeBase): knowledge base.
-      artifact_filter_names (Optional[list[str]]): names of artifact
-          definitions that are used for filtering file system and Windows
-          Registry key paths.
-      filter_file_path (Optional[str]): path of filter file.
-
-    Raises:
-      InvalidFilter: if no valid file system find specifications are built.
-    """
-    environment_variables = knowledge_base_object.GetEnvironmentVariables()
-    if artifact_filter_names:
-      logger.debug(
-          'building find specification based on artifacts: {0:s}'.format(
-              ', '.join(artifact_filter_names)))
-
-      artifacts_registry_object = self._BuildArtifactsRegistry(
-          artifact_definitions_path, custom_artifacts_path)
-      self.collection_filters_helper = (
-          artifact_filters.ArtifactDefinitionsFiltersHelper(
-              artifacts_registry_object, knowledge_base_object))
-      self.collection_filters_helper.BuildFindSpecs(
-          artifact_filter_names, environment_variables=environment_variables)
-
-      # If the user selected Windows Registry artifacts we have to ensure
-      # the Windows Registry files are parsed.
-      if self.collection_filters_helper.registry_find_specs:
-        self.collection_filters_helper.BuildFindSpecs(
-            self._WINDOWS_REGISTRY_FILES_ARTIFACT_NAMES,
-            environment_variables=environment_variables)
-
-      if not self.collection_filters_helper.included_file_system_find_specs:
-        raise errors.InvalidFilter(
-            'No valid file system find specifications were built from '
-            'artifacts.')
+          self._artifacts_registry, file_system, mount_point, mediator)
 
-    elif filter_file_path:
-      logger.debug(
-          'building find specification based on filter file: {0:s}'.format(
-              filter_file_path))
-
-      filter_file_path_lower = filter_file_path.lower()
-      if (filter_file_path_lower.endswith('.yaml') or
-          filter_file_path_lower.endswith('.yml')):
-        filter_file_object = yaml_filter_file.YAMLFilterFile()
-      else:
-        filter_file_object = filter_file.FilterFile()
+      operating_system = mediator.GetValue('operating_system')
+      if not operating_system:
+        continue
 
-      filter_file_path_filters = filter_file_object.ReadFromFile(
-          filter_file_path)
+      detected_operating_systems.append(operating_system)
 
-      self.collection_filters_helper = (
-          path_filters.PathCollectionFiltersHelper())
-      self.collection_filters_helper.BuildFindSpecs(
-          filter_file_path_filters, environment_variables=environment_variables)
+      system_configuration = artifacts.SystemConfigurationArtifact(
+          code_page=mediator.code_page, language=mediator.language)
+      # Ensure environment_variables is a list otherwise serialization will
+      # fail.
+      system_configuration.environment_variables = list(
+          mediator.GetEnvironmentVariables())
+      system_configuration.hostname = mediator.hostname
+      system_configuration.keyboard_layout = mediator.GetValue(
+          'keyboard_layout')
+      system_configuration.operating_system = mediator.GetValue(
+          'operating_system')
+      system_configuration.operating_system_product = mediator.GetValue(
+          'operating_system_product')
+      system_configuration.operating_system_version = mediator.GetValue(
+          'operating_system_version')
+      # TODO: add support for multi file system system configurations.
+      system_configuration.path_specs = [path_spec]
+
+      if mediator.time_zone:
+        system_configuration.time_zone = mediator.time_zone.zone
+
+      system_configurations.append(system_configuration)
+
+      mediator.Reset()
+
+    if system_configurations:
+      # TODO: kept for backwards compatibility.
+      self.knowledge_base.ReadSystemConfigurationArtifact(
+          system_configurations[0])
+      for environment_variable in system_configuration.environment_variables:
+        self.knowledge_base.AddEnvironmentVariable(environment_variable)
 
-      if (not self.collection_filters_helper.excluded_file_system_find_specs and
-          not self.collection_filters_helper.included_file_system_find_specs):
-        raise errors.InvalidFilter((
-            'No valid file system find specifications were built from filter '
-            'file: {0:s}.').format(filter_file_path))
+    return system_configurations
 
   def SetStatusUpdateInterval(self, status_update_interval):
     """Sets the status update interval.
 
     Args:
       status_update_interval (float): status update interval.
     """
```

### Comparing `plaso-20230311/plaso/engine/extractors.py` & `plaso-20230717/plaso/engine/extractors.py`

 * *Files 2% similar despite different names*

```diff
@@ -185,22 +185,22 @@
         parser.Parse(parser_mediator)
       elif isinstance(parser, parsers_interface.FileObjectParser):
         parser.Parse(parser_mediator, file_object)
       result = self._PARSE_RESULT_SUCCESS
 
     # We catch IOError so we can determine the parser that generated the error.
     except (IOError, dfvfs_errors.BackEndError) as exception:
-      display_name = parser_mediator.GetDisplayName(file_entry)
+      display_name = parser_mediator.GetDisplayName(file_entry=file_entry)
       logger.warning(
           '{0:s} unable to parse file: {1:s} with error: {2!s}'.format(
               parser.NAME, display_name, exception))
       result = self._PARSE_RESULT_FAILURE
 
     except errors.WrongParser as exception:
-      display_name = parser_mediator.GetDisplayName(file_entry)
+      display_name = parser_mediator.GetDisplayName(file_entry=file_entry)
       logger.debug(
           '{0:s} unable to parse file: {1:s} with error: {2!s}'.format(
               parser.NAME, display_name, exception))
       result = self._PARSE_RESULT_UNSUPPORTED
 
     parser_mediator.SampleMemoryUsage(parser.NAME)
 
@@ -236,15 +236,15 @@
             'Parser object missing for parser: {0:s}'.format(parser_name))
 
       if parser.FILTERS:
         if not self._CheckParserCanProcessFileEntry(parser, file_entry):
           parse_results = self._PARSE_RESULT_SUCCESS
           continue
 
-      display_name = parser_mediator.GetDisplayName(file_entry)
+      display_name = parser_mediator.GetDisplayName(file_entry=file_entry)
       logger.debug((
           '[ParseFileEntryWithParsers] parsing file: {0:s} with parser: '
           '{1:s}').format(display_name, parser_name))
 
       parse_result = self._ParseFileEntryWithParser(
           parser_mediator, parser, file_entry, file_object=file_object)
 
@@ -347,61 +347,14 @@
   directory, file or storage media device or image.
   """
 
   _MAXIMUM_DEPTH = 255
 
   _UNICODE_SURROGATES_RE = re.compile('[\ud800-\udfff]')
 
-  def _ExtractPathSpecs(
-      self, path_spec, find_specs=None, recurse_file_system=True,
-      resolver_context=None):
-    """Extracts path specification from a specific source.
-
-    Args:
-      path_spec (dfvfs.PathSpec): path specification.
-      find_specs (Optional[list[dfvfs.FindSpec]]): find specifications
-          used in path specification extraction.
-      recurse_file_system (Optional[bool]): True if extraction should
-          recurse into a file system.
-      resolver_context (Optional[dfvfs.Context]): resolver context.
-
-    Yields:
-      dfvfs.PathSpec: path specification of a file entry found in the source.
-    """
-    file_entry = None
-    try:
-      file_entry = path_spec_resolver.Resolver.OpenFileEntry(
-          path_spec, resolver_context=resolver_context)
-    except (
-        dfvfs_errors.AccessError, dfvfs_errors.BackEndError,
-        dfvfs_errors.PathSpecError) as exception:
-      logger.error('Unable to open file entry with error: {0!s}'.format(
-          exception))
-
-    if not file_entry:
-      path_spec_string = self._GetPathSpecificationString(path_spec)
-      logger.warning('Unable to open: {0:s}'.format(path_spec_string))
-
-    elif (not file_entry.IsDirectory() and not file_entry.IsFile() and
-          not file_entry.IsDevice()):
-      path_spec_string = self._GetPathSpecificationString(path_spec)
-      logger.warning((
-          'Source path specification not a device, file or directory.\n'
-          '{0:s}').format(path_spec_string))
-
-    elif file_entry.IsFile():
-      yield path_spec
-
-    else:
-      for extracted_path_spec in self._ExtractPathSpecsFromFileSystem(
-          path_spec, find_specs=find_specs,
-          recurse_file_system=recurse_file_system,
-          resolver_context=resolver_context):
-        yield extracted_path_spec
-
   def _ExtractPathSpecsFromDirectory(self, file_entry, depth=0):
     """Extracts path specification from a directory.
 
     Args:
       file_entry (dfvfs.FileEntry): file entry that refers to the directory.
       depth (Optional[int]): current depth where 0 represents the file system
           root.
@@ -442,15 +395,15 @@
 
       for path_spec in self._ExtractPathSpecsFromFile(sub_file_entry):
         yield path_spec
 
     for sub_file_entry in sub_directories:
       try:
         for path_spec in self._ExtractPathSpecsFromDirectory(
-            sub_file_entry, depth=(depth + 1)):
+            sub_file_entry, depth=depth + 1):
           yield path_spec
 
       except (
           IOError, dfvfs_errors.AccessError, dfvfs_errors.BackEndError,
           dfvfs_errors.PathSpecError) as exception:
         logger.warning('{0!s}'.format(exception))
 
@@ -546,28 +499,52 @@
           'utf-8', errors='surrogateescape')
       path_spec_string = path_spec_string.decode(
           'utf-8', errors='backslashreplace')
 
     return path_spec_string
 
   def ExtractPathSpecs(
-      self, path_specs, find_specs=None, recurse_file_system=True,
+      self, path_spec, find_specs=None, recurse_file_system=True,
       resolver_context=None):
     """Extracts path specification from a specific source.
 
     Args:
-      path_specs (Optional[list[dfvfs.PathSpec]]): path specifications.
+      path_spec (dfvfs.PathSpec): path specification.
       find_specs (Optional[list[dfvfs.FindSpec]]): find specifications
           used in path specification extraction.
       recurse_file_system (Optional[bool]): True if extraction should
           recurse into a file system.
       resolver_context (Optional[dfvfs.Context]): resolver context.
 
     Yields:
       dfvfs.PathSpec: path specification of a file entry found in the source.
     """
-    for path_spec in path_specs:
-      for extracted_path_spec in self._ExtractPathSpecs(
+    file_entry = None
+    try:
+      file_entry = path_spec_resolver.Resolver.OpenFileEntry(
+          path_spec, resolver_context=resolver_context)
+    except (
+        dfvfs_errors.AccessError, dfvfs_errors.BackEndError,
+        dfvfs_errors.PathSpecError) as exception:
+      logger.error('Unable to open file entry with error: {0!s}'.format(
+          exception))
+
+    if not file_entry:
+      path_spec_string = self._GetPathSpecificationString(path_spec)
+      logger.warning('Unable to open: {0:s}'.format(path_spec_string))
+
+    elif (not file_entry.IsDirectory() and not file_entry.IsFile() and
+          not file_entry.IsDevice()):
+      path_spec_string = self._GetPathSpecificationString(path_spec)
+      logger.warning((
+          'Source path specification not a device, file or directory.\n'
+          '{0:s}').format(path_spec_string))
+
+    elif file_entry.IsFile():
+      yield path_spec
+
+    else:
+      for extracted_path_spec in self._ExtractPathSpecsFromFileSystem(
           path_spec, find_specs=find_specs,
           recurse_file_system=recurse_file_system,
           resolver_context=resolver_context):
         yield extracted_path_spec
```

### Comparing `plaso-20230311/plaso/engine/filter_file.py` & `plaso-20230717/plaso/engine/filter_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/engine/path_filters.py` & `plaso-20230717/plaso/engine/path_filters.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 
 Path filters are specified in filter files and are used during collection
 to include or exclude file system paths.
 """
 
 from dfvfs.helpers import file_system_searcher
 
-from plaso.engine import filters_helper
 from plaso.engine import logger
 from plaso.engine import path_helper
 
 
 class PathFilter(object):
   """Path filter.
 
@@ -47,16 +46,29 @@
     super(PathFilter, self).__init__()
     self.description = description
     self.filter_type = filter_type
     self.path_separator = path_separator
     self.paths = paths or []
 
 
-class PathCollectionFiltersHelper(filters_helper.CollectionFiltersHelper):
-  """Path collection filters helper."""
+class PathCollectionFiltersHelper(object):
+  """Path collection filters helper.
+
+  Attributes:
+    excluded_file_system_find_specs (list[dfvfs.FindSpec]): file system find
+        specifications of paths to exclude from the collection.
+    included_file_system_find_specs (list[dfvfs.FindSpec]): file system find
+        specifications of paths to include in the collection.
+  """
+
+  def __init__(self):
+    """Initializes a collection filters helper."""
+    super(PathCollectionFiltersHelper, self).__init__()
+    self.excluded_file_system_find_specs = []
+    self.included_file_system_find_specs = []
 
   def BuildFindSpecs(self, path_filters, environment_variables=None):
     """Builds find specifications from path filters.
 
     Args:
       path_filters (list[PathFilter]): path filters.
       environment_variables (Optional[list[EnvironmentVariableArtifact]]):
```

### Comparing `plaso-20230311/plaso/engine/path_helper.py` & `plaso-20230717/plaso/engine/path_helper.py`

 * *Files 0% similar despite different names*

```diff
@@ -58,15 +58,15 @@
     if first_path_segment not in ('%%users.homedir%%', '%%users.userprofile%%'):
       if cls._IsWindowsDrivePathSegment(path_segments[0]):
         path_segments[0] = ''
 
       user_path = path_separator.join(path_segments)
       user_paths.append(user_path)
 
-    else:
+    elif user_accounts:
       for user_account in user_accounts:
         user_path_segments = user_account.GetUserDirectoryPathSegments()
 
         if not user_path_segments:
           continue
 
         if cls._IsWindowsDrivePathSegment(user_path_segments[0]):
```

### Comparing `plaso-20230311/plaso/engine/process_info.py` & `plaso-20230717/plaso/engine/process_info.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/engine/processing_status.py` & `plaso-20230717/plaso/engine/processing_status.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/engine/profilers.py` & `plaso-20230717/plaso/engine/profilers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/engine/tagging_file.py` & `plaso-20230717/plaso/engine/tagging_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/engine/timeliner.py` & `plaso-20230717/plaso/engine/timeliner.py`

 * *Files 16% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 
 import collections
 import copy
 import datetime
 import os
 import pytz
 
+from dfdatetime import interface as dfdatetime_interface
 from dfdatetime import semantic_time as dfdatetime_semantic_time
 
 from plaso.containers import events
 from plaso.containers import warnings
 from plaso.engine import yaml_timeliner_file
 from plaso.lib import definitions
 
@@ -22,41 +23,62 @@
     number_of_produced_events (int): number of produced events.
     parsers_counter (collections.Counter): number of events per parser or
         parser plugin.
   """
 
   _DEFAULT_TIME_ZONE = pytz.UTC
 
+  _INT64_MIN = -1 << 63
+  _INT64_MAX = (1 << 63) - 1
+
   _TIMELINER_CONFIGURATION_FILENAME = 'timeliner.yaml'
 
-  def __init__(self, knowledge_base, data_location=None, preferred_year=None):
+  def __init__(
+      self, data_location=None, preferred_year=None,
+      system_configurations=None):
     """Initializes an event data timeliner.
 
     Args:
-      knowledge_base (KnowledgeBase): contains information from the source
-          data needed for generation of the time line.
       data_location (Optional[str]): path of the timeliner configuration file.
       preferred_year (Optional[int]): preferred initial year value for year-less
           date and time values.
+      system_configurations (Optional[list[SystemConfigurationArtifact]]):
+          system configurations.
     """
     super(EventDataTimeliner, self).__init__()
     self._attribute_mappings = {}
     self._base_years = {}
     self._current_year = self._GetCurrentYear()
     self._data_location = data_location
-    self._knowledge_base = knowledge_base
     self._place_holder_event = set()
+    self._preferred_time_zone = None
     self._preferred_year = preferred_year
-    self._time_zone = None
+    self._time_zone_per_path_spec = None
 
     self.number_of_produced_events = 0
     self.parsers_counter = collections.Counter()
 
+    self._CreateTimeZonePerPathSpec(system_configurations)
     self._ReadConfigurationFile()
 
+  def _CreateTimeZonePerPathSpec(self, system_configurations):
+    """Creates the time zone per path specification lookup table.
+
+    Args:
+      system_configurations (list[SystemConfigurationArtifact]): system
+          configurations.
+    """
+    self._time_zone_per_path_spec = {}
+    for system_configuration in system_configurations or []:
+      if system_configuration.time_zone:
+        for path_spec in system_configuration.path_specs:
+          if path_spec.parent:
+            self._time_zone_per_path_spec[path_spec.parent] = (
+                system_configuration.time_zone)
+
   def _GetBaseYear(self, storage_writer, event_data):
     """Retrieves the base year.
 
     Args:
       storage_writer (StorageWriter): storage writer.
       event_data (EventData): event data.
 
@@ -140,54 +162,78 @@
     Returns:
       int: the current year.
     """
     datetime_object = datetime.datetime.now()
     return datetime_object.year
 
   def _GetEvent(
-      self, storage_writer, event_data, date_time, date_time_description):
+      self, storage_writer, event_data, event_data_stream, date_time,
+      date_time_description):
     """Retrieves an event.
 
     Args:
       storage_writer (StorageWriter): storage writer.
       event_data (EventData): event data.
+      event_data_stream (EventDataStream): event data stream.
       date_time (dfdatetime.DateTimeValues): date and time values.
       date_time_description (str): description of the meaning of the date and
           time values.
 
     Returns:
       EventObject: event.
     """
     if date_time.is_delta:
       base_year = self._GetBaseYear(storage_writer, event_data)
       date_time = date_time.NewFromDeltaAndYear(base_year)
 
     timestamp = date_time.GetPlasoTimestamp()
-    if date_time.is_local_time:
-      time_zone = None
-      if date_time.time_zone_hint:
-        # TODO: cache time zones per hint.
-        try:
-          time_zone = pytz.timezone(date_time.time_zone_hint)
-        except pytz.UnknownTimeZoneError:
-          message = (
-              'unsupported time zone hint: {0:s}, using default time '
-              'zone').format(date_time.time_zone_hint)
-          self._ProduceTimeliningWarning(storage_writer, event_data, message)
+    if timestamp is None:
+      self._ProduceTimeliningWarning(
+          storage_writer, event_data, 'unable to determine timestamp')
+
+      date_time = dfdatetime_semantic_time.InvalidTime()
+      timestamp = 0
+
+    # Check for out of bounds timestamps, for example if a data format has
+    # changed and the conversion leads to an incorrect large integer value.
+    # Integer values that are larger than 64-bit will cause an OverflowError
+    # in the SQLite storage.
+
+    elif timestamp < self._INT64_MIN or timestamp > self._INT64_MAX:
+      self._ProduceTimeliningWarning(
+          storage_writer, event_data, 'timestamp out of bounds')
 
-      if not time_zone:
-        time_zone = self._time_zone
+      date_time = dfdatetime_semantic_time.InvalidTime()
+      timestamp = 0
 
-      if not time_zone:
-        message = 'date and time is in local time and no time zone is defined'
-        self._ProduceTimeliningWarning(storage_writer, event_data, message)
+    else:
+      if date_time.is_local_time:
+        time_zone = None
+        if date_time.time_zone_hint:
+          # TODO: cache time zones per hint.
+          try:
+            time_zone = pytz.timezone(date_time.time_zone_hint)
+          except pytz.UnknownTimeZoneError:
+            message = (
+                'unsupported time zone hint: {0:s}, using default time '
+                'zone').format(date_time.time_zone_hint)
+            self._ProduceTimeliningWarning(storage_writer, event_data, message)
+
+        if not time_zone and event_data_stream:
+          try:
+            time_zone = self._GetTimeZoneByPathSpec(event_data_stream.path_spec)
+          except pytz.UnknownTimeZoneError:
+            message = (
+                'unsupported system time zone: {0:s}, using default time '
+                'zone').format(date_time.time_zone_hint)
+            self._ProduceTimeliningWarning(storage_writer, event_data, message)
 
-        date_time = dfdatetime_semantic_time.NotSet()
+        if not time_zone:
+          time_zone = self._preferred_time_zone or self._DEFAULT_TIME_ZONE
 
-      else:
         date_time = copy.deepcopy(date_time)
         date_time.is_local_time = False
 
         if time_zone != pytz.UTC:
           datetime_object = datetime.datetime(
               1970, 1, 1, 0, 0, 0, 0, tzinfo=None)
           datetime_object += datetime.timedelta(microseconds=timestamp)
@@ -204,14 +250,43 @@
     event.timestamp_desc = date_time_description
 
     event_data_identifier = event_data.GetIdentifier()
     event.SetEventDataIdentifier(event_data_identifier)
 
     return event
 
+  def _GetTimeZoneByPathSpec(self, path_spec):
+    """Retrieves a time zone for a specific path specification.
+
+    Args:
+      path_spec (dfvfs.PathSpec): path specification.
+
+    Returns:
+      pytz.tzfile: time zone or None if not available.
+
+    Raises:
+      pytz.UnknownTimeZoneError: if the time zone is unknown.
+    """
+    if not path_spec or not path_spec.parent:
+      return None
+
+    time_zone = self._time_zone_per_path_spec.get(path_spec.parent, None)
+    if not time_zone:
+      return None
+
+    if isinstance(time_zone, str):
+      try:
+        time_zone = pytz.timezone(time_zone)
+        self._time_zone_per_path_spec[path_spec.parent] = time_zone
+      except pytz.UnknownTimeZoneError as exeception:
+        self._time_zone_per_path_spec[path_spec.parent] = None
+        raise exeception
+
+    return time_zone
+
   def _ProduceTimeliningWarning(self, storage_writer, event_data, message):
     """Produces a timelining warning.
 
     Args:
       storage_writer (StorageWriter): storage writer.
       event_data (EventData): event data.
       message (str): message of the warning.
@@ -249,20 +324,21 @@
 
       self._attribute_mappings[timeliner_definition.data_type] = (
           timeliner_definition.attribute_mappings)
 
       if timeliner_definition.place_holder_event:
         self._place_holder_event.add(timeliner_definition.data_type)
 
-  def ProcessEventData(self, storage_writer, event_data):
+  def ProcessEventData(self, storage_writer, event_data, event_data_stream):
     """Generate events from event data.
 
     Args:
       storage_writer (StorageWriter): storage writer.
       event_data (EventData): event data.
+      event_data_stream (EventDataStream): event data stream.
     """
     self.number_of_produced_events = 0
 
     attribute_mappings = self._attribute_mappings.get(
         event_data.data_type) or {}
     if (not attribute_mappings and
         event_data.data_type not in self._place_holder_event):
@@ -276,24 +352,30 @@
     number_of_events = 0
     for attribute_name, time_description in attribute_mappings.items():
       attribute_values = getattr(event_data, attribute_name, None) or []
       if not isinstance(attribute_values, list):
         attribute_values = [attribute_values]
 
       for attribute_value in attribute_values:
-        try:
-          event = self._GetEvent(
-              storage_writer, event_data, attribute_value, time_description)
-
-        except ValueError as exception:
-          self._ProduceTimeliningWarning(
-              storage_writer, event_data, str(exception))
+        if not isinstance(attribute_value, dfdatetime_interface.DateTimeValues):
+          message = 'unsupported date time attribute: {0:s}'.format(
+              attribute_name)
+          self._ProduceTimeliningWarning(storage_writer, event_data, message)
           continue
 
-        storage_writer.AddAttributeContainer(event)
+        event = self._GetEvent(
+            storage_writer, event_data, event_data_stream, attribute_value,
+            time_description)
+
+        try:
+          storage_writer.AddAttributeContainer(event)
+        except OverflowError as exception:
+          message = 'unable to add event with error: {0!s}'.format(exception)
+          self._ProduceTimeliningWarning(storage_writer, event_data, message)
+          continue
 
         number_of_events += 1
 
         if parser_name:
           self.parsers_counter[parser_name] += 1
         self.parsers_counter['total'] += 1
 
@@ -301,15 +383,15 @@
 
     # Create a place holder event for event_data without date and time
     # values to map.
     if (not number_of_events and
         event_data.data_type in self._place_holder_event):
       date_time = dfdatetime_semantic_time.NotSet()
       event = self._GetEvent(
-          storage_writer, event_data, date_time,
+          storage_writer, event_data, event_data_stream, date_time,
           definitions.TIME_DESCRIPTION_NOT_A_TIME)
 
       storage_writer.AddAttributeContainer(event)
 
       if parser_name:
         self.parsers_counter[parser_name] += 1
       self.parsers_counter['total'] += 1
@@ -323,18 +405,16 @@
       time_zone_string (str): time zone such as "Europe/Amsterdam" or None if
           the time zone determined by preprocessing or the default should be
           used.
 
     Raises:
       ValueError: if the time zone is not supported.
     """
-    self._time_zone = None
-
+    time_zone = None
     if time_zone_string:
       try:
-        self._time_zone = pytz.timezone(time_zone_string)
+        time_zone = pytz.timezone(time_zone_string)
       except pytz.UnknownTimeZoneError:
         raise ValueError('Unsupported time zone: {0!s}'.format(
             time_zone_string))
 
-    if not self._time_zone:
-      self._time_zone = self._knowledge_base.timezone or self._DEFAULT_TIME_ZONE
+    self._preferred_time_zone = time_zone
```

### Comparing `plaso-20230311/plaso/engine/worker.py` & `plaso-20230717/plaso/engine/worker.py`

 * *Files 2% similar despite different names*

```diff
@@ -577,16 +577,15 @@
     self.processing_status = definitions.STATUS_INDICATOR_COLLECTING
 
     archive_path_spec = path_spec_factory.Factory.NewPathSpec(
         type_indicator, location='/', parent=path_spec)
 
     try:
       path_spec_generator = self._path_spec_extractor.ExtractPathSpecs(
-          [archive_path_spec],
-          resolver_context=parser_mediator.resolver_context)
+          archive_path_spec, resolver_context=parser_mediator.resolver_context)
 
       for generated_path_spec in path_spec_generator:
         if self._abort:
           break
 
         event_source = event_sources.FileEntryEventSource(
             file_entry_type=dfvfs_definitions.FILE_ENTRY_TYPE_FILE,
@@ -651,29 +650,29 @@
       self, parser_mediator, path_spec, type_indicators):
     """Processes a data stream containing compressed stream types such as: bz2.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       path_spec (dfvfs.PathSpec): path specification.
-      type_indicators(list[str]): dfVFS archive type indicators found in
+      type_indicators (list[str]): dfVFS archive type indicators found in
           the data stream.
     """
     number_of_type_indicators = len(type_indicators)
     if number_of_type_indicators == 0:
       return
 
     self.processing_status = definitions.STATUS_INDICATOR_COLLECTING
 
     if number_of_type_indicators > 1:
       display_name = parser_mediator.GetDisplayName()
       logger.debug((
           'Found multiple format type indicators: {0:s} for '
           'compressed stream file: {1:s}').format(
-              type_indicators, display_name))
+              ', '.join(type_indicators), display_name))
 
     for type_indicator in type_indicators:
       if type_indicator == dfvfs_definitions.TYPE_INDICATOR_BZIP2:
         compressed_stream_path_spec = path_spec_factory.Factory.NewPathSpec(
             dfvfs_definitions.TYPE_INDICATOR_COMPRESSED_STREAM,
             compression_method=dfvfs_definitions.COMPRESSION_METHOD_BZIP2,
             parent=path_spec)
@@ -688,15 +687,15 @@
             compression_method=dfvfs_definitions.COMPRESSION_METHOD_XZ,
             parent=path_spec)
 
       else:
         compressed_stream_path_spec = None
 
         warning_message = (
-            'unsupported compressed stream format type indicators: '
+            'unsupported compressed stream format type indicator: '
             '{0:s}').format(type_indicator)
         parser_mediator.ProduceExtractionWarning(
             warning_message, path_spec=path_spec)
 
       if compressed_stream_path_spec:
         event_source = event_sources.FileEntryEventSource(
             file_entry_type=dfvfs_definitions.FILE_ENTRY_TYPE_FILE,
@@ -988,59 +987,58 @@
     """Gets the names of the active analyzers.
 
     Returns:
       list[str]: names of active analyzers.
     """
     return [analyzer_instance.NAME for analyzer_instance in self._analyzers]
 
-  def ProcessPathSpec(
-      self, parser_mediator, path_spec, excluded_find_specs=None):
-    """Processes a path specification.
+  def ProcessFileEntry(self, parser_mediator, file_entry):
+    """Processes a file entry.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
-      path_spec (dfvfs.PathSpec): path specification.
-      excluded_find_specs (Optional[list[dfvfs.FindSpec]]): find specifications
-         that are excluded from processing.
+      file_entry (dfvfs.FileEntry): file entry.
     """
     self.last_activity_timestamp = time.time()
     self.processing_status = definitions.STATUS_INDICATOR_RUNNING
 
-    file_entry = path_spec_resolver.Resolver.OpenFileEntry(
-        path_spec, resolver_context=parser_mediator.resolver_context)
-
-    if file_entry is None:
-      display_name = parser_mediator.GetDisplayNameForPathSpec(path_spec)
-      logger.warning('Unable to open file entry: {0:s}'.format(display_name))
-      self.processing_status = definitions.STATUS_INDICATOR_IDLE
-      return
-
-    for find_spec in excluded_find_specs or []:
-      if find_spec.CompareLocation(file_entry):
-        display_name = parser_mediator.GetDisplayNameForPathSpec(path_spec)
-        logger.info('Skipped: {0:s} because of exclusion filter.'.format(
-            display_name))
-        self.processing_status = definitions.STATUS_INDICATOR_IDLE
-        return
-
     parser_mediator.SetFileEntry(file_entry)
 
     try:
       if file_entry.IsDirectory():
         self._ProcessDirectory(parser_mediator, file_entry)
 
       self._ProcessFileEntry(parser_mediator, file_entry)
 
     finally:
       parser_mediator.ResetFileEntry()
 
       self.last_activity_timestamp = time.time()
       self.processing_status = definitions.STATUS_INDICATOR_IDLE
 
+  def ProcessPathSpec(self, parser_mediator, path_spec):
+    """Processes a path specification.
+
+    Args:
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
+      path_spec (dfvfs.PathSpec): path specification.
+    """
+    file_entry = path_spec_resolver.Resolver.OpenFileEntry(
+        path_spec, resolver_context=parser_mediator.resolver_context)
+
+    if file_entry is None:
+      display_name = parser_mediator.GetDisplayNameForPathSpec(path_spec)
+      logger.warning('Unable to open file entry: {0:s}'.format(display_name))
+      self.processing_status = definitions.STATUS_INDICATOR_IDLE
+      return
+
+    self.ProcessFileEntry(parser_mediator, file_entry)
+
   # TODO: move the functionality of this method into the constructor.
   def SetExtractionConfiguration(self, configuration):
     """Sets the extraction configuration settings.
 
     Args:
       configuration (ExtractionConfiguration): extraction configuration.
     """
```

### Comparing `plaso-20230311/plaso/engine/yaml_filter_file.py` & `plaso-20230717/plaso/engine/yaml_filter_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/engine/yaml_timeliner_file.py` & `plaso-20230717/plaso/engine/yaml_timeliner_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/filters/event_filter.py` & `plaso-20230717/plaso/filters/event_filter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/filters/expression_parser.py` & `plaso-20230717/plaso/filters/expression_parser.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/filters/expressions.py` & `plaso-20230717/plaso/filters/expressions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/filters/file_entry.py` & `plaso-20230717/plaso/filters/file_entry.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/filters/filters.py` & `plaso-20230717/plaso/filters/filters.py`

 * *Files 0% similar despite different names*

```diff
@@ -248,21 +248,23 @@
     if attribute_name in self._UNSUPPORTED_ATTRIBUTE_NAMES:
       logger.warning(
           'Expansion of {0:s} in event filter no longer supported'.format(
               attribute_name))
 
     if attribute_name in self._EVENT_ATTRIBUTE_NAMES:
       attribute_value = getattr(event, attribute_name, None)
-
-      # Make sure timestamp attribute values are (dfdatetime) date time objects.
-      # TODO: remove when timestamp values are (de)serialized as dfdatetime
-      # objects.
-      if attribute_name == 'timestamp' and not isinstance(attribute_value, (
-          dfdatetime_interface.DateTimeValues, value_types.DateTimeValueType)):
-        attribute_value = value_types.DateTimeValueType(attribute_value)
+      if attribute_value is not None:
+        # Make sure timestamp attribute values are (dfDateTime) date time
+        # objects.
+        # TODO: remove when timestamp values are (de)serialized as dfDateTime
+        # objects.
+        if attribute_name == 'timestamp' and not isinstance(attribute_value, (
+            dfdatetime_interface.DateTimeValues,
+            value_types.DateTimeValueType)):
+          attribute_value = value_types.DateTimeValueType(attribute_value)
 
     elif (event_data_stream and
           attribute_name in event_data_stream.GetAttributeNames()):
       attribute_value = getattr(event_data_stream, attribute_name, None)
 
     elif attribute_name == 'tag':
       attribute_value = getattr(event_tag, 'labels', None)
```

### Comparing `plaso-20230311/plaso/filters/parser_filter.py` & `plaso-20230717/plaso/filters/parser_filter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/filters/path_filter.py` & `plaso-20230717/plaso/filters/path_filter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/filters/value_types.py` & `plaso-20230717/plaso/filters/value_types.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/chrome.py` & `plaso-20230717/plaso/formatters/chrome.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/chrome_preferences.py` & `plaso-20230717/plaso/formatters/chrome_preferences.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/default.py` & `plaso-20230717/plaso/formatters/default.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/file_system.py` & `plaso-20230717/plaso/formatters/file_system.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/firefox.py` & `plaso-20230717/plaso/formatters/firefox.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/interface.py` & `plaso-20230717/plaso/formatters/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/manager.py` & `plaso-20230717/plaso/formatters/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/msiecf.py` & `plaso-20230717/plaso/formatters/msiecf.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/shell_items.py` & `plaso-20230717/plaso/formatters/shell_items.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/winevt.py` & `plaso-20230717/plaso/formatters/winevt.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/winlnk.py` & `plaso-20230717/plaso/formatters/winlnk.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/winprefetch.py` & `plaso-20230717/plaso/formatters/winprefetch.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/formatters/winreg.py` & `plaso-20230717/plaso/formatters/winreg.py`

 * *Files 12% similar despite different names*

```diff
@@ -16,12 +16,19 @@
 
     Args:
       output_mediator (OutputMediator): output mediator.
       event_values (dict[str, object]): event values.
     """
     values = event_values.get('values', None)
     if not values:
-      event_values['values'] = '(empty)'
+      values = '(empty)'
+    elif isinstance(values, list):
+      values = ' '.join([
+          '{0:s}: [{1:s}] {2:s}'.format(
+              name or '(default)', data_type, data or '(empty)')
+          for name, data_type, data in sorted(values)])
+
+    event_values['values'] = values
 
 
 manager.FormattersManager.RegisterEventFormatterHelper(
     WindowsRegistryValuesFormatterHelper)
```

### Comparing `plaso-20230311/plaso/formatters/yaml_formatters_file.py` & `plaso-20230717/plaso/formatters/yaml_formatters_file.py`

 * *Files 0% similar despite different names*

```diff
@@ -50,15 +50,15 @@
 
   def _ReadBooleanHelpers(self, formatter, boolean_helpers_definition_values):
     """Reads boolean helper definitions from a list.
 
     Args:
       formatter (EventFormatter): an event formatter.
       boolean_helpers_definition_values (list[dict[str, object]]):
-           boolean helpers definition values.
+          boolean helpers definition values.
 
     Raises:
       ParseError: if the format of the boolean helper definitions are incorrect.
     """
     for boolean_helper in boolean_helpers_definition_values:
       input_attribute = boolean_helper.get('input_attribute', None)
       if not input_attribute:
@@ -81,15 +81,15 @@
 
   def _ReadCustomHelpers(self, formatter, custom_helpers_definition_values):
     """Reads custom helper definitions from a list.
 
     Args:
       formatter (EventFormatter): an event formatter.
       custom_helpers_definition_values (list[dict[str, object]]):
-           custom helpers definition values.
+          custom helpers definition values.
 
     Raises:
       ParseError: if the format of the custom helper definitions are incorrect.
     """
     for custom_helper in custom_helpers_definition_values:
       identifier = custom_helper.get('identifier', None)
       if not identifier:
@@ -106,15 +106,15 @@
   def _ReadEnumerationHelpers(
       self, formatter, enumeration_helpers_definition_values):
     """Reads enumeration helper definitions from a list.
 
     Args:
       formatter (EventFormatter): an event formatter.
       enumeration_helpers_definition_values (list[dict[str, object]]):
-           enumeration helpers definition values.
+          enumeration helpers definition values.
 
     Raises:
       ParseError: if the format of the enumeration helper definitions are
           incorrect.
     """
     for enumeration_helper in enumeration_helpers_definition_values:
       input_attribute = enumeration_helper.get('input_attribute', None)
@@ -172,15 +172,15 @@
       formatter.AddHelper(helper)
 
   def _ReadFormatterDefinition(self, formatter_definition_values):
     """Reads an event formatter definition from a dictionary.
 
     Args:
       formatter_definition_values (dict[str, object]): formatter definition
-           values.
+          values.
 
     Returns:
       EventFormatter: an event formatter.
 
     Raises:
       ParseError: if the format of the formatter definition is not set
           or incorrect.
```

### Comparing `plaso-20230311/plaso/helpers/language_tags.py` & `plaso-20230717/plaso/helpers/language_tags.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/helpers/windows/eventlog_providers.py` & `plaso-20230717/plaso/helpers/windows/eventlog_providers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/helpers/windows/known_folders.py` & `plaso-20230717/plaso/helpers/windows/known_folders.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/helpers/windows/languages.py` & `plaso-20230717/plaso/helpers/windows/languages.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/helpers/windows/resource_files.py` & `plaso-20230717/plaso/helpers/windows/resource_files.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/helpers/windows/shell_folders.py` & `plaso-20230717/plaso/helpers/windows/shell_folders.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/helpers/windows/time_zones.py` & `plaso-20230717/plaso/helpers/windows/time_zones.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/bufferlib.py` & `plaso-20230717/plaso/lib/bufferlib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/cookie_plugins_helper.py` & `plaso-20230717/plaso/lib/cookie_plugins_helper.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/decorators.py` & `plaso-20230717/plaso/lib/decorators.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/definitions.py` & `plaso-20230717/plaso/lib/definitions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/dtfabric_helper.py` & `plaso-20230717/plaso/lib/dtfabric_helper.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/errors.py` & `plaso-20230717/plaso/lib/errors.py`

 * *Files 12% similar despite different names*

```diff
@@ -34,18 +34,14 @@
   """Raised when a parser preset definition is malformed."""
 
 
 class MaximumRecursionDepth(Error):
   """Raised when the maximum recursion depth is reached."""
 
 
-class NoFormatterFound(Error):
-  """Raised when no formatter is found for a particular event object."""
-
-
 class ParseError(Error):
   """Raised when a parse error occurred."""
 
 
 class PreProcessFail(Error):
   """Raised when a preprocess module is unable to gather information."""
```

### Comparing `plaso-20230311/plaso/lib/line_reader_file.py` & `plaso-20230717/plaso/lib/line_reader_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/loggers.py` & `plaso-20230717/plaso/lib/loggers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/plist.py` & `plaso-20230717/plaso/lib/plist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/specification.py` & `plaso-20230717/plaso/lib/specification.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/lib/yearless_helper.py` & `plaso-20230717/plaso/lib/yearless_helper.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/analysis_engine.py` & `plaso-20230717/plaso/multi_process/analysis_engine.py`

 * *Files 1% similar despite different names*

```diff
@@ -55,15 +55,14 @@
     self._analysis_plugins = {}
     self._completed_analysis_processes = set()
     self._data_location = None
     self._event_filter_expression = None
     self._event_labels_counter = None
     self._event_queues = {}
     self._events_status = processing_status.EventsStatus()
-    self._knowledge_base = None
     self._memory_profiler = None
     self._merge_task = None
     self._number_of_consumed_analysis_reports = 0
     self._number_of_consumed_event_data = 0
     self._number_of_consumed_event_tags = 0
     self._number_of_consumed_events = 0
     self._number_of_consumed_sources = 0
@@ -73,14 +72,15 @@
     self._number_of_produced_events = 0
     self._number_of_produced_sources = 0
     self._processing_profiler = None
     self._serializers_profiler = None
     self._session = None
     self._status = definitions.STATUS_INDICATOR_IDLE
     self._status_update_callback = None
+    self._user_accounts = None
     self._worker_memory_limit = worker_memory_limit
     self._worker_timeout = worker_timeout or definitions.DEFAULT_WORKER_TIMEOUT
 
   def _AnalyzeEvents(self, storage_writer, analysis_plugins, event_filter=None):
     """Analyzes events in a Plaso storage.
 
     Args:
@@ -372,16 +372,16 @@
 
     queue_name = '{0:s} input event queue'.format(process_name)
     input_event_queue = zeromq_queue.ZeroMQPullConnectQueue(
         name=queue_name, delay_open=True, port=output_event_queue.port,
         timeout_seconds=self._QUEUE_TIMEOUT)
 
     process = analysis_process.AnalysisProcess(
-        input_event_queue, self._knowledge_base, self._session, analysis_plugin,
-        self._processing_configuration, data_location=self._data_location,
+        input_event_queue, analysis_plugin, self._processing_configuration,
+        self._user_accounts, data_location=self._data_location,
         event_filter_expression=self._event_filter_expression,
         name=process_name)
 
     process.start()
 
     logger.info('Started analysis plugin: {0:s} (PID: {1:d}).'.format(
         process_name, process.pid))
@@ -534,24 +534,22 @@
     self._UpdateForemanProcessStatus()
 
     if self._status_update_callback:
       self._status_update_callback(self._processing_status)
 
   # pylint: disable=too-many-arguments
   def AnalyzeEvents(
-      self, session, knowledge_base_object, storage_writer, data_location,
-      analysis_plugins, processing_configuration, event_filter=None,
+      self, session, storage_writer, data_location, analysis_plugins,
+      processing_configuration, event_filter=None,
       event_filter_expression=None, status_update_callback=None,
       storage_file_path=None):
     """Analyzes events in a Plaso storage.
 
     Args:
       session (Session): session in which the events are analyzed.
-      knowledge_base_object (KnowledgeBase): contains information from
-          the source data needed for processing.
       storage_writer (StorageWriter): storage writer.
       data_location (str): path to the location that data files should
           be loaded from.
       analysis_plugins (dict[str, AnalysisPlugin]): analysis plugins that
           should be run and their names.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
@@ -575,20 +573,22 @@
     keyboard_interrupt = False
     queue_full = False
 
     self._analysis_plugins = {}
     self._data_location = data_location
     self._event_filter_expression = event_filter_expression
     self._events_status = processing_status.EventsStatus()
-    self._knowledge_base = knowledge_base_object
     self._processing_configuration = processing_configuration
     self._session = session
     self._status_update_callback = status_update_callback
     self._storage_file_path = storage_file_path
 
+    self._user_accounts = list(
+        storage_writer.GetAttributeContainers('user_account'))
+
     stored_event_labels_counter = {}
     if storage_writer.HasAttributeContainers('event_label_count'):
       stored_event_labels_counter = {
           event_label_count.label: event_label_count
           for event_label_count in storage_writer.GetAttributeContainers(
               'event_label_count')}
 
@@ -692,17 +692,17 @@
     # Update the status view one last time.
     self._UpdateStatus()
 
     # Reset values.
     self._analysis_plugins = {}
     self._data_location = None
     self._event_filter_expression = None
-    self._knowledge_base = None
     self._processing_configuration = None
     self._session = None
     self._status_update_callback = None
     self._storage_file_path = None
+    self._user_accounts = None
 
     if keyboard_interrupt:
       raise KeyboardInterrupt
 
     return self._processing_status
```

### Comparing `plaso-20230311/plaso/multi_process/analysis_process.py` & `plaso-20230717/plaso/multi_process/analysis_process.py`

 * *Files 9% similar despite different names*

```diff
@@ -16,47 +16,44 @@
   """Multi-processing analysis worker process."""
 
   # Number of seconds to wait for the completion status to be queried
   # by the foreman process.
   _FOREMAN_STATUS_WAIT = 5 * 60
 
   def __init__(
-      self, event_queue, knowledge_base, session, analysis_plugin,
-      processing_configuration, data_location=None,
-      event_filter_expression=None, **kwargs):
+      self, event_queue, analysis_plugin, processing_configuration,
+      user_accounts, data_location=None, event_filter_expression=None,
+      **kwargs):
     """Initializes an analysis worker process.
 
     Non-specified keyword arguments (kwargs) are directly passed to
     multiprocessing.Process.
 
     Args:
       event_queue (plaso_queue.Queue): event queue.
-      knowledge_base (KnowledgeBase): contains information from the source
-          data needed for analysis.
-      session (Session): session.
       analysis_plugin (AnalysisPlugin): plugin running in the process.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
+      user_accounts (list[UserAccountArtifact]): user accounts.
       data_location (Optional[str]): path to the location that data files
           should be loaded from.
       event_filter_expression (Optional[str]): event filter expression.
     """
     super(AnalysisProcess, self).__init__(processing_configuration, **kwargs)
     self._abort = False
     self._analysis_mediator = None
     self._analysis_plugin = analysis_plugin
     self._data_location = data_location
     self._event_filter_expression = event_filter_expression
     self._event_queue = event_queue
     self._foreman_status_wait_event = None
-    self._knowledge_base = knowledge_base
     self._number_of_consumed_events = 0
-    self._session = session
     self._status = definitions.STATUS_INDICATOR_INITIALIZED
     self._task = None
+    self._user_accounts = user_accounts
 
   def _GetStatus(self):
     """Retrieves status information.
 
     Returns:
       dict[str, object]: status attributes, indexed by name.
     """
@@ -104,34 +101,14 @@
         definitions.STATUS_INDICATOR_ABORTED,
         definitions.STATUS_INDICATOR_COMPLETED):
       logger.debug('Set foreman status wait event')
       self._foreman_status_wait_event.set()
 
     return status
 
-  def _CreateAnalysisMediator(self, session, knowledge_base, data_location):
-    """Creates an analysis mediator.
-
-    Args:
-      session (Session): session in which the sources are processed.
-      knowledge_base (KnowledgeBase): knowledge base which contains
-          information from the source data needed for parsing.
-      data_location (str): path to the location that data files
-          should be loaded from.
-
-    Returns:
-      AnalysisMediator: parser mediator.
-    """
-    mediator = analysis_mediator.AnalysisMediator(
-        session, knowledge_base, data_location=data_location)
-
-    # TODO: move data_location to processing_configuration
-
-    return mediator
-
   def _Main(self):
     """The main loop."""
     self._StartProfiling(self._processing_configuration.profiling)
 
     logger.debug('Analysis plugin: {0!s} (PID: {1:d}) started'.format(
         self._name, self._pid))
 
@@ -156,16 +133,18 @@
     if self._storage_profiler:
       task_storage_writer.SetStorageProfiler(self._storage_profiler)
 
     storage_file_path = self._GetTaskStorageFilePath(
         definitions.STORAGE_FORMAT_SQLITE, task)
     task_storage_writer.Open(path=storage_file_path)
 
-    self._analysis_mediator = self._CreateAnalysisMediator(
-        self._session, self._knowledge_base, self._data_location)
+    self._analysis_mediator = analysis_mediator.AnalysisMediator(
+        data_location=self._data_location, user_accounts=self._user_accounts)
+
+    # TODO: move into analysis process.
     self._analysis_mediator.SetStorageWriter(task_storage_writer)
 
     # TODO: set event_filter_expression in mediator.
 
     task_storage_writer.AddAttributeContainer(task)
 
     try:
```

### Comparing `plaso-20230311/plaso/multi_process/base_process.py` & `plaso-20230717/plaso/multi_process/base_process.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/engine.py` & `plaso-20230717/plaso/multi_process/engine.py`

 * *Files 0% similar despite different names*

```diff
@@ -49,15 +49,14 @@
     self._process_information = process_info.ProcessInfo(self._pid)
     self._process_information_per_pid = {}
     self._processes_per_pid = {}
     self._quiet_mode = False
     self._rpc_clients_per_pid = {}
     self._rpc_errors_per_pid = {}
     self._status_update_active = False
-    self._status_update_callback = None
     self._status_update_thread = None
     self._storage_writer = None
     self._worker_memory_limit = definitions.DEFAULT_WORKER_MEMORY_LIMIT
 
   def _AbortJoin(self, timeout=None):
     """Aborts all registered processes by joining with the parent process.
```

### Comparing `plaso-20230311/plaso/multi_process/extraction_engine.py` & `plaso-20230717/plaso/multi_process/extraction_engine.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,20 +8,22 @@
 import os
 import re
 import time
 import traceback
 
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.resolver import context
+from dfvfs.resolver import resolver as path_spec_resolver
 
 from plaso.containers import counts
 from plaso.containers import event_sources
 from plaso.containers import events
 from plaso.containers import warnings
 from plaso.engine import extractors
+from plaso.engine import path_helper
 from plaso.engine import timeliner
 from plaso.lib import definitions
 from plaso.lib import errors
 from plaso.lib import loggers
 from plaso.multi_process import extraction_process
 from plaso.multi_process import logger
 from plaso.multi_process import merge_helpers
@@ -92,35 +94,41 @@
   """
 
   _CONTAINER_TYPE_EVENT_DATA = events.EventData.CONTAINER_TYPE
   _CONTAINER_TYPE_EVENT_DATA_STREAM = events.EventDataStream.CONTAINER_TYPE
   _CONTAINER_TYPE_EVENT_SOURCE = event_sources.EventSource.CONTAINER_TYPE
   _CONTAINER_TYPE_YEAR_LESS_LOG_HELPER = events.YearLessLogHelper.CONTAINER_TYPE
 
+  # Maximum number of dfVFS file system objects to cache in the foreman process.
+  _FILE_SYSTEM_CACHE_SIZE = 3
+
   # Maximum number of concurrent tasks.
   _MAXIMUM_NUMBER_OF_TASKS = 10000
 
   _TASK_QUEUE_TIMEOUT_SECONDS = 2
 
   _UNICODE_SURROGATES_RE = re.compile('[\ud800-\udfff]')
 
   _WORKER_PROCESSES_MINIMUM = 2
   _WORKER_PROCESSES_MAXIMUM = 99
 
   _ZEROMQ_NO_WORKER_REQUEST_TIME_SECONDS = 10 * 60
 
   def __init__(
       self, maximum_number_of_tasks=None, number_of_worker_processes=0,
-      worker_memory_limit=None, worker_timeout=None):
+      status_update_callback=None, worker_memory_limit=None,
+      worker_timeout=None):
     """Initializes an engine.
 
     Args:
       maximum_number_of_tasks (Optional[int]): maximum number of concurrent
           tasks, where 0 represents no limit.
       number_of_worker_processes (Optional[int]): number of worker processes.
+      status_update_callback (Optional[function]): callback function for status
+          updates.
       worker_memory_limit (Optional[int]): maximum amount of memory a worker is
           allowed to consume, where None represents the default memory limit
           and 0 represents no limit.
       worker_timeout (Optional[float]): number of minutes before a worker
           process that is not providing status updates is considered inactive,
           where None or 0.0 represents the default timeout.
     """
@@ -158,36 +166,159 @@
     if not worker_timeout:
       worker_timeout = definitions.DEFAULT_WORKER_TIMEOUT
 
     super(ExtractionMultiProcessEngine, self).__init__()
     self._enable_sigsegv_handler = False
     self._event_data_timeliner = None
     self._extraction_worker = None
+    self._file_system_cache = []
     self._maximum_number_of_containers = 50
     self._maximum_number_of_tasks = maximum_number_of_tasks
     self._merge_task = None
     self._merge_task_on_hold = None
     self._number_of_consumed_event_data = 0
     self._number_of_consumed_sources = 0
     self._number_of_produced_event_data = 0
     self._number_of_produced_events = 0
     self._number_of_produced_sources = 0
     self._number_of_worker_processes = number_of_worker_processes
-    self._parsers_counter = collections.Counter()
     self._path_spec_extractor = extractors.PathSpecExtractor()
     self._resolver_context = context.Context()
     self._status = definitions.STATUS_INDICATOR_IDLE
+    self._status_update_callback = status_update_callback
     self._task_manager = task_manager.TaskManager()
     self._task_merge_helper = None
     self._task_merge_helper_on_hold = None
     self._task_queue = None
     self._task_queue_port = None
     self._task_storage_format = None
     self._worker_memory_limit = worker_memory_limit
     self._worker_timeout = worker_timeout
+    self._system_configurations = None
+
+  def _CacheFileSystem(self, file_system):
+    """Caches a dfVFS file system object.
+
+    Keeping and additional reference to a dfVFS file system object causes the
+    object to remain cached in the resolver context. This minimizes the number
+    times the file system is re-opened.
+
+    Args:
+      file_system (dfvfs.FileSystem): file system.
+    """
+    if file_system not in self._file_system_cache:
+      if len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
+        self._file_system_cache.pop(0)
+      self._file_system_cache.append(file_system)
+
+    elif len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
+      # Move the file system to the end of the list to preserve the most
+      # recently file system object.
+      self._file_system_cache.remove(file_system)
+      self._file_system_cache.append(file_system)
+
+  def _CheckExcludedPathSpec(self, file_system, path_spec):
+    """Determines if the path specification should be excluded from extraction.
+
+    Args:
+      file_system (dfvfs.FileSystem): file system which the path specification
+          is part of.
+      path_spec (dfvfs.PathSpec): path specification.
+
+    Returns:
+      bool: True if the path specification should be excluded from extraction.
+    """
+    for find_spec in self._excluded_file_system_find_specs or []:
+      if find_spec.ComparePathSpecLocation(path_spec, file_system):
+        return True
+
+    return False
+
+  def _CollectInitialEventSources(self, storage_writer, file_system_path_specs):
+    """Collects the initial event sources.
+
+    Args:
+      storage_writer (StorageWriter): storage writer for a session storage.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
+    """
+    self._status = definitions.STATUS_INDICATOR_COLLECTING
+
+    included_find_specs = self.GetCollectionIncludedFindSpecs()
+
+    for file_system_path_spec in file_system_path_specs:
+      if self._abort:
+        break
+
+      file_system = path_spec_resolver.Resolver.OpenFileSystem(
+          file_system_path_spec, resolver_context=self._resolver_context)
+
+      path_spec_generator = self._path_spec_extractor.ExtractPathSpecs(
+          file_system_path_spec, find_specs=included_find_specs,
+          recurse_file_system=False, resolver_context=self._resolver_context)
+      for path_spec in path_spec_generator:
+        if self._abort:
+          break
+
+        if self._CheckExcludedPathSpec(file_system, path_spec):
+          display_name = path_helper.PathHelper.GetDisplayNameForPathSpec(
+              path_spec)
+          logger.debug('Excluded from extraction: {0:s}.'.format(display_name))
+          continue
+
+        # TODO: determine if event sources should be DataStream or FileEntry
+        # or both.
+        event_source = event_sources.FileEntryEventSource(path_spec=path_spec)
+        storage_writer.AddAttributeContainer(event_source)
+
+        self._number_of_produced_sources += 1
+
+        # Update the foreman process status in case we are using a filter file.
+        self._UpdateForemanProcessStatus()
+
+        if self._status_update_callback:
+          self._status_update_callback(self._processing_status)
+
+  def _CreateTask(self, storage_writer, session_identifier, event_source):
+    """Creates a task to processes an event source.
+
+    Args:
+      storage_writer (StorageWriter): storage writer for a session storage.
+      session_identifier (str): the identifier of the session the tasks are
+          part of.
+      event_source (EventSource): event source.
+
+    Returns:
+      Task: task or None if no task could be created.
+    """
+    file_entry = path_spec_resolver.Resolver.OpenFileEntry(
+        event_source.path_spec, resolver_context=self._resolver_context)
+    if file_entry is None:
+      self._ProduceExtractionWarning(
+          storage_writer, 'Unable to open file entry', event_source.path_spec)
+      return None
+
+    file_system = file_entry.GetFileSystem()
+
+    if not event_source.path_spec.IsSystemLevel():
+      self._CacheFileSystem(file_system)
+
+    if self._CheckExcludedPathSpec(file_system, event_source.path_spec):
+      display_name = path_helper.PathHelper.GetDisplayNameForPathSpec(
+          event_source.path_spec)
+      logger.debug('Excluded from extraction: {0:s}.'.format(
+          display_name))
+      return None
+
+    task = self._task_manager.CreateTask(
+        session_identifier, storage_format=self._task_storage_format)
+    task.file_entry_type = event_source.file_entry_type
+    task.path_spec = event_source.path_spec
+
+    return task
 
   def _FillEventSourceHeap(
       self, storage_writer, event_source_heap, start_with_first=False):
     """Fills the event source heap with the available written event sources.
 
     Args:
       storage_writer (StorageWriter): storage writer for a session storage.
@@ -330,16 +461,26 @@
       merge_helper.SetAttributeContainerIdentifier(lookup_key, identifier)
 
     if container.CONTAINER_TYPE == self._CONTAINER_TYPE_EVENT_DATA:
       self._number_of_produced_event_data += 1
 
       self._status = definitions.STATUS_INDICATOR_TIMELINING
 
+      event_data_stream_identifier = container.GetEventDataStreamIdentifier()
+
+      event_data_stream = None
+      if event_data_stream_identifier:
+        event_data_stream = (
+            self._storage_writer.GetAttributeContainerByIdentifier(
+                self._CONTAINER_TYPE_EVENT_DATA_STREAM,
+                event_data_stream_identifier))
+
       # Generate events on merge.
-      self._event_data_timeliner.ProcessEventData(storage_writer, container)
+      self._event_data_timeliner.ProcessEventData(
+          storage_writer, container, event_data_stream)
 
       self._number_of_consumed_event_data += 1
       self._number_of_produced_events += (
           self._event_data_timeliner.number_of_produced_events)
 
     elif container.CONTAINER_TYPE == self._CONTAINER_TYPE_EVENT_SOURCE:
       self._number_of_produced_sources += 1
@@ -509,137 +650,33 @@
           self._task_merge_helper = self._task_merge_helper_on_hold
 
           self._merge_task_on_hold = None
           self._task_merge_helper_on_hold = None
 
           self._task_manager.SampleTaskStatus(self._merge_task, 'merge_resumed')
 
-  def _ProcessSources(
-      self, source_configurations, storage_writer, session_identifier):
-    """Processes the sources.
+  def _ProduceExtractionWarning(self, storage_writer, message, path_spec):
+    """Produces an extraction warning.
 
     Args:
-      source_configurations (list[SourceConfigurationArtifact]): configurations
-          of the sources to process.
       storage_writer (StorageWriter): storage writer for a session storage.
-      session_identifier (str): the identifier of the session the tasks are
-          part of.
-    """
-    if self._processing_profiler:
-      self._processing_profiler.StartTiming('process_sources')
-
-    self._status = definitions.STATUS_INDICATOR_COLLECTING
-    self._number_of_consumed_event_data = 0
-    self._number_of_consumed_sources = 0
-    self._number_of_produced_event_data = 0
-    self._number_of_produced_events = 0
-    self._number_of_produced_sources = 0
-
-    stored_parsers_counter = collections.Counter({
-        parser_count.name: parser_count
-        for parser_count in storage_writer.GetAttributeContainers(
-            'parser_count')})
-
-    find_specs = None
-    if self.collection_filters_helper:
-      find_specs = (
-          self.collection_filters_helper.included_file_system_find_specs)
-
-    source_path_specs = [
-        configuration.path_spec for configuration in source_configurations]
-
-    path_spec_generator = self._path_spec_extractor.ExtractPathSpecs(
-        source_path_specs, find_specs=find_specs, recurse_file_system=False,
-        resolver_context=self._resolver_context)
-
-    for path_spec in path_spec_generator:
-      if self._abort:
-        break
-
-      # TODO: determine if event sources should be DataStream or FileEntry
-      # or both.
-      event_source = event_sources.FileEntryEventSource(path_spec=path_spec)
-      storage_writer.AddAttributeContainer(event_source)
-
-      self._number_of_produced_sources += 1
-
-      # Update the foreman process status in case we are using a filter file.
-      self._UpdateForemanProcessStatus()
-
-      if self._status_update_callback:
-        self._status_update_callback(self._processing_status)
-
-    self._ScheduleTasks(storage_writer, session_identifier)
-
-    if self._abort:
-      self._status = definitions.STATUS_INDICATOR_ABORTED
-    else:
-      self._status = definitions.STATUS_INDICATOR_COMPLETED
-
-    for key, value in self._event_data_timeliner.parsers_counter.items():
-      parser_count = stored_parsers_counter.get(key, None)
-      if parser_count:
-        parser_count.number_of_events += value
-        storage_writer.UpdateAttributeContainer(parser_count)
-      else:
-        parser_count = counts.ParserCount(name=key, number_of_events=value)
-        storage_writer.AddAttributeContainer(parser_count)
-
-    # TODO: remove after completion event and event data split.
-    for key, value in self._parsers_counter.items():
-      parser_count = stored_parsers_counter.get(key, None)
-      if parser_count:
-        parser_count.number_of_events += value
-        storage_writer.UpdateAttributeContainer(parser_count)
-      else:
-        parser_count = counts.ParserCount(name=key, number_of_events=value)
-        storage_writer.AddAttributeContainer(parser_count)
-
-    if self._processing_profiler:
-      self._processing_profiler.StopTiming('process_sources')
-
-    # Update the foreman process and task status in case we are using
-    # a filter file.
-    self._UpdateForemanProcessStatus()
-
-    tasks_status = self._task_manager.GetStatusInformation()
-    if self._task_queue_profiler:
-      self._task_queue_profiler.Sample(tasks_status)
-
-    self._processing_status.UpdateTasksStatus(tasks_status)
-
-    if self._status_update_callback:
-      self._status_update_callback(self._processing_status)
-
-  def _ScheduleTask(self, task):
-    """Schedules a task.
-
-    Args:
-      task (Task): task.
+      message (str): message of the warning.
+      path_spec (dfvfs.PathSpec): path specification.
 
-    Returns:
-      bool: True if the task was scheduled.
+    Raises:
+      RuntimeError: when storage writer is not set.
     """
-    if self._processing_profiler:
-      self._processing_profiler.StartTiming('schedule_task')
-
-    try:
-      self._task_queue.PushItem(task, block=False)
-      is_scheduled = True
-
-    except errors.QueueFull:
-      is_scheduled = False
+    warning = warnings.ExtractionWarning(message=message, path_spec=path_spec)
+    storage_writer.AddAttributeContainer(warning)
 
-    if self._processing_profiler:
-      self._processing_profiler.StopTiming('schedule_task')
+    if path_spec:
+      self._processing_status.error_path_specs.append(path_spec)
 
-    return is_scheduled
-
-  def _ScheduleTasks(self, storage_writer, session_identifier):
-    """Schedules tasks.
+  def _ProcessEventSources(self, storage_writer, session_identifier):
+    """Processes event sources.
 
     Args:
       storage_writer (StorageWriter): storage writer for a session storage.
       session_identifier (str): the identifier of the session the tasks are
           part of.
     """
     logger.debug('Task scheduler started')
@@ -666,18 +703,17 @@
         break
 
       try:
         if not task:
           task = self._task_manager.CreateRetryTask()
 
         if not task and event_source:
-          task = self._task_manager.CreateTask(
-              session_identifier, storage_format=self._task_storage_format)
-          task.file_entry_type = event_source.file_entry_type
-          task.path_spec = event_source.path_spec
+          task = self._CreateTask(
+              storage_writer, session_identifier, event_source)
+
           event_source = None
 
           self._number_of_consumed_sources += 1
 
         if task:
           if not self._ScheduleTask(task):
             self._task_manager.SampleTaskStatus(task, 'schedule_attempted')
@@ -690,18 +726,18 @@
 
             self._task_manager.SampleTaskStatus(task, 'scheduled')
 
             task = None
 
         self._MergeTaskStorage(storage_writer, session_identifier)
 
-        if not event_source_heap.IsFull():
-          self._FillEventSourceHeap(storage_writer, event_source_heap)
-        else:
+        if event_source_heap.IsFull():
           logger.debug('Event source heap is full.')
+        else:
+          self._FillEventSourceHeap(storage_writer, event_source_heap)
 
         if not task and not event_source:
           event_source = event_source_heap.PopEventSource()
 
         has_pending_tasks = self._task_manager.HasPendingTasks()
 
       except KeyboardInterrupt:
@@ -709,28 +745,117 @@
           traceback.print_exc()
         self._abort = True
 
         self._processing_status.aborted = True
         if self._status_update_callback:
           self._status_update_callback(self._processing_status)
 
+      # All exceptions need to be caught here to prevent the foreman
+      # from being killed by an uncaught exception.
+      except Exception as exception:  # pylint: disable=broad-except
+        self._ProduceExtractionWarning(storage_writer, (
+            'unable to process path specification with error: '
+            '{0!s}').format(exception), event_source.path_spec)
+        event_source = None
+
     for task in self._task_manager.GetFailedTasks():
-      warning = warnings.ExtractionWarning(
-          message='Worker failed to process path specification',
-          path_spec=task.path_spec)
-      self._storage_writer.AddAttributeContainer(warning)
-      self._processing_status.error_path_specs.append(task.path_spec)
+      self._ProduceExtractionWarning(
+          storage_writer, 'Worker failed to process path specification',
+          task.path_spec)
 
     self._status = definitions.STATUS_INDICATOR_IDLE
 
     if self._abort:
       logger.debug('Task scheduler aborted')
     else:
       logger.debug('Task scheduler stopped')
 
+  def _ProcessSource(
+      self, storage_writer, session_identifier, file_system_path_specs):
+    """Processes file systems within a source.
+
+    Args:
+      storage_writer (StorageWriter): storage writer for a session storage.
+      session_identifier (str): the identifier of the session the tasks are
+          part of.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
+    """
+    if self._processing_profiler:
+      self._processing_profiler.StartTiming('process_source')
+
+    self._number_of_consumed_event_data = 0
+    self._number_of_consumed_sources = 0
+    self._number_of_produced_event_data = 0
+    self._number_of_produced_events = 0
+    self._number_of_produced_sources = 0
+
+    stored_parsers_counter = collections.Counter({
+        parser_count.name: parser_count
+        for parser_count in storage_writer.GetAttributeContainers(
+            'parser_count')})
+
+    self._CollectInitialEventSources(storage_writer, file_system_path_specs)
+
+    self._ProcessEventSources(storage_writer, session_identifier)
+
+    if self._abort:
+      self._status = definitions.STATUS_INDICATOR_ABORTED
+    else:
+      self._status = definitions.STATUS_INDICATOR_COMPLETED
+
+    for key, value in self._event_data_timeliner.parsers_counter.items():
+      parser_count = stored_parsers_counter.get(key, None)
+      if parser_count:
+        parser_count.number_of_events += value
+        storage_writer.UpdateAttributeContainer(parser_count)
+      else:
+        parser_count = counts.ParserCount(name=key, number_of_events=value)
+        storage_writer.AddAttributeContainer(parser_count)
+
+    if self._processing_profiler:
+      self._processing_profiler.StopTiming('process_source')
+
+    # Update the foreman process and task status in case we are using
+    # a filter file.
+    self._UpdateForemanProcessStatus()
+
+    tasks_status = self._task_manager.GetStatusInformation()
+    if self._task_queue_profiler:
+      self._task_queue_profiler.Sample(tasks_status)
+
+    self._processing_status.UpdateTasksStatus(tasks_status)
+
+    if self._status_update_callback:
+      self._status_update_callback(self._processing_status)
+
+  def _ScheduleTask(self, task):
+    """Schedules a task.
+
+    Args:
+      task (Task): task.
+
+    Returns:
+      bool: True if the task was scheduled.
+    """
+    if self._processing_profiler:
+      self._processing_profiler.StartTiming('schedule_task')
+
+    try:
+      self._task_queue.PushItem(task, block=False)
+      is_scheduled = True
+
+    except errors.QueueFull:
+      is_scheduled = False
+
+    if self._processing_profiler:
+      self._processing_profiler.StopTiming('schedule_task')
+
+    return is_scheduled
+
   def _StartWorkerProcess(self, process_name):
     """Creates, starts, monitors and registers a worker process.
 
     Args:
       process_name (str): process name.
 
     Returns:
@@ -742,16 +867,16 @@
     queue_name = '{0:s} task queue'.format(process_name)
     task_queue = zeromq_queue.ZeroMQRequestConnectQueue(
         delay_open=True, linger_seconds=0, name=queue_name,
         port=self._task_queue_port,
         timeout_seconds=self._TASK_QUEUE_TIMEOUT_SECONDS)
 
     process = extraction_process.ExtractionWorkerProcess(
-        task_queue, self.collection_filters_helper, self.knowledge_base,
-        self._processing_configuration,
+        task_queue, self._processing_configuration, self._system_configurations,
+        self._registry_find_specs,
         enable_sigsegv_handler=self._enable_sigsegv_handler, name=process_name)
 
     # Remove all possible log handlers to prevent a child process from logging
     # to the main process log file and garbling the log. The log handlers are
     # recreated after the worker process has been started.
     for handler in logging.root.handlers:
       logging.root.removeHandler(handler)
@@ -922,59 +1047,80 @@
       self._task_queue_profiler.Sample(tasks_status)
 
     self._processing_status.UpdateTasksStatus(tasks_status)
 
     if self._status_update_callback:
       self._status_update_callback(self._processing_status)
 
-  def ProcessSources(
-      self, source_configurations, storage_writer, session_identifier,
-      processing_configuration, enable_sigsegv_handler=False,
-      status_update_callback=None, storage_file_path=None):
-    """Processes the sources and extract events.
+  def ProcessSourceMulti(
+      self, storage_writer, session_identifier, processing_configuration,
+      system_configurations, file_system_path_specs,
+      enable_sigsegv_handler=False, storage_file_path=None):
+    """Processes file systems within a source.
 
     Args:
-      source_configurations (list[SourceConfigurationArtifact]): configurations
-          of the sources to process.
       storage_writer (StorageWriter): storage writer for a session storage.
       session_identifier (str): the identifier of the session the tasks are
           part of.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
+      system_configurations (list[SystemConfigurationArtifact]): system
+          configurations.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
       enable_sigsegv_handler (Optional[bool]): True if the SIGSEGV handler
           should be enabled.
-      status_update_callback (Optional[function]): callback function for status
-          updates.
       storage_file_path (Optional[str]): path to the session storage file.
 
     Returns:
       ProcessingStatus: processing status.
 
     Raises:
-      BadConfigOption: if the preferred time zone is invalid.
+      BadConfigOption: if an invalid collection filter was specified or if
+          the preferred time zone is invalid.
     """
     self._enable_sigsegv_handler = enable_sigsegv_handler
+    self._system_configurations = system_configurations
+
+    if not self._artifacts_registry:
+      # TODO: refactor.
+      self.BuildArtifactsRegistry(
+          processing_configuration.artifact_definitions_path,
+          processing_configuration.custom_artifacts_path)
+
+    # TODO: get environment_variables per system_configuration
+    environment_variables = self.knowledge_base.GetEnvironmentVariables()
+    user_accounts = list(storage_writer.GetAttributeContainers('user_account'))
+
+    try:
+      self.BuildCollectionFilters(
+          environment_variables, user_accounts,
+          artifact_filter_names=processing_configuration.artifact_filters,
+          filter_file_path=processing_configuration.filter_file)
+    except errors.InvalidFilter as exception:
+      raise errors.BadConfigOption(
+          'Unable to build collection filters with error: {0!s}'.format(
+              exception))
 
     self._event_data_timeliner = timeliner.EventDataTimeliner(
-        self.knowledge_base,
         data_location=processing_configuration.data_location,
-        preferred_year=processing_configuration.preferred_year)
+        preferred_year=processing_configuration.preferred_year,
+        system_configurations=system_configurations)
 
     try:
       self._event_data_timeliner.SetPreferredTimeZone(
           processing_configuration.preferred_time_zone)
     except ValueError as exception:
       raise errors.BadConfigOption(exception)
 
     # Keep track of certain values so we can spawn new extraction workers.
     self._processing_configuration = processing_configuration
 
     self._debug_output = processing_configuration.debug_output
     self._log_filename = processing_configuration.log_filename
-    self._status_update_callback = status_update_callback
     self._storage_file_path = storage_file_path
     self._storage_writer = storage_writer
     self._task_storage_format = processing_configuration.task_storage_format
 
     # Set up the task queue.
     task_outbound_queue = zeromq_queue.ZeroMQBufferedReplyBindQueue(
         delay_open=True, linger_seconds=0, maximum_items=1,
@@ -1007,16 +1153,16 @@
 
     if self._storage_profiler:
       storage_writer.SetStorageProfiler(self._storage_profiler)
 
     self._StartStatusUpdateThread()
 
     try:
-      self._ProcessSources(
-          source_configurations, storage_writer, session_identifier)
+      self._ProcessSource(
+          storage_writer, session_identifier, file_system_path_specs)
 
     finally:
       # Stop the status update thread after close of the storage writer
       # so we include the storage sync to disk in the status updates.
       self._StopStatusUpdateThread()
 
       if self._serializers_profiler:
@@ -1063,14 +1209,15 @@
 
     # Update the status view one last time.
     self._UpdateStatus()
 
     # Reset values.
     self._enable_sigsegv_handler = None
     self._event_data_timeliner = None
+    self._file_system_cache = []
     self._processing_configuration = None
-    self._status_update_callback = None
     self._storage_file_path = None
     self._storage_writer = None
+    self._system_configurations = None
     self._task_storage_format = None
 
     return self._processing_status
```

### Comparing `plaso-20230311/plaso/multi_process/extraction_process.py` & `plaso-20230717/plaso/multi_process/extraction_process.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,114 +1,107 @@
 # -*- coding: utf-8 -*-
 """The multi-process extraction worker process."""
 
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.resolver import context
-from dfvfs.resolver import resolver
+from dfvfs.resolver import resolver as path_spec_resolver
 
 from plaso.engine import worker
 from plaso.lib import definitions
 from plaso.lib import errors
 from plaso.multi_process import logger
 from plaso.multi_process import plaso_queue
 from plaso.multi_process import task_process
 from plaso.parsers import mediator as parsers_mediator
 
 
 class ExtractionWorkerProcess(task_process.MultiProcessTaskProcess):
   """Multi-processing extraction worker process."""
 
-  # Maximum number of dfVFS file system objects to cache in the worker
-  # process.
+  # Maximum number of dfVFS file system objects to cache in the worker process.
   _FILE_SYSTEM_CACHE_SIZE = 3
 
   def __init__(
-      self, task_queue, collection_filters_helper, knowledge_base,
-      processing_configuration, **kwargs):
+      self, task_queue, processing_configuration, system_configurations,
+      registry_find_specs, **kwargs):
     """Initializes an extraction worker process.
 
     Non-specified keyword arguments (kwargs) are directly passed to
     multiprocessing.Process.
 
     Args:
       task_queue (PlasoQueue): task queue.
-      collection_filters_helper (CollectionFiltersHelper): collection filters
-          helper.
-      knowledge_base (KnowledgeBase): knowledge base which contains
-          information from the source data needed for parsing.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
+      system_configurations (list[SystemConfigurationArtifact]): system
+          configurations.
+     registry_find_specs (list[dfwinreg.FindSpec]): Windows Registry find
+         specifications.
       kwargs: keyword arguments to pass to multiprocessing.Process.
     """
     super(ExtractionWorkerProcess, self).__init__(
         processing_configuration, **kwargs)
     self._abort = False
-    self._collection_filters_helper = collection_filters_helper
     self._buffer_size = 0
     self._current_display_name = ''
     self._extraction_worker = None
     self._file_system_cache = []
-    self._knowledge_base = knowledge_base
     self._number_of_consumed_sources = 0
     self._parser_mediator = None
+    self._registry_find_specs = registry_find_specs
     self._resolver_context = None
     self._status = definitions.STATUS_INDICATOR_INITIALIZED
     self._task = None
     self._task_queue = task_queue
+    self._system_configurations = system_configurations
 
-  def _CacheFileSystem(self, path_spec):
+  def _CacheFileSystem(self, file_system):
     """Caches a dfVFS file system object.
 
     Keeping and additional reference to a dfVFS file system object causes the
     object to remain cached in the resolver context. This minimizes the number
     times the file system is re-opened.
 
     Args:
-      path_spec (dfvfs.PathSpec): path specification.
+      file_system (dfvfs.FileSystem): file system.
     """
-    if (path_spec and not path_spec.IsSystemLevel() and
-        path_spec.type_indicator != dfvfs_definitions.TYPE_INDICATOR_GZIP):
-      file_system = resolver.Resolver.OpenFileEntry(
-          path_spec, resolver_context=self._resolver_context)
-
-      if file_system not in self._file_system_cache:
-        if len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
-          self._file_system_cache.pop(0)
-        self._file_system_cache.append(file_system)
-
-      elif len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
-        # Move the file system to the end of the list to preserve the most
-        # recently file system object.
-        self._file_system_cache.remove(file_system)
-        self._file_system_cache.append(file_system)
+    if file_system not in self._file_system_cache:
+      if len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
+        self._file_system_cache.pop(0)
+      self._file_system_cache.append(file_system)
+
+    elif len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
+      # Move the file system to the end of the list to preserve the most
+      # recently file system object.
+      self._file_system_cache.remove(file_system)
+      self._file_system_cache.append(file_system)
 
   def _CreateParserMediator(
-      self, knowledge_base, resolver_context, processing_configuration):
+      self, resolver_context, processing_configuration, system_configurations):
     """Creates a parser mediator.
 
     Args:
-      knowledge_base (KnowledgeBase): knowledge base which contains
-          information from the source data needed for parsing.
       resolver_context (dfvfs.Context): resolver context.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
+      system_configurations (list[SystemConfigurationArtifact]): system
+          configurations.
 
     Returns:
       ParserMediator: parser mediator.
     """
     mediator = parsers_mediator.ParserMediator(
-        knowledge_base,
-        collection_filters_helper=self._collection_filters_helper,
-        resolver_context=resolver_context)
+        registry_find_specs=self._registry_find_specs,
+        resolver_context=resolver_context,
+        system_configurations=system_configurations)
 
     mediator.SetExtractWinEvtResources(
         processing_configuration.extraction.extract_winevt_resources)
     mediator.SetPreferredCodepage(processing_configuration.preferred_codepage)
     mediator.SetPreferredLanguage(processing_configuration.preferred_language)
-    mediator.SetPreferredTimeZone(processing_configuration.preferred_time_zone)
     mediator.SetTemporaryDirectory(processing_configuration.temporary_directory)
 
     return mediator
 
   def _GetStatus(self):
     """Retrieves status information.
 
@@ -168,22 +161,22 @@
   def _Main(self):
     """The main loop."""
     # We need a resolver context per process to prevent multi processing
     # issues with file objects stored in images.
     self._resolver_context = context.Context()
 
     for credential_configuration in self._processing_configuration.credentials:
-      resolver.Resolver.key_chain.SetCredential(
+      path_spec_resolver.Resolver.key_chain.SetCredential(
           credential_configuration.path_spec,
           credential_configuration.credential_type,
           credential_configuration.credential_data)
 
     self._parser_mediator = self._CreateParserMediator(
-        self._knowledge_base, self._resolver_context,
-        self._processing_configuration)
+        self._resolver_context, self._processing_configuration,
+        self._system_configurations)
 
     # We need to initialize the parser and hasher objects after the process
     # has forked otherwise on Windows the "fork" will fail with
     # a PickleError for Python modules that cannot be pickled.
     self._extraction_worker = worker.EventExtractionWorker(
         parser_filter_expression=(
             self._processing_configuration.parser_filter_expression))
@@ -269,27 +262,31 @@
     """Processes a path specification.
 
     Args:
       extraction_worker (worker.ExtractionWorker): extraction worker.
       parser_mediator (ParserMediator): parser mediator.
       path_spec (dfvfs.PathSpec): path specification.
     """
-    excluded_find_specs = None
-    if self._collection_filters_helper:
-      excluded_find_specs = (
-          self._collection_filters_helper.excluded_file_system_find_specs)
-
     self._current_display_name = parser_mediator.GetDisplayNameForPathSpec(
         path_spec)
 
     try:
-      self._CacheFileSystem(path_spec)
+      file_entry = path_spec_resolver.Resolver.OpenFileEntry(
+          path_spec, resolver_context=parser_mediator.resolver_context)
+      if file_entry is None:
+        logger.warning('Unable to open file entry: {0:s}'.format(
+            self._current_display_name))
+        return
+
+      if (path_spec and not path_spec.IsSystemLevel() and
+          path_spec.type_indicator != dfvfs_definitions.TYPE_INDICATOR_GZIP):
+        file_system = file_entry.GetFileSystem()
+        self._CacheFileSystem(file_system)
 
-      extraction_worker.ProcessPathSpec(
-          parser_mediator, path_spec, excluded_find_specs=excluded_find_specs)
+      extraction_worker.ProcessFileEntry(parser_mediator, file_entry)
 
     except Exception as exception:  # pylint: disable=broad-except
       parser_mediator.ProduceExtractionWarning((
           'unable to process path specification with error: '
           '{0!s}').format(exception), path_spec=path_spec)
 
       if self._processing_configuration.debug_output:
```

### Comparing `plaso-20230311/plaso/multi_process/merge_helpers.py` & `plaso-20230717/plaso/multi_process/merge_helpers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/output_engine.py` & `plaso-20230717/plaso/multi_process/output_engine.py`

 * *Files 5% similar despite different names*

```diff
@@ -127,57 +127,54 @@
     """Initializes an output and formatting multi-processing engine."""
     super(OutputAndFormattingMultiProcessEngine, self).__init__()
     # The export event heap is used to make sure the events are sorted in
     # a deterministic way.
     self._events_status = processing_status.EventsStatus()
     self._export_event_heap = PsortEventHeap()
     self._export_event_timestamp = 0
-    self._knowledge_base = None
     self._number_of_consumed_events = 0
     self._output_mediator = None
     self._processing_configuration = None
     self._status = definitions.STATUS_INDICATOR_IDLE
     self._status_update_callback = None
 
-  def _CreateOutputMediator(
-      self, knowledge_base_object, processing_configuration):
+  def _CreateOutputMediator(self, storage_reader, processing_configuration):
     """Creates an output mediator.
 
     Args:
-      knowledge_base_object (KnowledgeBase): contains information from
-          the source data needed for processing.
+      storage_reader (StorageReader): storage reader.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
 
     Returns:
       OutputMediator: mediates interactions between output modules and other
           components, such as storage and dfVFS.
 
     Raises:
       BadConfigOption: if the message formatters file or directory cannot be
           read.
     """
     mediator = output_mediator.OutputMediator(
-        knowledge_base_object,
-        data_location=processing_configuration.data_location,
+        storage_reader, data_location=processing_configuration.data_location,
         dynamic_time=processing_configuration.dynamic_time,
         preferred_encoding=processing_configuration.preferred_encoding)
 
     if processing_configuration.preferred_language:
       try:
         mediator.SetPreferredLanguageIdentifier(
             processing_configuration.preferred_language)
       except (KeyError, TypeError):
         logger.warning('Unable to to set preferred language: {0!s}.'.format(
               processing_configuration.preferred_language))
 
     mediator.SetTimeZone(processing_configuration.preferred_time_zone)
 
     self._ReadMessageFormatters(
-        mediator, processing_configuration.data_location)
+        mediator, processing_configuration.data_location,
+        processing_configuration.custom_formatters_path)
 
     return mediator
 
   def _ExportEvent(
       self, storage_reader, output_module, event, event_data, event_data_stream,
       deduplicate_events=True):
     """Exports an event using an output module.
@@ -372,21 +369,23 @@
       last_macb_group_identifier = macb_group_identifier
       last_timestamp_desc = timestamp_desc
 
     if macb_group:
       output_module.WriteFieldValuesOfMACBGroup(
           self._output_mediator, macb_group)
 
-  def _ReadMessageFormatters(self, output_mediator_object, data_location):
+  def _ReadMessageFormatters(
+      self, output_mediator_object, data_location, custom_formatters_path):
     """Reads the message formatters from a formatters file or directory.
 
     Args:
       output_mediator_object (OutputMediator): mediates interactions between
           output modules and other components, such as storage and dfVFS.
       data_location (str): path to the data files.
+      custom_formatters_path (str): path to custom formatter definitions file.
 
     Raises:
       BadConfigOption: if the message formatters file or directory cannot be
           read.
     """
     formatters_directory = os.path.join(
         data_location, self._MESSAGE_FORMATTERS_DIRECTORY_NAME)
@@ -409,14 +408,23 @@
         raise errors.BadConfigOption((
             'Unable to read message formatters from file: {0:s} with error: '
             '{1!s}').format(formatters_file, exception))
 
     else:
       raise errors.BadConfigOption('Missing formatters file and directory.')
 
+    if custom_formatters_path:
+      try:
+        output_mediator_object.ReadMessageFormattersFromFile(
+            custom_formatters_path, override_existing=True)
+      except KeyError as exception:
+        raise errors.BadConfigOption((
+            'Unable to read custrom message formatters from file: {0:s} with '
+            'error: {1!s}').format(formatters_file, exception))
+
   def _UpdateForemanProcessStatus(self):
     """Update the foreman process status."""
     used_memory = self._process_information.GetUsedMemory() or 0
 
     self._processing_status.UpdateForemanStatus(
         self._name, self._status, self._pid, used_memory, '',
         0, 0, 0, 0, self._number_of_consumed_events, 0, 0, 0, 0, 0)
@@ -427,22 +435,20 @@
     """Update the status."""
     self._UpdateForemanProcessStatus()
 
     if self._status_update_callback:
       self._status_update_callback(self._processing_status)
 
   def ExportEvents(
-      self, knowledge_base_object, storage_reader, output_module,
-      processing_configuration, deduplicate_events=True, event_filter=None,
-      status_update_callback=None, time_slice=None, use_time_slicer=False):
+      self, storage_reader, output_module, processing_configuration,
+      deduplicate_events=True, event_filter=None, status_update_callback=None,
+      time_slice=None, use_time_slicer=False):
     """Exports events using an output module.
 
     Args:
-      knowledge_base_object (KnowledgeBase): contains information from
-          the source data needed for processing.
       storage_reader (StorageReader): storage reader.
       output_module (OutputModule): output module.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
       deduplicate_events (Optional[bool]): True if events should be
           deduplicated.
       event_filter (Optional[EventObjectFilter]): event filter.
@@ -454,15 +460,14 @@
           an event of interest.
 
     Raises:
       BadConfigOption: if the message formatters file or directory cannot be
           read.
     """
     self._events_status = processing_status.EventsStatus()
-    self._knowledge_base = knowledge_base_object
     self._processing_configuration = processing_configuration
     self._status_update_callback = status_update_callback
 
     total_number_of_events = 0
     if storage_reader.HasAttributeContainers('parser_count'):
       parsers_counter = {
           parser_count.name: parser_count.number_of_events
@@ -470,16 +475,15 @@
               'parser_count')}
 
       total_number_of_events = parsers_counter['total']
 
     self._events_status.total_number_of_events = total_number_of_events
 
     self._output_mediator = self._CreateOutputMediator(
-        knowledge_base_object, processing_configuration)
-    self._output_mediator.SetStorageReader(storage_reader)
+        storage_reader, processing_configuration)
 
     output_module.WriteHeader(output_mediator)
 
     self._StartStatusUpdateThread()
 
     self._StartProfiling(self._processing_configuration.profiling)
 
@@ -501,11 +505,10 @@
     # Update the status view one last time.
     self._UpdateStatus()
 
     self._StopProfiling()
 
     # Reset values.
     self._events_status = None
-    self._knowledge_base = None
     self._output_mediator = None
     self._processing_configuration = None
     self._status_update_callback = None
```

### Comparing `plaso-20230311/plaso/multi_process/plaso_queue.py` & `plaso-20230717/plaso/multi_process/plaso_queue.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/plaso_xmlrpc.py` & `plaso-20230717/plaso/multi_process/plaso_xmlrpc.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/rpc.py` & `plaso-20230717/plaso/multi_process/rpc.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/task_engine.py` & `plaso-20230717/plaso/multi_process/task_engine.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/task_manager.py` & `plaso-20230717/plaso/multi_process/task_manager.py`

 * *Files 1% similar despite different names*

```diff
@@ -80,18 +80,20 @@
     Raises:
       ValueError: if the size of the storage file is not set in the task.
     """
     storage_file_size = getattr(task, 'storage_file_size', None)
     if not storage_file_size:
       raise ValueError('Task storage file size not set.')
 
-    if task.file_entry_type == dfvfs_definitions.FILE_ENTRY_TYPE_FILE:
-      weight = storage_file_size
+    # Prioritize directories over files and other types of file entries to try
+    # to prevent merge depletion.
+    if task.file_entry_type == dfvfs_definitions.FILE_ENTRY_TYPE_DIRECTORY:
+      weight = -1
     else:
-      weight = 1
+      weight = storage_file_size
 
     task.merge_priority = weight
 
     heap_values = (weight, task)
     heapq.heappush(self._heap, heap_values)
     self._task_identifiers.add(task.identifier)
```

### Comparing `plaso-20230311/plaso/multi_process/task_process.py` & `plaso-20230717/plaso/multi_process/task_process.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/multi_process/zeromq_queue.py` & `plaso-20230717/plaso/multi_process/zeromq_queue.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,21 +1,16 @@
 # -*- coding: utf-8 -*-
 """ZeroMQ implementations of the Plaso queue interface."""
 
 import abc
 import errno
+import queue
 import threading
 import time
 
-# The 'Queue' module was renamed to 'queue' in Python 3
-try:
-  import Queue  # pylint: disable=import-error
-except ImportError:
-  import queue as Queue  # pylint: disable=import-error
-
 import zmq
 
 from plaso.engine import logger
 from plaso.lib import errors
 from plaso.multi_process import plaso_queue
 
 
@@ -364,14 +359,16 @@
         if time.time() > last_retry_timestamp:
           raise
 
       except KeyboardInterrupt:
         self.Close(abort=True)
         raise
 
+    return None
+
   def PushItem(self, item, block=True):
     """Pushes an item on to the queue.
 
     Provided for compatibility with the API, but doesn't actually work.
 
     Args:
       item (object): item to push on the queue.
@@ -526,14 +523,16 @@
       except errors.QueueEmpty:
         continue
 
       except KeyboardInterrupt:
         self.Close(abort=True)
         raise
 
+    return None
+
   def PushItem(self, item, block=True):
     """Pushes an item on to the queue.
 
     Provided for compatibility with the API, but doesn't actually work.
 
     Args:
       item (object): item to push on the queue.
@@ -589,15 +588,15 @@
       name (Optional[str]): name to identify the queue.
       port (Optional[int]): The TCP port to use for the queue. None indicates
           that the queue should choose a random port to bind to.
       timeout_seconds (Optional[int]): number of seconds that calls to PopItem
           and PushItem may block for, before returning queue.QueueEmpty.
     """
     self._buffer_timeout_seconds = buffer_timeout_seconds
-    self._queue = Queue.Queue(maxsize=buffer_max_size)
+    self._queue = queue.Queue(maxsize=buffer_max_size)
     self._zmq_thread = None
 
     # We need to set up the internal buffer queue before we call super, so that
     # if the call to super opens the ZMQSocket, the backing thread will work.
     super(ZeroMQBufferedQueue, self).__init__(
         delay_open=delay_open, linger_seconds=linger_seconds,
         maximum_items=maximum_items, name=name, port=port,
@@ -613,15 +612,15 @@
       self._zmq_thread.start()
 
   @abc.abstractmethod
   def _ZeroMQResponder(self, source_queue):
     """Listens for requests and replies to clients.
 
     Args:
-      source_queue (Queue.queue): queue to to pull items from.
+      source_queue (queue.queue): queue to to pull items from.
     """
 
   def Close(self, abort=False):
     """Closes the queue.
 
     Args:
       abort (Optional[bool]): whether the Close is the result of an abort
@@ -665,15 +664,15 @@
               self.name, self._linger_seconds))
 
   def Empty(self):
     """Removes all items from the internal buffer."""
     try:
       while True:
         self._queue.get(False)
-    except Queue.Empty:
+    except queue.Empty:
       pass
 
 
 class ZeroMQBufferedReplyQueue(ZeroMQBufferedQueue):
   """Parent class for buffered Plaso queues backed by ZeroMQ REP sockets.
 
   This class should not be instantiated directly, a subclass should be
@@ -688,15 +687,15 @@
 
   _SOCKET_TYPE = zmq.REP
 
   def _ZeroMQResponder(self, source_queue):
     """Listens for requests and replies to clients.
 
     Args:
-      source_queue (Queue.queue): queue to use to pull items from.
+      source_queue (queue.Queue): queue to use to pull items from.
 
     Raises:
       RuntimeError: if closed or terminate event is missing.
     """
     if not self._closed_event or not self._terminate_event:
       raise RuntimeError('Missing closed or terminate event.')
 
@@ -707,15 +706,15 @@
       if not item:
         try:
           if self._closed_event.is_set():
             item = source_queue.get_nowait()
           else:
             item = source_queue.get(True, self._buffer_timeout_seconds)
 
-        except Queue.Empty:
+        except queue.Empty:
           if self._closed_event.is_set():
             break
 
           continue
 
       try:
         # We need to receive a request before we can reply with the item.
@@ -773,15 +772,15 @@
       self._CreateZMQSocket()
 
     try:
       if block:
         self._queue.put(item, timeout=self.timeout_seconds)
       else:
         self._queue.put(item, block=False)
-    except Queue.Full as exception:
+    except queue.Full as exception:
       raise errors.QueueFull(exception)
 
 
 class ZeroMQBufferedReplyBindQueue(ZeroMQBufferedReplyQueue):
   """A Plaso queue backed by a ZeroMQ REP socket that binds to a port.
 
   This queue may only be used to pop items, not to push.
```

### Comparing `plaso-20230311/plaso/output/__init__.py` & `plaso-20230717/plaso/output/__init__.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/dynamic.py` & `plaso-20230717/plaso/output/dynamic.py`

 * *Files 1% similar despite different names*

```diff
@@ -38,14 +38,15 @@
       'tag': '_FormatTag',
       'time': '_FormatTime',
       'timestamp_desc': '_FormatTimestampDescription',
       'timezone': '_FormatTimeZone',
       'type': '_FormatTimestampDescription',
       'user': '_FormatUsername',
       'username': '_FormatUsername',
+      'values': '_FormatValues',
       'yara_match': '_FormatYaraMatch',
       'zone': '_FormatTimeZone'}
 
   # The field format callback methods require specific arguments hence
   # the check for unused arguments is disabled here.
   # pylint: disable=unused-argument
 
@@ -73,21 +74,21 @@
           timestamp=event.timestamp)
 
     # Note that GetDateWithTimeOfDay will return the date and time in UTC,
     # so no adjustment for date_time.time_zone_offset is needed.
     year, month, day_of_month, hours, minutes, seconds = (
         date_time.GetDateWithTimeOfDay())
 
-    if output_mediator.timezone != pytz.UTC:
+    if output_mediator.time_zone != pytz.UTC:
       try:
         datetime_object = datetime.datetime(
             year, month, day_of_month, hours, minutes, seconds,
             tzinfo=pytz.UTC)
 
-        datetime_object = datetime_object.astimezone(output_mediator.timezone)
+        datetime_object = datetime_object.astimezone(output_mediator.time_zone)
 
         year = datetime_object.year
         month = datetime_object.month
         day_of_month = datetime_object.day
 
       except (OSError, OverflowError, TypeError, ValueError):
         year, month, day_of_month = (None, None, None)
```

### Comparing `plaso-20230311/plaso/output/formatting_helper.py` & `plaso-20230717/plaso/output/formatting_helper.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import math
 import pytz
 
 from dfdatetime import posix_time as dfdatetime_posix_time
 from dfvfs.lib import definitions as dfvfs_definitions
 
 from plaso.containers import events
-from plaso.lib import errors
+from plaso.formatters import default
 from plaso.output import logger
 
 
 class EventFormattingHelper(object):
   """Output module event formatting helper."""
 
   @abc.abstractmethod
@@ -34,14 +34,16 @@
       list[str]: output field values.
     """
 
 
 class FieldFormattingHelper(object):
   """Output module field formatting helper."""
 
+  _DEFAULT_MESSAGE_FORMATTER = default.DefaultEventFormatter()
+
   # Maps the name of a field to callback function that formats the field value.
   _FIELD_FORMAT_CALLBACKS = {}
 
   def __init__(self):
     """Initializes a field formatting helper."""
     event_data_stream = events.EventDataStream()
 
@@ -93,26 +95,27 @@
       iso8601_string = date_time.CopyToDateTimeStringISO8601()
       if not iso8601_string:
         return 'Invalid'
 
       if iso8601_string[-1] == 'Z':
         iso8601_string = '{0:s}+00:00'.format(iso8601_string[:-1])
 
-      if output_mediator.timezone != pytz.UTC or date_time.time_zone_offset:
+      if output_mediator.time_zone != pytz.UTC or date_time.time_zone_offset:
         # For output in a specific time zone overwrite the date, time in
         # seconds and time zone offset in the UTC ISO8601 string.
         year, month, day_of_month, hours, minutes, seconds = (
             date_time.GetDateWithTimeOfDay())
 
         try:
           datetime_object = datetime.datetime(
               year, month, day_of_month, hours, minutes, seconds,
               tzinfo=pytz.UTC)
 
-          datetime_object = datetime_object.astimezone(output_mediator.timezone)
+          datetime_object = datetime_object.astimezone(
+              output_mediator.time_zone)
 
           isoformat_string = datetime_object.isoformat()
           iso8601_string = ''.join([
               isoformat_string[:19], iso8601_string[19:-6],
               isoformat_string[-6:]])
         except (OSError, OverflowError, TypeError, ValueError):
           return 'Invalid'
@@ -139,15 +142,15 @@
       if not timestamp:
         return '0000-00-00T00:00:00.000000+00:00'
 
       try:
         datetime_object = datetime.datetime(1970, 1, 1) + datetime.timedelta(
             microseconds=timestamp)
 
-        datetime_object = datetime_object.astimezone(output_mediator.timezone)
+        datetime_object = datetime_object.astimezone(output_mediator.time_zone)
 
         iso8601_string = datetime_object.isoformat()
         iso8601_string = '{0:s}.{1:06d}{2:s}'.format(
             iso8601_string[:19], datetime_object.microsecond,
             iso8601_string[-6:])
 
       except (OSError, OverflowError, TypeError, ValueError) as exception:
@@ -295,25 +298,22 @@
           modules and other components, such as storage and dfVFS.
       event (EventObject): event.
       event_data (EventData): event data.
       event_data_stream (EventDataStream): event data stream.
 
     Returns:
       str: message field.
-
-    Raises:
-      NoFormatterFound: if no message formatter can be found to match the data
-          type in the event data.
     """
     message_formatter = output_mediator.GetMessageFormatter(
         event_data.data_type)
     if not message_formatter:
-      raise errors.NoFormatterFound((
-          'Unable to find message formatter event with data type: '
-          '{0:s}.').format(event_data.data_type))
+      logger.warning(
+          'Using default message formatter for data type: {0:s}'.format(
+              event_data.data_type))
+      message_formatter = self._DEFAULT_MESSAGE_FORMATTER
 
     event_values = event_data.CopyToDict()
     message_formatter.FormatEventValues(output_mediator, event_values)
 
     return message_formatter.GetMessage(event_values)
 
   def _FormatMessageShort(
@@ -325,25 +325,22 @@
           modules and other components, such as storage and dfVFS.
       event (EventObject): event.
       event_data (EventData): event data.
       event_data_stream (EventDataStream): event data stream.
 
     Returns:
       str: short message field.
-
-    Raises:
-      NoFormatterFound: if no message formatter can be found to match the data
-          type in the event data.
     """
     message_formatter = output_mediator.GetMessageFormatter(
         event_data.data_type)
     if not message_formatter:
-      raise errors.NoFormatterFound((
-          'Unable to find message formatter event with data type: '
-          '{0:s}.').format(event_data.data_type))
+      logger.warning(
+          'Using default message formatter for data type: {0:s}'.format(
+              event_data.data_type))
+      message_formatter = self._DEFAULT_MESSAGE_FORMATTER
 
     event_values = event_data.CopyToDict()
     message_formatter.FormatEventValues(output_mediator, event_values)
 
     return message_formatter.GetMessageShort(event_values)
 
   def _FormatSource(
@@ -355,18 +352,14 @@
           modules and other components, such as storage and dfVFS.
       event (EventObject): event.
       event_data (EventData): event data.
       event_data_stream (EventDataStream): event data stream.
 
     Returns:
       str: source field.
-
-    Raises:
-      NoFormatterFound: if no event formatter can be found to match the data
-          type in the event data.
     """
     data_type = getattr(event_data, 'data_type', None) or '-'
     _, source = output_mediator.GetSourceMapping(data_type)
     return source or 'N/A'
 
   def _FormatSourceShort(
       self, output_mediator, event, event_data, event_data_stream):
@@ -377,18 +370,14 @@
           modules and other components, such as storage and dfVFS.
       event (EventObject): event.
       event_data (EventData): event data.
       event_data_stream (EventDataStream): event data stream.
 
     Returns:
       str: short source field.
-
-    Raises:
-      NoFormatterFound: If no event formatter can be found to match the data
-          type in the event data.
     """
     data_type = getattr(event_data, 'data_type', None) or '-'
     source_short, _ = output_mediator.GetSourceMapping(data_type)
     return source_short or 'N/A'
 
   def _FormatTag(self, output_mediator, event_tag):
     """Formats an event tag field.
@@ -428,21 +417,21 @@
     if not date_time or date_time.is_local_time:
       date_time = dfdatetime_posix_time.PosixTimeInMicroseconds(
           timestamp=event.timestamp)
 
     year, month, day_of_month, hours, minutes, seconds = (
         date_time.GetDateWithTimeOfDay())
 
-    if output_mediator.timezone != pytz.UTC:
+    if output_mediator.time_zone != pytz.UTC:
       try:
         datetime_object = datetime.datetime(
             year, month, day_of_month, hours, minutes, seconds,
             tzinfo=pytz.UTC)
 
-        datetime_object = datetime_object.astimezone(output_mediator.timezone)
+        datetime_object = datetime_object.astimezone(output_mediator.time_zone)
 
         hours, minutes, seconds = (
             datetime_object.hour, datetime_object.minute,
             datetime_object.second)
 
       except (OSError, OverflowError, TypeError, ValueError):
         hours, minutes, seconds = (None, None, None)
@@ -473,26 +462,26 @@
       return '-'
 
     date_time = event.date_time
     if not date_time or date_time.is_local_time:
       date_time = dfdatetime_posix_time.PosixTimeInMicroseconds(
           timestamp=event.timestamp)
 
-    if output_mediator.timezone == pytz.UTC:
+    if output_mediator.time_zone == pytz.UTC:
       return 'UTC'
 
     year, month, day_of_month, hours, minutes, seconds = (
         date_time.GetDateWithTimeOfDay())
 
     try:
       # For tzname to work the datetime object must be naive (without
       # a time zone).
       datetime_object = datetime.datetime(
           year, month, day_of_month, hours, minutes, seconds)
-      return output_mediator.timezone.tzname(datetime_object)
+      return output_mediator.time_zone.tzname(datetime_object)
 
     except (OverflowError, TypeError, ValueError):
       self._ReportEventError(event, event_data, (
           'unable to copy timestamp: {0!s} to a human readable time zone. '
           'Defaulting to: "-"').format(event.timestamp))
 
       return '-'
@@ -509,14 +498,38 @@
       event_data_stream (EventDataStream): event data stream.
 
     Returns:
       str: username field.
     """
     return output_mediator.GetUsername(event_data)
 
+  def _FormatValues(
+      self, output_mediator, event, event_data, event_data_stream):
+    """Formats a values.
+
+    Args:
+      output_mediator (OutputMediator): mediates interactions between output
+          modules and other components, such as storage and dfVFS.
+      event (EventObject): event.
+      event_data (EventData): event data.
+      event_data_stream (EventDataStream): event data stream.
+
+    Returns:
+      str: values field.
+    """
+    values = event_data.values
+    if isinstance(values, list) and event_data.data_type in (
+        'windows:registry:key_value', 'windows:registry:service'):
+      values = ' '.join([
+          '{0:s}: [{1:s}] {2:s}'.format(
+              name or '(default)', data_type, data or '(empty)')
+          for name, data_type, data in sorted(values)])
+
+    return values
+
   # pylint: enable=unused-argument
 
   def _ReportEventError(self, event, event_data, error_message):
     """Reports an event related error.
 
     Args:
       event (EventObject): event.
```

### Comparing `plaso-20230311/plaso/output/interface.py` & `plaso-20230717/plaso/output/interface.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 # -*- coding: utf-8 -*-
 """This file contains the output module interface class."""
 
 import abc
 
-from plaso.lib import errors
 from plaso.output import logger
 
 
 class OutputModule(object):
   """Output module interface."""
 
   NAME = ''
@@ -98,22 +97,16 @@
       output_mediator (OutputMediator): mediates interactions between output
           modules and other components, such as storage and dfVFS.
       event (EventObject): event.
       event_data (EventData): event data.
       event_data_stream (EventDataStream): event data stream.
       event_tag (EventTag): event tag.
     """
-    try:
-      field_values = self._GetFieldValues(
-          output_mediator, event, event_data, event_data_stream, event_tag)
-
-    except errors.NoFormatterFound as exception:
-      error_message = 'unable to retrieve formatter with error: {0!s}'.format(
-          exception)
-      self._ReportEventError(event, event_data, error_message)
+    field_values = self._GetFieldValues(
+        output_mediator, event, event_data, event_data_stream, event_tag)
 
     self._WriteFieldValues(output_mediator, field_values)
 
   def WriteFieldValuesOfMACBGroup(self, output_mediator, macb_group):
     """Writes field values of a MACB group to the output.
 
     Args:
```

### Comparing `plaso-20230311/plaso/output/json_line.py` & `plaso-20230717/plaso/output/json_line.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/json_out.py` & `plaso-20230717/plaso/output/json_out.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/kml.py` & `plaso-20230717/plaso/output/kml.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/l2t_csv.py` & `plaso-20230717/plaso/output/l2t_csv.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,14 @@
 import pytz
 
 from acstore.containers import interface as containers_interface
 
 from dfdatetime import interface as dfdatetime_interface
 from dfdatetime import posix_time as dfdatetime_posix_time
 
-from plaso.lib import errors
 from plaso.output import formatting_helper
 from plaso.output import logger
 from plaso.output import manager
 from plaso.output import shared_dsv
 from plaso.output import text_file
 
 
@@ -81,14 +80,15 @@
       'short': '_FormatMessageShort',
       'source': '_FormatSourceShort',
       'sourcetype': '_FormatSource',
       'time': '_FormatTime',
       'timezone': '_FormatTimeZone',
       'type': '_FormatType',
       'user': '_FormatUsername',
+      'values': '_FormatValues',
       'version': '_FormatVersion'}
 
   # Note that list is kept as-is for backwards compatibility.
   _RESERVED_VARIABLE_NAMES = frozenset([
       '_event_values_hash',
       '_parser_chain',
       'body',
@@ -140,21 +140,21 @@
           timestamp=event.timestamp)
 
     # Note that GetDateWithTimeOfDay will return the date and time in UTC,
     # so no adjustment for date_time.time_zone_offset is needed.
     year, month, day_of_month, hours, minutes, seconds = (
         date_time.GetDateWithTimeOfDay())
 
-    if output_mediator.timezone != pytz.UTC:
+    if output_mediator.time_zone != pytz.UTC:
       try:
         datetime_object = datetime.datetime(
             year, month, day_of_month, hours, minutes, seconds,
             tzinfo=pytz.UTC)
 
-        datetime_object = datetime_object.astimezone(output_mediator.timezone)
+        datetime_object = datetime_object.astimezone(output_mediator.time_zone)
 
         year = datetime_object.year
         month = datetime_object.month
         day_of_month = datetime_object.day
 
       except (OSError, OverflowError, TypeError, ValueError):
         year, month, day_of_month = (None, None, None)
@@ -176,25 +176,22 @@
           modules and other components, such as storage and dfVFS.
       event (EventObject): event.
       event_data (EventData): event data.
       event_data_stream (EventDataStream): event data stream.
 
     Returns:
       str: extra attributes field.
-
-    Raises:
-      NoFormatterFound: if no event formatter can be found to match the data
-          type in the event data.
     """
     message_formatter = output_mediator.GetMessageFormatter(
         event_data.data_type)
     if not message_formatter:
-      raise errors.NoFormatterFound((
-          'Unable to find message formatter event with data type: '
-          '{0:s}.').format(event_data.data_type))
+      logger.warning(
+          'Using default message formatter for data type: {0:s}'.format(
+              event_data.data_type))
+      message_formatter = self._DEFAULT_MESSAGE_FORMATTER
 
     formatted_attribute_names = (
         message_formatter.GetFormatStringAttributeNames())
     formatted_attribute_names.update(self._RESERVED_VARIABLE_NAMES)
 
     extra_attributes = []
     for attribute_name, attribute_value in event_data.GetAttributes():
```

### Comparing `plaso-20230311/plaso/output/manager.py` & `plaso-20230717/plaso/output/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/mediator.py` & `plaso-20230717/plaso/output/mediator.py`

 * *Files 7% similar despite different names*

```diff
@@ -2,110 +2,130 @@
 """The output mediator object."""
 
 import glob
 import os
 import pytz
 
 from plaso.engine import path_helper
-from plaso.formatters import default
 from plaso.formatters import manager as formatters_manager
 from plaso.formatters import yaml_formatters_file
 from plaso.helpers.windows import languages
 from plaso.lib import definitions
-from plaso.output import logger
 from plaso.output import winevt_rc
 
 
 class OutputMediator(object):
   """Output mediator.
 
   Attributes:
     data_location (Optional[str]): path of the formatter data files.
   """
 
-  _DEFAULT_LANGUAGE_TAG = 'en-US'
+  _DEFAULT_ENCODING = 'utf-8'
 
-  # LCID 0x0409 is en-US.
+  # The default LCID 0x0409, which represents en-US.
   _DEFAULT_LCID = 0x0409
 
-  _DEFAULT_MESSAGE_FORMATTER = default.DefaultEventFormatter()
-
   _DEFAULT_TIME_ZONE = pytz.UTC
 
   _WINEVT_RC_DATABASE = 'winevt-rc.db'
 
   def __init__(
-      self, knowledge_base, data_location=None, dynamic_time=False,
+      self, storage_reader, data_location=None, dynamic_time=False,
       preferred_encoding='utf-8'):
     """Initializes an output mediator.
 
     Args:
-      knowledge_base (KnowledgeBase): knowledge base.
+      storage_reader (StorageReader): storage reader.
       data_location (Optional[str]): path of the formatter data files.
       dynamic_time (Optional[bool]): True if date and time values should be
           represented in their granularity or semantically.
       preferred_encoding (Optional[str]): preferred encoding to output.
     """
     super(OutputMediator, self).__init__()
     self._dynamic_time = dynamic_time
-    self._knowledge_base = knowledge_base
-    self._language_tag = self._DEFAULT_LANGUAGE_TAG
-    self._lcid = self._DEFAULT_LCID
+    self._hostname = None
+    self._language_tag = None
+    self._lcid = None
     self._message_formatters = {}
     self._preferred_encoding = preferred_encoding
     self._source_mappings = {}
-    self._storage_reader = None
+    self._storage_reader = storage_reader
+    self._system_configurations = None
     self._time_zone = None
+    self._username_by_identifier = {}
 
     self.data_location = data_location
 
   @property
   def dynamic_time(self):
-    """bool: True if date and time values should be represented in their
-             granularity or semantically.
-    """
+    """bool: True if dynamic time should be used."""
     return self._dynamic_time
 
   @property
   def encoding(self):
-    """str: preferred encoding."""
-    return self._preferred_encoding
+    """str: preferred encoding to output."""
+    return self._preferred_encoding or self._DEFAULT_ENCODING
 
   @property
-  def timezone(self):
-    """The time zone."""
-    if not self._time_zone:
-      self._time_zone = self._DEFAULT_TIME_ZONE
+  def time_zone(self):
+    """datetime.tzinfo: time zone."""
+    return self._time_zone or self._DEFAULT_TIME_ZONE
 
-    return self._time_zone
-
-  def _ReadMessageFormattersFile(self, path):
+  def _ReadMessageFormattersFile(self, path, override_existing=False):
     """Reads a message formatters configuration file.
 
     Args:
       path (str): path of file that contains the message formatters
-           configuration.
+          configuration.
+      override_existing (bool): True if existing message formatters should
+          be overridden.
 
     Raises:
       KeyError: if the message formatter is already set for the corresponding
-          data type.
+          data type and override existing is False.
     """
     message_formatters_file = yaml_formatters_file.YAMLFormattersFile()
     for message_formatter in message_formatters_file.ReadFromFile(path):
+      if (message_formatter.data_type in self._message_formatters and
+          not override_existing):
+        raise KeyError(
+            'Message formatter for data type: {0:s} already exists'.format(
+                message_formatter.data_type))
+
       for identifier in message_formatter.custom_helpers:
         custom_formatter_helper = (
              formatters_manager.FormattersManager.GetEventFormatterHelper(
                 identifier))
         if custom_formatter_helper:
           message_formatter.AddHelper(custom_formatter_helper)
 
       self._message_formatters[message_formatter.data_type] = message_formatter
       self._source_mappings[message_formatter.data_type] = (
           message_formatter.source_mapping)
 
+  def _ReadUserAccount(self, user_identifier):
+    """Reads a specific user account from the storage.
+
+    Args:
+      user_identifier (str): user identifier (UID or SID).
+
+    Returns:
+      UserAccountArtifact: user account or None if not available.
+    """
+    # TODO: get username related to the source.
+    filter_expression = 'identifier == "{0:s}"'.format(user_identifier)
+    user_accounts = list(self._storage_reader.GetAttributeContainers(
+        'user_account', filter_expression=filter_expression))
+
+    if not user_accounts:
+      return None
+
+    return user_accounts[0]
+
   def GetDisplayNameForPathSpec(self, path_spec):
     """Retrieves the display name for a path specification.
 
     Args:
       path_spec (dfvfs.PathSpec): path specification.
 
     Returns:
@@ -123,16 +143,25 @@
     Returns:
       str: hostname.
     """
     hostname = getattr(event_data, 'hostname', None)
     if hostname:
       return hostname
 
-    hostname = self._knowledge_base.GetHostname()
-    return hostname or default_hostname
+    if self._system_configurations is None:
+      self._system_configurations = list(
+          self._storage_reader.GetAttributeContainers('system_configuration'))
+
+    # TODO: get hostname related to the source.
+    if not self._hostname and self._system_configurations:
+      hostname_artifact = self._system_configurations[-1].hostname
+      if hostname_artifact:
+        self._hostname = hostname_artifact.name
+
+    return self._hostname or default_hostname
 
   def GetMACBRepresentation(self, event, event_data):
     """Retrieves the MACB representation.
 
     Args:
       event (EventObject): event.
       event_data (EventData): event data.
@@ -254,22 +283,15 @@
       data_type (str): data type.
 
     Returns:
       EventFormatter: corresponding message formatter or the default message
           formatter if not available.
     """
     data_type = data_type.lower()
-    message_formatter = self._message_formatters.get(data_type, None)
-    if not message_formatter:
-      logger.warning(
-          'Using default message formatter for data type: {0:s}'.format(
-              data_type))
-      message_formatter = self._DEFAULT_MESSAGE_FORMATTER
-
-    return message_formatter
+    return self._message_formatters.get(data_type, None)
 
   def GetRelativePathForPathSpec(self, path_spec):
     """Retrieves the relative path for a path specification.
 
     Args:
       path_spec (dfvfs.PathSpec): path specification.
 
@@ -288,47 +310,54 @@
       tuple[str, str]: short and (long) source mappings or (None, None) if not
           available.
     """
     data_type = data_type.lower()
     return self._source_mappings.get(data_type, (None, None))
 
   def GetUsername(self, event_data, default_username='-'):
-    """Retrieves the username related to the event.
+    """Retrieves the username related to the event data.
 
     Args:
       event_data (EventData): event data.
       default_username (Optional[str]): default username.
 
     Returns:
       str: username.
     """
     username = getattr(event_data, 'username', None)
     if username and username != '-':
       return username
 
-    user_sid = getattr(event_data, 'user_sid', None)
-    username = self._knowledge_base.GetUsernameByIdentifier(user_sid)
+    username = default_username
+
+    user_identifier = getattr(event_data, 'user_sid', None)
+    if (user_identifier and
+        user_identifier not in self._username_by_identifier):
+      user_account = self._ReadUserAccount(user_identifier)
+      if user_account:
+        username = user_account.username
+        self._username_by_identifier[user_identifier] = username
+
     return username or default_username
 
   def GetWinevtResourcesHelper(self):
     """Retrieves a Windows EventLog resources helper.
 
     Returns:
       WinevtResourcesHelper: Windows EventLog resources helper.
     """
-    lcid = self._lcid or self._DEFAULT_LCID
-
-    if not self._storage_reader.HasAttributeContainers('environment_variable'):
-      environment_variables = []
-    else:
-      environment_variables = list(
-          self._storage_reader.GetAttributeContainers('environment_variable'))
+    lcid = self._lcid
+    if not lcid:
+      # TODO: determine LCID from system configurations
+      pass
+    if not lcid:
+      lcid = self._DEFAULT_LCID
 
     return winevt_rc.WinevtResourcesHelper(
-        self._storage_reader, self.data_location, lcid, environment_variables)
+        self._storage_reader, self.data_location, lcid)
 
   def ReadMessageFormattersFromDirectory(self, path):
     """Reads message formatters from a directory.
 
     Args:
       path (str): path of directory that contains the message formatters
           configuration files.
@@ -336,26 +365,28 @@
     Raises:
       KeyError: if the message formatter is already set for the corresponding
           data type.
     """
     for formatters_file_path in glob.glob(os.path.join(path, '*.yaml')):
       self._ReadMessageFormattersFile(formatters_file_path)
 
-  def ReadMessageFormattersFromFile(self, path):
+  def ReadMessageFormattersFromFile(self, path, override_existing=False):
     """Reads message formatters from a file.
 
     Args:
       path (str): path of file that contains the message formatters
           configuration.
+      override_existing (bool): True if existing message formatters should
+          be overridden.
 
     Raises:
       KeyError: if the message formatter is already set for the corresponding
           data type.
     """
-    self._ReadMessageFormattersFile(path)
+    self._ReadMessageFormattersFile(path, override_existing=override_existing)
 
   def SetPreferredLanguageIdentifier(self, language_tag):
     """Sets the preferred language identifier.
 
     Args:
       language_tag (str): language tag such as "en-US" for US English or
           "is-IS" for Icelandic.
@@ -374,22 +405,14 @@
       if not lcid:
         raise ValueError('No LCID found for language tag: {0:s}.'.format(
             language_tag))
 
     self._language_tag = language_tag
     self._lcid = lcid
 
-  def SetStorageReader(self, storage_reader):
-    """Sets the storage reader.
-
-    Args:
-      storage_reader (StorageReader): storage reader.
-    """
-    self._storage_reader = storage_reader
-
   def SetTimeZone(self, time_zone):
     """Sets the time zone.
 
     Args:
       time_zone (str): time zone.
 
     Raises:
```

### Comparing `plaso-20230311/plaso/output/null.py` & `plaso-20230717/plaso/output/null.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/opensearch.py` & `plaso-20230717/plaso/output/opensearch.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/opensearch_ts.py` & `plaso-20230717/plaso/output/opensearch_ts.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/rawpy.py` & `plaso-20230717/plaso/output/rawpy.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/shared_dsv.py` & `plaso-20230717/plaso/output/shared_dsv.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/shared_json.py` & `plaso-20230717/plaso/output/shared_json.py`

 * *Files 24% similar despite different names*

```diff
@@ -3,29 +3,103 @@
 
 import abc
 
 from acstore.containers import interface as containers_interface
 
 from dfdatetime import interface as dfdatetime_interface
 
-from plaso.lib import errors
-from plaso.output import dynamic
+from plaso.output import formatting_helper
 from plaso.output import text_file
 from plaso.serializer import json_serializer
 
 
+class JSONFieldFormattingHelper(formatting_helper.FieldFormattingHelper):
+  """JSON output module field formatting helper."""
+
+  # Maps the name of a fields to a a callback function that formats
+  # the field value.
+  _FIELD_FORMAT_CALLBACKS = {
+      'display_name': '_FormatDisplayName',
+      'filename': '_FormatFilename',
+      'inode': '_FormatInode',
+      'message': '_FormatMessage',
+      'values': '_FormatValues'}
+
+  # The field format callback methods require specific arguments hence
+  # the check for unused arguments is disabled here.
+  # pylint: disable=unused-argument
+
+  def _FormatValues(
+      self, output_mediator, event, event_data, event_data_stream):
+    """Formats a values.
+
+    Args:
+      output_mediator (OutputMediator): mediates interactions between output
+          modules and other components, such as storage and dfVFS.
+      event (EventObject): event.
+      event_data (EventData): event data.
+      event_data_stream (EventDataStream): event data stream.
+
+    Returns:
+      list[dict[str, str]]: values field.
+    """
+    values = event_data.values
+    if isinstance(values, list) and event_data.data_type in (
+        'windows:registry:key_value', 'windows:registry:service'):
+      values = [
+          {'data': data, 'data_type': data_type, 'name': name}
+          for name, data_type, data in sorted(values)]
+
+    return values
+
+  # pylint: enable=unused-argument
+
+  def GetFormattedField(
+      self, output_mediator, field_name, event, event_data, event_data_stream,
+      event_tag):
+    """Formats the specified field.
+
+    Args:
+      output_mediator (OutputMediator): mediates interactions between output
+          modules and other components, such as storage and dfVFS.
+      field_name (str): name of the field.
+      event (EventObject): event.
+      event_data (EventData): event data.
+      event_data_stream (EventDataStream): event data stream.
+      event_tag (EventTag): event tag.
+
+    Returns:
+      object: value of the field or None if not available.
+    """
+    if field_name in self._event_tag_field_names:
+      return self._FormatTag(output_mediator, event_tag)
+
+    callback_function = self._callback_functions.get(field_name, None)
+    if callback_function:
+      output_value = callback_function(
+          output_mediator, event, event_data, event_data_stream)
+    elif field_name in self._event_data_stream_field_names:
+      output_value = getattr(event_data_stream, field_name, None)
+    else:
+      output_value = getattr(event_data, field_name, None)
+
+    return output_value
+
+
 class SharedJSONOutputModule(text_file.TextFileOutputModule):
   """Shared functionality for JSON based output modules."""
 
   _JSON_SERIALIZER = json_serializer.JSONAttributeContainerSerializer
 
+  _GENERATED_FIELD_VALUES = ['display_name', 'filename', 'inode']
+
   def __init__(self):
     """Initializes an output module."""
     super(SharedJSONOutputModule, self).__init__()
-    self._field_formatting_helper = dynamic.DynamicFieldFormattingHelper()
+    self._field_formatting_helper = JSONFieldFormattingHelper()
 
   def _GetFieldValues(
       self, output_mediator, event, event_data, event_data_stream, event_tag):
     """Retrieves the output field values.
 
     Args:
       output_mediator (OutputMediator): mediates interactions between output
@@ -46,28 +120,27 @@
       for attribute_name, attribute_value in event_data.GetAttributes():
         # Ignore attribute container identifier and date and time values.
         if isinstance(attribute_value, (
             containers_interface.AttributeContainerIdentifier,
             dfdatetime_interface.DateTimeValues)):
           continue
 
-        # Ignore date and time values.
-        if isinstance(attribute_value, dfdatetime_interface.DateTimeValues):
-          continue
-
         if (isinstance(attribute_value, list) and attribute_value and
             isinstance(attribute_value[0],
                        dfdatetime_interface.DateTimeValues)):
           continue
 
         # Output _parser_chain as parser for backwards compatibility.
         if attribute_name == '_parser_chain':
           attribute_name = 'parser'
 
-        field_values[attribute_name] = attribute_value
+        field_value = self._field_formatting_helper.GetFormattedField(
+            output_mediator, attribute_name, event, event_data,
+            event_data_stream, event_tag)
+        field_values[attribute_name] = field_value
 
     if event_data_stream:
       for attribute_name, attribute_value in event_data_stream.GetAttributes():
         # Output path_spec as pathspec for backwards compatibility.
         if attribute_name == 'path_spec':
           attribute_name = 'pathspec'
           attribute_value = self._JSON_SERIALIZER.WriteSerializedDict(
@@ -84,42 +157,25 @@
 
         if attribute_name == 'date_time':
           attribute_value = self._JSON_SERIALIZER.WriteSerializedDict(
               attribute_value)
 
         field_values[attribute_name] = attribute_value
 
-    display_name = field_values.get('display_name', None)
-    if display_name is None:
-      display_name = self._field_formatting_helper.GetFormattedField(
-          output_mediator, 'display_name', event, event_data, event_data_stream,
-          event_tag)
-      field_values['display_name'] = display_name
-
-    filename = field_values.get('filename', None)
-    if filename is None:
-      filename = self._field_formatting_helper.GetFormattedField(
-          output_mediator, 'filename', event, event_data, event_data_stream,
-          event_tag)
-      field_values['filename'] = filename
-
-    inode = field_values.get('inode', None)
-    if inode is None:
-      inode = self._field_formatting_helper.GetFormattedField(
-          output_mediator, 'inode', event, event_data, event_data_stream,
-          event_tag)
-      field_values['inode'] = inode
-
-    try:
-      message = self._field_formatting_helper.GetFormattedField(
-          output_mediator, 'message', event, event_data, event_data_stream,
-          event_tag)
-      field_values['message'] = message
-    except errors.NoFormatterFound:
-      pass
+    for field_name in self._GENERATED_FIELD_VALUES:
+      field_value = field_values.get(field_name, None)
+      if field_value is None:
+        field_value = self._field_formatting_helper.GetFormattedField(
+            output_mediator, field_name, event, event_data, event_data_stream,
+            event_tag)
+        field_values[field_name] = field_value
+
+    field_values['message'] = self._field_formatting_helper.GetFormattedField(
+        output_mediator, 'message', event, event_data, event_data_stream,
+        event_tag)
 
     if event_tag:
       event_tag_values = {
           '__container_type__': 'event_tag',
           '__type__': 'AttributeContainer'}
 
       for attribute_name, attribute_value in event_tag.GetAttributes():
```

### Comparing `plaso-20230311/plaso/output/shared_opensearch.py` & `plaso-20230717/plaso/output/shared_opensearch.py`

 * *Files 1% similar despite different names*

```diff
@@ -356,15 +356,17 @@
           continue
 
         if (isinstance(attribute_value, list) and attribute_value and
             isinstance(attribute_value[0],
                        dfdatetime_interface.DateTimeValues)):
           continue
 
-        event_values[attribute_name] = attribute_value
+        # Ignore protected internal only attributes.
+        if attribute_name[0] != '_':
+          event_values[attribute_name] = attribute_value
 
     if event_data_stream:
       for attribute_name, attribute_value in event_data_stream.GetAttributes():
         event_values[attribute_name] = attribute_value
 
     for attribute_name in self._field_names:
       if attribute_name not in event_values:
```

### Comparing `plaso-20230311/plaso/output/text_file.py` & `plaso-20230717/plaso/output/text_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/output/tln.py` & `plaso-20230717/plaso/output/tln.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,15 +19,16 @@
       'description': '_FormatDescription',
       'host': '_FormatHostname',
       'inode': '_FormatInode',
       'notes': '_FormatNotes',
       'source': '_FormatSourceShort',
       'time': '_FormatTimestamp',
       'tz': '_FormatTimeZone',
-      'user': '_FormatUsername'}
+      'user': '_FormatUsername',
+      'values': '_FormatValues'}
 
   # The field format callback methods require specific arguments hence
   # the check for unused arguments is disabled here.
   # pylint: disable=unused-argument
 
   def _FormatDescription(
       self, output_mediator, event, event_data, event_data_stream):
@@ -38,18 +39,14 @@
           modules and other components, such as storage and dfVFS.
       event (EventObject): event.
       event_data (EventData): event data.
       event_data_stream (EventDataStream): event data stream.
 
     Returns:
       str: description field.
-
-    Raises:
-      NoFormatterFound: If no event formatter can be found to match the data
-          type in the event data.
     """
     date_time_string = self._FormatDateTime(
         output_mediator, event, event_data, event_data_stream)
     timestamp_description = event.timestamp_desc or 'UNKNOWN'
 
     message = self._FormatMessage(
         output_mediator, event, event_data, event_data_stream)
```

### Comparing `plaso-20230311/plaso/output/winevt_rc.py` & `plaso-20230717/plaso/output/winevt_rc.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 # -*- coding: utf-8 -*-
 """Windows EventLog resources database reader."""
 
 import collections
 import os
 import sqlite3
 
-from plaso.containers import artifacts
 from plaso.engine import path_helper
 from plaso.helpers.windows import languages
 from plaso.helpers.windows import resource_files
 from plaso.output import logger
 
 
 class Sqlite3DatabaseFile(object):
@@ -340,31 +339,28 @@
   DEFAULT_LCID = 0x0409
 
   # The maximum number of cached message strings
   _MAXIMUM_CACHED_MESSAGE_STRINGS = 32 * 1024
 
   _WINEVT_RC_DATABASE = 'winevt-rc.db'
 
-  def __init__(
-      self, storage_reader, data_location, lcid, environment_variables):
+  def __init__(self, storage_reader, data_location, lcid):
     """Initializes Windows EventLog resources helper.
 
     Args:
       storage_reader (StorageReader): storage reader.
       data_location (str): data location of the winevt-rc database.
       lcid (int): Windows Language Code Identifier (LCID).
-      environment_variables (list[EnvironmentVariableArtifact]): environment
-          variable artifacts.
     """
     language_tag = languages.WindowsLanguageHelper.GetLanguageTagForLCID(
         lcid or self.DEFAULT_LCID)
 
     super(WinevtResourcesHelper, self).__init__()
     self._data_location = data_location
-    self._environment_variables = environment_variables or None
+    self._environment_variables = None
     self._language_tag = language_tag.lower()
     self._lcid = lcid or self.DEFAULT_LCID
     self._message_string_cache = collections.OrderedDict()
     self._storage_reader = storage_reader
     self._windows_eventlog_message_files = None
     self._windows_eventlog_providers = None
     self._winevt_database_reader = None
@@ -408,14 +404,15 @@
       log_source (str): EventLog source, such as "Application Error".
       message_identifier (int): message identifier.
       event_version (int): event version or None if not set.
 
     Returns:
       str: message string or None if not available.
     """
+    lookup_key = None
     message_string = None
 
     if provider_identifier:
       lookup_key = '{0:s}:0x{1:08x}'.format(
           provider_identifier, message_identifier)
       if event_version is not None:
         lookup_key = '{0:s}:{1:d}'.format(lookup_key, event_version)
@@ -481,25 +478,25 @@
 
   def _ReadEnvironmentVariables(self, storage_reader):
     """Reads the environment variables.
 
     Args:
       storage_reader (StorageReader): storage reader.
     """
-    # TODO: read environment variables from storage reader.
-    _ = storage_reader
-    self._environment_variables = [artifacts.EnvironmentVariableArtifact(
-        case_sensitive=False, name='SystemRoot', value='C:\\Windows')]
+    # TODO: get environment variables related to the source.
+    self._environment_variables = list(storage_reader.GetAttributeContainers(
+        'environment_variable'))
 
   def _ReadWindowsEventLogMessageFiles(self, storage_reader):
     """Reads the Windows EventLog message files.
 
     Args:
       storage_reader (StorageReader): storage reader.
     """
+    # TODO: get windows eventlog message files related to the source.
     self._windows_eventlog_message_files = {}
     if storage_reader.HasAttributeContainers('windows_eventlog_message_file'):
       for message_file in storage_reader.GetAttributeContainers(
           'windows_eventlog_message_file'):
         path, filename = path_helper.PathHelper.GetWindowsSystemPath(
             message_file.path, self._environment_variables)
 
@@ -622,14 +619,15 @@
 
   def _ReadWindowsEventLogProviders(self, storage_reader):
     """Reads the Windows EventLog providers.
 
     Args:
       storage_reader (StorageReader): storage reader.
     """
+    # TODO: get windows eventlog providers to the source.
     self._windows_eventlog_providers = {}
     if storage_reader.HasAttributeContainers('windows_eventlog_provider'):
       for provider in storage_reader.GetAttributeContainers(
           'windows_eventlog_provider'):
 
         if provider.identifier:
           self._windows_eventlog_providers[provider.identifier] = provider
@@ -650,14 +648,15 @@
 
     Returns:
       str: message string or None if not available.
     """
     message_string = self._GetCachedMessageString(
         provider_identifier, log_source, message_identifier, event_version)
     if not message_string:
+      # TODO: change this logic.
       if self._storage_reader and self._storage_reader.HasAttributeContainers(
           'windows_eventlog_provider'):
         message_string = self._ReadWindowsEventLogMessageString(
             self._storage_reader, provider_identifier, log_source,
             message_identifier, event_version)
       else:
         message_string = self._GetWinevtRcDatabaseMessageString(
```

### Comparing `plaso-20230311/plaso/output/xlsx.py` & `plaso-20230717/plaso/output/xlsx.py`

 * *Files 1% similar despite different names*

```diff
@@ -66,15 +66,15 @@
       datetime.datetime|str: date and time value or a string containing
           "ERROR" on OverflowError.
     """
     try:
       datetime_object = datetime.datetime(
           1970, 1, 1, 0, 0, 0, 0, tzinfo=pytz.UTC)
       datetime_object += datetime.timedelta(microseconds=event.timestamp)
-      datetime_object.astimezone(output_mediator.timezone)
+      datetime_object.astimezone(output_mediator.time_zone)
 
       return datetime_object.replace(tzinfo=None)
 
     except (OSError, OverflowError, TypeError, ValueError) as exception:
       self._ReportEventError(event, event_data, (
           'unable to copy timestamp: {0!s} to a human readable date and time '
           'with error: {1!s}. Defaulting to: "ERROR"').format(
```

### Comparing `plaso-20230311/plaso/parsers/__init__.py` & `plaso-20230717/plaso/parsers/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,33 +21,37 @@
 from plaso.parsers import locate
 from plaso.parsers import macos_keychain
 from plaso.parsers import mcafeeav
 from plaso.parsers import msiecf
 from plaso.parsers import networkminer
 from plaso.parsers import ntfs
 from plaso.parsers import olecf
+from plaso.parsers import onedrive
 from plaso.parsers import opera
 from plaso.parsers import pe
 from plaso.parsers import plist
 from plaso.parsers import pls_recall
 from plaso.parsers import recycler
 from plaso.parsers import safari_cookies
 from plaso.parsers import spotlight_storedb
 from plaso.parsers import sqlite
 from plaso.parsers import symantec
 from plaso.parsers import systemd_journal
 from plaso.parsers import text_parser
 from plaso.parsers import trendmicroav
+from plaso.parsers import unified_logging
 from plaso.parsers import utmp
 from plaso.parsers import utmpx
+from plaso.parsers import wincc
 from plaso.parsers import windefender_history
 from plaso.parsers import winevt
 from plaso.parsers import winevtx
 from plaso.parsers import winjob
 from plaso.parsers import winlnk
+from plaso.parsers import winpca
 from plaso.parsers import winprefetch
 from plaso.parsers import winreg_parser
 from plaso.parsers import winrestore
 
 # Register parser plugins.
 from plaso.parsers import bencode_plugins
 from plaso.parsers import czip_plugins
```

### Comparing `plaso-20230311/plaso/parsers/android_app_usage.py` & `plaso-20230717/plaso/parsers/android_app_usage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/asl.py` & `plaso-20230717/plaso/parsers/asl.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/asl.yaml` & `plaso-20230717/plaso/parsers/asl.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/bencode_parser.py` & `plaso-20230717/plaso/parsers/bencode_parser.py`

 * *Files 5% similar despite different names*

```diff
@@ -163,35 +163,33 @@
     Raises:
       WrongParser: when the file cannot be parsed.
     """
     header_data = file_object.read(2)
     if not self._BENCODE_RE.match(header_data):
       raise errors.WrongParser('Not a valid Bencoded file.')
 
+    display_name = parser_mediator.GetDisplayName()
     bencode_file = BencodeFile()
 
     try:
       bencode_file.Open(file_object)
     except IOError as exception:
-      display_name = parser_mediator.GetDisplayName()
       raise errors.WrongParser(
           '[{0:s}] unable to parse file: {1:s} with error: {2!s}'.format(
               self.NAME, display_name, exception))
 
     if bencode_file.IsEmpty():
       parser_mediator.ProduceExtractionWarning('missing decoded Bencode values')
       return
 
     try:
       for plugin_name, plugin in self._plugins_per_name.items():
         if parser_mediator.abort:
           break
 
-        file_entry = parser_mediator.GetFileEntry()
-        display_name = parser_mediator.GetDisplayName(file_entry)
         profiling_name = '/'.join([self.NAME, plugin.NAME])
 
         parser_mediator.SampleFormatCheckStartTiming(profiling_name)
 
         try:
           result = plugin.CheckRequiredKeys(bencode_file)
         finally:
```

### Comparing `plaso-20230311/plaso/parsers/bencode_plugins/interface.py` & `plaso-20230717/plaso/parsers/bencode_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/bencode_plugins/transmission.py` & `plaso-20230717/plaso/parsers/bencode_plugins/transmission.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/bencode_plugins/utorrent.py` & `plaso-20230717/plaso/parsers/bencode_plugins/utorrent.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/bodyfile.py` & `plaso-20230717/plaso/parsers/bodyfile.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/bsm.py` & `plaso-20230717/plaso/parsers/bsm.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/bsm.yaml` & `plaso-20230717/plaso/parsers/bsm.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/chrome_cache.py` & `plaso-20230717/plaso/parsers/chrome_cache.py`

 * *Files 2% similar despite different names*

```diff
@@ -135,18 +135,17 @@
     except (ValueError, errors.ParseError) as exception:
       raise errors.ParseError(
           'Unable to parse index file header with error: {0!s}'.format(
               exception))
 
     format_version = '{0:d}.{1:d}'.format(
         file_header.major_version, file_header.minor_version)
-    if format_version not in ('2.0', '2.1'):
+    if format_version not in ('2.0', '2.1', '3.0'):
       raise errors.ParseError(
           'Unsupported index file format version: {0:s}'.format(format_version))
-
     self.creation_time = file_header.creation_time
 
   def _ParseIndexTable(self, file_object):
     """Parses the index table.
 
     Args:
       file_object (dfvfs.FileIO): a file-like object to parse.
@@ -359,15 +358,24 @@
               'Unable to parse cache entry with error: {0!s}'.format(
                   exception))
           break
 
         event_data = ChromeCacheEntryEventData()
         event_data.creation_time = dfdatetime_webkit_time.WebKitTime(
             timestamp=cache_entry.creation_time)
-        event_data.original_url = cache_entry.original_url
+
+        # In Chrome Cache v3, doublekey-ing cache entries was introduced
+        # This shows up as r"_dk_{domain}( {domain})* {url}"
+        # https://chromium.googlesource.com/chromium/src/+/
+        # 95faad3cfd90169f0a267e979c36e3348476a948/net/http/http_cache.cc#427
+        if "_dk_" in cache_entry.original_url[:20]:
+          parsed_url = cache_entry.original_url.strip().rsplit(' ', 1)[-1]
+          event_data.original_url = parsed_url
+        else:
+          event_data.original_url = cache_entry.original_url
 
         parser_mediator.ProduceEventData(event_data)
 
         cache_address = cache_entry.next
         cache_address_chain_length += 1
 
   def _ParseIndexTable(
@@ -427,17 +435,15 @@
                 parser_mediator, data_block_file_object)
           except (IOError, errors.ParseError) as exception:
             message = (
                 'Unable to parse data block file: {0:s} with error: '
                 '{1!s}').format(cache_address.filename, exception)
             parser_mediator.ProduceExtractionWarning(message)
             data_block_file_object = None
-
         data_block_files[cache_address.filename] = data_block_file_object
-
     self._ParseCacheEntries(parser_mediator, index_table, data_block_files)
 
   @classmethod
   def GetFormatSpecification(cls):
     """Retrieves the format specification.
 
     Returns:
```

### Comparing `plaso-20230311/plaso/parsers/chrome_cache.yaml` & `plaso-20230717/plaso/parsers/chrome_cache.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/chrome_preferences.py` & `plaso-20230717/plaso/parsers/chrome_preferences.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/cookie_plugins/ganalytics.py` & `plaso-20230717/plaso/parsers/cookie_plugins/ganalytics.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/cookie_plugins/interface.py` & `plaso-20230717/plaso/parsers/cookie_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/cookie_plugins/manager.py` & `plaso-20230717/plaso/parsers/cookie_plugins/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/cups_ipp.py` & `plaso-20230717/plaso/parsers/cups_ipp.py`

 * *Files 1% similar despite different names*

```diff
@@ -98,14 +98,16 @@
 
   _DELIMITER_TAGS = frozenset([
       _DELIMITER_TAG_OPERATION_ATTRIBUTES,
       _DELIMITER_TAG_JOB_ATTRIBUTES,
       _DELIMITER_TAG_PRINTER_ATTRIBUTES,
       _DELIMITER_TAG_UNSUPPORTED_ATTRIBUTES])
 
+  _TAG_VALUE_NONE = 0x13
+
   _TAG_VALUE_INTEGER = 0x21
   _TAG_VALUE_BOOLEAN = 0x22
   _TAG_VALUE_ENUM = 0x23
 
   _TAG_VALUE_DATE_TIME = 0x31
   _TAG_VALUE_RESOLUTION = 0x32
 
@@ -190,16 +192,18 @@
     try:
       attribute, _ = self._ReadStructureFromFileObject(
           file_object, file_offset, attribute_map)
     except (ValueError, errors.ParseError) as exception:
       raise errors.ParseError(
           'Unable to parse attribute with error: {0!s}'.format(exception))
 
-    value = None
-    if attribute.tag_value in self._INTEGER_TAG_VALUES:
+    if attribute.tag_value == self._TAG_VALUE_NONE:
+      value = None
+
+    elif attribute.tag_value in self._INTEGER_TAG_VALUES:
       # TODO: correct file offset to point to the start of value_data.
       value = self._ParseIntegerValue(attribute.value_data, file_offset)
 
     elif attribute.tag_value == self._TAG_VALUE_BOOLEAN:
       value = self._ParseBooleanValue(attribute.value_data)
 
     elif attribute.tag_value == self._TAG_VALUE_DATE_TIME:
@@ -377,14 +381,17 @@
     self._ParseHeader(parser_mediator, file_object)
 
     cupp_ipp_values = {}
     is_first_attribute_group = True
 
     try:
       for name, value in self._ParseAttributesGroup(file_object):
+        if value is None:
+          continue
+
         name = self._ATTRIBUTE_NAME_TRANSLATION.get(name, name)
 
         cupp_ipp_values.setdefault(name, []).append(value)
 
         is_first_attribute_group = False
 
     except (ValueError, errors.ParseError) as exception:
```

### Comparing `plaso-20230311/plaso/parsers/cups_ipp.yaml` & `plaso-20230717/plaso/parsers/cups_ipp.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/custom_destinations.py` & `plaso-20230717/plaso/parsers/custom_destinations.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/custom_destinations.yaml` & `plaso-20230717/plaso/parsers/custom_destinations.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/czip.py` & `plaso-20230717/plaso/parsers/czip.py`

 * *Files 3% similar despite different names*

```diff
@@ -50,16 +50,14 @@
           '[{0:s}] unable to parse file: {1:s} with error: {2!s}'.format(
               self.NAME, display_name, exception))
 
     for plugin_name, plugin in self._plugins_per_name.items():
       if parser_mediator.abort:
         break
 
-      file_entry = parser_mediator.GetFileEntry()
-      display_name = parser_mediator.GetDisplayName(file_entry)
       profiling_name = '/'.join([self.NAME, plugin.NAME])
 
       parser_mediator.SampleFormatCheckStartTiming(profiling_name)
 
       try:
         result = plugin.CheckRequiredPaths(zip_file)
       finally:
```

### Comparing `plaso-20230311/plaso/parsers/czip_plugins/interface.py` & `plaso-20230717/plaso/parsers/czip_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/czip_plugins/oxml.py` & `plaso-20230717/plaso/parsers/czip_plugins/oxml.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/detection_history.yaml` & `plaso-20230717/plaso/parsers/windefender_history.yaml`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # dtFabric format specification.
 ---
-name: detection_history
+name: windefender_history
 type: format
 description: Windows Defender scan DetectionHistory file format
 urls: ["https://github.com/libyal/dtformats/blob/main/documentation/Windows%20Defender%20scan%20DetectionHistory%20file%20format.asciidoc"]
 ---
 name: byte
 type: integer
 attributes:
```

### Comparing `plaso-20230311/plaso/parsers/dsv_parser.py` & `plaso-20230717/plaso/parsers/dsv_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -88,15 +88,15 @@
 
     The line reader is advanced to the beginning of the DSV content, skipping
     any header lines.
 
     Args:
       file_object (dfvfs.FileIO): file-like object.
       encoding (Optional[str]): encoding used in the DSV file, where None
-          indicates the codepage of the parser mediator should be used.
+          indicates the code page of the parser mediator should be used.
 
     Returns:
       TextFile: an object that implements an iterator over lines in a text file.
 
     Raises:
       UnicodeDecodeError: if the file cannot be read with the specified
           encoding.
@@ -124,15 +124,15 @@
     As we know the maximum length of valid lines in the DSV file, the presence
     of lines longer than this indicates that the file will not be parsed
     successfully, without reading excessive data from a large file.
 
     Args:
       file_object (dfvfs.FileIO): file-like object.
       encoding (Optional[str]): encoding used in the DSV file, where None
-          indicates the codepage of the parser mediator should be used.
+          indicates the code page of the parser mediator should be used.
 
     Returns:
       bool: True if the file has lines of the expected length.
     """
     original_file_position = file_object.tell()
     result = True
 
@@ -209,18 +209,17 @@
 
     if encoding and self._encoding and encoding != self._encoding:
       display_name = parser_mediator.GetDisplayName()
       raise errors.WrongParser((
           '[{0:s}] Unable to parse DSV file: {1:s} encoding does not match the '
           'one required by the parser.').format(self._encoding, display_name))
 
+    encoding = self._encoding
     if not encoding:
-      # Fallback to UTF-8 as a last resort otherwise the creation of
-      # text_file.TextFile will fail if no encoding is set.
-      encoding = self._encoding or parser_mediator.codepage or 'utf-8'
+      encoding = parser_mediator.GetCodePage()
 
     file_object.seek(text_offset, os.SEEK_SET)
 
     try:
       if not self._HasExpectedLineLength(file_object, encoding=encoding):
         display_name = parser_mediator.GetDisplayName()
         raise errors.WrongParser((
```

### Comparing `plaso-20230311/plaso/parsers/esedb.py` & `plaso-20230717/plaso/parsers/esedb.py`

 * *Files 2% similar despite different names*

```diff
@@ -110,23 +110,23 @@
     try:
       database.Open(file_object)
     except (IOError, ValueError) as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to open file with error: {0!s}'.format(exception))
       return
 
+    display_name = parser_mediator.GetDisplayName()
+
     # Compare the list of available plugin objects.
     cache = ESEDBCache()
     try:
       for plugin_name, plugin in self._plugins_per_name.items():
         if parser_mediator.abort:
           break
 
-        file_entry = parser_mediator.GetFileEntry()
-        display_name = parser_mediator.GetDisplayName(file_entry)
         profiling_name = '/'.join([self.NAME, plugin.NAME])
 
         parser_mediator.SampleFormatCheckStartTiming(profiling_name)
 
         try:
           result = plugin.CheckRequiredTables(database)
         finally:
```

### Comparing `plaso-20230311/plaso/parsers/esedb_plugins/file_history.py` & `plaso-20230717/plaso/parsers/esedb_plugins/file_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/esedb_plugins/interface.py` & `plaso-20230717/plaso/parsers/esedb_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/esedb_plugins/msie_webcache.py` & `plaso-20230717/plaso/parsers/esedb_plugins/msie_webcache.py`

 * *Files 17% similar despite different names*

```diff
@@ -86,14 +86,47 @@
     self.request_headers = None
     self.response_headers = None
     self.synchronization_count = None
     self.synchronization_time = None
     self.url = None
 
 
+class MsieWebCacheCookieData(events.EventData):
+  """MSIE WebCache Container table event data.
+
+  Attributes:
+    container_identifier (int): container identifier.
+    cookie_hash (str): a similarity hash of the cookie contents
+    cookie_name (str): name of the cookie
+    cookie_value_raw (str): raw value of cookie in hex
+    cookie_value (str): value of the cookie encoded in ascii
+    entry_identifier (int): entry identifier.
+    expiration_time (dfdatetime.DateTimeValues): expiration date and time.
+    flags (int): an representation of cookie flags
+    modification_time (dfdatetime.DateTimeValues): modification date and time.
+    request_domain (str): Request domain for which the cookie was set.
+  """
+
+  DATA_TYPE = 'msie:webcache:cookie'
+
+  def __init__(self):
+    """Initializes event data."""
+    super(MsieWebCacheCookieData, self).__init__(data_type=self.DATA_TYPE)
+    self.container_identifier = None
+    self.cookie_hash = None
+    self.cookie_name = None
+    self.cookie_value = None
+    self.cookie_value_raw = None
+    self.entry_identifier = None
+    self.expiration_time = None
+    self.flags = None
+    self.modification_time = None
+    self.request_domain = None
+
+
 class MsieWebCacheLeakFilesEventData(events.EventData):
   """MSIE WebCache LeakFiles event data.
 
   Attributes:
     cached_filename (str): name of the cached file.
     creation_time (dfdatetime.DateTimeValues): creation date and time.
     leak_identifier (int): leak identifier.
@@ -181,15 +214,15 @@
 
     return None
 
   def _GetDateTimeValue(self, record_values, value_name):
     """Retrieves a date and time record value.
 
     Args:
-      record_values (dict[str,object]): values per column name.
+      record_values (dict[str, object]): values per column name.
       value_name (str): name of the record value.
 
     Returns:
       dfdatetime.DateTimeValues: date and time or None if not set.
     """
     filetime = record_values.get(value_name, None)
     if not filetime:
@@ -274,14 +307,91 @@
         event_data.synchronization_count = record_values.get('SyncCount', None)
         event_data.synchronization_time = self._GetDateTimeValue(
             record_values, 'SyncTime')
         event_data.url = url
 
         parser_mediator.ProduceEventData(event_data)
 
+  def _CookieHexToAscii(self, raw_cookie):
+    """Translates a cookie from a binary string to a string.
+
+    Args:
+      raw_cookie (bytes): the raw binary string of a cookie field.
+
+    Returns:
+      str: the decoded binary string or None if not available.
+    """
+    if raw_cookie is not None:
+      try:
+        string_value = raw_cookie.decode('utf-8')
+        return string_value.rstrip('\x00')
+      except UnicodeDecodeError:
+        pass
+
+    return None
+
+  def GetRawCookieValue(self, record_values, value_name):
+    """Retrieves the binary string as a hexadecimal formatted string.
+      
+    Args:
+      record_values (dict[str, object]): values per column name.
+      value_name (str): the name of the value we are converting
+
+    Returns:
+      str: the hexadecimal formatted binary string or None if not available.
+    """
+    cookie_hash = record_values.get(value_name, None)
+    if cookie_hash is not None:
+      return cookie_hash.hex()
+    return None
+
+  def _ParseCookieExTable(self, parser_mediator, table):
+    """Parses a CookieEntryEx_# table.
+
+    Args:
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
+      table (pyesedb.table): table.
+      container_name (str): container name, which indicates the table type.
+    """
+    for record_index, esedb_record in enumerate(table.records):
+      if parser_mediator.abort:
+        break
+
+      try:
+        record_values = self._GetRecordValues(
+            parser_mediator, table.name, record_index, esedb_record)
+
+      except UnicodeDecodeError:
+        parser_mediator.ProduceExtractionWarning((
+            'Unable to retrieve record values from record: {0:d} '
+            'in table: {1:s}').format(record_index, table.name))
+        continue
+
+      cookie_name = self._CookieHexToAscii(record_values.get('Name', None))
+      cookie_value = self._CookieHexToAscii(record_values.get('Value', None))
+
+      cookie_hash = self.GetRawCookieValue(record_values, 'CookieHash')
+      cookie_value_raw = self.GetRawCookieValue(record_values, 'Value')
+
+      event_data = MsieWebCacheCookieData()
+      event_data.container_identifier = record_values.get('ContainerId', None)
+      event_data.cookie_hash = cookie_hash
+      event_data.cookie_name = cookie_name
+      event_data.cookie_value_raw = cookie_value_raw
+      event_data.cookie_value = cookie_value
+      event_data.entry_identifier = record_values.get('EntryId', None)
+      event_data.flags = record_values.get('Flags', None)
+      event_data.expiration_time = self._GetDateTimeValue(
+          record_values, 'Expires')
+      event_data.modification_time = self._GetDateTimeValue(
+          record_values, 'LastModified')
+      event_data.request_domain = record_values.get('RDomain', None)
+      parser_mediator.ProduceEventData(event_data)
+
   def ParseContainersTable(
       self, parser_mediator, database=None, table=None, **unused_kwargs):
     """Parses a Containers table.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
@@ -328,14 +438,18 @@
                 container_identifier, container_name))
         continue
 
       table_name = 'Container_{0:d}'.format(container_identifier)
       esedb_table = database.GetTableByName(table_name)
       if esedb_table:
         self._ParseContainerTable(parser_mediator, esedb_table, container_name)
+      cookie_table_name = 'CookieEntryEx_{0:d}'.format(container_identifier)
+      cookie_table = database.GetTableByName(cookie_table_name)
+      if cookie_table.name==cookie_table_name:
+        self._ParseCookieExTable(parser_mediator, cookie_table)
 
   def ParseLeakFilesTable(
       self, parser_mediator, database=None, table=None, **unused_kwargs):
     """Parses a LeakFiles table.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
```

### Comparing `plaso-20230311/plaso/parsers/esedb_plugins/srum.py` & `plaso-20230717/plaso/parsers/esedb_plugins/srum.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/esedb_plugins/types.yaml` & `plaso-20230717/plaso/parsers/esedb_plugins/types.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/esedb_plugins/user_access_logging.py` & `plaso-20230717/plaso/parsers/esedb_plugins/user_access_logging.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/filestat.py` & `plaso-20230717/plaso/parsers/filestat.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/firefox_cache.py` & `plaso-20230717/plaso/parsers/firefox_cache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/firefox_cache.yaml` & `plaso-20230717/plaso/parsers/firefox_cache.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/fish_history.py` & `plaso-20230717/plaso/parsers/fish_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/fseventsd.py` & `plaso-20230717/plaso/parsers/fseventsd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/fseventsd.yaml` & `plaso-20230717/plaso/parsers/fseventsd.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/interface.py` & `plaso-20230717/plaso/parsers/interface.py`

 * *Files 13% similar despite different names*

```diff
@@ -225,18 +225,19 @@
     return cls._plugin_classes is not None
 
 
 class FileEntryParser(BaseParser):
   """The file entry parser interface."""
 
   def Parse(self, parser_mediator):
-    """Parses the file entry and extracts event objects.
+    """Parses a file entry.
 
     Args:
-      parser_mediator (ParserMediator): a parser mediator.
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
 
     Raises:
       WrongParser: when the file cannot be parsed.
     """
     file_entry = parser_mediator.GetFileEntry()
     if not file_entry:
       raise errors.WrongParser('Invalid file entry')
@@ -255,15 +256,16 @@
       parser_mediator.PopFromParserChain()
 
   @abc.abstractmethod
   def ParseFileEntry(self, parser_mediator, file_entry):
     """Parses a file entry.
 
     Args:
-      parser_mediator (ParserMediator): a parser mediator.
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
       file_entry (dfvfs.FileEntry): a file entry to parse.
 
     Raises:
       WrongParser: when the file cannot be parsed.
     """
 
 
@@ -282,15 +284,16 @@
   # file size check needs to be performed.
   _MINIMUM_FILE_SIZE = None
 
   def Parse(self, parser_mediator, file_object):
     """Parses a single file-like object.
 
     Args:
-      parser_mediator (ParserMediator): a parser mediator.
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): a file-like object to parse.
 
     Raises:
       WrongParser: when the file cannot be parsed.
     """
     if not file_object:
       raise errors.WrongParser('Invalid file object')
@@ -328,13 +331,14 @@
       parser_mediator.PopFromParserChain()
 
   @abc.abstractmethod
   def ParseFileObject(self, parser_mediator, file_object):
     """Parses a file-like object.
 
     Args:
-      parser_mediator (ParserMediator): a parser mediator.
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): a file-like object to parse.
 
     Raises:
       WrongParser: when the file cannot be parsed.
     """
```

### Comparing `plaso-20230311/plaso/parsers/java_idx.py` & `plaso-20230717/plaso/parsers/java_idx.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/java_idx.yaml` & `plaso-20230717/plaso/parsers/java_idx.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_parser.py` & `plaso-20230717/plaso/parsers/jsonl_parser.py`

 * *Files 3% similar despite different names*

```diff
@@ -31,19 +31,22 @@
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): a file-like object.
 
     Raises:
       WrongParser: when the file cannot be parsed.
     """
+    encoding = self._ENCODING
+    if not encoding:
+      encoding = parser_mediator.GetCodePage()
+
     # Use strict encoding error handling in the verification step so that
     # a JSON-L parser does not generate extraction warning for encoding errors
     # of unsupported files.
-    text_file_object = text_file.TextFile(
-        file_object, encoding=self._ENCODING or parser_mediator.codepage)
+    text_file_object = text_file.TextFile(file_object, encoding=encoding)
 
     try:
       line = text_file_object.readline(size=self._MAXIMUM_LINE_LENGTH)
     except UnicodeDecodeError:
       raise errors.WrongParser('Not a JSON-L file or encoding not supported.')
 
     if not line:
```

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/__init__.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/__init__.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/aws_cloudtrail_log.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/aws_cloudtrail_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/azure_activity_log.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/azure_activity_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/azure_application_gateway_log.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/azure_application_gateway_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/docker_container_config.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/docker_container_config.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/docker_container_log.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/docker_container_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/docker_layer_config.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/docker_layer_config.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/gcp_log.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/gcp_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/interface.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/ios_app_privacy.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/ios_app_privacy.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/jsonl_plugins/microsoft365_audit_log.py` & `plaso-20230717/plaso/parsers/jsonl_plugins/microsoft365_audit_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/locate.py` & `plaso-20230717/plaso/parsers/locate.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/locate.yaml` & `plaso-20230717/plaso/parsers/locate.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/macos_keychain.py` & `plaso-20230717/plaso/parsers/macos_keychain.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/macos_keychain.yaml` & `plaso-20230717/plaso/parsers/macos_keychain.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/manager.py` & `plaso-20230717/plaso/parsers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/mcafeeav.py` & `plaso-20230717/plaso/parsers/mcafeeav.py`

 * *Files 1% similar despite different names*

```diff
@@ -51,14 +51,16 @@
   DATA_FORMAT = 'McAfee Anti-Virus access protection log file'
 
   DELIMITER = '\t'
   COLUMNS = [
       'date', 'time', 'status', 'username', 'filename',
       'trigger_location', 'rule', 'action']
 
+  _ENCODING = 'utf-8'
+
   _NUMBER_OF_COLUMNS = len(COLUMNS)
 
   def _CreateDateTime(self, date_string, time_string):
     """Creates a date time value from the date time strings.
 
     The format stores the date and time as 2 separate strings separated by
     a tab. The time is in local time. The month and day can be either 1 or 2
```

### Comparing `plaso-20230311/plaso/parsers/mediator.py` & `plaso-20230717/plaso/parsers/mediator.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,124 +1,103 @@
 # -*- coding: utf-8 -*-
 """The parser mediator."""
 
 import collections
 import datetime
 import time
 
-import pytz
-
 from plaso.containers import artifacts
 from plaso.containers import events
 from plaso.containers import warnings
 from plaso.engine import path_helper
 from plaso.engine import profilers
 from plaso.helpers import language_tags
 from plaso.helpers.windows import languages
 
 
 class ParserMediator(object):
   """Parser mediator.
 
   Attributes:
-    collection_filters_helper (CollectionFiltersHelper): collection filters
-        helper.
     last_activity_timestamp (int): timestamp received that indicates the last
         time activity was observed. The last activity timestamp is updated
         when the mediator produces an attribute container, such as an event
         source. This timestamp is used by the multi processing worker process
         to indicate the last time the worker was known to be active. This
         information is then used by the foreman to detect workers that are
         not responding (stalled).
     parsers_counter (collections.Counter): number of events per parser or
         parser plugin.
+    registry_find_specs (list[dfwinreg.FindSpec]): Windows Registry find
+        specifications.
   """
 
-  _DEFAULT_LANGUAGE_TAG = 'en-US'
+  _DEFAULT_CODE_PAGE = 'cp1252'
+
+  _DEFAULT_LANGUAGE_TAG = 'en-US'.lower()
 
   # LCID 0x0409 is en-US.
   _DEFAULT_LCID = 0x0409
 
-  _DEFAULT_TIME_ZONE = pytz.UTC
-
-  _INT64_MIN = -1 << 63
-  _INT64_MAX = (1 << 63) - 1
-
   def __init__(
-      self, knowledge_base, collection_filters_helper=None,
-      resolver_context=None):
+      self, registry_find_specs=None, resolver_context=None,
+      system_configurations=None):
     """Initializes a parser mediator.
 
     Args:
-      knowledge_base (KnowledgeBase): contains information from the source
-          data needed for parsing.
-      collection_filters_helper (Optional[CollectionFiltersHelper]): collection
-          filters helper.
+      registry_find_specs (Optional[list[dfwinreg.FindSpec]]): Windows Registry
+          find specifications.
       resolver_context (Optional[dfvfs.Context]): resolver context.
+      system_configurations (Optional[list[SystemConfigurationArtifact]]):
+          system configurations.
     """
     super(ParserMediator, self).__init__()
     self._abort = False
     self._cached_parser_chain = None
+    self._environment_variables_per_path_spec = None
     self._event_data_stream = None
     self._event_data_stream_identifier = None
     self._extract_winevt_resources = True
     self._file_entry = None
     self._format_checks_cpu_time_profiler = None
-    self._knowledge_base = knowledge_base
-    self._language_tag = self._DEFAULT_LANGUAGE_TAG
+    self._language_tag = None
     self._last_event_data_hash = None
     self._last_event_data_identifier = None
-    self._lcid = self._DEFAULT_LCID
+    self._lcid = None
     self._number_of_event_data = 0
     self._number_of_event_sources = 0
     self._number_of_extraction_warnings = 0
     self._number_of_recovery_warnings = 0
     self._parser_chain_components = []
     self._parsers_cpu_time_profiler = None
     self._parsers_memory_profiler = None
-    self._preferred_codepage = None
+    self._preferred_code_page = None
     self._process_information = None
     self._resolver_context = resolver_context
     self._storage_writer = None
     self._temporary_directory = None
-    self._time_zone = None
     self._windows_event_log_providers_per_path = None
 
-    self.collection_filters_helper = collection_filters_helper
+    self.registry_find_specs = registry_find_specs
     self.last_activity_timestamp = 0.0
     self.parsers_counter = collections.Counter()
 
+    self._CreateEnvironmentVariablesPerPathSpec(system_configurations)
+
   @property
   def abort(self):
     """bool: True if parsing should be aborted."""
     return self._abort
 
   @property
-  def codepage(self):
-    """str: preferred codepage in lower case."""
-    if not self._preferred_codepage:
-      self._preferred_codepage = self._knowledge_base.codepage.lower()
-    return self._preferred_codepage
-
-  @property
   def extract_winevt_resources(self):
     """bool: extract Windows EventLog resources."""
     return self._extract_winevt_resources
 
   @property
-  def language(self):
-    """str: language tag in lower case."""
-    if not self._language_tag:
-      language_tag = (
-          self._knowledge_base.language.lower() or self._DEFAULT_LANGUAGE_TAG)
-      self._language_tag = language_tag.lower()
-
-    return self._language_tag
-
-  @property
   def number_of_produced_event_data(self):
     """int: number of produced event data."""
     return self._number_of_event_data
 
   @property
   def number_of_produced_event_sources(self):
     """int: number of produced event sources."""
@@ -135,21 +114,42 @@
     return self._resolver_context
 
   @property
   def temporary_directory(self):
     """str: path of the directory for temporary files."""
     return self._temporary_directory
 
-  @property
-  def timezone(self):
-    """datetime.tzinfo: timezone."""
-    if not self._time_zone:
-      self._time_zone = self._knowledge_base.timezone or self._DEFAULT_TIME_ZONE
+  def _CreateEnvironmentVariablesPerPathSpec(self, system_configurations):
+    """Creates the environment variables per path specification lookup table.
+
+    Args:
+      system_configurations (list[SystemConfigurationArtifact]): system
+          configurations.
+    """
+    self._environment_variables_per_path_spec = {}
+    for system_configuration in system_configurations or []:
+      if system_configuration.environment_variables:
+        for path_spec in system_configuration.path_specs:
+          if path_spec.parent:
+            self._environment_variables_per_path_spec[path_spec.parent] = (
+                system_configuration.environment_variables)
+
+  def _GetEnvironmentVariablesByPathSpec(self, path_spec):
+    """Retrieves the environment variables for a specific path specification.
+
+    Args:
+      path_spec (dfvfs.PathSpec): path specification.
 
-    return self._time_zone
+    Returns:
+      list[EnvironmentVariableArtifact]: environment variables.
+    """
+    if not path_spec or not path_spec.parent:
+      return None
+
+    return self._environment_variables_per_path_spec.get(path_spec.parent, None)
 
   def AddYearLessLogHelper(self, year_less_log_helper):
     """Adds a year-less log helper.
 
     Args:
       year_less_log_helper (YearLessLogHelper): year-less log helper.
     """
@@ -205,32 +205,46 @@
 
     Args:
       path (str): Windows path with environment variables.
 
     Returns:
       str: expanded Windows path.
     """
-    environment_variables = self._knowledge_base.GetEnvironmentVariables()
+    path_spec = getattr(self._file_entry, 'path_spec', None)
+    environment_variables = self._GetEnvironmentVariablesByPathSpec(path_spec)
     return path_helper.PathHelper.ExpandWindowsPath(path, environment_variables)
 
+  def GetCodePage(self):
+    """Retrieves the code page related to the file entry.
+
+    Returns:
+      str: code page.
+    """
+    path_spec = getattr(self._file_entry, 'path_spec', None)
+    if path_spec:
+      # TODO: determine code page from system_configurations.
+      pass
+
+    return self._preferred_code_page or self._DEFAULT_CODE_PAGE
+
   def GetCurrentYear(self):
     """Retrieves current year.
 
     Returns:
       int: the current year.
     """
     datetime_object = datetime.datetime.now()
     return datetime_object.year
 
   def GetDisplayName(self, file_entry=None):
     """Retrieves the display name for a file entry.
 
     Args:
       file_entry (Optional[dfvfs.FileEntry]): file entry object, where None
-          will return the display name of self._file_entry.
+          will use the active file entry.
 
     Returns:
       str: human readable string that describes the path to the file entry.
 
     Raises:
       ValueError: if the file entry is missing.
     """
@@ -278,14 +292,27 @@
 
     data_stream = getattr(self._file_entry.path_spec, 'data_stream', None)
     if data_stream:
       return '{0:s}:{1:s}'.format(self._file_entry.name, data_stream)
 
     return self._file_entry.name
 
+  def GetLanguageTag(self):
+    """Retrieves the language tag related to the file entry.
+
+    Returns:
+      str: code page.
+    """
+    path_spec = getattr(self._file_entry, 'path_spec', None)
+    if path_spec:
+      # TODO: determine language tag from system_configurations.
+      pass
+
+    return self._language_tag or self._DEFAULT_LANGUAGE_TAG
+
   def GetParserChain(self):
     """Retrieves the current parser chain.
 
     Returns:
       str: parser chain.
     """
     if not self._cached_parser_chain:
@@ -295,19 +322,19 @@
   def GetRelativePath(self):
     """Retrieves the relative path of the current file entry.
 
     Returns:
       str: relative path of the current file entry or None if no current
           file entry.
     """
-    if self._file_entry is None:
+    path_spec = getattr(self._file_entry, 'path_spec', None)
+    if not path_spec:
       return None
 
-    return path_helper.PathHelper.GetRelativePathForPathSpec(
-        self._file_entry.path_spec)
+    return path_helper.PathHelper.GetRelativePathForPathSpec(path_spec)
 
   def GetRelativePathForPathSpec(self, path_spec):
     """Retrieves the relative path for a path specification.
 
     Args:
       path_spec (dfvfs.PathSpec): path specification.
 
@@ -320,19 +347,24 @@
     """Retrieves the Windows EventLog message file for a specific path.
 
     Returns:
       WindowsEventLogMessageFileArtifact: Windows EventLog message file or None
           if no current file entry or no Windows EventLog message file was
           found.
     """
-    if self._windows_event_log_providers_per_path is None:
+    path_spec = getattr(self._file_entry, 'path_spec', None)
+
+    if (self._windows_event_log_providers_per_path is None and
+        self._storage_writer):
+      environment_variables = self._GetEnvironmentVariablesByPathSpec(path_spec)
+
       self._windows_event_log_providers_per_path = {}
-      environment_variables = self._knowledge_base.GetEnvironmentVariables()
 
-      for provider in self._knowledge_base.GetWindowsEventLogProviders():
+      for provider in self._storage_writer.GetAttributeContainers(
+          'windows_eventlog_provider'):
         for windows_path in provider.event_message_files or []:
           path, filename = path_helper.PathHelper.GetWindowsSystemPath(
               windows_path, environment_variables)
           path = path.lower()
           filename = filename.lower()
 
           # Use the path prefix as the key to handle language specific EventLog
@@ -340,21 +372,21 @@
           if path not in self._windows_event_log_providers_per_path:
             self._windows_event_log_providers_per_path[path] = {}
 
           # Note that multiple providers can share EventLog message files.
           self._windows_event_log_providers_per_path[path][filename] = provider
 
     message_file = None
-    if self._file_entry:
+    if path_spec:
       relative_path = path_helper.PathHelper.GetRelativePathForPathSpec(
-          self._file_entry.path_spec)
+          path_spec)
       lookup_path = relative_path.lower()
 
       path_segment_separator = path_helper.PathHelper.GetPathSegmentSeparator(
-          self._file_entry.path_spec)
+          path_spec)
 
       lookup_path, _, lookup_filename = lookup_path.rpartition(
           path_segment_separator)
 
       # Language specific EventLog message file paths contain a language tag
       # such as "en-US".
       base_lookup_path, _, last_path_segment = lookup_path.rpartition(
@@ -568,73 +600,52 @@
 
   def SetFileEntry(self, file_entry):
     """Sets the active file entry.
 
     Args:
       file_entry (dfvfs.FileEntry): file entry.
     """
-    self._file_entry = file_entry
     self._event_data_stream = None
     self._event_data_stream_identifier = None
+    self._file_entry = file_entry
 
-  def SetPreferredCodepage(self, codepage):
-    """Sets the preferred codepage.
+  def SetPreferredCodepage(self, code_page):
+    """Sets the preferred code page.
 
     Args:
-      codepage (str): codepage.
+      code_page (str): code page.
     """
-    self._preferred_codepage = codepage
+    if code_page:
+      code_page = code_page.lower()
+    self._preferred_code_page = code_page
 
   def SetPreferredLanguage(self, language_tag):
     """Sets the preferred language.
 
     Args:
       language_tag (str): language tag such as "en-US" for US English or
           "is-IS" for Icelandic or None if the language determined by
           preprocessing or the default should be used.
 
     Raises:
       ValueError: if the language tag is not a string type or no LCID can
           be determined that corresponds with the language tag.
     """
     lcid = None
-    if language_tag is not None:
-      if not isinstance(language_tag, str):
-        raise ValueError('Language tag: {0!s} is not a string.'.format(
-            language_tag))
-
+    if language_tag:
       lcid = languages.WindowsLanguageHelper.GetLCIDForLanguageTag(language_tag)
       if not lcid:
         raise ValueError('No LCID found for language tag: {0:s}.'.format(
             language_tag))
 
+      language_tag = language_tag.lower()
+
     self._language_tag = language_tag
     self._lcid = lcid
 
-  def SetPreferredTimeZone(self, time_zone_string):
-    """Sets the preferred time zone for zone-less date and time values.
-
-    Args:
-      time_zone_string (str): time zone such as "Europe/Amsterdam" or None if
-          the time zone determined by preprocessing or the default should be
-          used.
-
-    Raises:
-      ValueError: if the time zone is not supported.
-    """
-    time_zone = None
-    if time_zone_string:
-      try:
-        time_zone = pytz.timezone(time_zone_string)
-      except pytz.UnknownTimeZoneError:
-        raise ValueError('Unsupported time zone: {0!s}'.format(
-            time_zone_string))
-
-    self._time_zone = time_zone
-
   def SetStorageWriter(self, storage_writer):
     """Sets the storage writer.
 
     Args:
       storage_writer (StorageWriter): storage writer.
     """
     self._storage_writer = storage_writer
```

### Comparing `plaso-20230311/plaso/parsers/msiecf.py` & `plaso-20230717/plaso/parsers/msiecf.py`

 * *Files 1% similar despite different names*

```diff
@@ -127,15 +127,15 @@
       self, parser_mediator, cache_directories, msiecf_item, recovered=False):
     """Extract data from a MSIE Cache Files (MSIECF) leak item.
 
     Every item is stored as an event object, one for each timestamp.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       cache_directories (list[str]): cache directory names.
       msiecf_item (pymsiecf.leak): MSIECF leak item.
       recovered (Optional[bool]): True if the item was recovered.
     """
     # TODO: add support for possible last cache synchronization date and time.
 
     event_data = MSIECFLeakEventData()
@@ -153,15 +153,15 @@
     parser_mediator.ProduceEventData(event_data)
 
   def _ParseItems(self, parser_mediator, msiecf_file):
     """Parses a MSIE Cache File (MSIECF) items.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       msiecf_file (pymsiecf.file): MSIECF file.
     """
     format_version = msiecf_file.format_version
 
     decode_error = False
     cache_directories = []
     for cache_directory_name in msiecf_file.cache_directories:
@@ -221,15 +221,15 @@
       self, parser_mediator, msiecf_item, recovered=False):
     """Extract data from a MSIE Cache Files (MSIECF) redirected item.
 
     Every item is stored as an event object, one for each timestamp.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       msiecf_item (pymsiecf.redirected): MSIECF redirected item.
       recovered (Optional[bool]): True if the item was recovered.
     """
     event_data = MSIECFRedirectedEventData()
     event_data.offset = msiecf_item.offset
     event_data.recovered = recovered
     event_data.url = msiecf_item.location
@@ -241,15 +241,15 @@
       recovered=False):
     """Extract data from a MSIE Cache Files (MSIECF) URL item.
 
     Every item is stored as an event object, one for each timestamp.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       format_version (str): MSIECF format version.
       cache_directories (list[str]): cache directory names.
       msiecf_item (pymsiecf.url): MSIECF URL item.
       recovered (Optional[bool]): True if the item was recovered.
     """
     # The secondary time can be stored in either UTC or local time this is
     # dependent on what the index.dat file is used for. Either the file path
@@ -274,15 +274,15 @@
 
     http_headers = ''
     if msiecf_item.type and msiecf_item.data:
       if msiecf_item.type == 'cache':
         if msiecf_item.data[:4] == b'HTTP':
           # Make sure the HTTP headers are ASCII encoded.
           # TODO: determine correct encoding currently indications that
-          # this could be the system narrow string codepage.
+          # this could be the system narrow string code page.
           try:
             http_headers = msiecf_item.data[:-1].decode('ascii')
           except UnicodeDecodeError:
             warning_message = (
                 'unable to decode HTTP headers of URL record at offset: '
                 '0x{0:08x}. Characters that cannot be decoded will be '
                 'replaced with "?" or "\\ufffd".').format(msiecf_item.offset)
@@ -368,19 +368,21 @@
     return format_specification
 
   def ParseFileObject(self, parser_mediator, file_object):
     """Parses a MSIE Cache File (MSIECF) file-like object.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): file-like object.
     """
+    code_page = parser_mediator.GetCodePage()
+
     msiecf_file = pymsiecf.file()
-    msiecf_file.set_ascii_codepage(parser_mediator.codepage)
+    msiecf_file.set_ascii_codepage(code_page)
 
     try:
       msiecf_file.open_file_object(file_object)
     except IOError as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to open file with error: {0!s}'.format(exception))
       return
```

### Comparing `plaso-20230311/plaso/parsers/networkminer.py` & `plaso-20230717/plaso/parsers/networkminer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/ntfs.py` & `plaso-20230717/plaso/parsers/ntfs.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/ntfs.yaml` & `plaso-20230717/plaso/parsers/ntfs.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/olecf.py` & `plaso-20230717/plaso/parsers/olecf.py`

 * *Files 6% similar despite different names*

```diff
@@ -44,28 +44,32 @@
     """Parses an OLE Compound File (OLECF) file-like object.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): file-like object.
     """
+    code_page = parser_mediator.GetCodePage()
+
     olecf_file = pyolecf.file()
-    olecf_file.set_ascii_codepage(parser_mediator.codepage)
+    olecf_file.set_ascii_codepage(code_page)
 
     try:
       olecf_file.open_file_object(file_object)
     except (IOError, TypeError) as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to open file with error: {0!s}'.format(exception))
       return
 
     root_item = olecf_file.root_item
     if not root_item:
       return
 
+    display_name = parser_mediator.GetDisplayName()
+
     # Get a list of all items in the root item from the OLECF file.
     item_names = [item.name for item in root_item.sub_items]
 
     # Compare the list of available plugin objects.
     # We will try to use every plugin against the file (except
     # the default plugin) and run it. Only if none of the plugins
     # works will we use the default plugin.
@@ -73,16 +77,14 @@
     item_names = frozenset(item_names)
 
     try:
       for plugin_name, plugin in self._plugins_per_name.items():
         if parser_mediator.abort:
           break
 
-        file_entry = parser_mediator.GetFileEntry()
-        display_name = parser_mediator.GetDisplayName(file_entry)
         profiling_name = '/'.join([self.NAME, plugin.NAME])
 
         parser_mediator.SampleFormatCheckStartTiming(profiling_name)
 
         try:
           result = plugin.REQUIRED_ITEMS.issubset(item_names)
         finally:
```

### Comparing `plaso-20230311/plaso/parsers/olecf_plugins/automatic_destinations.py` & `plaso-20230717/plaso/parsers/olecf_plugins/automatic_destinations.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/olecf_plugins/automatic_destinations.yaml` & `plaso-20230717/plaso/parsers/olecf_plugins/automatic_destinations.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/olecf_plugins/default.py` & `plaso-20230717/plaso/parsers/olecf_plugins/default.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/olecf_plugins/interface.py` & `plaso-20230717/plaso/parsers/olecf_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/olecf_plugins/summary.py` & `plaso-20230717/plaso/parsers/olecf_plugins/summary.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/opera.py` & `plaso-20230717/plaso/parsers/opera.py`

 * *Files 2% similar despite different names*

```diff
@@ -307,19 +307,21 @@
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): file-like object.
 
     Raises:
       WrongParser: when the file cannot be parsed.
     """
-    encoding = self._ENCODING or parser_mediator.codepage
+    encoding = self._ENCODING
+    if not encoding:
+      encoding = parser_mediator.GetCodePage()
+
     text_file_object = text_file.TextFile(file_object, encoding=encoding)
     if not self._ParseAndValidateRecord(parser_mediator, text_file_object):
-      raise errors.WrongParser(
-          'Unable to parse as Opera global_history.dat.')
+      raise errors.WrongParser('Unable to parse as Opera global_history.dat.')
 
     while self._ParseRecord(parser_mediator, text_file_object):
       pass
 
 
 manager.ParsersManager.RegisterParsers([
     OperaTypedHistoryParser, OperaGlobalHistoryParser])
```

### Comparing `plaso-20230311/plaso/parsers/pe.py` & `plaso-20230717/plaso/parsers/pe.py`

 * *Files 2% similar despite different names*

```diff
@@ -376,15 +376,15 @@
               'Unable to read message table string: 0x{0:08x} at offset: {1:d} '
               'with error: {2!s}').format(
                   message_identifier, string_offset, exception))
 
         if message_table_string.flags & 0x01:
           string_encoding = 'utf-16-le'
         else:
-          string_encoding = parser_mediator.codepage
+          string_encoding = parser_mediator.GetCodePage()
 
         try:
           string = message_table_string.data.decode(string_encoding)
         except UnicodeDecodeError:
           raise errors.ParseError((
               'Unable to decode {0:s} encoded message table string: 0x{1:08x} '
               'at offset: {2:d} with error: {3!s}').format(
@@ -422,15 +422,15 @@
           resource.
     """
     if (not message_table_resource or not message_table_resource.directory or
         not message_table_resource.directory.entries or
         not message_table_resource.directory.entries[0].directory):
       return
 
-    desired_language_tag = parser_mediator.language.lower()
+    desired_language_tag = parser_mediator.GetLanguageTag().lower()
 
     for entry in message_table_resource.directory.entries[0].directory.entries:
       language_tag = languages.WindowsLanguageHelper.GetLanguageTagForLCID(
           entry.id)
       # TODO: add support for common language tag fallback.
       if not language_tag or language_tag.lower() != desired_language_tag:
         continue
@@ -523,15 +523,15 @@
       ParseError: when the message table cannot be parsed.
     """
     if (not wevt_template_resource or not wevt_template_resource.directory or
         not wevt_template_resource.directory.entries or
         not wevt_template_resource.directory.entries[0].directory):
       return
 
-    desired_language_tag = parser_mediator.language.lower()
+    desired_language_tag = parser_mediator.GetLanguageTag().lower()
 
     for entry in wevt_template_resource.directory.entries[0].directory.entries:
       language_tag = languages.WindowsLanguageHelper.GetLanguageTagForLCID(
           entry.id)
       # TODO: add support for common language tag fallback.
       if not language_tag or language_tag.lower() != desired_language_tag:
         continue
```

### Comparing `plaso-20230311/plaso/parsers/pe_resources.yaml` & `plaso-20230717/plaso/parsers/pe_resources.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist.py` & `plaso-20230717/plaso/parsers/plist.py`

 * *Files 2% similar despite different names*

```diff
@@ -138,30 +138,29 @@
             'object'))
       return
 
     if has_leading_whitespace:
       parser_mediator.ProduceExtractionWarning(
           'XML plist file with leading whitespace')
 
+    display_name = parser_mediator.GetDisplayName()
     filename_lower_case = filename.lower()
 
     try:
       top_level_keys = set(top_level_object.keys())
     except AttributeError as exception:
       raise errors.WrongParser(
           'Unable to parse top level keys of: {0:s} with error: {1!s}.'.format(
               filename, exception))
 
     found_matching_plugin = False
     for plugin_name, plugin in self._plugins_per_name.items():
       if parser_mediator.abort:
         break
 
-      file_entry = parser_mediator.GetFileEntry()
-      display_name = parser_mediator.GetDisplayName(file_entry)
       profiling_name = '/'.join([self.NAME, plugin.NAME])
 
       parser_mediator.SampleFormatCheckStartTiming(profiling_name)
 
       try:
         if not plugin.PLIST_PATH_FILTERS:
           path_filter_match = True
```

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/__init__.py` & `plaso-20230717/plaso/parsers/plist_plugins/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 
 from plaso.parsers.plist_plugins import airport
 from plaso.parsers.plist_plugins import apple_account
 from plaso.parsers.plist_plugins import bluetooth
 from plaso.parsers.plist_plugins import default
 from plaso.parsers.plist_plugins import install_history
 from plaso.parsers.plist_plugins import ios_carplay
+from plaso.parsers.plist_plugins import ios_identityservices
 from plaso.parsers.plist_plugins import ipod
 from plaso.parsers.plist_plugins import launchd
 from plaso.parsers.plist_plugins import macos_user
 from plaso.parsers.plist_plugins import safari_downloads
 from plaso.parsers.plist_plugins import safari_history
 from plaso.parsers.plist_plugins import software_update
 from plaso.parsers.plist_plugins import spotlight_searched_terms
```

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/airport.py` & `plaso-20230717/plaso/parsers/plist_plugins/airport.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/apple_account.py` & `plaso-20230717/plaso/parsers/plist_plugins/apple_account.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/bluetooth.py` & `plaso-20230717/plaso/parsers/plist_plugins/bluetooth.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/default.py` & `plaso-20230717/plaso/parsers/plist_plugins/default.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/install_history.py` & `plaso-20230717/plaso/parsers/plist_plugins/install_history.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from plaso.parsers.plist_plugins import interface
 
 
 class MacOSInstallHistoryEventData(events.EventData):
   """MacOS install history event data.
 
   Attributes:
-    identifiers (list[str]): indentifiers of the installed package.
+    identifiers (list[str]): identifiers of the installed package.
     name (str): display name of the installed package.
     process_name (str): name of the process that installed the package.
     version (str): display version of the installed package.
     written_time (dfdatetime.DateTimeValues): entry written date and time.
   """
 
   DATA_TYPE = 'macos:install_history:entry'
```

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/interface.py` & `plaso-20230717/plaso/parsers/plist_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/ios_carplay.py` & `plaso-20230717/plaso/parsers/plist_plugins/ios_carplay.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/ipod.py` & `plaso-20230717/plaso/parsers/plist_plugins/ipod.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/launchd.py` & `plaso-20230717/plaso/parsers/plist_plugins/launchd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/macos_user.py` & `plaso-20230717/plaso/parsers/plist_plugins/macos_user.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/safari_downloads.py` & `plaso-20230717/plaso/parsers/plist_plugins/safari_downloads.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/safari_history.py` & `plaso-20230717/plaso/parsers/plist_plugins/safari_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/software_update.py` & `plaso-20230717/plaso/parsers/plist_plugins/software_update.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/spotlight_searched_terms.py` & `plaso-20230717/plaso/parsers/plist_plugins/spotlight_searched_terms.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/spotlight_volume.py` & `plaso-20230717/plaso/parsers/plist_plugins/spotlight_volume.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/time_machine.py` & `plaso-20230717/plaso/parsers/plist_plugins/time_machine.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plist_plugins/time_machine.yaml` & `plaso-20230717/plaso/parsers/plist_plugins/time_machine.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/pls_recall.py` & `plaso-20230717/plaso/parsers/pls_recall.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/pls_recall.yaml` & `plaso-20230717/plaso/parsers/pls_recall.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/plugins.py` & `plaso-20230717/plaso/parsers/plugins.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/presets.py` & `plaso-20230717/plaso/parsers/presets.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/recycler.py` & `plaso-20230717/plaso/parsers/recycler.py`

 * *Files 2% similar despite different names*

```diff
@@ -175,24 +175,24 @@
       record = self._ReadStructureFromByteStream(
           record_data, record_offset, record_map)
     except (ValueError, errors.ParseError) as exception:
       raise errors.ParseError((
           'Unable to map record data at offset: 0x{0:08x} with error: '
           '{1!s}').format(record_offset, exception))
 
-    codepage = parser_mediator.codepage or 'ascii'
+    code_page = parser_mediator.GetCodePage()
 
     # The original filename can contain remnant data after the end-of-string
     # character.
     ascii_filename = record.original_filename.split(b'\x00')[0]
 
     try:
-      ascii_filename = ascii_filename.decode(codepage)
+      ascii_filename = ascii_filename.decode(code_page)
     except UnicodeDecodeError:
-      ascii_filename = ascii_filename.decode(codepage, errors='replace')
+      ascii_filename = ascii_filename.decode(code_page, errors='replace')
 
       parser_mediator.ProduceExtractionWarning(
           'unable to decode original filename.')
 
     unicode_filename = None
     if record_size > 280:
       record_offset += 280
```

### Comparing `plaso-20230311/plaso/parsers/recycler.yaml` & `plaso-20230717/plaso/parsers/recycler.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/safari_cookies.py` & `plaso-20230717/plaso/parsers/safari_cookies.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/safari_cookies.yaml` & `plaso-20230717/plaso/parsers/safari_cookies.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/shared/shell_items.py` & `plaso-20230717/plaso/parsers/shared/shell_items.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/spotlight_storedb.py` & `plaso-20230717/plaso/parsers/spotlight_storedb.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # -*- coding: utf-8 -*-
 """Parser for Apple Spotlight store database files."""
 
 from collections import abc as collections
 
+import abc
 import os
 import zlib
 
 from dfdatetime import cocoa_time as dfdatetime_cocoa_time
 from dfdatetime import posix_time as dfdatetime_posix_time
 
 from dtfabric import errors as dtfabric_errors
@@ -18,14 +19,29 @@
 from plaso.lib import dtfabric_helper
 from plaso.lib import errors
 from plaso.lib import specification
 from plaso.parsers import interface
 from plaso.parsers import manager
 
 
+class SpotlightStoreIndexValue(object):
+  """Index value.
+
+  Attributes:
+    table_index (int): table index.
+    values_list (list[str]): values list.
+  """
+
+  def __init__(self):
+    """Initializes an index value."""
+    super(SpotlightStoreIndexValue, self).__init__()
+    self.table_index = None
+    self.values_list = []
+
+
 class SpotlightStoreMetadataItemEventData(events.EventData):
   """Apple Spotlight store database metadata item event data.
 
   Attributes:
     added_time (dfdatetime.DateTimeValues): date and time the item was added
         (kMDItemDateAdded).
     attribute_change_time (dfdatetime.DateTimeValues): date and time
@@ -124,16 +140,246 @@
     self.flags = 0
     self.identifier = 0
     self.item_identifier = 0
     self.last_update_time = 0
     self.parent_identifier = 0
 
 
+class BaseSpotlightFile(dtfabric_helper.DtFabricHelper):
+  """Shared functionality for Apple Spotlight files."""
+
+  _DEFINITION_FILE = os.path.join(
+      os.path.dirname(__file__), 'spotlight_storedb.yaml')
+
+  def __init__(self):
+    """Initializes a Apple Spotlight file."""
+    super(BaseSpotlightFile, self).__init__()
+    self._file_entry = None
+    self._file_object = None
+
+  def Close(self):
+    """Closes an Apple Spotlight file.
+
+    Raises:
+      IOError: if the file is not opened.
+      OSError: if the file is not opened.
+    """
+    if not self._file_object:
+      raise IOError('File not opened')
+
+    self._file_object = None
+    self._file_entry = None
+
+  def Open(self, file_entry):
+    """Opens an Apple Spotlight file.
+
+    Args:
+      file_entry (dfvfs.FileEntry): a file entry.
+
+    Raises:
+      IOError: if the file is already opened.
+      OSError: if the file is already opened.
+    """
+    if self._file_object:
+      raise IOError('File already opened')
+
+    self._file_entry = file_entry
+
+    file_object = file_entry.GetFileObject()
+
+    self.ReadFileObject(file_object)
+
+    self._file_object = file_object
+
+  @abc.abstractmethod
+  def ReadFileObject(self, file_object):
+    """Reads an Apple Spotlight file-like object.
+
+    Args:
+      file_object (file): file-like object.
+    """
+
+
+class SpotlightStreamsMapDataFile(BaseSpotlightFile):
+  """Apple Spotlight database streams map data file (dbStr-#.map.data).
+
+  Attributes:
+    stream_values (list[bytes]): stream values.
+  """
+
+  def __init__(self, data_size, ranges):
+    """Initializes a database streams map data file.
+
+    Args:
+      data_size (int): data size.
+      ranges (list[tuple[int, int]]): offset and size pairs of the stream value
+          data ranges.
+    """
+    super(SpotlightStreamsMapDataFile, self).__init__()
+    self._data_size = data_size
+    self._ranges = ranges
+    self.stream_values = []
+
+  def _ReadVariableSizeInteger(self, data):
+    """Reads a variable size integer.
+
+    Args:
+      data (bytes): data.
+
+    Returns:
+      tuple[int, int]: integer value and number of bytes read.
+    """
+    byte_value = data[0]
+    bytes_read = 1
+
+    number_of_additional_bytes = 0
+    for bitmask in (0x80, 0xc0, 0xe0, 0xf0, 0xf8, 0xfc, 0xfe, 0xff):
+      if byte_value & bitmask != bitmask:
+        break
+      number_of_additional_bytes += 1
+
+    if number_of_additional_bytes > 4:
+      byte_value = 0
+    elif number_of_additional_bytes > 0:
+      byte_value &= bitmask ^ 0xff
+
+    integer_value = int(byte_value)
+    while number_of_additional_bytes > 0:
+      integer_value <<= 8
+
+      integer_value += int(data[bytes_read])
+      bytes_read += 1
+
+      number_of_additional_bytes -= 1
+
+    return integer_value, bytes_read
+
+  def ReadFileObject(self, file_object):
+    """Reads a database streams map data file-like object.
+
+    Args:
+      file_object (file): file-like object.
+
+    Raises:
+      ParseError: if the file cannot be read.
+    """
+    data = file_object.read(self._data_size)
+
+    for value_range in self._ranges:
+      value_offset, value_size = value_range
+
+      stream_value = data[value_offset:value_offset + value_size]
+
+      self.stream_values.append(stream_value)
+
+
+class SpotlightStreamsMapHeaderFile(BaseSpotlightFile):
+  """Apple Spotlight database streams map header file (dbStr-#.map.header).
+
+  Attributes:
+    data_size (int): data size.
+    number_of_buckets (int): number of entries in the database streams map
+        buckets file (dbStr-#.map.buckets).
+    number_of_offsets (int): number of entries in the database streams map
+        offsets file (dbStr-#.map.offsets).
+  """
+
+  def __init__(self):
+    """Initializes a database streams map header file."""
+    super(SpotlightStreamsMapHeaderFile, self).__init__()
+    self.data_size = None
+    self.number_of_buckets = None
+    self.number_of_offsets = None
+
+  def ReadFileObject(self, file_object):
+    """Reads a database streams map header file-like object.
+
+    Args:
+      file_object (file): file-like object.
+
+    Raises:
+      ParseError: if the file cannot be read.
+    """
+    data_type_map = self._GetDataTypeMap(
+        'spotlight_database_streams_map_header')
+
+    streams_map_header, _ = self._ReadStructureFromFileObject(
+        file_object, 0, data_type_map)
+
+    self.data_size = streams_map_header.unknown4
+    self.number_of_buckets = streams_map_header.unknown5
+    self.number_of_offsets = streams_map_header.unknown6
+
+
+class SpotlightStreamsMapOffsetsFile(BaseSpotlightFile):
+  """Apple Spotlight database streams map offsets file (dbStr-#.map.offsets).
+
+  Attributes:
+    ranges (list[tuple[int, int]]): offset and size pairs of the stream value
+        data ranges.
+  """
+
+  def __init__(self, data_size, number_of_entries):
+    """Initializes a database streams map offsets file.
+
+    Args:
+      data_size (int): data size.
+      number_of_entries (int): number of entries in the offsets file.
+    """
+    super(SpotlightStreamsMapOffsetsFile, self).__init__()
+    self._data_size = data_size
+    self._number_of_entries = number_of_entries
+    self.ranges = []
+
+  def ReadFileObject(self, file_object):
+    """Reads a database streams map offsets file-like object.
+
+    Args:
+      file_object (file): file-like object.
+
+    Raises:
+      ParseError: if the file cannot be read.
+    """
+    data_size = self._number_of_entries * 4
+    data = file_object.read(data_size)
+
+    data_type_map = self._GetDataTypeMap('array_of_uint32le')
+
+    context = dtfabric_data_maps.DataTypeMapContext(values={
+        'number_of_elements': self._number_of_entries})
+
+    try:
+      offsets_array = data_type_map.MapByteStream(data, context=context)
+
+    except dtfabric_errors.MappingError as exception:
+      raise errors.ParseError(
+          f'Unable to parse array of 32-bit offsets with error: {exception!s}')
+
+    index = 0
+    last_offset = 0
+
+    for index, offset in enumerate(offsets_array):
+      if index == 0:
+        last_offset = offsets_array[0]
+        continue
+
+      range_size = offset - last_offset
+
+      self.ranges.append((last_offset, range_size))
+
+      last_offset = offset
+
+    if last_offset:
+      range_size = self._data_size - last_offset
+
+      self.ranges.append((last_offset, range_size))
+
+
 class SpotlightStoreDatabaseParser(
-    interface.FileObjectParser, dtfabric_helper.DtFabricHelper):
+    interface.FileEntryParser, dtfabric_helper.DtFabricHelper):
   """Parser for Apple Spotlight store database (store.db) files."""
 
   NAME = 'spotlight_storedb'
   DATA_FORMAT = 'Apple Spotlight store database (store.db) file'
 
   _DEFINITION_FILE = os.path.join(
       os.path.dirname(__file__), 'spotlight_storedb.yaml')
@@ -143,14 +389,101 @@
     super(SpotlightStoreDatabaseParser, self).__init__()
     self._map_values = []
     self._metadata_lists = {}
     self._metadata_localized_strings = {}
     self._metadata_types = {}
     self._metadata_values = {}
 
+  def _DecompressLZ4Block(
+      self, file_offset, compressed_data, previous_uncompressed_data):
+    """Decompresses LZ4 compressed block.
+
+    Args:
+      file_offset (int): file offset.
+      compressed_data (bytes): LZ4 compressed data.
+      previous_uncompressed_data (bytes): uncompressed data of the previous
+          (preceding) block.
+
+    Returns:
+      tuple[bytes, int]: uncompressed data and number of bytes read.
+
+    Raises:
+      ParseError: if the data cannot be decompressed.
+    """
+    data_type_map = self._GetDataTypeMap('spotlight_store_db_lz4_block_header')
+
+    try:
+      lz4_block_header = data_type_map.MapByteStream(compressed_data)
+    except dtfabric_errors.MappingError as exception:
+      raise errors.ParseError((
+          f'Unable to map LZ4 block header at offset: 0x{file_offset:08x} '
+          f'with error: {exception!s}'))
+
+    if lz4_block_header.signature == b'bv41':
+      end_of_data_offset = 12 + lz4_block_header.compressed_data_size
+
+      uncompressed_data = lz4.block.decompress(
+          compressed_data[12:end_of_data_offset],
+          uncompressed_size=lz4_block_header.uncompressed_data_size,
+          dict=previous_uncompressed_data)
+
+    elif lz4_block_header.signature == b'bv4-':
+      end_of_data_offset = 8 + lz4_block_header.uncompressed_data_size
+      uncompressed_data = compressed_data[8:end_of_data_offset]
+
+    else:
+      raise errors.ParseError((
+          f'Unsupported start of LZ4 block marker at offset: '
+          f'0x{file_offset:08x}'))
+
+    return uncompressed_data, end_of_data_offset
+
+  def _DecompressLZ4PageData(self, compressed_page_data, file_offset):
+    """Decompresses LZ4 compressed page data.
+
+    Args:
+      compressed_page_data (bytes): LZ4 compressed page data.
+      file_offset (int): file offset.
+
+    Returns:
+      bytes: uncompressed page data.
+
+    Raises:
+      ParseError: if the page data cannot be decompressed.
+    """
+    compressed_data_offset = 0
+    compressed_data_size = len(compressed_page_data)
+
+    last_uncompressed_block = None
+
+    uncompressed_blocks = []
+    while compressed_data_offset < compressed_data_size:
+      lz4_block_marker = compressed_page_data[
+          compressed_data_offset:compressed_data_offset + 4]
+
+      if lz4_block_marker == b'bv4$':
+        break
+
+      uncompressed_data, bytes_read = self._DecompressLZ4Block(
+          file_offset, compressed_page_data[compressed_data_offset:],
+          last_uncompressed_block)
+
+      compressed_data_offset += bytes_read
+      file_offset += bytes_read
+
+      last_uncompressed_block = uncompressed_data
+
+      uncompressed_blocks.append(uncompressed_data)
+
+    if lz4_block_marker != b'bv4$':
+      raise errors.ParseError(
+          f'Unsupported end of LZ4 block marker at offset: 0x{file_offset:08x}')
+
+    return b''.join(uncompressed_blocks)
+
   def _GetDateTimeMetadataItemValue(self, metadata_item, name):
     """Retrieves a date and time value from a metadata item.
 
     Args:
       metadata_item (SpotlightStoreMetadataItem): a metadata item.
       name (str): name of the attribute.
 
@@ -361,16 +694,16 @@
 
   def _ReadIndexPageValues(self, page_header, page_data, property_table):
     """Reads the index page values.
 
     Args:
       page_header (spotlight_store_db_property_page_header): page header.
       page_data (bytes): page data.
-      property_table (dict[int, object]): property table in which to store the
-          property page values.
+      property_table (dict[int, SpotlightStoreIndexValue]): property table in
+          which to store the property page values.
 
     Raises:
       ParseError: if the property page values cannot be read.
     """
     data_type_map = self._GetDataTypeMap('spotlight_store_db_property_value81')
     index_values_data_type_map = self._GetDataTypeMap(
         'spotlight_store_db_index_values')
@@ -414,21 +747,81 @@
 
       values_list = []
       for metadata_value_index in index_values:
         metadata_value = self._metadata_values.get(metadata_value_index, None)
         value_string = getattr(metadata_value, 'value_name', '')
         values_list.append(value_string)
 
-      setattr(property_value, 'values_list', values_list)
+      index_value = SpotlightStoreIndexValue()
+      index_value.table_index = property_value.table_index
+      index_value.values_list = values_list
 
-      property_table[property_value.table_index] = property_value
+      property_table[index_value.table_index] = index_value
 
       page_data_offset += page_value_size
       page_value_index += 1
 
+  def _ReadIndexStreamsMap(
+      self, parent_file_entry, streams_map_number, property_table):
+    """Reads an index streams map.
+
+    Args:
+      parent_file_entry (dfvfs.FileEntry): parent of the Spotlight store.db
+          file entry.
+      streams_map_number (int): number of the streams map.
+      property_table (dict[int, SpotlightStoreIndexValue]): property table in
+          which to store the index values.
+
+    Raises:
+      ParseError: if the index streams map cannot be read.
+    """
+    stream_values = self._ReadStreamsMap(parent_file_entry, streams_map_number)
+
+    index_values_data_type_map = self._GetDataTypeMap(
+        'spotlight_store_db_index_values')
+
+    for index, stream_value in enumerate(stream_values):
+      if index == 0:
+        continue
+
+      _, data_offset = self._ReadVariableSizeInteger(stream_value)
+
+      index_size, bytes_read = self._ReadVariableSizeInteger(
+          stream_value[data_offset:])
+
+      data_offset += bytes_read
+
+      _, padding_size = divmod(index_size, 4)
+
+      index_size -= padding_size
+
+      context = dtfabric_data_maps.DataTypeMapContext(values={
+          'index_size': index_size})
+
+      try:
+        index_values = index_values_data_type_map.MapByteStream(
+            stream_value[data_offset + padding_size:], context=context)
+
+      except dtfabric_errors.MappingError as exception:
+        raise errors.ParseError((
+            f'Unable to map stream value: {index:d} data with error: '
+            f'{exception!s}'))
+
+      values_list = []
+      for metadata_value_index in index_values:
+        metadata_value = self._metadata_values.get(metadata_value_index, None)
+        value_string = getattr(metadata_value, 'value_name', '')
+        values_list.append(value_string)
+
+      index_value = SpotlightStoreIndexValue()
+      index_value.table_index = index
+      index_value.values_list = values_list
+
+      property_table[index] = index_value
+
   def _ReadMapPage(self, file_object, file_offset):
     """Reads a map page.
 
     Args:
       file_object (file): file-like object.
       file_offset (int): file offset.
 
@@ -504,16 +897,16 @@
     if value_type is None:
       return None, 0
 
     key_name = getattr(metadata_type, 'key_name', None)
     property_type = getattr(metadata_type, 'property_type', None)
 
     if key_name == 'kMDStoreAccumulatedSizes':
-      bytes_read = 4 * 16
-      value = data[:bytes_read]
+      bytes_read = len(data)
+      value = data
 
     elif value_type in (0x00, 0x02, 0x06):
       value, bytes_read = self._ReadVariableSizeInteger(data)
 
     elif value_type == 0x07:
       value, bytes_read = self._ReadMetadataAttributeVariableSizeIntegerValue(
           property_type, data)
@@ -567,18 +960,18 @@
 
     Returns:
       tuple[object, int]: value and number of bytes read.
 
     Raises:
       ParseError: if the metadata attribute byte value cannot be read.
     """
-    if property_type & 0x02 == 0x00:
-      data_size, bytes_read = 1, 0
-    else:
+    if property_type & 0x02:
       data_size, bytes_read = self._ReadVariableSizeInteger(data)
+    else:
+      data_size, bytes_read = 1, 0
 
     data_type_map = self._GetDataTypeMap('array_of_byte')
 
     context = dtfabric_data_maps.DataTypeMapContext(values={
         'elements_data_size': data_size})
 
     try:
@@ -679,14 +1072,55 @@
     else:
       value = array_of_values
 
     bytes_read += data_size
 
     return value, bytes_read
 
+  def _ReadMetadataAttributePageValues(
+      self, page_header, page_data, property_table):
+    """Reads the metadata atribute page values.
+
+    Args:
+      page_header (spotlight_store_db_property_page_header): page header.
+      page_data (bytes): page data.
+      property_table (dict[int, object]): property table in which to store the
+          property page values.
+
+    Raises:
+      ParseError: if the property page values cannot be read.
+    """
+    if page_header.property_table_type == 0x00000011:
+      data_type_map = self._GetDataTypeMap(
+          'spotlight_store_db_property_value11')
+
+    elif page_header.property_table_type == 0x00000021:
+      data_type_map = self._GetDataTypeMap(
+          'spotlight_store_db_property_value21')
+
+    page_data_offset = 12
+    page_data_size = page_header.used_page_size - 20
+    page_value_index = 0
+
+    while page_data_offset < page_data_size:
+      context = dtfabric_data_maps.DataTypeMapContext()
+
+      try:
+        property_value = data_type_map.MapByteStream(
+            page_data[page_data_offset:], context=context)
+      except dtfabric_errors.MappingError as exception:
+        raise errors.ParseError((
+            'Unable to map property value data at offset: 0x{0:08x} with '
+            'error: {1!s}').format(page_data_offset, exception))
+
+      property_table[property_value.table_index] = property_value
+
+      page_data_offset += context.byte_size
+      page_value_index += 1
+
   def _ReadMetadataAttributeReferenceValue(self, property_type, data):
     """Reads a metadata attribute reference value.
 
     Args:
       property_type (int): metadata attribute property type.
       data (bytes): data.
 
@@ -787,14 +1221,60 @@
 
       array_of_values.append(integer_value)
 
     bytes_read += data_size
 
     return array_of_values, bytes_read
 
+  def _ReadMetadataAttributeStreamsMap(
+      self, parent_file_entry, streams_map_number, property_table):
+    """Reads a metadata attribute streams map.
+
+    Args:
+      parent_file_entry (dfvfs.FileEntry): parent of the Spotlight store.db
+          file entry.
+      streams_map_number (int): number of the streams map.
+      property_table (dict[int, object]): property table in which to store the
+          metadata attribute values.
+
+    Raises:
+      ParseError: if the metadata attribute streams map cannot be read.
+    """
+    stream_values = self._ReadStreamsMap(parent_file_entry, streams_map_number)
+
+    if streams_map_number == 1:
+      data_type_map = self._GetDataTypeMap(
+          'spotlight_metadata_attribute_type')
+
+    elif streams_map_number == 2:
+      data_type_map = self._GetDataTypeMap(
+          'spotlight_metadata_attribute_value')
+
+    for index, stream_value in enumerate(stream_values):
+      if index == 0:
+        continue
+
+      data_size, data_offset = self._ReadVariableSizeInteger(stream_value)
+
+      if data_offset + data_size != len(stream_value):
+        # Stream values where the data size does not match appear to contain
+        # remnant data.
+        continue
+
+      try:
+        property_value = data_type_map.MapByteStream(stream_value[data_offset:])
+      except dtfabric_errors.MappingError as exception:
+        raise errors.ParseError((
+            f'Unable to map stream value: {index:d} data with error: '
+            f'{exception!s}'))
+
+      property_value.table_index = index
+
+      property_table[index] = property_value
+
   def _ReadPropertyPage(self, file_object, file_offset, property_table):
     """Reads a property page.
 
     Args:
       file_object (file): file-like object.
       file_offset (int): file offset.
       property_table (dict[int, object]): property table in which to store the
@@ -823,15 +1303,16 @@
 
     file_offset += bytes_read
 
     page_values_header = self._ReadStructureFromByteStream(
         page_data, file_offset, data_type_map)
 
     if page_header.property_table_type in (0x00000011, 0x00000021):
-      self._ReadPropertyPageValues(page_header, page_data, property_table)
+      self._ReadMetadataAttributePageValues(
+          page_header, page_data, property_table)
 
     elif page_header.property_table_type == 0x00000081:
       self._ReadIndexPageValues(page_header, page_data, property_table)
 
     return page_header, page_values_header.next_block_number
 
   def _ReadPropertyPageHeader(self, file_object, file_offset):
@@ -869,54 +1350,14 @@
     file_offset = block_number * 0x1000
     while file_offset != 0:
       _, next_block_number = self._ReadPropertyPage(
           file_object, file_offset, property_table)
 
       file_offset = next_block_number * 0x1000
 
-  def _ReadPropertyPageValues(self, page_header, page_data, property_table):
-    """Reads the property page values.
-
-    Args:
-      page_header (spotlight_store_db_property_page_header): page header.
-      page_data (bytes): page data.
-      property_table (dict[int, object]): property table in which to store the
-          property page values.
-
-    Raises:
-      ParseError: if the property page values cannot be read.
-    """
-    if page_header.property_table_type == 0x00000011:
-      data_type_map = self._GetDataTypeMap(
-          'spotlight_store_db_property_value11')
-
-    elif page_header.property_table_type == 0x00000021:
-      data_type_map = self._GetDataTypeMap(
-          'spotlight_store_db_property_value21')
-
-    page_data_offset = 12
-    page_data_size = page_header.used_page_size - 20
-    page_value_index = 0
-
-    while page_data_offset < page_data_size:
-      context = dtfabric_data_maps.DataTypeMapContext()
-
-      try:
-        property_value = data_type_map.MapByteStream(
-            page_data[page_data_offset:], context=context)
-      except dtfabric_errors.MappingError as exception:
-        raise errors.ParseError((
-            'Unable to map property value data at offset: 0x{0:08x} with '
-            'error: {1!s}').format(page_data_offset, exception))
-
-      property_table[property_value.table_index] = property_value
-
-      page_data_offset += context.byte_size
-      page_value_index += 1
-
   def _ReadRecordHeader(self, data, page_data_offset):
     """Reads a record header.
 
     Args:
       data (bytes): data.
       page_data_offset (int): offset of the page value relative to the start
           of the page data.
@@ -961,57 +1402,14 @@
     metadata_item.identifier = identifier
     metadata_item.item_identifier = values.get('item_identifier')
     metadata_item.last_update_time = values.get('last_update_time')
     metadata_item.parent_identifier = values.get('parent_identifier')
 
     return metadata_item, data_offset
 
-  def _DecompressLZ4PageData(self, compressed_page_data, file_offset):
-    """Decompresses LZ4 compressed page data.
-
-    Args:
-      compressed_page_data (bytes): LZ4 compressed page data.
-      file_offset (int): file offset.
-
-    Returns:
-      bytes: uncompressed page data.
-
-    Raises:
-      ParseError: if the page data cannot be decompressed.
-    """
-    data_type_map = self._GetDataTypeMap(
-        'spotlight_store_db_lz4_block_header')
-    context = dtfabric_data_maps.DataTypeMapContext()
-
-    try:
-      lz4_block_header = data_type_map.MapByteStream(
-          compressed_page_data, context=context)
-    except dtfabric_errors.MappingError as exception:
-      raise errors.ParseError((
-          'Unable to map LZ4 block header at offset: 0x{0:08x} with error: '
-          '{1!s}').format(file_offset, exception))
-
-    lz4_block_header_size = context.byte_size
-    end_of_compressed_data_offset = (
-        lz4_block_header_size + lz4_block_header.compressed_data_size)
-
-    page_data = lz4.block.decompress(
-        compressed_page_data[12:end_of_compressed_data_offset],
-        uncompressed_size=lz4_block_header.uncompressed_data_size)
-
-    end_of_compressed_data_identifier = compressed_page_data[
-        end_of_compressed_data_offset:end_of_compressed_data_offset + 4]
-
-    if end_of_compressed_data_identifier != b'bv4$':
-      raise errors.ParseError((
-          'Unsupported LZ4 end of compressed data marker at offset: '
-          '0x{0:08x}').format(file_offset + end_of_compressed_data_offset))
-
-    return page_data
-
   def _ReadRecordPage(self, file_object, file_offset):
     """Reads a record page.
 
     Args:
       file_object (file): file-like object.
       file_offset (int): file offset.
 
@@ -1021,40 +1419,88 @@
 
     Raises:
       ParseError: if the property page cannot be read.
     """
     page_header, bytes_read = self._ReadPropertyPageHeader(
         file_object, file_offset)
 
-    if page_header.property_table_type not in (0x00000009, 0x00001009):
+    if page_header.property_table_type not in (
+        0x00000009, 0x00001009, 0x00005009):
       raise errors.ParseError(
           'Unsupported property table type: 0x{0:08x}'.format(
               page_header.property_table_type))
 
     page_data = file_object.read(page_header.page_size - bytes_read)
 
     file_offset += bytes_read
 
     if page_header.uncompressed_page_size > 0:
       compressed_page_data = page_data
 
-      if (page_header.property_table_type == 0x00000009 and
-          compressed_page_data[0] == 0x78):
-        page_data = zlib.decompress(compressed_page_data)
-
-      elif (page_header.property_table_type == 0x00001009 and
-            compressed_page_data[0:4] == b'bv41'):
+      if (page_header.property_table_type & 0x00001000 and
+          compressed_page_data[0:4] in (b'bv41', b'bv4-')):
         page_data = self._DecompressLZ4PageData(
             compressed_page_data, file_offset)
 
+      elif compressed_page_data[0] == 0x78:
+        page_data = zlib.decompress(compressed_page_data)
+
       else:
         raise errors.ParseError('Unsupported compression type')
 
     return page_header, page_data
 
+  def _ReadStreamsMap(self, parent_file_entry, streams_map_number):
+    """Reads a streams map.
+
+    Args:
+      parent_file_entry (dfvfs.FileEntry): parent of the Spotlight store.db
+          file entry.
+      streams_map_number (int): number of the streams map.
+
+    Returns:
+      list[bytes]: stream values.
+
+    Raises:
+      ParseError: if the streams map cannot be read.
+    """
+    header_file_entry = parent_file_entry.GetSubFileEntryByName(
+        f'dbStr-{streams_map_number:d}.map.header')
+
+    streams_map_header = SpotlightStreamsMapHeaderFile()
+    streams_map_header.Open(header_file_entry)
+
+    data_size = streams_map_header.data_size
+    number_of_offsets = streams_map_header.number_of_offsets
+
+    streams_map_header.Close()
+
+    offsets_file_entry = parent_file_entry.GetSubFileEntryByName(
+        f'dbStr-{streams_map_number:d}.map.offsets')
+
+    streams_map_offsets = SpotlightStreamsMapOffsetsFile(
+        data_size, number_of_offsets)
+    streams_map_offsets.Open(offsets_file_entry)
+
+    ranges = streams_map_offsets.ranges
+
+    streams_map_offsets.Close()
+
+    data_file_entry = parent_file_entry.GetSubFileEntryByName(
+        f'dbStr-{streams_map_number:d}.map.data')
+
+    streams_map_data = SpotlightStreamsMapDataFile(data_size, ranges)
+    streams_map_data.Open(data_file_entry)
+
+    stream_values = streams_map_data.stream_values
+
+    streams_map_data.Close()
+
+    return stream_values
+
   def _ReadVariableSizeInteger(self, data):
     """Reads a variable size integer.
 
     Args:
       data (bytes): data.
 
     Returns:
@@ -1116,58 +1562,80 @@
     Returns:
       FormatSpecification: format specification.
     """
     format_specification = specification.FormatSpecification(cls.NAME)
     format_specification.AddNewSignature(b'8tsd', offset=0)
     return format_specification
 
-  def ParseFileObject(self, parser_mediator, file_object):
-    """Parses an Apple Spotlight store database file-like object.
+  def ParseFileEntry(self, parser_mediator, file_entry):
+    """Parses an Apple Spotlight store database file entry.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
-      file_object (dfvfs.FileIO): a file-like object.
+      file_entry (dfvfs.FileEntry): a file entry to parse.
 
     Raises:
       WrongParser: when the file cannot be parsed.
     """
+    parent_file_entry = file_entry.GetParentFileEntry()
+
+    file_object = file_entry.GetFileObject()
+
     try:
       file_header = self._ReadFileHeader(file_object)
     except (ValueError, errors.ParseError):
       raise errors.WrongParser('Unable to parse file header.')
 
     try:
       self._map_values = []
       self._ReadMapPages(
           file_object, file_header.map_offset, file_header.map_size)
 
       self._metadata_types = {}
-      self._ReadPropertyPages(
-          file_object, file_header.metadata_types_block_number,
-          self._metadata_types)
+      if not file_header.metadata_types_block_number:
+        self._ReadMetadataAttributeStreamsMap(
+            parent_file_entry, 1, self._metadata_types)
+      else:
+        self._ReadPropertyPages(
+            file_object, file_header.metadata_types_block_number,
+            self._metadata_types)
 
       self._metadata_values = {}
-      self._ReadPropertyPages(
-          file_object, file_header.metadata_values_block_number,
-          self._metadata_values)
+      if not file_header.metadata_values_block_number:
+        self._ReadMetadataAttributeStreamsMap(
+            parent_file_entry, 2, self._metadata_values)
+      else:
+        self._ReadPropertyPages(
+            file_object, file_header.metadata_values_block_number,
+            self._metadata_values)
 
       # Note that the content of this property page is currently unknown.
-      self._ReadPropertyPages(
-          file_object, file_header.unknown_values41_block_number, {})
+      if not file_header.unknown_values41_block_number:
+        self._ReadIndexStreamsMap(parent_file_entry, 3, {})
+      else:
+        self._ReadPropertyPages(
+            file_object, file_header.unknown_values41_block_number, {})
 
       self._metadata_lists = {}
-      self._ReadPropertyPages(
-          file_object, file_header.metadata_lists_block_number,
-          self._metadata_lists)
+      if not file_header.metadata_lists_block_number:
+        self._ReadIndexStreamsMap(parent_file_entry, 4, self._metadata_lists)
+      else:
+        self._ReadPropertyPages(
+            file_object, file_header.metadata_lists_block_number,
+            self._metadata_lists)
 
       self._metadata_localized_strings = {}
-      self._ReadPropertyPages(
-          file_object, file_header.metadata_localized_strings_block_number,
-          self._metadata_localized_strings)
+      if not file_header.metadata_localized_strings_block_number:
+        self._ReadIndexStreamsMap(
+            parent_file_entry, 5, self._metadata_localized_strings)
+      else:
+        self._ReadPropertyPages(
+            file_object, file_header.metadata_localized_strings_block_number,
+            self._metadata_localized_strings)
 
     except errors.ParseError as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to read store database with error: {0!s}'.format(
               exception))
       return
```

### Comparing `plaso-20230311/plaso/parsers/spotlight_storedb.yaml` & `plaso-20230717/plaso/parsers/spotlight_storedb.yaml`

 * *Files 19% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # dtFabric format specification.
 ---
-name: spotlight_store_db
+name: spotlight_store
 type: format
-description: Apple Spotlight store database file format
+description: Apple Spotlight store file formats
 urls: ["https://github.com/libyal/dtformats/blob/main/documentation/Apple%20Spotlight%20store%20database%20file%20format.asciidoc"]
 ---
 name: byte
 type: integer
 attributes:
   format: unsigned
   size: 1
@@ -89,14 +89,81 @@
 elements_data_size: elements_data_size
 ---
 name: array_of_float64
 type: sequence
 element_data_type: float64
 elements_data_size: elements_data_size
 ---
+name: array_of_uint32le
+type: sequence
+element_data_type: uint32le
+number_of_elements: number_of_elements
+---
+name: spotlight_database_streams_map_header
+type: structure
+description: Spotlight database streams map header file (dbStr-#.map.header) format.
+attributes:
+  byte_order: little-endian
+members:
+- name: signature
+  type: stream
+  element_data_type: byte
+  number_of_elements: 8
+  value: "\x00PataD\x00\x00"
+- name: unknown1
+  data_type: uint32
+- name: unknown2
+  data_type: uint32
+- name: unknown3
+  data_type: uint32
+- name: unknown4
+  data_type: uint32
+- name: unknown5
+  data_type: uint32
+- name: unknown6
+  data_type: uint32
+- name: unknown7
+  data_type: uint32
+- name: unknown8
+  data_type: uint32
+- name: unknown9
+  data_type: uint32
+- name: unknown10
+  data_type: uint32
+- name: unknown11
+  data_type: uint32
+- name: unknown12
+  data_type: uint32
+---
+name: spotlight_metadata_attribute_type
+type: structure
+attributes:
+  byte_order: little-endian
+members:
+- name: value_type
+  data_type: uint8
+- name: property_type
+  data_type: uint8
+- name: key_name
+  type: string
+  encoding: utf8
+  element_data_type: char
+  elements_terminator: "\x00"
+---
+name: spotlight_metadata_attribute_value
+type: structure
+attributes:
+  byte_order: little-endian
+members:
+- name: value_name
+  type: string
+  encoding: utf8
+  element_data_type: char
+  elements_terminator: "\x00"
+---
 name: spotlight_store_db_file_header
 type: structure
 attributes:
   byte_order: little-endian
 members:
 - name: signature
   type: stream
```

### Comparing `plaso-20230311/plaso/parsers/sqlite.py` & `plaso-20230717/plaso/parsers/sqlite.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # -*- coding: utf-8 -*-
 """SQLite parser."""
 
 import os
 import sqlite3
 import tempfile
 
-from dfvfs.path import factory as dfvfs_factory
+from dfvfs.path import factory as path_spec_factory
 
 from plaso.containers import events
 from plaso.lib import specification
 from plaso.parsers import interface
 from plaso.parsers import logger
 from plaso.parsers import manager
 from plaso.parsers import plugins
@@ -325,15 +325,15 @@
     path_spec = database_file_entry.path_spec
     location = getattr(path_spec, 'location', None)
     if not path_spec or not location:
       return None, None
 
     location_wal = '{0:s}-wal'.format(location)
     file_system = database_file_entry.GetFileSystem()
-    wal_path_spec = dfvfs_factory.Factory.NewPathSpec(
+    wal_path_spec = path_spec_factory.Factory.NewPathSpec(
         file_system.type_indicator, parent=path_spec.parent,
         location=location_wal)
 
     wal_file_entry = file_system.GetFileEntryByPathSpec(wal_path_spec)
     if not wal_file_entry:
       return None, None
 
@@ -434,15 +434,15 @@
       parser_mediator.ProduceExtractionWarning(
           'unable to open SQLite database with error: {0!s}'.format(exception))
       return
 
     # Create a cache in which the resulting tables are cached.
     cache = SQLiteCache()
 
-    display_name = parser_mediator.GetDisplayName(file_entry)
+    display_name = parser_mediator.GetDisplayName(file_entry=file_entry)
 
     try:
       for plugin in self._plugins_per_name.values():
         self._ParseFileEntryWithPlugin(
             parser_mediator, plugin, database, display_name, cache)
     finally:
       database.Close()
@@ -461,15 +461,15 @@
     event_data_stream.path_spec = wal_file_entry.path_spec
 
     parser_mediator.ProduceEventDataStream(event_data_stream)
 
     # Create a cache in which the resulting tables are cached.
     cache = SQLiteCache()
 
-    display_name = parser_mediator.GetDisplayName(wal_file_entry)
+    display_name = parser_mediator.GetDisplayName(file_entry=wal_file_entry)
 
     try:
       for plugin in self._plugins_per_name.values():
         self._ParseFileEntryWithPlugin(
             parser_mediator, plugin, database_wal, display_name, cache)
     finally:
       database_wal.Close()
```

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/__init__.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 from plaso.parsers.sqlite_plugins import chrome_history
 from plaso.parsers.sqlite_plugins import dropbox
 from plaso.parsers.sqlite_plugins import firefox_cookies
 from plaso.parsers.sqlite_plugins import firefox_downloads
 from plaso.parsers.sqlite_plugins import firefox_history
 from plaso.parsers.sqlite_plugins import gdrive
 from plaso.parsers.sqlite_plugins import imessage
+from plaso.parsers.sqlite_plugins import ios_datausage
 from plaso.parsers.sqlite_plugins import ios_kik
 from plaso.parsers.sqlite_plugins import ios_netusage
 from plaso.parsers.sqlite_plugins import ios_powerlog
 from plaso.parsers.sqlite_plugins import ios_screentime
 from plaso.parsers.sqlite_plugins import ios_twitter
 from plaso.parsers.sqlite_plugins import kodi
 from plaso.parsers.sqlite_plugins import ls_quarantine
```

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/android_calls.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/android_calls.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/android_hangouts.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/android_hangouts.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/android_sms.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/android_sms.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/android_tango.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/android_tango.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/android_twitter.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/android_twitter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/android_webview.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/android_webview.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/android_webviewcache.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/android_webviewcache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/chrome_autofill.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/chrome_autofill.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/chrome_cookies.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/chrome_cookies.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/chrome_extension_activity.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/chrome_extension_activity.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/chrome_history.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/chrome_history.py`

 * *Files 0% similar despite different names*

```diff
@@ -60,17 +60,19 @@
     last_visited_time (dfdatetime.DateTimeValues): date and time the URL was
         last visited.
     offset (str): identifier of the row, from which the event data was
         extracted.
     page_transition_type (int): type of transitions between pages.
     query (str): SQL query that was used to obtain the event data.
     title (str): title of the visited page.
-    typed_count (int): number of characters of the URL that were typed.
+    typed_count (int): number of times the user has navigated to
+        the page by typing in the address.
     url (str): URL of the visited page.
     url_hidden (bool): True if the URL is hidden.
+    visit_count (int): number of times the user has navigated to this page.
     visit_source (int): source of the page visit.
   """
 
   DATA_TYPE = 'chrome:history:page_visited'
 
   def __init__(self):
     """Initializes event data."""
@@ -81,14 +83,15 @@
     self.offset = None
     self.page_transition_type = None
     self.query = None
     self.title = None
     self.typed_count = None
     self.url = None
     self.url_hidden = None
+    self.visit_count = None
     self.visit_source = None
 
 
 class BaseGoogleChromeHistoryPlugin(interface.SQLitePlugin):
   """SQLite parser plugin for Google Chrome history database files.
 
   The Google Chrome history database file is typically stored in:
@@ -229,14 +232,15 @@
     event_data.query = query
     event_data.page_transition_type = (
         transition & self._PAGE_TRANSITION_CORE_MASK)
     event_data.title = self._GetRowValue(query_hash, row, 'title')
     event_data.typed_count = self._GetRowValue(query_hash, row, 'typed_count')
     event_data.url = self._GetRowValue(query_hash, row, 'url')
     event_data.url_hidden = hidden == '1'
+    event_data.visit_count = self._GetRowValue(query_hash, row, 'visit_count')
     event_data.visit_source = self._GetVisitSource(
         visit_identifier, cache, database)
 
     parser_mediator.ProduceEventData(event_data)
 
 
 class GoogleChrome8HistoryPlugin(BaseGoogleChromeHistoryPlugin):
```

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/dropbox.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/dropbox.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/firefox_cookies.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/firefox_cookies.py`

 * *Files 18% similar despite different names*

```diff
@@ -47,43 +47,17 @@
     self.offset = None
     self.path = None
     self.query = None
     self.secure = None
     self.url = None
 
 
-class FirefoxCookiePlugin(
+class BaseFirefoxCookiePlugin(
     interface.SQLitePlugin, cookie_plugins_helper.CookiePluginsHelper):
-  """SQLite parser plugin for Mozilla Firefox cookies database files.
-
-  Also see:
-    https://hg.mozilla.org/mozilla-central/file/349a2f003529/netwerk/cookie/nsCookie.h
-  """
-
-  NAME = 'firefox_cookies'
-  DATA_FORMAT = 'Mozilla Firefox cookies SQLite database file'
-
-  REQUIRED_STRUCTURE = {
-      'moz_cookies': frozenset([
-          'id', 'baseDomain', 'name', 'value', 'host', 'path', 'expiry',
-          'lastAccessed', 'creationTime', 'isSecure', 'isHttpOnly'])}
-
-  QUERIES = [
-      (('SELECT id, baseDomain, name, value, host, path, expiry, '
-        'lastAccessed, creationTime, isSecure, isHttpOnly FROM moz_cookies'),
-       'ParseCookieRow')]
-
-  SCHEMAS = [{
-      'moz_cookies': (
-          'CREATE TABLE moz_cookies (id INTEGER PRIMARY KEY, baseDomain TEXT, '
-          'appId INTEGER DEFAULT 0, inBrowserElement INTEGER DEFAULT 0, name '
-          'TEXT, value TEXT, host TEXT, path TEXT, expiry INTEGER, '
-          'lastAccessed INTEGER, creationTime INTEGER, isSecure INTEGER, '
-          'isHttpOnly INTEGER, CONSTRAINT moz_uniqueid UNIQUE (name, host, '
-          'path, appId, inBrowserElement))')}]
+  """Shared SQLite parser plugin for Mozilla Firefox cookies database files."""
 
   def _GetPosixTimeDateTimeRowValue(self, query_hash, row, value_name):
     """Retrieves a POSIX time (in seconds) date and time value from the row.
 
     Args:
       query_hash (int): hash of the query, that uniquely identifies the query
           that produced the row.
@@ -172,8 +146,71 @@
         query_hash, row, 'expiry')
 
     parser_mediator.ProduceEventData(event_data)
 
     self._ParseCookie(parser_mediator, cookie_name, cookie_data, url)
 
 
-sqlite.SQLiteParser.RegisterPlugin(FirefoxCookiePlugin)
+class FirefoxCookie2Plugin(BaseFirefoxCookiePlugin):
+  """SQLite parser plugin for Mozilla Firefox cookies schema 2 databases.
+
+  Also see:
+    https://hg.mozilla.org/mozilla-central/file/349a2f003529/netwerk/cookie/nsCookie.h
+  """
+
+  NAME = 'firefox_2_cookies'
+  DATA_FORMAT = 'Mozilla Firefox cookies SQLite database file version 2'
+
+  REQUIRED_STRUCTURE = {
+      'moz_cookies': frozenset([
+          'id', 'baseDomain', 'name', 'value', 'host', 'path', 'expiry',
+          'lastAccessed', 'creationTime', 'isSecure', 'isHttpOnly'])}
+
+  QUERIES = [
+      (('SELECT id, baseDomain, name, value, host, path, expiry, '
+        'lastAccessed, creationTime, isSecure, isHttpOnly FROM moz_cookies'),
+       'ParseCookieRow')]
+
+  SCHEMAS = [{
+      'moz_cookies': (
+          'CREATE TABLE moz_cookies (id INTEGER PRIMARY KEY, baseDomain TEXT, '
+          'appId INTEGER DEFAULT 0, inBrowserElement INTEGER DEFAULT 0, name '
+          'TEXT, value TEXT, host TEXT, path TEXT, expiry INTEGER, '
+          'lastAccessed INTEGER, creationTime INTEGER, isSecure INTEGER, '
+          'isHttpOnly INTEGER, CONSTRAINT moz_uniqueid UNIQUE (name, host, '
+          'path, appId, inBrowserElement))')}]
+
+
+class FirefoxCookie10Plugin(BaseFirefoxCookiePlugin):
+  """SQLite parser plugin for Mozilla Firefox cookies schema 10 databases.
+  
+  In schema 10 baseDomain was removed.
+  
+  Also see:
+    https://searchfox.org/mozilla-central/source/netwerk/cookie/CookiePersistentStorage.cpp
+  """
+
+  NAME = 'firefox_10_cookies'
+  DATA_FORMAT = 'Mozilla Firefox cookies SQLite database file version 10'
+
+  REQUIRED_STRUCTURE = {
+      'moz_cookies': frozenset([
+          'id', 'name', 'value', 'host', 'path', 'expiry',
+          'lastAccessed', 'creationTime', 'isSecure', 'isHttpOnly'])}
+
+  QUERIES = [
+      (('SELECT id, name, value, host, path, expiry, '
+        'lastAccessed, creationTime, isSecure, isHttpOnly FROM moz_cookies'),
+       'ParseCookieRow')]
+
+  SCHEMAS = [{
+      'moz_cookies': (
+          'CREATE TABLE moz_cookies (id INTEGER PRIMARY KEY, '
+          'appId INTEGER DEFAULT 0, inBrowserElement INTEGER DEFAULT 0, name '
+          'TEXT, value TEXT, host TEXT, path TEXT, expiry INTEGER, '
+          'lastAccessed INTEGER, creationTime INTEGER, isSecure INTEGER, '
+          'isHttpOnly INTEGER, CONSTRAINT moz_uniqueid UNIQUE (name, host, '
+          'path, appId, inBrowserElement))')}]
+
+
+sqlite.SQLiteParser.RegisterPlugins([
+    FirefoxCookie2Plugin, FirefoxCookie10Plugin])
```

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/firefox_downloads.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/firefox_downloads.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/firefox_history.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/firefox_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/gdrive.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/gdrive.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/interface.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/ios_kik.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/ios_kik.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/ios_netusage.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/ios_netusage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/ios_powerlog.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/ios_powerlog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/ios_screentime.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/ios_screentime.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/ios_twitter.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/ios_twitter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/kodi.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/kodi.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/ls_quarantine.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/ls_quarantine.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/mackeeper_cache.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/mackeeper_cache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/macos_appusage.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/macos_appusage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/macos_document_versions.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/macos_document_versions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/macos_knowledgec.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/macos_knowledgec.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/macos_notes.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/macos_notes.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/macos_notification_center.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/macos_notification_center.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/macos_tcc.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/macos_tcc.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/safari.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/safari.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/skype.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/skype.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/windows_eventtranscript.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/windows_eventtranscript.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/windows_timeline.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/windows_timeline.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/sqlite_plugins/zeitgeist.py` & `plaso-20230717/plaso/parsers/sqlite_plugins/zeitgeist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/symantec.py` & `plaso-20230717/plaso/parsers/symantec.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/systemd_journal.py` & `plaso-20230717/plaso/parsers/systemd_journal.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/systemd_journal.yaml` & `plaso-20230717/plaso/parsers/systemd_journal.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_parser.py` & `plaso-20230717/plaso/parsers/text_parser.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,19 +13,23 @@
 from plaso.parsers import manager
 
 
 class EncodedTextReader(object):
   """Encoded text reader.
 
   Attributes:
+    line_number (int): current line number.
     lines (str): lines of text.
+    lines_size (int): size of the lines of text.
   """
 
   BUFFER_SIZE = 65536
 
+  _READ_BUFFER_SIZE = 16 * BUFFER_SIZE
+
   def __init__(
       self, file_object, encoding='utf-8', encoding_errors='strict'):
     """Initializes the encoded text reader object.
 
     Args:
       file_object (FileIO): a file-like object to read from.
       encoding (Optional[str]): text encoding.
@@ -34,65 +38,73 @@
     stream_reader_class = codecs.getreader(encoding)
 
     super(EncodedTextReader, self).__init__()
     self._file_object = file_object
     self._stream_reader = stream_reader_class(
         file_object, errors=encoding_errors)
 
-    self.lines = ''
     self.line_number = 0
+    self.lines = ''
+    self.lines_size = 0
 
   def ReadLine(self):
     """Reads a line.
 
     Returns:
       str: line read from the lines buffer.
     """
     if not self.lines:
       self.ReadLines()
 
     line, _, self.lines = self.lines.partition('\n')
+    self.lines_size += len(line) + 1
     self.line_number += 1
 
     return line
 
   def ReadLines(self):
     """Reads lines into the lines buffer."""
-    current_offset = self._file_object.tell()
+    if self.lines_size < self.BUFFER_SIZE:
+      current_offset = self._file_object.tell()
 
-    decoded_data = self._stream_reader.read(size=self.BUFFER_SIZE)
-    if decoded_data:
-      # Remove a byte-order mark at the start of the file.
-      if current_offset == 0 and decoded_data[0] == '\ufeff':
-        decoded_data = decoded_data[1:]
-
-      # Strip carriage returns from the text.
-      decoded_data = '\n'.join([
-          line.rstrip('\r') for line in decoded_data.split('\n')])
+      # Consequative reads, decodes and joins are expensive hence we read
+      # a larger buffer at once.
+      decoded_data = self._stream_reader.read(size=self._READ_BUFFER_SIZE)
+      if decoded_data:
+        # Remove a byte-order mark at the start of the file.
+        if current_offset == 0 and decoded_data[0] == '\ufeff':
+          decoded_data = decoded_data[1:]
+
+        # Strip carriage returns from the text.
+        decoded_data = '\n'.join([
+            line.rstrip('\r') for line in decoded_data.split('\n')])
 
-      self.lines = ''.join([self.lines, decoded_data])
+        self.lines = ''.join([self.lines, decoded_data])
+        self.lines_size += len(decoded_data)
 
   def SkipAhead(self, number_of_characters):
     """Skips ahead a number of characters.
 
     Args:
       number_of_characters (int): number of characters.
     """
-    lines_size = len(self.lines)
-    while number_of_characters >= lines_size:
-      number_of_characters -= lines_size
+    while number_of_characters >= self.lines_size:
+      number_of_characters -= self.lines_size
 
       self.lines = ''
+      self.lines_size = 0
+
       self.ReadLines()
-      lines_size = len(self.lines)
-      if lines_size == 0:
+
+      if self.lines_size == 0:
         return
 
     self.line_number += self.lines[:number_of_characters].count('\n')
     self.lines = self.lines[number_of_characters:]
+    self.lines_size -= number_of_characters
 
   # Note: that the following functions do not follow the style guide
   # because they are part of the file-like object interface.
   # pylint: disable=invalid-name
 
   def get_offset(self):
     """Retrieves the current offset into the file-like object.
@@ -148,15 +160,17 @@
     scanner_object = pysigscan.scanner()
     scanner_object.set_scan_buffer_size(65536)
 
     for plugin_name, plugin in self._plugins_per_name.items():
       if not plugin.VERIFICATION_LITERALS:
         self._non_sigscan_plugin_names.add(plugin_name)
       else:
-        encoding = plugin.ENCODING or parser_mediator.codepage
+        encoding = plugin.ENCODING
+        if not encoding:
+          encoding = parser_mediator.GetCodePage()
 
         for index, literal in enumerate(plugin.VERIFICATION_LITERALS):
           identifier = '{0:s}{1:d}'.format(plugin_name, index)
           encoded_literal = literal.encode(encoding)
           scanner_object.add_signature(
               identifier, 0, encoded_literal,
               pysigscan.signature_flags.NO_OFFSET)
@@ -238,15 +252,15 @@
 
     matching_plugin = False
     for encoding, plugins in self._plugins_per_encoding.items():
       if parser_mediator.abort:
         break
 
       if encoding == 'default':
-        encoding = parser_mediator.codepage
+        encoding = parser_mediator.GetCodePage()
 
       text_reader = None
 
       for plugin in plugins:
         if parser_mediator.abort:
           break
```

### Comparing `plaso-20230311/plaso/parsers/text_plugins/__init__.py` & `plaso-20230717/plaso/parsers/text_plugins/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 from plaso.parsers.text_plugins import ios_logd
 from plaso.parsers.text_plugins import ios_sysdiag_log
 from plaso.parsers.text_plugins import macos_appfirewall
 from plaso.parsers.text_plugins import macos_securityd
 from plaso.parsers.text_plugins import macos_wifi
 from plaso.parsers.text_plugins import popcontest
 from plaso.parsers.text_plugins import postgresql
+from plaso.parsers.text_plugins import powershell_transcript
 from plaso.parsers.text_plugins import santa
 from plaso.parsers.text_plugins import sccm
 from plaso.parsers.text_plugins import selinux
 from plaso.parsers.text_plugins import setupapi
 from plaso.parsers.text_plugins import skydrivelog
 from plaso.parsers.text_plugins import snort_fastlog
 from plaso.parsers.text_plugins import sophos_av
```

### Comparing `plaso-20230311/plaso/parsers/text_plugins/android_logcat.py` & `plaso-20230717/plaso/parsers/text_plugins/android_logcat.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/apache_access.py` & `plaso-20230717/plaso/parsers/text_plugins/apache_access.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/apt_history.py` & `plaso-20230717/plaso/parsers/text_plugins/apt_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/aws_elb_access.py` & `plaso-20230717/plaso/parsers/text_plugins/aws_elb_access.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/bash_history.py` & `plaso-20230717/plaso/parsers/text_plugins/bash_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/confluence_access.py` & `plaso-20230717/plaso/parsers/text_plugins/confluence_access.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/dpkg.py` & `plaso-20230717/plaso/parsers/text_plugins/dpkg.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/gdrive_synclog.py` & `plaso-20230717/plaso/parsers/text_plugins/gdrive_synclog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/google_logging.py` & `plaso-20230717/plaso/parsers/text_plugins/google_logging.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/iis.py` & `plaso-20230717/plaso/parsers/text_plugins/iis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/interface.py` & `plaso-20230717/plaso/parsers/text_plugins/interface.py`

 * *Files 2% similar despite different names*

```diff
@@ -353,15 +353,18 @@
     self._parser_mediator = parser_mediator
 
     try:
       # Set the offset to the beginning of the file.
       file_object.seek(0, os.SEEK_SET)
       self._current_offset = 0
 
-      encoding = self.ENCODING or parser_mediator.codepage
+      encoding = self.ENCODING
+      if not encoding:
+        encoding = parser_mediator.GetCodePage()
+
       text_reader = text_parser.EncodedTextReader(
           file_object, encoding=encoding, encoding_errors='text_parser_handler')
 
       try:
         text_reader.ReadLines()
         self._current_offset = text_reader.get_offset()
       except UnicodeDecodeError as exception:
```

### Comparing `plaso-20230311/plaso/parsers/text_plugins/ios_lockdownd.py` & `plaso-20230717/plaso/parsers/text_plugins/ios_lockdownd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/ios_logd.py` & `plaso-20230717/plaso/parsers/text_plugins/ios_logd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/ios_sysdiag_log.py` & `plaso-20230717/plaso/parsers/text_plugins/ios_sysdiag_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/macos_appfirewall.py` & `plaso-20230717/plaso/parsers/text_plugins/macos_appfirewall.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/macos_securityd.py` & `plaso-20230717/plaso/parsers/text_plugins/macos_securityd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/macos_wifi.py` & `plaso-20230717/plaso/parsers/text_plugins/macos_wifi.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/popcontest.py` & `plaso-20230717/plaso/parsers/text_plugins/popcontest.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/postgresql.py` & `plaso-20230717/plaso/parsers/text_plugins/postgresql.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/santa.py` & `plaso-20230717/plaso/parsers/text_plugins/santa.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/sccm.py` & `plaso-20230717/plaso/parsers/text_plugins/sccm.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/selinux.py` & `plaso-20230717/plaso/parsers/text_plugins/selinux.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/setupapi.py` & `plaso-20230717/plaso/parsers/text_plugins/setupapi.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/skydrivelog.py` & `plaso-20230717/plaso/parsers/text_plugins/skydrivelog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/snort_fastlog.py` & `plaso-20230717/plaso/parsers/text_plugins/snort_fastlog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/sophos_av.py` & `plaso-20230717/plaso/parsers/text_plugins/sophos_av.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/syslog.py` & `plaso-20230717/plaso/parsers/text_plugins/syslog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/viminfo.py` & `plaso-20230717/plaso/parsers/text_plugins/viminfo.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/vsftpd.py` & `plaso-20230717/plaso/parsers/text_plugins/vsftpd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/winfirewall.py` & `plaso-20230717/plaso/parsers/text_plugins/winfirewall.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/xchatlog.py` & `plaso-20230717/plaso/parsers/text_plugins/xchatlog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/xchatscrollback.py` & `plaso-20230717/plaso/parsers/text_plugins/xchatscrollback.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/text_plugins/zsh_extended_history.py` & `plaso-20230717/plaso/parsers/text_plugins/zsh_extended_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/trendmicroav.py` & `plaso-20230717/plaso/parsers/trendmicroav.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/utmp.py` & `plaso-20230717/plaso/parsers/utmp.py`

 * *Files 8% similar despite different names*

```diff
@@ -91,36 +91,36 @@
       raise errors.ParseError((
           'Unable to parse utmp entry at offset: 0x{0:08x} with error: '
           '{1!s}.').format(file_offset, exception))
 
     if entry.type not in self._SUPPORTED_TYPES:
       raise errors.ParseError('Unsupported type: {0:d}'.format(entry.type))
 
-    encoding = parser_mediator.codepage or 'utf-8'
+    code_page = parser_mediator.GetCodePage()
 
     try:
       username = entry.username.split(b'\x00')[0]
-      username = username.decode(encoding).rstrip()
+      username = username.decode(code_page).rstrip()
     except UnicodeDecodeError:
       warning_strings.append('unable to decode username string')
       username = None
 
     try:
       terminal = entry.terminal.split(b'\x00')[0]
-      terminal = terminal.decode(encoding).rstrip()
+      terminal = terminal.decode(code_page).rstrip()
     except UnicodeDecodeError:
       warning_strings.append('unable to decode terminal string')
       terminal = None
 
     if terminal == '~':
       terminal = 'system boot'
 
     try:
       hostname = entry.hostname.split(b'\x00')[0]
-      hostname = hostname.decode(encoding).rstrip()
+      hostname = hostname.decode(code_page).rstrip()
     except UnicodeDecodeError:
       warning_strings.append('unable to decode hostname string')
       hostname = None
 
     if not hostname or hostname == ':0':
       hostname = 'localhost'
```

### Comparing `plaso-20230311/plaso/parsers/utmp.yaml` & `plaso-20230717/plaso/parsers/utmp.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/utmpx.py` & `plaso-20230717/plaso/parsers/utmpx.py`

 * *Files 2% similar despite different names*

```diff
@@ -83,38 +83,38 @@
       raise errors.ParseError((
           'Unable to parse utmpx entry at offset: 0x{0:08x} with error: '
           '{1!s}.').format(file_offset, exception))
 
     if entry.type not in self._SUPPORTED_TYPES:
       raise errors.ParseError('Unsupported type: {0:d}'.format(entry.type))
 
-    encoding = parser_mediator.codepage or 'utf8'
+    code_page = parser_mediator.GetCodePage()
 
     try:
       username = entry.username.split(b'\x00')[0]
-      username = username.decode(encoding).rstrip()
+      username = username.decode(code_page).rstrip()
     except UnicodeDecodeError:
       parser_mediator.ProduceExtractionWarning(
           'unable to decode username string')
       username = None
 
     try:
       terminal = entry.terminal.split(b'\x00')[0]
-      terminal = terminal.decode(encoding).rstrip()
+      terminal = terminal.decode(code_page).rstrip()
     except UnicodeDecodeError:
       parser_mediator.ProduceExtractionWarning(
           'unable to decode terminal string')
       terminal = None
 
     if terminal == '~':
       terminal = 'system boot'
 
     try:
       hostname = entry.hostname.split(b'\x00')[0]
-      hostname = hostname.decode(encoding).rstrip()
+      hostname = hostname.decode(code_page).rstrip()
     except UnicodeDecodeError:
       parser_mediator.ProduceExtractionWarning(
           'unable to decode hostname string')
       hostname = None
 
     if not hostname:
       hostname = 'localhost'
```

### Comparing `plaso-20230311/plaso/parsers/windefender_history.py` & `plaso-20230717/plaso/parsers/windefender_history.py`

 * *Files 1% similar despite different names*

```diff
@@ -69,15 +69,15 @@
        12: 'Domain user1',
        14: 'Process name',
        18: 'Initial detection time',
        20: 'Remediation time',
        24: 'Domain user2'}]
 
   _DEFINITION_FILE = os.path.join(
-      os.path.dirname(__file__), 'detection_history.yaml')
+      os.path.dirname(__file__), 'windefender_history.yaml')
 
   _VALUE_DATA_TYPE_BINARY_DATA = 0x00000028
   _VALUE_DATA_TYPE_FILETIME = 0x0000000a
   _VALUE_DATA_TYPE_GUID = 0x0000001e
   _VALUE_DATA_TYPE_STRING = 0x00000015
 
   _VALUE_DATA_TYPES_INTEGER = frozenset([
```

### Comparing `plaso-20230311/plaso/parsers/winevt.py` & `plaso-20230717/plaso/parsers/winevt.py`

 * *Files 2% similar despite different names*

```diff
@@ -78,15 +78,15 @@
 
   def _GetEventData(
       self, parser_mediator, record_index, evt_record, recovered=False):
     """Retrieves event data from the Windows EventLog (EVT) record.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       record_index (int): event record index.
       evt_record (pyevt.record): event record.
       recovered (Optional[bool]): True if the record was recovered.
 
     Returns:
       WinEvtRecordEventData: event data.
     """
@@ -142,15 +142,15 @@
 
   def _ParseRecord(
       self, parser_mediator, record_index, evt_record, recovered=False):
     """Parses a Windows EventLog (EVT) record.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       record_index (int): event record index.
       evt_record (pyevt.record): event record.
       recovered (Optional[bool]): True if the record was recovered.
     """
     event_data = self._GetEventData(
         parser_mediator, record_index, evt_record, recovered=recovered)
 
@@ -191,15 +191,15 @@
     parser_mediator.ProduceEventData(event_data)
 
   def _ParseRecords(self, parser_mediator, evt_file):
     """Parses Windows EventLog (EVT) records.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       evt_file (pyevt.file): Windows EventLog (EVT) file.
     """
     # To handle errors when parsing a Windows EventLog (EVT) file in the most
     # granular way the following code iterates over every event record. The
     # call to evt_file.get_record() and access to members of evt_record should
     # be called within a try-except.
 
@@ -229,19 +229,21 @@
             '{1!s}').format(record_index, exception))
 
   def ParseFileObject(self, parser_mediator, file_object):
     """Parses a Windows EventLog (EVT) file-like object.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): a file-like object.
     """
+    code_page = parser_mediator.GetCodePage()
+
     evt_file = pyevt.file()
-    evt_file.set_ascii_codepage(parser_mediator.codepage)
+    evt_file.set_ascii_codepage(code_page)
 
     try:
       evt_file.open_file_object(file_object)
     except IOError as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to open file with error: {0!s}'.format(exception))
       return
```

### Comparing `plaso-20230311/plaso/parsers/winevtx.py` & `plaso-20230717/plaso/parsers/winevtx.py`

 * *Files 1% similar despite different names*

```diff
@@ -67,15 +67,15 @@
 
   def _GetEventDataFromRecord(
       self, parser_mediator, record_index, evtx_record, recovered=False):
     """Extract data from a Windows XML EventLog (EVTX) record.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       record_index (int): event record index.
       evtx_record (pyevtx.record): event record.
       recovered (Optional[bool]): True if the record was recovered.
 
     Return:
       WinEvtxRecordEventData: event data.
     """
@@ -148,15 +148,15 @@
 
   def _ParseRecord(
       self, parser_mediator, record_index, evtx_record, recovered=False):
     """Extract data from a Windows XML EventLog (EVTX) record.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       record_index (int): event record index.
       evtx_record (pyevtx.record): event record.
       recovered (Optional[bool]): True if the record was recovered.
     """
     event_data = self._GetEventDataFromRecord(
         parser_mediator, record_index, evtx_record, recovered=recovered)
 
@@ -197,15 +197,15 @@
     parser_mediator.ProduceEventData(event_data)
 
   def _ParseRecords(self, parser_mediator, evtx_file):
     """Parses Windows XML EventLog (EVTX) records.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       evtx_file (pyevtx.file): Windows XML EventLog (EVTX) file.
     """
     # To handle errors when parsing a Windows XML EventLog (EVTX) file in the
     # most granular way the following code iterates over every event record.
     # The call to evt_file.get_record() and access to members of evt_record
     # should be called within a try-except.
 
@@ -248,19 +248,21 @@
     return format_specification
 
   def ParseFileObject(self, parser_mediator, file_object):
     """Parses a Windows XML EventLog (EVTX) file-like object.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
-          and other components, such as storage and dfvfs.
+          and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): a file-like object.
     """
+    code_page = parser_mediator.GetCodePage()
+
     evtx_file = pyevtx.file()
-    evtx_file.set_ascii_codepage(parser_mediator.codepage)
+    evtx_file.set_ascii_codepage(code_page)
 
     try:
       evtx_file.open_file_object(file_object)
     except IOError as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to open file with error: {0!s}'.format(exception))
       return
```

### Comparing `plaso-20230311/plaso/parsers/winjob.py` & `plaso-20230717/plaso/parsers/winjob.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winjob.yaml` & `plaso-20230717/plaso/parsers/winjob.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winlnk.py` & `plaso-20230717/plaso/parsers/winlnk.py`

 * *Files 2% similar despite different names*

```diff
@@ -147,16 +147,18 @@
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       file_object (dfvfs.FileIO): file-like object.
       display_name (str): display name.
     """
+    code_page = parser_mediator.GetCodePage()
+
     lnk_file = pylnk.file()
-    lnk_file.set_ascii_codepage(parser_mediator.codepage)
+    lnk_file.set_ascii_codepage(code_page)
 
     try:
       lnk_file.open_file_object(file_object)
     except IOError as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to open file with error: {0!s}'.format(exception))
       return
@@ -165,15 +167,15 @@
     if lnk_file.link_target_identifier_data:  # pylint: disable=using-constant-test
       # TODO: change file_entry.name to display name once it is generated
       # correctly.
       display_name = parser_mediator.GetFilename()
       shell_items_parser = shell_items.ShellItemsParser(display_name)
       shell_items_parser.ParseByteStream(
           parser_mediator, lnk_file.link_target_identifier_data,
-          codepage=parser_mediator.codepage)
+          codepage=code_page)
 
       link_target = shell_items_parser.CopyToPath()
 
     event_data = WinLnkLinkEventData()
     event_data.access_time = self._GetDateTime(
         lnk_file.get_file_access_time_as_integer())
     event_data.birth_droid_file_identifier = (
```

### Comparing `plaso-20230311/plaso/parsers/winprefetch.py` & `plaso-20230717/plaso/parsers/winprefetch.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_parser.py` & `plaso-20230717/plaso/parsers/winreg_parser.py`

 * *Files 1% similar despite different names*

```diff
@@ -237,19 +237,18 @@
   def ParseFileObject(self, parser_mediator, file_object):
     """Parses a Windows Registry file-like object.
 
     Args:
       parser_mediator (ParserMediator): parser mediator.
       file_object (dfvfs.FileIO): a file-like object.
     """
-    registry_find_specs = getattr(
-        parser_mediator.collection_filters_helper, 'registry_find_specs', None)
+    code_page = parser_mediator.GetCodePage()
 
     registry_file = dfwinreg_regf.REGFWinRegistryFile(
-        ascii_codepage=parser_mediator.codepage, emulate_virtual_keys=False)
+        ascii_codepage=code_page, emulate_virtual_keys=False)
 
     try:
       registry_file.Open(file_object)
     except IOError as exception:
       parser_mediator.ProduceExtractionWarning(
           'unable to open Windows Registry file with error: {0!s}'.format(
               exception))
@@ -262,15 +261,15 @@
       registry_file.SetKeyPathPrefix(key_path_prefix)
       root_key = registry_file.GetRootKey()
       if root_key:
         # For now treat AMCache.hve separately.
         if root_key.name.lower() in self._AMCACHE_ROOT_KEY_NAMES:
           self._ParseRecurseKeys(parser_mediator, root_key)
 
-        elif not registry_find_specs:
+        elif not parser_mediator.registry_find_specs:
           self._ParseRecurseKeys(parser_mediator, root_key)
 
         elif not self._ARTIFACTS_FILTER_HELPER.CheckKeyCompatibility(
             key_path_prefix):
           logger.warning((
               'Artifacts filters are not supported for Windows Registry '
               'file with key path prefix: "{0:s}".').format(
@@ -278,15 +277,16 @@
 
         else:
           win_registry.MapFile(key_path_prefix, registry_file)
           # Note that win_registry will close the mapped registry_file.
           registry_file = None
 
           self._ParseKeysFromFindSpecs(
-              parser_mediator, win_registry, registry_find_specs)
+              parser_mediator, win_registry,
+              parser_mediator.registry_find_specs)
 
     except IOError as exception:
       parser_mediator.ProduceExtractionWarning('{0!s}'.format(exception))
 
     finally:
       if registry_file:
         registry_file.Close()
```

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/__init__.py` & `plaso-20230717/plaso/parsers/winreg_plugins/__init__.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/amcache.py` & `plaso-20230717/plaso/parsers/winreg_plugins/amcache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/appcompatcache.py` & `plaso-20230717/plaso/parsers/winreg_plugins/appcompatcache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/appcompatcache.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/appcompatcache.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/bagmru.py` & `plaso-20230717/plaso/parsers/winreg_plugins/bagmru.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/bam.py` & `plaso-20230717/plaso/parsers/winreg_plugins/bam.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/ccleaner.py` & `plaso-20230717/plaso/parsers/winreg_plugins/ccleaner.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/default.py` & `plaso-20230717/plaso/parsers/winreg_plugins/default.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/interface.py` & `plaso-20230717/plaso/parsers/winreg_plugins/interface.py`

 * *Files 6% similar despite different names*

```diff
@@ -245,42 +245,43 @@
     return registry_value.GetDataAsObject()
 
   def _GetValuesFromKey(
       self, parser_mediator, registry_key, names_to_skip=None):
     """Retrieves the values from a Windows Registry key.
 
     Where:
-    * the default value is represented as "(default)";
+    * the name of the default value is represented as an empty string;
     * binary data values are represented as "(# bytes)", where # contains
           the number of bytes of the data;
-    * empty values are represented as "(empty)".
+    * empty values are represented as None;
     * empty multi value string values are represented as "[]".
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       names_to_skip (Optional[list[str]]): names of values that should
           be skipped.
 
     Returns:
-      dict[str, object]: names and data of the values in the key.
+      list[tuple[str, str, str]]: name, data type and data pais of the values
+          in the key.
     """
     names_to_skip = [name.lower() for name in names_to_skip or []]
 
-    values_dict = {}
+    value_tuples = []
     for registry_value in registry_key.GetValues():
-      value_name = registry_value.name or '(default)'
+      value_name = registry_value.name or ''
       if value_name.lower() in names_to_skip:
         continue
 
       data_type_string = registry_value.data_type_string
 
       if registry_value.data is None:
-        value_string = '(empty)'
+        value_string = None
       else:
         try:
           value_object = registry_value.GetDataAsObject()
 
           if registry_value.DataIsMultiString():
             value_string = '[{0:s}]'.format(', '.join(value_object or []))
 
@@ -296,39 +297,34 @@
         except dfwinreg_errors.WinRegistryValueError as exception:
           parser_mediator.ProduceRecoveryWarning((
               'Unable to retrieve value data of type: {0:s} as object from '
               'value: {1:s} in key: {2:s} with error: {3!s}').format(
                   data_type_string, value_name, registry_key.path, exception))
           value_string = '({0:d} bytes)'.format(len(registry_value.data))
 
-      value_string = '[{0:s}] {1:s}'.format(data_type_string, value_string)
-      values_dict[value_name] = value_string
+      value_tuples.append((value_name, data_type_string, value_string))
 
-    return values_dict
+    return value_tuples or None
 
   def _ProduceDefaultWindowsRegistryEvent(
       self, parser_mediator, registry_key, names_to_skip=None):
     """Produces a default Windows Registry event.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       names_to_skip (Optional[list[str]]): names of values that should
           be skipped.
     """
-    values_dict = self._GetValuesFromKey(
-        parser_mediator, registry_key, names_to_skip=names_to_skip)
-
     event_data = windows_events.WindowsRegistryEventData()
     event_data.key_path = registry_key.path
     event_data.last_written_time = registry_key.last_written_time
-    event_data.values = ' '.join([
-        '{0:s}: {1!s}'.format(name, value)
-        for name, value in sorted(values_dict.items())]) or None
+    event_data.values = self._GetValuesFromKey(
+        parser_mediator, registry_key, names_to_skip=names_to_skip)
 
     parser_mediator.ProduceEventData(event_data)
 
   # pylint: disable=arguments-differ
   @abc.abstractmethod
   def ExtractEvents(self, parser_mediator, registry_key, **kwargs):
     """Extracts events from a Windows Registry key.
```

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/lfu.py` & `plaso-20230717/plaso/parsers/winreg_plugins/lfu.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/mountpoints.py` & `plaso-20230717/plaso/parsers/winreg_plugins/mountpoints.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/mru.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/mru.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/mrulist.py` & `plaso-20230717/plaso/parsers/winreg_plugins/mrulist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/mrulistex.py` & `plaso-20230717/plaso/parsers/winreg_plugins/mrulistex.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/msie_zones.py` & `plaso-20230717/plaso/parsers/winreg_plugins/msie_zones.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/network_drives.py` & `plaso-20230717/plaso/parsers/winreg_plugins/network_drives.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/networks.py` & `plaso-20230717/plaso/parsers/winreg_plugins/networks.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/officemru.py` & `plaso-20230717/plaso/parsers/winreg_plugins/officemru.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/outlook.py` & `plaso-20230717/plaso/parsers/winreg_plugins/outlook.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/programscache.py` & `plaso-20230717/plaso/parsers/winreg_plugins/programscache.py`

 * *Files 1% similar despite different names*

```diff
@@ -65,14 +65,16 @@
           and other components, such as storage and dfVFS.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       registry_value (dfwinreg.WinRegistryValue): Windows Registry value.
 
     Raises:
       ParseError: if the value data could not be parsed.
     """
+    code_page = parser_mediator.GetCodePage()
+
     value_data = registry_value.data
 
     value_data_size = len(value_data)
     if value_data_size < 4:
       return
 
     header_map = self._GetDataTypeMap('programscache_header')
@@ -143,16 +145,15 @@
       value_data_offset += context.byte_size
 
       display_name = '{0:s} {1:s}'.format(
           registry_key.path, registry_value.name)
 
       shell_items_parser = shell_items.ShellItemsParser(display_name)
       shell_items_parser.ParseByteStream(
-          parser_mediator, value_data[value_data_offset:],
-          codepage=parser_mediator.codepage)
+          parser_mediator, value_data[value_data_offset:], codepage=code_page)
 
       link_target = shell_items_parser.CopyToPath()
       if link_target:
         link_targets.append(link_target)
 
       value_data_offset += entry_header.data_size
```

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/programscache.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/programscache.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/run.py` & `plaso-20230717/plaso/parsers/winreg_plugins/run.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/sam_users.py` & `plaso-20230717/plaso/parsers/winreg_plugins/sam_users.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/sam_users.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/sam_users.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/services.py` & `plaso-20230717/plaso/parsers/winreg_plugins/services.py`

 * *Files 3% similar despite different names*

```diff
@@ -18,14 +18,16 @@
         time.
     name (str): name of the Windows driver or service.
     object_name (str): Windows service object name.
     service_dll (str): Windows service DLL.
     service_type (int): Windows driver or service type.
     start_type (int): Device or service start type.
     values (str): names and data of additional values in the key.
+    values (list[tuple[str, str, str]]): name, data type and data of the
+        additional values in the key.
   """
 
   DATA_TYPE = 'windows:registry:service'
 
   def __init__(self):
     """Initializes event data."""
     super(WindowsRegistryServiceEventData, self).__init__(
@@ -99,19 +101,15 @@
     event_data.last_written_time = registry_key.last_written_time
     event_data.name = registry_key.name
     event_data.object_name = self._GetValueFromKey(
         registry_key, 'ObjectName')
     event_data.service_type = service_type
     event_data.service_dll = self._GetServiceDll(registry_key)
     event_data.start_type = start_type
-
-    values_dict = self._GetValuesFromKey(
+    event_data.values = self._GetValuesFromKey(
          parser_mediator, registry_key, names_to_skip=[
             'ErrorControl', 'ImagePath', 'ObjectName', 'Start', 'Type'])
-    event_data.values = ' '.join([
-        '{0:s}: {1!s}'.format(name, value)
-        for name, value in sorted(values_dict.items())]) or None
 
     parser_mediator.ProduceEventData(event_data)
 
 
 winreg_parser.WinRegistryParser.RegisterPlugin(ServicesPlugin)
```

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/shutdown.py` & `plaso-20230717/plaso/parsers/winreg_plugins/shutdown.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/systemtime.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/systemtime.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/task_scheduler.py` & `plaso-20230717/plaso/parsers/winreg_plugins/task_scheduler.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/task_scheduler.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/task_scheduler.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/terminal_server.py` & `plaso-20230717/plaso/parsers/winreg_plugins/terminal_server.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/timezone.py` & `plaso-20230717/plaso/parsers/winreg_plugins/timezone.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/typedurls.py` & `plaso-20230717/plaso/parsers/winreg_plugins/typedurls.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/usb.py` & `plaso-20230717/plaso/parsers/winreg_plugins/usb.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/usbstor.py` & `plaso-20230717/plaso/parsers/winreg_plugins/usbstor.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/usbstor.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/usbstor.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/userassist.py` & `plaso-20230717/plaso/parsers/winreg_plugins/userassist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/userassist.yaml` & `plaso-20230717/plaso/parsers/winreg_plugins/userassist.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/windows_version.py` & `plaso-20230717/plaso/parsers/winreg_plugins/windows_version.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/winlogon.py` & `plaso-20230717/plaso/parsers/winreg_plugins/winlogon.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winreg_plugins/winrar.py` & `plaso-20230717/plaso/parsers/winreg_plugins/winrar.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/parsers/winrestore.py` & `plaso-20230717/plaso/parsers/winrestore.py`

 * *Files 1% similar despite different names*

```diff
@@ -64,16 +64,15 @@
     file_header_map = self._GetDataTypeMap('rp_log_file_header')
 
     try:
       file_header, _ = self._ReadStructureFromFileObject(
           file_object, 0, file_header_map)
     except (ValueError, errors.ParseError) as exception:
       raise errors.WrongParser(
-          'Unable to parse file header with error: {0!s}'.format(
-              exception))
+          'Unable to parse file header with error: {0!s}'.format(exception))
 
     file_footer_map = self._GetDataTypeMap('rp_log_file_footer')
 
     file_footer_offset = file_size - 8
 
     try:
       file_footer, _ = self._ReadStructureFromFileObject(
```

### Comparing `plaso-20230311/plaso/parsers/winrestore.yaml` & `plaso-20230717/plaso/parsers/winrestore.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/preprocessors/generic.py` & `plaso-20230717/plaso/preprocessors/generic.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/preprocessors/interface.py` & `plaso-20230717/plaso/preprocessors/interface.py`

 * *Files 15% similar despite different names*

```diff
@@ -32,15 +32,15 @@
   def _ParsePathSpecification(
       self, mediator, searcher, file_system, path_specification,
       path_separator):
     """Parses a file system for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       searcher (dfvfs.FileSystemSearcher): file system searcher to preprocess
           the file system.
       file_system (dfvfs.FileSystem): file system to be preprocessed.
       path_specification (dfvfs.PathSpec): path specification that contains
           the artifact value data.
       path_separator (str): path segment separator.
 
@@ -49,38 +49,50 @@
     """
 
   def Collect(self, mediator, artifact_definition, searcher, file_system):
     """Collects values using a file artifact definition.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       artifact_definition (artifacts.ArtifactDefinition): artifact definition.
       searcher (dfvfs.FileSystemSearcher): file system searcher to preprocess
           the file system.
       file_system (dfvfs.FileSystem): file system to be preprocessed.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
+    last_exception = None
+
     for source in artifact_definition.sources:
       if source.type_indicator not in (
           artifact_definitions.TYPE_INDICATOR_FILE,
           artifact_definitions.TYPE_INDICATOR_PATH):
         continue
 
       for path in source.paths:
         find_spec = file_system_searcher.FindSpec(
             case_sensitive=False, location_glob=path,
             location_separator=source.separator)
 
         for path_specification in searcher.Find(find_specs=[find_spec]):
-          self._ParsePathSpecification(
-              mediator, searcher, file_system, path_specification,
-              source.separator)
+          try:
+            self._ParsePathSpecification(
+                mediator, searcher, file_system, path_specification,
+                source.separator)
+
+            last_exception = None
+          except errors.PreProcessFail as exception:
+            last_exception = exception
+
+    if last_exception:
+      # Only raise an exception if none of the sources were successfully
+      # pre-processed.
+      raise last_exception
 
 
 class FileEntryArtifactPreprocessorPlugin(FileSystemArtifactPreprocessorPlugin):
   """File entry artifact preprocessor plugin interface.
 
   Shared functionality for preprocessing attributes based on a file entry
   artifact definition, such as file or path.
@@ -88,30 +100,30 @@
 
   @abc.abstractmethod
   def _ParseFileEntry(self, mediator, file_entry):
     """Parses a file entry for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_entry (dfvfs.FileEntry): file entry that contains the artifact
           value data.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
 
   def _ParsePathSpecification(
       self, mediator, searcher, file_system, path_specification,
       path_separator):
     """Parses a file system for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       searcher (dfvfs.FileSystemSearcher): file system searcher to preprocess
           the file system.
       file_system (dfvfs.FileSystem): file system to be preprocessed.
       path_specification (dfvfs.PathSpec): path specification that contains
           the artifact value data.
       path_separator (str): path segment separator.
 
@@ -145,28 +157,28 @@
 
   @abc.abstractmethod
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
 
   def _ParseFileEntry(self, mediator, file_entry):
     """Parses a file entry for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_entry (dfvfs.FileEntry): file entry that contains the artifact
           value data.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
     if not file_entry.IsFile():
@@ -187,30 +199,30 @@
 
   @abc.abstractmethod
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
 
   def Collect(
       self, mediator, artifact_definition, searcher):
     """Collects values using a Windows Registry value artifact definition.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       artifact_definition (artifacts.ArtifactDefinition): artifact definition.
       searcher (dfwinreg.WinRegistrySearcher): Windows Registry searcher to
           preprocess the Windows Registry.
 
     Raises:
       PreProcessFail: if the Windows Registry key or value cannot be read.
     """
@@ -261,15 +273,15 @@
   """
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
@@ -288,33 +300,34 @@
 
   @abc.abstractmethod
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
 
 
+# TODO: rename class.
 class KnowledgeBasePreprocessorPlugin(object):
   """The knowledge base preprocessor plugin interface.
 
   The knowledge base preprocessor determines preprocessing attributes based on
   other values in the knowledge base.
   """
 
   @abc.abstractmethod
   def Collect(self, mediator):
     """Collects values from the knowledge base.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
```

### Comparing `plaso-20230311/plaso/preprocessors/linux.py` & `plaso-20230717/plaso/preprocessors/linux.py`

 * *Files 6% similar despite different names*

```diff
@@ -21,15 +21,15 @@
   ARTIFACT_DEFINITION_NAME = 'LinuxHostnameFile'
 
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for a hostname preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     text_file_object = dfvfs_text_file.TextFile(file_object, encoding='utf-8')
@@ -47,15 +47,15 @@
   ARTIFACT_DEFINITION_NAME = 'LinuxDistributionRelease'
 
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for system product preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     text_file_object = dfvfs_text_file.TextFile(file_object, encoding='utf-8')
@@ -73,15 +73,15 @@
   ARTIFACT_DEFINITION_NAME = 'LinuxIssueFile'
 
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for system product preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     text_file_object = dfvfs_text_file.TextFile(file_object, encoding='utf-8')
@@ -106,15 +106,15 @@
   ARTIFACT_DEFINITION_NAME = 'LinuxLSBRelease'
 
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for system product preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     text_file_object = dfvfs_text_file.TextFile(file_object, encoding='utf-8')
@@ -141,15 +141,15 @@
   ARTIFACT_DEFINITION_NAME = 'LinuxSystemdOSRelease'
 
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for system product preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     text_file_object = dfvfs_text_file.TextFile(file_object, encoding='utf-8')
@@ -178,15 +178,15 @@
   ARTIFACT_DEFINITION_NAME = 'LinuxLocalTime'
 
   def _ParseFileEntry(self, mediator, file_entry):
     """Parses artifact file system data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_entry (dfvfs.FileEntry): file entry that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if file_entry.link:
@@ -223,15 +223,15 @@
   ARTIFACT_DEFINITION_NAME = 'LinuxPasswdFile'
 
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for user account preprocessing attributes.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     line_reader = line_reader_file.BinaryLineReader(file_object)
```

### Comparing `plaso-20230311/plaso/preprocessors/macos.py` & `plaso-20230717/plaso/preprocessors/macos.py`

 * *Files 2% similar despite different names*

```diff
@@ -43,15 +43,15 @@
         self._FindKeys(subkey, names, matches)
 
   def _ParseFileData(self, mediator, file_object):
     """Parses file content (data) for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_object (dfvfs.FileIO): file-like object that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     plist_file = plist.PlistFile()
@@ -93,15 +93,15 @@
 
   @abc.abstractmethod
   def _ParsePlistKeyValue(self, mediator, name, value):
     """Parses a plist key value.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       name (str): name of the plist key.
       value (str): value of the plist key.
     """
 
 
 class MacOSHostnamePlugin(PlistFileArtifactPreprocessorPlugin):
   """MacOS hostname plugin."""
@@ -111,15 +111,15 @@
   _PLIST_KEYS = ['ComputerName', 'LocalHostName']
 
   def _ParsePlistKeyValue(self, mediator, name, value):
     """Parses a plist key value.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       name (str): name of the plist key.
       value (str): value of the plist key.
     """
     if name in self._PLIST_KEYS:
       hostname_artifact = artifacts.HostnameArtifact(name=value)
       mediator.AddHostname(hostname_artifact)
 
@@ -132,15 +132,15 @@
   _PLIST_KEYS = ['AppleCurrentKeyboardLayoutInputSourceID']
 
   def _ParsePlistKeyValue(self, mediator, name, value):
     """Parses a plist key value.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       name (str): name of the plist key.
       value (str): value of the plist key.
     """
     if name in self._PLIST_KEYS:
       if isinstance(value, (list, tuple)):
         value = value[0]
 
@@ -157,15 +157,15 @@
   _PLIST_KEYS = ['ProductUserVisibleVersion']
 
   def _ParsePlistKeyValue(self, mediator, name, value):
     """Parses a plist key value.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       name (str): name of the plist key.
       value (str): value of the plist key.
     """
     if name in self._PLIST_KEYS:
       mediator.SetValue('operating_system_version', value)
 
 
@@ -175,15 +175,15 @@
   ARTIFACT_DEFINITION_NAME = 'MacOSLocalTime'
 
   def _ParseFileEntry(self, mediator, file_entry):
     """Parses artifact file system data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_entry (dfvfs.FileEntry): file entry that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not file_entry or not file_entry.link:
@@ -228,15 +228,15 @@
     return match
 
   def _ParseFileEntry(self, mediator, file_entry):
     """Parses artifact file system data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       file_entry (dfvfs.FileEntry): file entry that contains the artifact
           value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     file_object = file_entry.GetFileObject()
```

### Comparing `plaso-20230311/plaso/preprocessors/manager.py` & `plaso-20230717/plaso/preprocessors/manager.py`

 * *Files 1% similar despite different names*

```diff
@@ -120,14 +120,15 @@
 
 
 class PreprocessPluginsManager(object):
   """Preprocess plugins manager."""
 
   _plugins = {}
   _file_system_plugins = {}
+  # TODO: rename knowledge base plugins.
   _knowledge_base_plugins = {}
   _windows_registry_plugins = {}
 
   @classmethod
   def CollectFromFileSystem(
       cls, artifacts_registry, mediator, searcher, file_system):
     """Collects values from Windows Registry values.
@@ -334,17 +335,15 @@
 
     cls.CollectFromFileSystem(
         artifacts_registry, mediator, searcher, file_system)
 
     # Run the Registry plugins separately so we do not have to open
     # Registry files for every preprocess plugin.
 
-    environment_variables = None
-    if mediator.knowledge_base:
-      environment_variables = mediator.knowledge_base.GetEnvironmentVariables()
+    environment_variables = mediator.GetEnvironmentVariables()
 
     registry_file_reader = FileSystemWinRegistryFileReader(
         file_system, mount_point, environment_variables=environment_variables)
     win_registry = dfwinreg_registry.WinRegistry(
         registry_file_reader=registry_file_reader)
 
     searcher = registry_searcher.WinRegistrySearcher(win_registry)
```

### Comparing `plaso-20230311/plaso/preprocessors/mediator.py` & `plaso-20230717/plaso/engine/knowledge_base.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,222 +1,241 @@
 # -*- coding: utf-8 -*-
-"""The preprocess mediator."""
+"""The artifact knowledge base object.
 
-from plaso.containers import warnings
-from plaso.helpers.windows import eventlog_providers
-from plaso.preprocessors import logger
-
-
-class PreprocessMediator(object):
-  """Preprocess mediator."""
-
-  def __init__(self, session, storage_writer, knowledge_base):
-    """Initializes a preprocess mediator.
-
-    Args:
-      session (Session): session the preprocessing is part of.
-      storage_writer (StorageWriter): storage writer, to store preprocessing
-          information in.
-      knowledge_base (KnowledgeBase): knowledge base, to fill with
-          preprocessing information.
-    """
-    super(PreprocessMediator, self).__init__()
-    self._file_entry = None
-    self._knowledge_base = knowledge_base
-    self._session = session
-    self._storage_writer = storage_writer
-    self._windows_eventlog_providers_helper = (
-        eventlog_providers.WindowsEventLogProvidersHelper())
-    self._windows_eventlog_providers_by_identifier = {}
+The knowledge base is filled by user provided input and the pre-processing
+phase. It is intended to provide successive phases, like the parsing and
+analysis phases, with essential information like the time zone and codepage
+of the source data.
+"""
+
+import codecs
+import pytz
+
+from plaso.engine import logger
+
+
+class KnowledgeBase(object):
+  """The knowledge base."""
+
+  _DEFAULT_ACTIVE_SESSION = '00000000000000000000000000000000'
+
+  def __init__(self):
+    """Initializes a knowledge base."""
+    super(KnowledgeBase, self).__init__()
+    self._active_session = self._DEFAULT_ACTIVE_SESSION
+    self._codepage = 'cp1252'
+    self._environment_variables = {}
+    self._hostnames = {}
+    self._language = 'en-US'
+    self._mount_path = None
+    self._time_zone = pytz.UTC
+    self._values = {}
 
   @property
-  def knowledge_base(self):
-    """KnowledgeBase: knowledge base."""
-    return self._knowledge_base
+  def codepage(self):
+    """str: codepage of the current session."""
+    return self.GetValue('codepage', default_value=self._codepage)
 
-  def AddArtifact(self, artifact_attribute_container):
-    """Adds a pre-processing artifact attribute container.
+  @property
+  def language(self):
+    """str: language of the current session."""
+    return self.GetValue('language', default_value=self._language)
 
-    Args:
-      artifact_attribute_container (ArtifactAttributeContainer): artifact
-          attribute container.
-    """
-    if self._storage_writer:
-      self._storage_writer.AddAttributeContainer(artifact_attribute_container)
+  @property
+  def timezone(self):
+    """datetime.tzinfo: time zone of the current session."""
+    return self._time_zone
 
-  def AddEnvironmentVariable(self, environment_variable_artifact):
+  def AddEnvironmentVariable(self, environment_variable):
     """Adds an environment variable.
 
     Args:
-      environment_variable_artifact (EnvironmentVariableArtifact): environment
-          variable artifact.
+      environment_variable (EnvironmentVariableArtifact): environment variable
+          artifact.
 
     Raises:
       KeyError: if the environment variable already exists.
     """
-    logger.debug('setting environment variable: {0:s} to: "{1:s}"'.format(
-        environment_variable_artifact.name,
-        environment_variable_artifact.value))
-    self._knowledge_base.AddEnvironmentVariable(environment_variable_artifact)
+    name = environment_variable.name.upper()
+    if name in self._environment_variables:
+      raise KeyError('Environment variable: {0:s} already exists.'.format(
+          environment_variable.name))
 
-    if self._storage_writer:
-      self._storage_writer.AddAttributeContainer(environment_variable_artifact)
+    self._environment_variables[name] = environment_variable
 
-  def AddHostname(self, hostname_artifact):
-    """Adds a hostname.
+  def GetEnvironmentVariable(self, name):
+    """Retrieves an environment variable.
 
     Args:
-      hostname_artifact (HostnameArtifact): hostname artifact.
-    """
-    # TODO: change storage and knowledge base to handle more than 1 hostname.
-    if not self._knowledge_base.GetHostname():
-      self._knowledge_base.SetHostname(hostname_artifact)
+      name (str): name of the environment variable.
 
-  def AddTimeZoneInformation(self, time_zone_artifact):
-    """Adds a time zone defined by the operating system.
+    Returns:
+      EnvironmentVariableArtifact: environment variable artifact or None
+          if there was no value set for the given name.
+    """
+    name = name.upper()
+    return self._environment_variables.get(name, None)
 
-    Args:
-      time_zone_artifact (TimeZoneArtifact): time zone artifact.
+  def GetEnvironmentVariables(self):
+    """Retrieves the environment variables.
 
-    Raises:
-      KeyError: if the time zone already exists.
+    Returns:
+      list[EnvironmentVariableArtifact]: environment variable artifacts.
     """
-    self._knowledge_base.AddAvailableTimeZone(time_zone_artifact)
+    return self._environment_variables.values()
 
-  def AddUserAccount(self, user_account):
-    """Adds an user account.
+  def GetHostname(self):
+    """Retrieves the hostname related to the event.
 
-    Args:
-      user_account (UserAccountArtifact): user account artifact.
+    If the hostname is not stored in the event it is determined based
+    on the preprocessing information that is stored inside the storage file.
 
-    Raises:
-      KeyError: if the user account already exists.
+    Returns:
+      str: hostname.
     """
-    self._knowledge_base.AddUserAccount(user_account)
+    hostname_artifact = self._hostnames.get(self._active_session, None)
+    if not hostname_artifact:
+      return ''
+
+    return hostname_artifact.name or ''
 
-  def AddWindowsEventLogProvider(self, windows_eventlog_provider):
-    """Adds a Windows EventLog provider.
+  def GetValue(self, identifier, default_value=None):
+    """Retrieves a value by identifier.
 
     Args:
-      windows_eventlog_provider (WindowsEventLogProviderArtifact): Windows
-          EventLog provider.
+      identifier (str): case insensitive unique identifier for the value.
+      default_value (object): default value.
+
+    Returns:
+      object: value or default value if not available.
 
     Raises:
-      KeyError: if the Windows EventLog provider already exists.
+      TypeError: if the identifier is not a string type.
     """
-    existing_provider = None
-    provider_identifier = windows_eventlog_provider.identifier
+    if not isinstance(identifier, str):
+      raise TypeError('Identifier not a string type.')
 
-    if provider_identifier:
-      existing_provider = self._windows_eventlog_providers_by_identifier.get(
-          provider_identifier, None)
+    identifier = identifier.lower()
+    return self._values.get(identifier, default_value)
 
-    if not existing_provider:
-      existing_provider = self._knowledge_base.GetWindowsEventLogProvider(
-          windows_eventlog_provider.log_sources[0])
+  def ReadSystemConfigurationArtifact(self, system_configuration):
+    """Reads the knowledge base values from a system configuration artifact.
 
-    if existing_provider:
-      self._windows_eventlog_providers_helper.Merge(
-          existing_provider, windows_eventlog_provider)
+    Note that this overwrites existing values in the knowledge base.
 
-      if self._storage_writer:
-        self._storage_writer.UpdateAttributeContainer(existing_provider)
+    Args:
+      system_configuration (SystemConfigurationArtifact): system configuration
+          artifact.
+    """
+    if not system_configuration:
+      return
 
-    else:
-      self._windows_eventlog_providers_helper.NormalizeMessageFiles(
-          windows_eventlog_provider)
+    if system_configuration.code_page:
+      try:
+        self.SetCodepage(system_configuration.code_page)
+      except ValueError:
+        logger.warning(
+            'Unsupported codepage: {0:s}, defaulting to {1:s}'.format(
+                system_configuration.code_page, self._codepage))
 
-      if self._storage_writer:
-        self._storage_writer.AddAttributeContainer(windows_eventlog_provider)
+    self._hostnames[self._active_session] = system_configuration.hostname
 
-      self._knowledge_base.AddWindowsEventLogProvider(
-          windows_eventlog_provider)
+    self.SetValue('keyboard_layout', system_configuration.keyboard_layout)
 
-      if provider_identifier:
-        self._windows_eventlog_providers_by_identifier[provider_identifier] = (
-            windows_eventlog_provider)
+    if system_configuration.language:
+      self.SetLanguage(system_configuration.language)
 
-  def GetEnvironmentVariable(self, name):
-    """Retrieves an environment variable.
+    self.SetValue('operating_system', system_configuration.operating_system)
+    self.SetValue(
+        'operating_system_product',
+        system_configuration.operating_system_product)
+    self.SetValue(
+        'operating_system_version',
+        system_configuration.operating_system_version)
 
-    Args:
-      name (str): name of the environment variable.
+    if system_configuration.time_zone:
+      try:
+        self.SetTimeZone(system_configuration.time_zone)
+      except ValueError:
+        logger.warning(
+            'Unsupported time zone: {0:s}, defaulting to {1:s}'.format(
+                system_configuration.time_zone, self._time_zone.zone))
 
-    Returns:
-      EnvironmentVariableArtifact: environment variable artifact or None
-          if there was no value set for the given name.
-    """
-    return self._knowledge_base.GetEnvironmentVariable(name)
-
-  def ProducePreprocessingWarning(self, plugin_name, message):
-    """Produces a preprocessing warning.
+  def SetActiveSession(self, session_identifier):
+    """Sets the active session.
 
     Args:
-      plugin_name (str): name of the preprocess plugin.
-      message (str): message of the warning.
+      session_identifier (str): session identifier where None represents
+          the default active session.
     """
-    if self._storage_writer:
-      path_spec = None
-      if self._file_entry:
-        path_spec = self._file_entry.path_spec
-
-      warning = warnings.PreprocessingWarning(
-          message=message, path_spec=path_spec, plugin_name=plugin_name)
-      self._storage_writer.AddAttributeContainer(warning)
-
-    logger.debug('[{0:s}] {1:s}'.format(plugin_name, message))
+    self._active_session = session_identifier or self._DEFAULT_ACTIVE_SESSION
 
   def SetCodepage(self, codepage):
     """Sets the codepage.
 
     Args:
       codepage (str): codepage.
 
     Raises:
       ValueError: if the codepage is not supported.
     """
-    logger.debug('setting codepage to: "{0:s}"'.format(codepage))
-    self._knowledge_base.SetCodepage(codepage)
+    try:
+      codecs.getencoder(codepage)
+      self._codepage = codepage
+    except LookupError:
+      raise ValueError('Unsupported codepage: {0:s}'.format(codepage))
+
+  def SetEnvironmentVariable(self, environment_variable):
+    """Sets an environment variable.
+
+    Args:
+      environment_variable (EnvironmentVariableArtifact): environment variable
+          artifact.
+    """
+    name = environment_variable.name.upper()
+    self._environment_variables[name] = environment_variable
 
-  def SetFileEntry(self, file_entry):
-    """Sets the active file entry.
+  def SetHostname(self, hostname):
+    """Sets a hostname.
 
     Args:
-      file_entry (dfvfs.FileEntry): file entry.
+      hostname (HostnameArtifact): hostname artifact.
     """
-    self._file_entry = file_entry
+    self._hostnames[self._active_session] = hostname
 
   def SetLanguage(self, language):
     """Sets the language.
 
     Args:
       language (str): language.
-
-    Raises:
-      ValueError: if the language is not supported.
     """
-    self._knowledge_base.SetLanguage(language)
+    self._language = language
 
   def SetTimeZone(self, time_zone):
     """Sets the time zone.
 
     Args:
       time_zone (str): time zone.
 
     Raises:
       ValueError: if the time zone is not supported.
     """
-    # TODO: check if time zone is set in knowledge base.
-    self._knowledge_base.SetTimeZone(time_zone)
+    try:
+      self._time_zone = pytz.timezone(time_zone)
+    except pytz.UnknownTimeZoneError:
+      raise ValueError('Unsupported time zone: {0!s}'.format(time_zone))
 
   def SetValue(self, identifier, value):
     """Sets a value by identifier.
 
     Args:
       identifier (str): case insensitive unique identifier for the value.
       value (object): value.
 
     Raises:
       TypeError: if the identifier is not a string type.
     """
-    if not self._knowledge_base.GetValue(identifier):
-      self._knowledge_base.SetValue(identifier, value)
+    if not isinstance(identifier, str):
+      raise TypeError('Identifier not a string type.')
+
+    identifier = identifier.lower()
+    self._values[identifier] = value
```

### Comparing `plaso-20230311/plaso/preprocessors/mounted_devices.yaml` & `plaso-20230717/plaso/preprocessors/mounted_devices.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/preprocessors/time_zone_information.yaml` & `plaso-20230717/plaso/preprocessors/time_zone_information.yaml`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/preprocessors/windows.py` & `plaso-20230717/plaso/preprocessors/windows.py`

 * *Files 5% similar despite different names*

```diff
@@ -18,15 +18,15 @@
   _NAME = None
 
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not isinstance(value_data, str):
       raise errors.PreProcessFail(
@@ -52,15 +52,15 @@
   _NAME = None
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
@@ -128,15 +128,15 @@
   def _ParsePathSpecification(
       self, mediator, searcher, file_system, path_specification,
       path_separator):
     """Parses artifact file system data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       searcher (dfvfs.FileSystemSearcher): file system searcher to preprocess
           the file system.
       file_system (dfvfs.FileSystem): file system to be preprocessed.
       path_specification (dfvfs.PathSpec): path specification that contains
           the artifact value data.
       path_separator (str): path segment separator.
 
@@ -174,15 +174,15 @@
   """
 
   def Collect(self, mediator):
     """Collects values from the knowledge base.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
     environment_variable = mediator.GetEnvironmentVariable('programdata')
     allusersappdata = getattr(environment_variable, 'value', None)
 
@@ -226,15 +226,15 @@
   """
 
   def Collect(self, mediator):
     """Collects values from the knowledge base.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
     environment_variable = mediator.GetEnvironmentVariable('allusersprofile')
     allusersprofile = getattr(environment_variable, 'value', None)
 
@@ -265,15 +265,15 @@
       os.path.dirname(__file__), 'time_zone_information.yaml')
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
@@ -337,59 +337,59 @@
 
     if tzi_record.standard_bias:
       time_zone_artifact.offset = tzi_record.standard_bias
     else:
       time_zone_artifact.offset = tzi_record.bias
 
 
-class WindowsCodepagePlugin(
+class WindowsCodePagePlugin(
     interface.WindowsRegistryValueArtifactPreprocessorPlugin):
-  """The Windows codepage plugin."""
+  """The Windows code page plugin."""
 
   ARTIFACT_DEFINITION_NAME = 'WindowsCodePage'
 
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not isinstance(value_data, str):
       raise errors.PreProcessFail(
           'Unsupported Windows Registry value type: {0!s} for '
           'artifact: {1:s}.'.format(
               type(value_data), self.ARTIFACT_DEFINITION_NAME))
 
     # Map the Windows code page name to a Python equivalent name.
-    codepage = 'cp{0:s}'.format(value_data)
+    code_page = 'cp{0:s}'.format(value_data)
 
     try:
-      mediator.SetCodepage(codepage)
+      mediator.SetCodePage(code_page)
     except ValueError:
       mediator.ProducePreprocessingWarning(
-          self.ARTIFACT_DEFINITION_NAME, 'Unable to set codepage.')
+          self.ARTIFACT_DEFINITION_NAME, 'Unable to set code page.')
 
 
 class WindowsEventLogPublishersPlugin(
     interface.WindowsRegistryKeyArtifactPreprocessorPlugin):
   """The Windows EventLog publishers plugin."""
 
   ARTIFACT_DEFINITION_NAME = 'WindowsEventLogPublishers'
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
@@ -435,15 +435,15 @@
   ARTIFACT_DEFINITION_NAME = 'WindowsEventLogSources'
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
@@ -506,15 +506,15 @@
   ARTIFACT_DEFINITION_NAME = 'WindowsComputerName'
 
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not isinstance(value_data, str):
       if not hasattr(value_data, '__iter__'):
@@ -537,15 +537,15 @@
   ARTIFACT_DEFINITION_NAME = 'WindowsLanguage'
 
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not isinstance(value_data, str):
       raise errors.PreProcessFail(
@@ -579,15 +579,15 @@
       os.path.dirname(__file__), 'mounted_devices.yaml')
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
@@ -673,15 +673,15 @@
   """
 
   def Collect(self, mediator):
     """Collects values from the knowledge base.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
 
     Raises:
       PreProcessFail: if the preprocessing fails.
     """
     environment_variable = mediator.GetEnvironmentVariable('programdata')
     allusersprofile = getattr(environment_variable, 'value', None)
 
@@ -726,15 +726,15 @@
   ARTIFACT_DEFINITION_NAME = 'WindowsServices'
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
@@ -790,15 +790,15 @@
   ARTIFACT_DEFINITION_NAME = 'WindowsProductName'
 
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not isinstance(value_data, str):
       raise errors.PreProcessFail(
@@ -825,15 +825,15 @@
   ARTIFACT_DEFINITION_NAME = 'WindowsCurrentVersion'
 
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not isinstance(value_data, str):
       raise errors.PreProcessFail(
@@ -851,15 +851,15 @@
   ARTIFACT_DEFINITION_NAME = 'WindowsTimezone'
 
   def _ParseValueData(self, mediator, value_data):
     """Parses Windows Registry value data for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       value_data (object): Windows Registry value data.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
     if not isinstance(value_data, str):
       raise errors.PreProcessFail(
@@ -902,15 +902,15 @@
     return path
 
   def _ParseKey(self, mediator, registry_key, value_name):
     """Parses a Windows Registry key for a preprocessing attribute.
 
     Args:
       mediator (PreprocessMediator): mediates interactions between preprocess
-          plugins and other components, such as storage and knowledge base.
+          plugins and other components, such as storage.
       registry_key (dfwinreg.WinRegistryKey): Windows Registry key.
       value_name (str): name of the Windows Registry value or None if not
           specified.
 
     Raises:
       errors.PreProcessFail: if the preprocessing fails.
     """
@@ -944,15 +944,15 @@
 
 
 manager.PreprocessPluginsManager.RegisterPlugins([
     WindowsAllUsersAppDataKnowledgeBasePlugin,
     WindowsAllUsersProfileEnvironmentVariablePlugin,
     WindowsAllUsersAppProfileKnowledgeBasePlugin,
     WindowsAvailableTimeZonesPlugin,
-    WindowsCodepagePlugin, WindowsEventLogPublishersPlugin,
+    WindowsCodePagePlugin, WindowsEventLogPublishersPlugin,
     WindowsEventLogSourcesPlugin, WindowsHostnamePlugin, WindowsLanguagePlugin,
     WindowsMountedDevicesPlugin, WindowsProgramDataEnvironmentVariablePlugin,
     WindowsProgramDataKnowledgeBasePlugin,
     WindowsProgramFilesEnvironmentVariablePlugin,
     WindowsProgramFilesX86EnvironmentVariablePlugin,
     WindowsServicesAndDriversPlugin, WindowsSystemProductPlugin,
     WindowsSystemRootEnvironmentVariablePlugin, WindowsSystemVersionPlugin,
```

### Comparing `plaso-20230311/plaso/serializer/json_serializer.py` & `plaso-20230717/plaso/serializer/json_serializer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/single_process/extraction_engine.py` & `plaso-20230717/plaso/single_process/extraction_engine.py`

 * *Files 13% similar despite different names*

```diff
@@ -4,37 +4,45 @@
 import collections
 import os
 import pdb
 import threading
 import time
 
 from dfvfs.lib import definitions as dfvfs_definitions
-from dfvfs.resolver import resolver
+from dfvfs.resolver import resolver as path_spec_resolver
 
 from plaso.containers import counts
 from plaso.containers import event_sources
+from plaso.containers import events
 from plaso.engine import engine
 from plaso.engine import extractors
 from plaso.engine import logger
 from plaso.engine import process_info
 from plaso.engine import timeliner
 from plaso.engine import worker
 from plaso.lib import definitions
 from plaso.lib import errors
 from plaso.parsers import mediator as parsers_mediator
 
 
 class SingleProcessEngine(engine.BaseEngine):
   """Single process extraction engine."""
 
+  _CONTAINER_TYPE_EVENT_DATA_STREAM = events.EventDataStream.CONTAINER_TYPE
+
   # Maximum number of dfVFS file system objects to cache.
   _FILE_SYSTEM_CACHE_SIZE = 3
 
-  def __init__(self):
-    """Initializes a single process extraction engine."""
+  def __init__(self, status_update_callback=None):
+    """Initializes a single process extraction engine.
+
+    Args:
+      status_update_callback (Optional[function]): callback function for status
+          updates.
+    """
     super(SingleProcessEngine, self).__init__()
     self._current_display_name = ''
     self._event_data_timeliner = None
     self._extraction_worker = None
     self._file_system_cache = []
     self._number_of_consumed_event_data = 0
     self._number_of_consumed_sources = 0
@@ -44,43 +52,93 @@
     self._path_spec_extractor = extractors.PathSpecExtractor()
     self._pid = os.getpid()
     self._process_information = process_info.ProcessInfo(self._pid)
     self._processing_configuration = None
     self._resolver_context = None
     self._status = definitions.STATUS_INDICATOR_IDLE
     self._status_update_active = False
-    self._status_update_callback = None
+    self._status_update_callback = status_update_callback
     self._status_update_thread = None
     self._storage_writer = None
 
-  def _CacheFileSystem(self, path_spec):
+  def _CacheFileSystem(self, file_system):
     """Caches a dfVFS file system object.
 
     Keeping and additional reference to a dfVFS file system object causes the
     object to remain cached in the resolver context. This minimizes the number
     times the file system is re-opened.
 
     Args:
+      file_system (dfvfs.FileSystem): file system.
+    """
+    if file_system not in self._file_system_cache:
+      if len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
+        self._file_system_cache.pop(0)
+      self._file_system_cache.append(file_system)
+
+    elif len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
+      # Move the file system to the end of the list to preserve the most
+      # recently file system object.
+      self._file_system_cache.remove(file_system)
+      self._file_system_cache.append(file_system)
+
+  def _CheckExcludedPathSpec(self, file_system, path_spec):
+    """Determines if the path specification should be excluded from extraction.
+
+    Args:
+      file_system (dfvfs.FileSystem): file system which the path specification
+          is part of.
       path_spec (dfvfs.PathSpec): path specification.
+
+    Returns:
+      bool: True if the path specification should be excluded from extraction.
     """
-    if (path_spec and not path_spec.IsSystemLevel() and
-        path_spec.type_indicator != dfvfs_definitions.TYPE_INDICATOR_GZIP):
-      file_system = resolver.Resolver.OpenFileEntry(
-          path_spec, resolver_context=self._resolver_context)
-
-      if file_system not in self._file_system_cache:
-        if len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
-          self._file_system_cache.pop(0)
-        self._file_system_cache.append(file_system)
-
-      elif len(self._file_system_cache) == self._FILE_SYSTEM_CACHE_SIZE:
-        # Move the file system to the end of the list to preserve the most
-        # recently file system object.
-        self._file_system_cache.remove(file_system)
-        self._file_system_cache.append(file_system)
+    for find_spec in self._excluded_file_system_find_specs or []:
+      if find_spec.ComparePathSpecLocation(path_spec, file_system):
+        return True
+
+    return False
+
+  def _CollectInitialEventSources(
+      self, parser_mediator, file_system_path_specs):
+    """Collects the initial event sources.
+
+    Args:
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
+    """
+    self._status = definitions.STATUS_INDICATOR_COLLECTING
+
+    included_find_specs = self.GetCollectionIncludedFindSpecs()
+
+    for file_system_path_spec in file_system_path_specs:
+      if self._abort:
+        break
+
+      file_system = path_spec_resolver.Resolver.OpenFileSystem(
+          file_system_path_spec, resolver_context=self._resolver_context)
+
+      path_spec_generator = self._path_spec_extractor.ExtractPathSpecs(
+          file_system_path_spec, find_specs=included_find_specs,
+          recurse_file_system=False, resolver_context=self._resolver_context)
+      for path_spec in path_spec_generator:
+        if self._abort:
+          break
+
+        if self._CheckExcludedPathSpec(file_system, path_spec):
+          display_name = parser_mediator.GetDisplayNameForPathSpec(path_spec)
+          logger.debug('Excluded from extraction: {0:s}.'.format(display_name))
+          continue
+
+        # TODO: determine if event sources should be DataStream or FileEntry
+        # or both.
+        event_source = event_sources.FileEntryEventSource(path_spec=path_spec)
+        parser_mediator.ProduceEventSource(event_source)
 
   def _ProcessEventData(self):
     """Generate events from event data."""
     if self._processing_profiler:
       self._processing_profiler.StartTiming('process_event_data')
 
     self._status = definitions.STATUS_INDICATOR_TIMELINING
@@ -93,16 +151,31 @@
     if self._processing_profiler:
       self._processing_profiler.StopTiming('get_event_data')
 
     while event_data:
       if self._abort:
         break
 
+      event_data_stream_identifier = event_data.GetEventDataStreamIdentifier()
+
+      event_data_stream = None
+      if event_data_stream_identifier:
+        if self._processing_profiler:
+          self._processing_profiler.StartTiming('get_event_data_stream')
+
+        event_data_stream = (
+            self._storage_writer.GetAttributeContainerByIdentifier(
+                self._CONTAINER_TYPE_EVENT_DATA_STREAM,
+                event_data_stream_identifier))
+
+        if self._processing_profiler:
+          self._processing_profiler.StopTiming('get_event_data_stream')
+
       self._event_data_timeliner.ProcessEventData(
-          self._storage_writer, event_data)
+          self._storage_writer, event_data, event_data_stream)
 
       self._number_of_consumed_event_data += 1
       self._number_of_produced_events += (
           self._event_data_timeliner.number_of_produced_events)
 
       # TODO: track number of consumed event data containers?
 
@@ -118,35 +191,79 @@
       self._status = definitions.STATUS_INDICATOR_ABORTED
     else:
       self._status = definitions.STATUS_INDICATOR_COMPLETED
 
     if self._processing_profiler:
       self._processing_profiler.StopTiming('process_event_data')
 
+  def _ProcessEventSources(self, storage_writer, parser_mediator):
+    """Processes event sources.
+
+    Args:
+      storage_writer (StorageWriter): storage writer for a session storage.
+      parser_mediator (ParserMediator): mediates interactions between parsers
+          and other components, such as storage and dfVFS.
+    """
+    self._status = definitions.STATUS_INDICATOR_RUNNING
+
+    if self._processing_profiler:
+      self._processing_profiler.StartTiming('get_event_source')
+
+    event_source = storage_writer.GetFirstWrittenEventSource()
+
+    if self._processing_profiler:
+      self._processing_profiler.StopTiming('get_event_source')
+
+    while event_source:
+      if self._abort:
+        break
+
+      self._ProcessPathSpec(parser_mediator, event_source.path_spec)
+
+      self._number_of_consumed_sources += 1
+
+      if self._processing_profiler:
+        self._processing_profiler.StartTiming('get_event_source')
+
+      event_source = storage_writer.GetNextWrittenEventSource()
+
+      if self._processing_profiler:
+        self._processing_profiler.StopTiming('get_event_source')
+
   def _ProcessPathSpec(self, parser_mediator, path_spec):
     """Processes a path specification.
 
     Args:
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
       path_spec (dfvfs.PathSpec): path specification.
     """
-    self._current_display_name = parser_mediator.GetDisplayNameForPathSpec(
-        path_spec)
-
-    self._CacheFileSystem(path_spec)
+    try:
+      self._current_display_name = parser_mediator.GetDisplayNameForPathSpec(
+          path_spec)
 
-    excluded_find_specs = None
-    if self.collection_filters_helper:
-      excluded_find_specs = (
-          self.collection_filters_helper.excluded_file_system_find_specs)
+      file_entry = path_spec_resolver.Resolver.OpenFileEntry(
+          path_spec, resolver_context=parser_mediator.resolver_context)
+      if file_entry is None:
+        logger.warning('Unable to open file entry: {0:s}'.format(
+            self._current_display_name))
+        return
+
+      file_system = file_entry.GetFileSystem()
+
+      if (path_spec and not path_spec.IsSystemLevel() and
+          path_spec.type_indicator != dfvfs_definitions.TYPE_INDICATOR_GZIP):
+        self._CacheFileSystem(file_system)
+
+      if self._CheckExcludedPathSpec(file_system, path_spec):
+        logger.debug('Excluded from extraction: {0:s}.'.format(
+            self._current_display_name))
+        return
 
-    try:
-      self._extraction_worker.ProcessPathSpec(
-          parser_mediator, path_spec, excluded_find_specs=excluded_find_specs)
+      self._extraction_worker.ProcessFileEntry(parser_mediator, file_entry)
 
     except KeyboardInterrupt:
       self._abort = True
 
       self._processing_status.aborted = True
       if self._status_update_callback:
         self._status_update_callback(self._processing_status)
@@ -166,89 +283,42 @@
                 self._current_display_name))
         logger.exception(exception)
 
         pdb.post_mortem()
 
         self._StartStatusUpdateThread()
 
-  def _ProcessSources(self, source_configurations, parser_mediator):
-    """Processes the sources.
+  def _ProcessSource(self, parser_mediator, file_system_path_specs):
+    """Processes file systems within a source.
 
     Args:
-      source_configurations (list[SourceConfigurationArtifact]): configurations
-          of the sources to process.
       parser_mediator (ParserMediator): mediates interactions between parsers
           and other components, such as storage and dfVFS.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
     """
-    if self._processing_profiler:
-      self._processing_profiler.StartTiming('process_sources')
-
-    self._status = definitions.STATUS_INDICATOR_COLLECTING
     self._current_display_name = ''
     self._number_of_consumed_sources = 0
 
-    find_specs = None
-    if self.collection_filters_helper:
-      find_specs = (
-          self.collection_filters_helper.included_file_system_find_specs)
-
-    source_path_specs = [
-        configuration.path_spec for configuration in source_configurations]
-
-    path_spec_generator = self._path_spec_extractor.ExtractPathSpecs(
-        source_path_specs, find_specs=find_specs, recurse_file_system=False,
-        resolver_context=self._resolver_context)
-
-    for path_spec in path_spec_generator:
-      if self._abort:
-        break
-
-      self._status = definitions.STATUS_INDICATOR_COLLECTING
-      self._current_display_name = parser_mediator.GetDisplayNameForPathSpec(
-          path_spec)
-
-      # TODO: determine if event sources should be DataStream or FileEntry
-      # or both.
-      event_source = event_sources.FileEntryEventSource(path_spec=path_spec)
-      parser_mediator.ProduceEventSource(event_source)
-
-    self._status = definitions.STATUS_INDICATOR_RUNNING
-
     if self._processing_profiler:
-      self._processing_profiler.StartTiming('get_event_source')
+      self._processing_profiler.StartTiming('process_source')
 
-    event_source = self._storage_writer.GetFirstWrittenEventSource()
+    self._CollectInitialEventSources(
+        parser_mediator, file_system_path_specs)
 
-    if self._processing_profiler:
-      self._processing_profiler.StopTiming('get_event_source')
+    self._ProcessEventSources(self._storage_writer, parser_mediator)
 
-    while event_source:
-      if self._abort:
-        break
-
-      self._ProcessPathSpec(parser_mediator, event_source.path_spec)
-
-      self._number_of_consumed_sources += 1
-
-      if self._processing_profiler:
-        self._processing_profiler.StartTiming('get_event_source')
-
-      event_source = self._storage_writer.GetNextWrittenEventSource()
-
-      if self._processing_profiler:
-        self._processing_profiler.StopTiming('get_event_source')
+    if self._processing_profiler:
+      self._processing_profiler.StopTiming('process_source')
 
     if self._abort:
       self._status = definitions.STATUS_INDICATOR_ABORTED
     else:
       self._status = definitions.STATUS_INDICATOR_COMPLETED
 
-    if self._processing_profiler:
-      self._processing_profiler.StopTiming('process_sources')
-
   def _StartStatusUpdateThread(self):
     """Starts the status update thread."""
     self._status_update_active = True
     self._status_update_thread = threading.Thread(
         name='Status update', target=self._StatusUpdateThreadMain)
     self._status_update_thread.start()
 
@@ -287,95 +357,120 @@
         0, 0,
         0, 0)
 
     if self._status_update_callback:
       self._status_update_callback(self._processing_status)
 
   def _CreateParserMediator(
-      self, knowledge_base, resolver_context, processing_configuration):
+      self, storage_writer, resolver_context, processing_configuration,
+      system_configurations):
     """Creates a parser mediator.
 
     Args:
-      knowledge_base (KnowledgeBase): knowledge base which contains
-          information from the source data needed for parsing.
+      storage_writer (StorageWriter): storage writer for a session storage.
       resolver_context (dfvfs.Context): resolver context.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
+      system_configurations (list[SystemConfigurationArtifact]): system
+          configurations.
 
     Returns:
       ParserMediator: parser mediator.
+
+    Raises:
+      BadConfigOption: if an invalid collection filter was specified.
     """
+    # TODO: get environment_variables per system_configuration
+    environment_variables = None
+    if self.knowledge_base:
+      environment_variables = self.knowledge_base.GetEnvironmentVariables()
+
+    user_accounts = list(storage_writer.GetAttributeContainers('user_account'))
+
+    try:
+      self.BuildCollectionFilters(
+          environment_variables, user_accounts,
+          artifact_filter_names=processing_configuration.artifact_filters,
+          filter_file_path=processing_configuration.filter_file)
+    except errors.InvalidFilter as exception:
+      raise errors.BadConfigOption(
+          'Unable to build collection filters with error: {0!s}'.format(
+              exception))
+
     parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base,
-        collection_filters_helper=self.collection_filters_helper,
-        resolver_context=resolver_context)
+        registry_find_specs=self._registry_find_specs,
+        resolver_context=resolver_context,
+        system_configurations=system_configurations)
 
     parser_mediator.SetExtractWinEvtResources(
         processing_configuration.extraction.extract_winevt_resources)
     parser_mediator.SetPreferredCodepage(
         processing_configuration.preferred_codepage)
     parser_mediator.SetPreferredLanguage(
         processing_configuration.preferred_language)
-    parser_mediator.SetPreferredTimeZone(
-        processing_configuration.preferred_time_zone)
     parser_mediator.SetTemporaryDirectory(
         processing_configuration.temporary_directory)
 
     return parser_mediator
 
-  def ProcessSources(
-      self, source_configurations, storage_writer, resolver_context,
-      processing_configuration, force_parser=False,
-      status_update_callback=None):
-    """Processes the sources.
+  def ProcessSource(
+      self, storage_writer, resolver_context, processing_configuration,
+      system_configurations, file_system_path_specs):
+    """Processes file systems within a source.
 
     Args:
-      source_configurations (list[SourceConfigurationArtifact]): configurations
-          of the sources to process.
       storage_writer (StorageWriter): storage writer for a session storage.
       resolver_context (dfvfs.Context): resolver context.
       processing_configuration (ProcessingConfiguration): processing
           configuration.
-      force_parser (Optional[bool]): True if a specified parser should be forced
-          to be used to extract events.
-      status_update_callback (Optional[function]): callback function for status
-          updates.
+      system_configurations (list[SystemConfigurationArtifact]): system
+          configurations.
+      file_system_path_specs (list[dfvfs.PathSpec]): path specifications of
+          the source file systems to process.
 
     Returns:
       ProcessingStatus: processing status.
 
     Raises:
-      BadConfigOption: if the preferred time zone is invalid.
+      BadConfigOption: if an invalid collection filter was specified or if
+          the preferred time zone is invalid.
     """
+    if not self._artifacts_registry:
+      # TODO: refactor.
+      self.BuildArtifactsRegistry(
+          processing_configuration.artifact_definitions_path,
+          processing_configuration.custom_artifacts_path)
+
     parser_mediator = self._CreateParserMediator(
-        self.knowledge_base, resolver_context, processing_configuration)
+        storage_writer, resolver_context, processing_configuration,
+        system_configurations)
     parser_mediator.SetStorageWriter(storage_writer)
 
     self._extraction_worker = worker.EventExtractionWorker(
-        force_parser=force_parser, parser_filter_expression=(
+        force_parser=processing_configuration.force_parser,
+        parser_filter_expression=(
             processing_configuration.parser_filter_expression))
 
     self._extraction_worker.SetExtractionConfiguration(
         processing_configuration.extraction)
 
     self._event_data_timeliner = timeliner.EventDataTimeliner(
-        self.knowledge_base,
         data_location=processing_configuration.data_location,
-        preferred_year=processing_configuration.preferred_year)
+        preferred_year=processing_configuration.preferred_year,
+        system_configurations=system_configurations)
 
     try:
       self._event_data_timeliner.SetPreferredTimeZone(
           processing_configuration.preferred_time_zone)
     except ValueError as exception:
       raise errors.BadConfigOption(exception)
 
     self._parser_mediator = parser_mediator
     self._processing_configuration = processing_configuration
     self._resolver_context = resolver_context
-    self._status_update_callback = status_update_callback
     self._storage_writer = storage_writer
 
     logger.debug('Processing started.')
 
     parser_mediator.StartProfiling(
         self._processing_configuration.profiling, self._name,
         self._process_information)
@@ -397,15 +492,15 @@
 
     self._parsers_counter = collections.Counter({
         parser_count.name: parser_count
         for parser_count in self._storage_writer.GetAttributeContainers(
             'parser_count')})
 
     try:
-      self._ProcessSources(source_configurations, parser_mediator)
+      self._ProcessSource(parser_mediator, file_system_path_specs)
 
       self._ProcessEventData()
 
     finally:
       # Stop the status update thread after close of the storage writer
       # so we include the storage sync to disk in the status updates.
       self._StopStatusUpdateThread()
@@ -457,11 +552,10 @@
 
     self._event_data_timeliner = None
     self._extraction_worker = None
     self._file_system_cache = []
     self._parser_mediator = None
     self._processing_configuration = None
     self._resolver_context = None
-    self._status_update_callback = None
     self._storage_writer = None
 
     return self._processing_status
```

### Comparing `plaso-20230311/plaso/storage/factory.py` & `plaso-20230717/plaso/storage/factory.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/fake/event_heap.py` & `plaso-20230717/plaso/storage/fake/event_heap.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/fake/fake_store.py` & `plaso-20230717/plaso/storage/fake/fake_store.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/fake/writer.py` & `plaso-20230717/plaso/storage/fake/writer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/reader.py` & `plaso-20230717/plaso/storage/reader.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/redis/reader.py` & `plaso-20230717/plaso/storage/redis/reader.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/redis/redis_store.py` & `plaso-20230717/plaso/storage/redis/redis_store.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/redis/writer.py` & `plaso-20230717/plaso/storage/redis/writer.py`

 * *Files 7% similar despite different names*

```diff
@@ -105,22 +105,7 @@
 
     if self._storage_profiler:
       self._store.SetStorageProfiler(self._storage_profiler)
 
     self._store.Open(
         redis_client=redis_client, session_identifier=session_identifier,
         task_identifier=task_identifier)
-
-  def WritePreprocessingInformation(self, knowledge_base):
-    """Writes preprocessing information.
-
-    Args:
-      knowledge_base (KnowledgeBase): contains the preprocessing information.
-
-    Raises:
-      IOError: always as the Redis store does not support preprocessing
-          information.
-      OSError: always as the Redis store does not support preprocessing
-          information.
-    """
-    raise IOError(
-        'Preprocessing information is not supported by the redis store.')
```

### Comparing `plaso-20230311/plaso/storage/sqlite/reader.py` & `plaso-20230717/plaso/storage/sqlite/reader.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/sqlite/sqlite_file.py` & `plaso-20230717/plaso/storage/sqlite/sqlite_file.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,31 +15,39 @@
 
 
 class SQLiteStorageFile(sqlite_store.SQLiteAttributeContainerStore):
   """SQLite-based storage file.
 
   Attributes:
     compression_format (str): compression format.
-    serialization_format (str): serialization format.
   """
 
-  _FORMAT_VERSION = 20230107
+  _FORMAT_VERSION = 20230327
+
+  _APPEND_COMPATIBLE_FORMAT_VERSION = 20230327
+
+  _UPGRADE_COMPATIBLE_FORMAT_VERSION = 20230327
+
+  _READ_COMPATIBLE_FORMAT_VERSION = 20221023
+
+  _READ_INCOMPATIBLE_CONTAINER_TYPES = frozenset([
+      'hostname', 'operating_system', 'path', 'source_configuration',
+      'time_zone', 'user_account'])
 
   _CONTAINER_TYPE_EVENT = events.EventObject.CONTAINER_TYPE
   _CONTAINER_TYPE_EVENT_DATA = events.EventData.CONTAINER_TYPE
   _CONTAINER_TYPE_EVENT_TAG = events.EventTag.CONTAINER_TYPE
 
   def __init__(self):
     """Initializes a SQLite-based storage file."""
     super(SQLiteStorageFile, self).__init__()
     self._serializer = json_serializer.JSONAttributeContainerSerializer
     self._serializers_profiler = None
 
     self.compression_format = definitions.COMPRESSION_FORMAT_ZLIB
-    self.serialization_format = definitions.SERIALIZER_FORMAT_JSON
 
   def _CheckStorageMetadata(self, metadata_values, check_readable_only=False):
     """Checks the storage metadata.
 
     Args:
       metadata_values (dict[str, str]): metadata values per key.
       check_readable_only (Optional[bool]): whether the store should only be
@@ -54,118 +62,91 @@
         metadata_values, check_readable_only=check_readable_only)
 
     compression_format = metadata_values.get('compression_format', None)
     if compression_format not in definitions.COMPRESSION_FORMATS:
       raise IOError('Unsupported compression format: {0!s}'.format(
           compression_format))
 
-    serialization_format = metadata_values.get('serialization_format', None)
-    if serialization_format != definitions.SERIALIZER_FORMAT_JSON:
-      raise IOError('Unsupported serialization format: {0!s}'.format(
-          serialization_format))
-
-  def _CreatetAttributeContainerFromRow(
+  def _CreateAttributeContainerFromRow(
       self, container_type, column_names, row, first_column_index):
     """Creates an attribute container of a row in the database.
 
     Args:
       container_type (str): attribute container type.
       column_names (list[str]): names of the columns selected.
       row (sqlite.Row): row as a result from a SELECT query.
       first_column_index (int): index of the first column in row.
 
     Returns:
       AttributeContainer: attribute container.
     """
-    schema = self._GetAttributeContainerSchema(container_type)
-    if schema:
-      container = self._containers_manager.CreateAttributeContainer(
-          container_type)
-
-      for column_index, name in enumerate(column_names):
-        attribute_value = row[first_column_index + column_index]
-        if attribute_value is None:
-          continue
-
-        data_type = schema[name]
-        if data_type == 'AttributeContainerIdentifier':
-          identifier = containers_interface.AttributeContainerIdentifier()
-          identifier.CopyFromString(attribute_value)
-          attribute_value = identifier
-
-        elif data_type == 'bool':
-          attribute_value = bool(attribute_value)
-
-        elif data_type not in self._CONTAINER_SCHEMA_TO_SQLITE_TYPE_MAPPINGS:
-          # TODO: add compression support
-          attribute_value = self._serializer.ReadSerialized(attribute_value)
+    if self.format_version > 20221023 or container_type not in (
+        self._READ_INCOMPATIBLE_CONTAINER_TYPES):
+      schema = self._GetAttributeContainerSchema(container_type)
+    else:
+      schema = None
 
-        setattr(container, name, attribute_value)
+    if schema:
+      return super(SQLiteStorageFile, self)._CreateAttributeContainerFromRow(
+          container_type, column_names, row, first_column_index)
 
+    if self.compression_format == definitions.COMPRESSION_FORMAT_ZLIB:
+      compressed_data = row[first_column_index]
+      serialized_data = zlib.decompress(compressed_data)
     else:
-      if self.compression_format == definitions.COMPRESSION_FORMAT_ZLIB:
-        compressed_data = row[first_column_index]
-        serialized_data = zlib.decompress(compressed_data)
-      else:
-        compressed_data = b''
-        serialized_data = row[first_column_index]
-
-      if self._storage_profiler:
-        self._storage_profiler.Sample(
-            'read_create', 'read', container_type, len(serialized_data),
-            len(compressed_data))
+      compressed_data = b''
+      serialized_data = row[first_column_index]
 
-      container = self._DeserializeAttributeContainer(
-          container_type, serialized_data)
+    if self._storage_profiler:
+      self._storage_profiler.Sample(
+          'read_create', 'read', container_type, len(serialized_data),
+          len(compressed_data))
 
-    return container
+    return self._DeserializeAttributeContainer(container_type, serialized_data)
 
   def _CreateAttributeContainerTable(self, container_type):
     """Creates a table for a specific attribute container type.
 
     Args:
       container_type (str): attribute container type.
 
     Raises:
       IOError: when there is an error querying the storage file or if
           an unsupported attribute container is provided.
       OSError: when there is an error querying the storage file or if
           an unsupported attribute container is provided.
     """
-    column_definitions = ['_identifier INTEGER PRIMARY KEY AUTOINCREMENT']
+    if self.format_version > 20221023 or container_type not in (
+        self._READ_INCOMPATIBLE_CONTAINER_TYPES):
+      schema = self._GetAttributeContainerSchema(container_type)
+    else:
+      schema = None
 
-    schema = self._GetAttributeContainerSchema(container_type)
     if schema:
-      schema_to_sqlite_type_mappings = (
-            self._CONTAINER_SCHEMA_TO_SQLITE_TYPE_MAPPINGS)
-      for name, data_type in sorted(schema.items()):
-        data_type = schema_to_sqlite_type_mappings.get(data_type, 'TEXT')
-        column_definitions.append('{0:s} {1:s}'.format(name, data_type))
-
+      super(SQLiteStorageFile, self)._CreateAttributeContainerTable(
+          container_type)
     else:
       if self.compression_format == definitions.COMPRESSION_FORMAT_ZLIB:
         data_column_type = 'BLOB'
       else:
         data_column_type = 'TEXT'
 
-      column_definitions.append('_data {0:s}'.format(data_column_type))
+      query = (
+          'CREATE TABLE {0:s} (_identifier INTEGER PRIMARY KEY AUTOINCREMENT, '
+          '_data {1:s});').format(container_type, data_column_type)
 
-    column_definitions = ', '.join(column_definitions)
-    query = 'CREATE TABLE {0:s} ({1:s});'.format(
-        container_type, column_definitions)
-
-    try:
-      self._cursor.execute(query)
-    except (sqlite3.InterfaceError, sqlite3.OperationalError) as exception:
-      raise IOError('Unable to query storage file with error: {0!s}'.format(
-          exception))
+      try:
+        self._cursor.execute(query)
+      except (sqlite3.InterfaceError, sqlite3.OperationalError) as exception:
+        raise IOError('Unable to query storage file with error: {0!s}'.format(
+            exception))
 
     if container_type == self._CONTAINER_TYPE_EVENT_TAG:
       query = ('CREATE INDEX event_tag_per_event '
-               'ON event_tag (_event_identifier)')
+             'ON event_tag (_event_identifier)')
       try:
         self._cursor.execute(query)
       except (sqlite3.InterfaceError, sqlite3.OperationalError) as exception:
         raise IOError('Unable to query storage file with error: {0!s}'.format(
             exception))
 
   def _DeserializeAttributeContainer(self, container_type, serialized_data):
@@ -256,15 +237,21 @@
 
       if container.CONTAINER_TYPE == self._CONTAINER_TYPE_EVENT_DATA:
         event_data_stream_identifier = container.GetEventDataStreamIdentifier()
         if event_data_stream_identifier:
           json_dict['_event_data_stream_identifier'] = (
               event_data_stream_identifier.CopyToString())
 
-      serialized_string = json.dumps(json_dict)
+      try:
+        serialized_string = json.dumps(json_dict)
+      except TypeError as exception:
+        raise IOError((
+            'Unable to serialize attribute container: {0:s} with error: '
+            '{1!s}.').format(container.CONTAINER_TYPE, exception))
+
       if not serialized_string:
         raise IOError('Unable to serialize attribute container: {0:s}.'.format(
             container.CONTAINER_TYPE))
 
       serialized_string = serialized_string.encode('utf-8')
 
     finally:
@@ -283,22 +270,27 @@
 
     Raises:
       IOError: when there is an error querying the storage file or if
           an unsupported identifier is provided.
       OSError: when there is an error querying the storage file or if
           an unsupported identifier is provided.
     """
-    identifier = container.GetIdentifier()
+    if self.format_version > 20221023 or container.CONTAINER_TYPE not in (
+        self._READ_INCOMPATIBLE_CONTAINER_TYPES):
+      schema = self._GetAttributeContainerSchema(container.CONTAINER_TYPE)
+    else:
+      schema = None
 
-    schema = self._GetAttributeContainerSchema(container.CONTAINER_TYPE)
     if not schema:
       raise IOError(
           'Unsupported attribute container type: {0:s}'.format(
               container.CONTAINER_TYPE))
 
+    identifier = container.GetIdentifier()
+
     self._CommitWriteCache(container.CONTAINER_TYPE)
 
     column_names = []
     values = []
     for name, data_type in sorted(schema.items()):
       attribute_value = getattr(container, name, None)
       if attribute_value is not None:
@@ -361,49 +353,34 @@
     Args:
       container (AttributeContainer): attribute container.
 
     Raises:
       IOError: when there is an error querying the storage file.
       OSError: when there is an error querying the storage file.
     """
-    next_sequence_number = self._GetAttributeContainerNextSequenceNumber(
-        container.CONTAINER_TYPE)
-
-    if (next_sequence_number == 1 and
-        not self._HasTable(container.CONTAINER_TYPE)):
-      self._CreateAttributeContainerTable(container.CONTAINER_TYPE)
-
-    identifier = containers_interface.AttributeContainerIdentifier(
-        name=container.CONTAINER_TYPE, sequence_number=next_sequence_number)
-    container.SetIdentifier(identifier)
-
-    schema = self._GetAttributeContainerSchema(container.CONTAINER_TYPE)
+    if self.format_version > 20221023 or container.CONTAINER_TYPE not in (
+        self._READ_INCOMPATIBLE_CONTAINER_TYPES):
+      schema = self._GetAttributeContainerSchema(container.CONTAINER_TYPE)
+    else:
+      schema = None
 
     if schema:
-      column_names = []
-      values = []
-      for name, data_type in sorted(schema.items()):
-        attribute_value = getattr(container, name, None)
-        if attribute_value is not None:
-          if data_type == 'AttributeContainerIdentifier' and isinstance(
-              attribute_value,
-              containers_interface.AttributeContainerIdentifier):
-            attribute_value = attribute_value.CopyToString()
-
-          elif data_type == 'bool':
-            attribute_value = int(attribute_value)
-
-          elif data_type not in self._CONTAINER_SCHEMA_TO_SQLITE_TYPE_MAPPINGS:
-            # TODO: add compression support
-            attribute_value = self._serializer.WriteSerialized(attribute_value)
+      super(SQLiteStorageFile, self)._WriteNewAttributeContainer(container)
+    else:
+      next_sequence_number = self._GetAttributeContainerNextSequenceNumber(
+          container.CONTAINER_TYPE)
 
-        column_names.append(name)
-        values.append(attribute_value)
+      if (next_sequence_number == 1 and
+          not self._HasTable(container.CONTAINER_TYPE)):
+        self._CreateAttributeContainerTable(container.CONTAINER_TYPE)
+
+      identifier = containers_interface.AttributeContainerIdentifier(
+          name=container.CONTAINER_TYPE, sequence_number=next_sequence_number)
+      container.SetIdentifier(identifier)
 
-    else:
       serialized_data = self._SerializeAttributeContainer(container)
 
       if self.compression_format == definitions.COMPRESSION_FORMAT_ZLIB:
         compressed_data = zlib.compress(serialized_data)
         serialized_data = sqlite3.Binary(compressed_data)
       else:
         compressed_data = ''
@@ -412,18 +389,18 @@
         self._storage_profiler.Sample(
             'write_new', 'write', container.CONTAINER_TYPE,
             len(serialized_data), len(compressed_data))
 
       column_names = ['_data']
       values = [serialized_data]
 
-    self._CacheAttributeContainerForWrite(
-        container.CONTAINER_TYPE, column_names, values)
+      self._CacheAttributeContainerForWrite(
+          container.CONTAINER_TYPE, column_names, values)
 
-    self._CacheAttributeContainerByIndex(container, next_sequence_number - 1)
+      self._CacheAttributeContainerByIndex(container, next_sequence_number - 1)
 
   def GetAttributeContainerByIndex(self, container_type, index):
     """Retrieves a specific attribute container.
 
     Args:
       container_type (str): attribute container type.
       index (int): attribute container index.
@@ -433,28 +410,34 @@
 
     Raises:
       IOError: when the store is closed or when there is an error querying
           the storage file.
       OSError: when the store is closed or when there is an error querying
           the storage file.
     """
+    if self.format_version > 20221023 or container_type not in (
+        self._READ_INCOMPATIBLE_CONTAINER_TYPES):
+      schema = self._GetAttributeContainerSchema(container_type)
+    else:
+      schema = None
+
+    if schema:
+      return super(SQLiteStorageFile, self).GetAttributeContainerByIndex(
+          container_type, index)
+
     container = self._GetCachedAttributeContainer(container_type, index)
     if container:
       return container
 
     self._CommitWriteCache(container_type)
 
     if not self._attribute_container_sequence_numbers[container_type]:
       return None
 
-    schema = self._GetAttributeContainerSchema(container_type)
-    if schema:
-      column_names = sorted(schema.keys())
-    else:
-      column_names = ['_data']
+    column_names = ['_data']
 
     row_number = index + 1
     query = 'SELECT {0:s} FROM {1:s} WHERE rowid = {2:d}'.format(
         ', '.join(column_names), container_type, row_number)
 
     try:
       self._cursor.execute(query)
@@ -471,15 +454,15 @@
     finally:
       if self._storage_profiler:
         self._storage_profiler.StopTiming('get_container_by_index')
 
     if not row:
       return None
 
-    container = self._CreatetAttributeContainerFromRow(
+    container = self._CreateAttributeContainerFromRow(
         container_type, column_names, row, 0)
 
     identifier = containers_interface.AttributeContainerIdentifier(
         name=container_type, sequence_number=row_number)
     container.SetIdentifier(identifier)
 
     self._CacheAttributeContainerByIndex(container, index)
@@ -496,28 +479,31 @@
     Returns:
       generator(AttributeContainer): attribute container generator.
 
     Raises:
       IOError: when there is an error querying the storage file.
       OSError: when there is an error querying the storage file.
     """
-    schema = self._GetAttributeContainerSchema(container_type)
+    if self.format_version > 20221023 or container_type not in (
+        self._READ_INCOMPATIBLE_CONTAINER_TYPES):
+      schema = self._GetAttributeContainerSchema(container_type)
+    else:
+      schema = None
 
     if schema:
-      column_names = sorted(schema.keys())
-    else:
-      column_names = ['_data']
+      return super(SQLiteStorageFile, self).GetAttributeContainers(
+          container_type, filter_expression=filter_expression)
 
     sql_filter_expression = None
     if filter_expression:
       expression_ast = ast.parse(filter_expression, mode='eval')
       sql_filter_expression = sqlite_store.PythonAST2SQL(expression_ast.body)
 
     return self._GetAttributeContainersWithFilter(
-        container_type, column_names=column_names,
+        container_type, column_names=['_data'],
         filter_expression=sql_filter_expression)
 
   def GetSortedEvents(self, time_range=None):
     """Retrieves the events in increasing chronological order.
 
     Args:
       time_range (Optional[TimeRange]): time range used to filter events
```

### Comparing `plaso-20230311/plaso/storage/sqlite/writer.py` & `plaso-20230717/plaso/storage/sqlite/writer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/time_range.py` & `plaso-20230717/plaso/storage/time_range.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso/storage/writer.py` & `plaso-20230717/plaso/storage/writer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/plaso.egg-info/PKG-INFO` & `plaso-20230717/plaso.egg-info/PKG-INFO`

 * *Files 19% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: plaso
-Version: 20230311
+Version: 20230717
 Summary: Plaso (log2timeline) - Super timeline all the things
 Home-page: https://github.com/log2timeline/plaso
 Maintainer: Log2Timeline maintainers
 Maintainer-email: log2timeline-maintainers@googlegroups.com
 License: Apache License, Version 2.0
 Classifier: Development Status :: 4 - Beta
 Classifier: Environment :: Console
```

### Comparing `plaso-20230311/plaso.egg-info/SOURCES.txt` & `plaso-20230717/plaso.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -44,15 +44,14 @@
 config/dpkg/plaso-data.install
 config/dpkg/plaso-tools.install
 config/dpkg/python3-plaso.install
 config/dpkg/rules
 config/dpkg/source/format
 config/end_to_end/extract_and_output.Dockerfile
 config/end_to_end/run_tests_with_docker.sh
-config/jenkins/travis.ini
 config/jenkins/greendale/acserver-archive-cpio.ini
 config/jenkins/greendale/acserver-archive-tgz.ini
 config/jenkins/greendale/acserver-archive-zip.ini
 config/jenkins/greendale/acserver-mounted.ini
 config/jenkins/greendale/acserver-with_archives.ini
 config/jenkins/greendale/acserver.ini
 config/jenkins/greendale/bchang-laptop.ini
@@ -134,14 +133,15 @@
 docs/sources/api/plaso.analyzers.rst
 docs/sources/api/plaso.cli.helpers.rst
 docs/sources/api/plaso.cli.rst
 docs/sources/api/plaso.containers.rst
 docs/sources/api/plaso.engine.rst
 docs/sources/api/plaso.filters.rst
 docs/sources/api/plaso.formatters.rst
+docs/sources/api/plaso.helpers.macos.rst
 docs/sources/api/plaso.helpers.rst
 docs/sources/api/plaso.helpers.windows.rst
 docs/sources/api/plaso.lib.rst
 docs/sources/api/plaso.multi_process.rst
 docs/sources/api/plaso.multi_processing.rst
 docs/sources/api/plaso.output.rst
 docs/sources/api/plaso.parsers.bencode_plugins.rst
@@ -328,15 +328,14 @@
 plaso/containers/windows_events.py
 plaso/engine/__init__.py
 plaso/engine/artifact_filters.py
 plaso/engine/configurations.py
 plaso/engine/engine.py
 plaso/engine/extractors.py
 plaso/engine/filter_file.py
-plaso/engine/filters_helper.py
 plaso/engine/knowledge_base.py
 plaso/engine/logger.py
 plaso/engine/path_filters.py
 plaso/engine/path_helper.py
 plaso/engine/process_info.py
 plaso/engine/processing_status.py
 plaso/engine/profilers.py
@@ -369,14 +368,16 @@
 plaso/formatters/winevt.py
 plaso/formatters/winlnk.py
 plaso/formatters/winprefetch.py
 plaso/formatters/winreg.py
 plaso/formatters/yaml_formatters_file.py
 plaso/helpers/__init__.py
 plaso/helpers/language_tags.py
+plaso/helpers/macos/__init__.py
+plaso/helpers/macos/darwin.py
 plaso/helpers/windows/__init__.py
 plaso/helpers/windows/eventlog_providers.py
 plaso/helpers/windows/known_folders.py
 plaso/helpers/windows/languages.py
 plaso/helpers/windows/resource_files.py
 plaso/helpers/windows/shell_folders.py
 plaso/helpers/windows/time_zones.py
@@ -431,27 +432,30 @@
 plaso/output/tln.py
 plaso/output/winevt_rc.py
 plaso/output/xlsx.py
 plaso/parsers/__init__.py
 plaso/parsers/android_app_usage.py
 plaso/parsers/asl.py
 plaso/parsers/asl.yaml
+plaso/parsers/aul_dsc.yaml
+plaso/parsers/aul_timesync.yaml
+plaso/parsers/aul_tracev3.yaml
+plaso/parsers/aul_uuidtext.yaml
 plaso/parsers/bencode_parser.py
 plaso/parsers/bodyfile.py
 plaso/parsers/bsm.py
 plaso/parsers/bsm.yaml
 plaso/parsers/chrome_cache.py
 plaso/parsers/chrome_cache.yaml
 plaso/parsers/chrome_preferences.py
 plaso/parsers/cups_ipp.py
 plaso/parsers/cups_ipp.yaml
 plaso/parsers/custom_destinations.py
 plaso/parsers/custom_destinations.yaml
 plaso/parsers/czip.py
-plaso/parsers/detection_history.yaml
 plaso/parsers/dsv_parser.py
 plaso/parsers/esedb.py
 plaso/parsers/filestat.py
 plaso/parsers/firefox_cache.py
 plaso/parsers/firefox_cache.yaml
 plaso/parsers/fish_history.py
 plaso/parsers/fseventsd.py
@@ -459,24 +463,29 @@
 plaso/parsers/interface.py
 plaso/parsers/java_idx.py
 plaso/parsers/java_idx.yaml
 plaso/parsers/jsonl_parser.py
 plaso/parsers/locate.py
 plaso/parsers/locate.yaml
 plaso/parsers/logger.py
+plaso/parsers/macos_core_location.yaml
 plaso/parsers/macos_keychain.py
 plaso/parsers/macos_keychain.yaml
+plaso/parsers/macos_mdns.yaml
+plaso/parsers/macos_open_directory.yaml
 plaso/parsers/manager.py
 plaso/parsers/mcafeeav.py
 plaso/parsers/mediator.py
 plaso/parsers/msiecf.py
 plaso/parsers/networkminer.py
 plaso/parsers/ntfs.py
 plaso/parsers/ntfs.yaml
 plaso/parsers/olecf.py
+plaso/parsers/onedrive.py
+plaso/parsers/onedrive.yaml
 plaso/parsers/opera.py
 plaso/parsers/pe.py
 plaso/parsers/pe_resources.yaml
 plaso/parsers/plist.py
 plaso/parsers/pls_recall.py
 plaso/parsers/pls_recall.yaml
 plaso/parsers/plugins.py
@@ -489,23 +498,28 @@
 plaso/parsers/spotlight_storedb.yaml
 plaso/parsers/sqlite.py
 plaso/parsers/symantec.py
 plaso/parsers/systemd_journal.py
 plaso/parsers/systemd_journal.yaml
 plaso/parsers/text_parser.py
 plaso/parsers/trendmicroav.py
+plaso/parsers/unified_logging.py
 plaso/parsers/utmp.py
 plaso/parsers/utmp.yaml
 plaso/parsers/utmpx.py
+plaso/parsers/wincc.py
 plaso/parsers/windefender_history.py
+plaso/parsers/windefender_history.yaml
+plaso/parsers/windows_nt.yaml
 plaso/parsers/winevt.py
 plaso/parsers/winevtx.py
 plaso/parsers/winjob.py
 plaso/parsers/winjob.yaml
 plaso/parsers/winlnk.py
+plaso/parsers/winpca.py
 plaso/parsers/winprefetch.py
 plaso/parsers/winreg_parser.py
 plaso/parsers/winrestore.py
 plaso/parsers/winrestore.yaml
 plaso/parsers/bencode_plugins/__init__.py
 plaso/parsers/bencode_plugins/interface.py
 plaso/parsers/bencode_plugins/transmission.py
@@ -545,14 +559,15 @@
 plaso/parsers/plist_plugins/airport.py
 plaso/parsers/plist_plugins/apple_account.py
 plaso/parsers/plist_plugins/bluetooth.py
 plaso/parsers/plist_plugins/default.py
 plaso/parsers/plist_plugins/install_history.py
 plaso/parsers/plist_plugins/interface.py
 plaso/parsers/plist_plugins/ios_carplay.py
+plaso/parsers/plist_plugins/ios_identityservices.py
 plaso/parsers/plist_plugins/ipod.py
 plaso/parsers/plist_plugins/launchd.py
 plaso/parsers/plist_plugins/macos_user.py
 plaso/parsers/plist_plugins/safari_downloads.py
 plaso/parsers/plist_plugins/safari_history.py
 plaso/parsers/plist_plugins/software_update.py
 plaso/parsers/plist_plugins/spotlight_searched_terms.py
@@ -576,14 +591,15 @@
 plaso/parsers/sqlite_plugins/dropbox.py
 plaso/parsers/sqlite_plugins/firefox_cookies.py
 plaso/parsers/sqlite_plugins/firefox_downloads.py
 plaso/parsers/sqlite_plugins/firefox_history.py
 plaso/parsers/sqlite_plugins/gdrive.py
 plaso/parsers/sqlite_plugins/imessage.py
 plaso/parsers/sqlite_plugins/interface.py
+plaso/parsers/sqlite_plugins/ios_datausage.py
 plaso/parsers/sqlite_plugins/ios_kik.py
 plaso/parsers/sqlite_plugins/ios_netusage.py
 plaso/parsers/sqlite_plugins/ios_powerlog.py
 plaso/parsers/sqlite_plugins/ios_screentime.py
 plaso/parsers/sqlite_plugins/ios_twitter.py
 plaso/parsers/sqlite_plugins/kodi.py
 plaso/parsers/sqlite_plugins/ls_quarantine.py
@@ -615,14 +631,15 @@
 plaso/parsers/text_plugins/ios_logd.py
 plaso/parsers/text_plugins/ios_sysdiag_log.py
 plaso/parsers/text_plugins/macos_appfirewall.py
 plaso/parsers/text_plugins/macos_securityd.py
 plaso/parsers/text_plugins/macos_wifi.py
 plaso/parsers/text_plugins/popcontest.py
 plaso/parsers/text_plugins/postgresql.py
+plaso/parsers/text_plugins/powershell_transcript.py
 plaso/parsers/text_plugins/santa.py
 plaso/parsers/text_plugins/sccm.py
 plaso/parsers/text_plugins/selinux.py
 plaso/parsers/text_plugins/setupapi.py
 plaso/parsers/text_plugins/skydrivelog.py
 plaso/parsers/text_plugins/snort_fastlog.py
 plaso/parsers/text_plugins/sophos_av.py
@@ -690,14 +707,15 @@
 plaso/serializer/logger.py
 plaso/single_process/__init__.py
 plaso/single_process/extraction_engine.py
 plaso/storage/__init__.py
 plaso/storage/factory.py
 plaso/storage/logger.py
 plaso/storage/reader.py
+plaso/storage/serializers.py
 plaso/storage/time_range.py
 plaso/storage/writer.py
 plaso/storage/fake/__init__.py
 plaso/storage/fake/event_heap.py
 plaso/storage/fake/fake_store.py
 plaso/storage/fake/writer.py
 plaso/storage/redis/__init__.py
@@ -811,15 +829,14 @@
 tests/data/test_lib.py
 tests/engine/__init__.py
 tests/engine/artifact_filters.py
 tests/engine/configurations.py
 tests/engine/engine.py
 tests/engine/extractors.py
 tests/engine/filter_file.py
-tests/engine/filters_helper.py
 tests/engine/knowledge_base.py
 tests/engine/path_filters.py
 tests/engine/path_helper.py
 tests/engine/process_info.py
 tests/engine/processing_status.py
 tests/engine/profilers.py
 tests/engine/tagging_file.py
@@ -928,35 +945,39 @@
 tests/parsers/manager.py
 tests/parsers/mcafeeav.py
 tests/parsers/mediator.py
 tests/parsers/msiecf.py
 tests/parsers/networkminer.py
 tests/parsers/ntfs.py
 tests/parsers/olecf.py
+tests/parsers/onedrive.py
 tests/parsers/opera.py
 tests/parsers/pe.py
 tests/parsers/plist.py
 tests/parsers/pls_recall.py
 tests/parsers/presets.py
 tests/parsers/recycler.py
 tests/parsers/safari_cookies.py
 tests/parsers/spotlight_storedb.py
 tests/parsers/sqlite.py
 tests/parsers/symantec.py
 tests/parsers/systemd_journal.py
 tests/parsers/test_lib.py
 tests/parsers/text_parser.py
 tests/parsers/trendmicroav.py
+tests/parsers/unified_logging.py
 tests/parsers/utmp.py
 tests/parsers/utmpx.py
+tests/parsers/wincc.py
 tests/parsers/windefender_history.py
 tests/parsers/winevt.py
 tests/parsers/winevtx.py
 tests/parsers/winjob.py
 tests/parsers/winlnk.py
+tests/parsers/winpca.py
 tests/parsers/winprefetch.py
 tests/parsers/winreg_parser.py
 tests/parsers/winrestore.py
 tests/parsers/bencode_plugins/__init__.py
 tests/parsers/bencode_plugins/test_lib.py
 tests/parsers/bencode_plugins/transmission.py
 tests/parsers/bencode_plugins/utorrent.py
@@ -992,24 +1013,26 @@
 tests/parsers/plist_plugins/airport.py
 tests/parsers/plist_plugins/apple_account.py
 tests/parsers/plist_plugins/bluetooth.py
 tests/parsers/plist_plugins/default.py
 tests/parsers/plist_plugins/install_history.py
 tests/parsers/plist_plugins/interface.py
 tests/parsers/plist_plugins/ios_carplay.py
+tests/parsers/plist_plugins/ios_identityservices.py
 tests/parsers/plist_plugins/ipod.py
 tests/parsers/plist_plugins/launchd.py
 tests/parsers/plist_plugins/macos_user.py
 tests/parsers/plist_plugins/safari_downloads.py
 tests/parsers/plist_plugins/safari_history.py
 tests/parsers/plist_plugins/software_update.py
 tests/parsers/plist_plugins/spotlight_searched_terms.py
 tests/parsers/plist_plugins/spotlight_volume.py
 tests/parsers/plist_plugins/test_lib.py
 tests/parsers/plist_plugins/time_machine.py
+tests/parsers/shared/__init__.py
 tests/parsers/sqlite_plugins/__init__.py
 tests/parsers/sqlite_plugins/android_calls.py
 tests/parsers/sqlite_plugins/android_hangouts.py
 tests/parsers/sqlite_plugins/android_sms.py
 tests/parsers/sqlite_plugins/android_tango.py
 tests/parsers/sqlite_plugins/android_twitter.py
 tests/parsers/sqlite_plugins/android_webview.py
@@ -1021,14 +1044,15 @@
 tests/parsers/sqlite_plugins/dropbox.py
 tests/parsers/sqlite_plugins/firefox_cookies.py
 tests/parsers/sqlite_plugins/firefox_downloads.py
 tests/parsers/sqlite_plugins/firefox_history.py
 tests/parsers/sqlite_plugins/gdrive.py
 tests/parsers/sqlite_plugins/imessage.py
 tests/parsers/sqlite_plugins/interface.py
+tests/parsers/sqlite_plugins/ios_datausage.py
 tests/parsers/sqlite_plugins/ios_kik.py
 tests/parsers/sqlite_plugins/ios_netusage.py
 tests/parsers/sqlite_plugins/ios_powerlog.py
 tests/parsers/sqlite_plugins/ios_screentime.py
 tests/parsers/sqlite_plugins/ios_twitter.py
 tests/parsers/sqlite_plugins/kodi.py
 tests/parsers/sqlite_plugins/ls_quarantine.py
@@ -1061,14 +1085,15 @@
 tests/parsers/text_plugins/ios_logd.py
 tests/parsers/text_plugins/ios_sysdiag_log.py
 tests/parsers/text_plugins/macos_appfirewall.py
 tests/parsers/text_plugins/macos_securityd.py
 tests/parsers/text_plugins/macos_wifi.py
 tests/parsers/text_plugins/popcontest.py
 tests/parsers/text_plugins/postgresql.py
+tests/parsers/text_plugins/powershell_transcript.py
 tests/parsers/text_plugins/santa.py
 tests/parsers/text_plugins/sccm.py
 tests/parsers/text_plugins/selinux.py
 tests/parsers/text_plugins/setupapi.py
 tests/parsers/text_plugins/skydrivelog.py
 tests/parsers/text_plugins/snort_fastlog.py
 tests/parsers/text_plugins/sophos_av.py
```

### Comparing `plaso-20230311/plaso.egg-info/requires.txt` & `plaso-20230717/plaso.egg-info/requires.txt`

 * *Files 22% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 pip>=7.0.0
 PyYAML>=3.10
 XlsxWriter>=0.9.3
-acstore>=20230101
+acstore>=20230519
 artifacts>=20220219
 bencode.py
 certifi>=2016.9.26
 cffi>=1.9.1
 cryptography>=2.0.2
 defusedxml>=0.5.0
 dfdatetime>=20221112
-dfvfs>=20221224
+dfvfs>=20230407
 dfwinreg>=20211207
-dtfabric>=20220219
+dtfabric>=20230518
 flor>=1.1.3
 future>=0.16.0
 libbde-python>=20220121
+libcaes-python>=20221127
 libcreg-python>=20200725
 libesedb-python>=20220806
 libevt-python>=20191104
 libevtx-python>=20220724
 libewf-python>=20131210
 libfsapfs-python>=20201107
 libfsext-python>=20220112
@@ -50,13 +51,15 @@
 opensearch-py
 pefile>=2021.5.24
 psutil>=5.4.3
 pyparsing<3.1.0,>=2.4.2
 python-dateutil>=1.5
 pytsk3>=20210419
 pytz
-pyxattr>=0.7.2
 pyzmq>=2.1.11
 redis>=3.4
 requests>=2.18.0
 six>=1.1.0
 yara-python>=3.4.0
+
+[:platform_system != "Windows"]
+pyxattr>=0.7.2
```

### Comparing `plaso-20230311/plaso.ini` & `plaso-20230717/plaso.ini`

 * *Files identical despite different names*

### Comparing `plaso-20230311/requirements.txt` & `plaso-20230717/requirements.txt`

 * *Files 10% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 pip >= 7.0.0
 PyYAML >= 3.10
 XlsxWriter >= 0.9.3
-acstore >= 20230101
+acstore >= 20230519
 artifacts >= 20220219
 bencode.py
 certifi >= 2016.9.26
 cffi >= 1.9.1
 cryptography >= 2.0.2
 defusedxml >= 0.5.0
 dfdatetime >= 20221112
-dfvfs >= 20221224
+dfvfs >= 20230407
 dfwinreg >= 20211207
-dtfabric >= 20220219
+dtfabric >= 20230518
 flor >= 1.1.3
 future >= 0.16.0
 libbde-python >= 20220121
+libcaes-python >= 20221127
 libcreg-python >= 20200725
 libesedb-python >= 20220806
 libevt-python >= 20191104
 libevtx-python >= 20220724
 libewf-python >= 20131210
 libfsapfs-python >= 20201107
 libfsext-python >= 20220112
@@ -50,13 +51,13 @@
 opensearch-py
 pefile >= 2021.5.24
 psutil >= 5.4.3
 pyparsing >= 2.4.2,< 3.1.0
 python-dateutil >= 1.5
 pytsk3 >= 20210419
 pytz
-pyxattr >= 0.7.2
+pyxattr >= 0.7.2 ; platform_system != "Windows"
 pyzmq >= 2.1.11
 redis >= 3.4
 requests >= 2.18.0
 six >= 1.1.0
 yara-python >= 3.4.0
```

### Comparing `plaso-20230311/run_tests.py` & `plaso-20230717/run_tests.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/setup.cfg` & `plaso-20230717/setup.cfg`

 * *Files 2% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 packager = Log2Timeline maintainers <log2timeline-maintainers@googlegroups.com>
 doc_files = ACKNOWLEDGEMENTS
 	AUTHORS
 	LICENSE
 	README
 build_requires = python3-setuptools
 requires = libbde-python3 >= 20220121
+	libcaes-python3 >= 20221127
 	libcreg-python3 >= 20200725
 	libesedb-python3 >= 20220806
 	libevt-python3 >= 20191104
 	libevtx-python3 >= 20220724
 	libewf-python3 >= 20131210
 	libfsapfs-python3 >= 20201107
 	libfsext-python3 >= 20220112
@@ -46,27 +47,27 @@
 	libsmraw-python3 >= 20140612
 	libvhdi-python3 >= 20201014
 	libvmdk-python3 >= 20140421
 	libvsgpt-python3 >= 20211115
 	libvshadow-python3 >= 20160109
 	libvslvm-python3 >= 20160109
 	python3-XlsxWriter >= 0.9.3
-	python3-acstore >= 20230101
+	python3-acstore >= 20230519
 	python3-artifacts >= 20220219
 	python3-bencode
 	python3-certifi >= 2016.9.26
 	python3-cffi >= 1.9.1
 	python3-chardet >= 2.0.1
 	python3-cryptography >= 2.0.2
 	python3-dateutil >= 1.5
 	python3-defusedxml >= 0.5.0
 	python3-dfdatetime >= 20221112
-	python3-dfvfs >= 20221224
+	python3-dfvfs >= 20230407
 	python3-dfwinreg >= 20211207
-	python3-dtfabric >= 20220219
+	python3-dtfabric >= 20230518
 	python3-future >= 0.16.0
 	python3-idna >= 2.5
 	python3-lz4 >= 0.10.0
 	python3-opensearch
 	python3-pefile >= 2021.5.24
 	python3-psutil >= 5.4.3
 	python3-pyparsing >= 2.4.2
```

### Comparing `plaso-20230311/setup.py` & `plaso-20230717/setup.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/bloom.py` & `plaso-20230717/tests/analysis/bloom.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/browser_search.py` & `plaso-20230717/tests/analysis/browser_search.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/chrome_extension.py` & `plaso-20230717/tests/analysis/chrome_extension.py`

 * *Files 9% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 """Tests for the Chrome extension analysis plugin."""
 
 import collections
 import os
 import unittest
 
 from plaso.analysis import chrome_extension
+from plaso.containers import artifacts
 from plaso.containers import reports
 from plaso.lib import definitions
 
 from tests import test_lib as shared_test_lib
 from tests.analysis import test_lib
 
 
@@ -59,20 +60,14 @@
       {'_parser_chain': 'filestat',
        'data_type': 'fs:stat',
        'filename': path,
        'timestamp': '2015-01-01 17:00:00',
        'timestamp_desc': definitions.TIME_DESCRIPTION_UNKNOWN}
       for path in _MACOS_PATHS]
 
-  _MACOS_USERS = [
-      {'name': 'root', 'path': '/var/root', 'sid': '0'},
-      {'name': 'frank', 'path': '/Users/frank', 'sid': '4052'},
-      {'name': 'hans', 'path': '/Users/hans', 'sid': '4352'},
-      {'name': 'dude', 'path': '/Users/dude', 'sid': '1123'}]
-
   _WINDOWS_PATHS = [
       'C:\\Users\\Dude\\SomeFolder\\Chrome\\Default\\Extensions',
       ('C:\\Users\\Dude\\SomeNoneStandardFolder\\Chrome\\Default\\Extensions\\'
        'hmjkmjkepdijhoojdojkdfohbdgmmhki'),
       ('C:\\Users\\frank\\AppData\\Local\\Google\\Chrome\\Extensions\\'
        'blpcfgokakmgnkcojhhkbfbldkacnbeo'),
       'C:\\Users\\frank\\AppData\\Local\\Google\\Chrome\\Extensions',
@@ -85,18 +80,14 @@
       {'_parser_chain': 'filestat',
        'data_type': 'fs:stat',
        'filename': path,
        'timestamp': '2015-01-01 17:00:00',
        'timestamp_desc': definitions.TIME_DESCRIPTION_UNKNOWN}
       for path in _WINDOWS_PATHS]
 
-  _WINDOWS_USERS = [
-      {'name': 'dude', 'path': 'C:\\Users\\dude', 'sid': 'S-1'},
-      {'name': 'frank', 'path': 'C:\\Users\\frank', 'sid': 'S-2'}]
-
   def testGetPathSegmentSeparator(self):
     """Tests the _GetPathSegmentSeparator function."""
     test_file_path = self._GetTestFilePath(['chrome_extensions'])
     self._SkipIfPathNotExists(test_file_path)
 
     plugin = MockChromeExtensionPlugin()
 
@@ -109,18 +100,27 @@
       self.assertEqual(path_segment_separator, '\\')
 
   def testExamineEventAndCompileReportMacOSPaths(self):
     """Tests the ExamineEvent and CompileReport functions on MacOS paths."""
     test_file_path = self._GetTestFilePath(['chrome_extensions'])
     self._SkipIfPathNotExists(test_file_path)
 
+    user_accounts = [
+        artifacts.UserAccountArtifact(
+            identifier='0', user_directory='/var/root', username='root'),
+        artifacts.UserAccountArtifact(
+            identifier='1123', user_directory='/Users/dude', username='dude'),
+        artifacts.UserAccountArtifact(
+            identifier='4052', user_directory='/Users/frank', username='frank'),
+        artifacts.UserAccountArtifact(
+            identifier='4352', user_directory='/Users/hans', username='hans')]
+
     plugin = MockChromeExtensionPlugin()
     storage_writer = self._AnalyzeEvents(
-        self._MACOS_TEST_EVENTS, plugin, knowledge_base_values={
-            'users': self._MACOS_USERS})
+        self._MACOS_TEST_EVENTS, plugin, user_accounts=user_accounts)
 
     analysis_results = list(storage_writer.GetAttributeContainers(
         'chrome_extension_analysis_result'))
     self.assertEqual(len(analysis_results), 2)
 
     analysis_result = analysis_results[0]
     self.assertEqual(analysis_result.extension, 'Google Drive')
@@ -146,18 +146,25 @@
         analysis_report.analysis_counter, expected_analysis_counter)
 
   def testExamineEventAndCompileReportWindowsPaths(self):
     """Tests the ExamineEvent and CompileReport functions on Windows paths."""
     test_file_path = self._GetTestFilePath(['chrome_extensions'])
     self._SkipIfPathNotExists(test_file_path)
 
+    user_accounts = [
+        artifacts.UserAccountArtifact(
+            identifier='S-1', path_separator='\\',
+            user_directory='C:\\Users\\dude', username='dude'),
+        artifacts.UserAccountArtifact(
+            identifier='S-2', path_separator='\\',
+            user_directory='C:\\Users\\frank', username='frank')]
+
     plugin = MockChromeExtensionPlugin()
     storage_writer = self._AnalyzeEvents(
-        self._WINDOWS_TEST_EVENTS, plugin, knowledge_base_values={
-            'users': self._WINDOWS_USERS})
+        self._WINDOWS_TEST_EVENTS, plugin, user_accounts=user_accounts)
 
     analysis_results = list(storage_writer.GetAttributeContainers(
         'chrome_extension_analysis_result'))
     self.assertEqual(len(analysis_results), 3)
 
     analysis_result = analysis_results[0]
     self.assertEqual(analysis_result.extension, 'Google Keep - notes and lists')
```

### Comparing `plaso-20230311/tests/analysis/hash_tagging.py` & `plaso-20230717/tests/analysis/hash_tagging.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/init_imports.py` & `plaso-20230717/tests/analysis/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/manager.py` & `plaso-20230717/tests/analysis/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/nsrlsvr.py` & `plaso-20230717/tests/analysis/nsrlsvr.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/sessionize.py` & `plaso-20230717/tests/analysis/sessionize.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/tagging.py` & `plaso-20230717/tests/analysis/tagging.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/test_lib.py` & `plaso-20230717/tests/parsers/test_lib.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,211 +1,228 @@
 # -*- coding: utf-8 -*-
-"""Analysis plugin related functions and classes for testing."""
+"""Parser related functions and classes for testing."""
+
+from dfdatetime import interface as dfdatetime_interface
+from dfdatetime import posix_time as dfdatetime_posix_time
+
+from dfvfs.file_io import fake_file_io
+from dfvfs.lib import definitions as dfvfs_definitions
+from dfvfs.path import factory as path_spec_factory
+from dfvfs.path import fake_path_spec
+from dfvfs.resolver import context as dfvfs_context
+from dfvfs.resolver import resolver as path_spec_resolver
 
-from plaso.analysis import mediator as analysis_mediator
-from plaso.containers import artifacts
 from plaso.containers import events
-from plaso.containers import sessions
-from plaso.engine import knowledge_base
-from plaso.engine import timeliner
-from plaso.parsers import interface as parsers_interface
+from plaso.parsers import interface
 from plaso.parsers import mediator as parsers_mediator
 from plaso.storage.fake import writer as fake_writer
 
 from tests import test_lib as shared_test_lib
-from tests.containers import test_lib as containers_test_lib
 
 
-class AnalysisPluginTestCase(shared_test_lib.BaseTestCase):
-  """The unit test case for an analysis plugin."""
+class ParserTestCase(shared_test_lib.BaseTestCase):
+  """Parser test case."""
 
-  def _AnalyzeEvents(
-      self, event_values_list, plugin, knowledge_base_values=None):
-    """Analyzes events using the analysis plugin.
+  def _CreateFileObject(self, filename, data):
+    """Creates a file-like object.
 
     Args:
-      event_values_list (list[dict[str, object]]): list of event values.
-      plugin (AnalysisPlugin): plugin.
-      knowledge_base_values (Optional[dict[str, str]]): knowledge base values.
+      filename (str): name of the file.
+      data (bytes): data of the file.
 
     Returns:
-      FakeStorageWriter: storage writer.
+      dfvfs.FakeFile: file-like object.
     """
-    knowledge_base_object = self._SetUpKnowledgeBase(
-        knowledge_base_values=knowledge_base_values)
+    resolver_context = dfvfs_context.Context()
 
-    session = sessions.Session()
-    storage_writer = fake_writer.FakeStorageWriter()
-    storage_writer.Open()
+    location = '/{0:s}'.format(filename)
+    test_path_spec = fake_path_spec.FakePathSpec(location=location)
+    file_object = fake_file_io.FakeFile(resolver_context, test_path_spec, data)
+    file_object.Open()
 
-    test_events = []
-    for event, event_data, event_data_stream in (
-        containers_test_lib.CreateEventsFromValues(event_values_list)):
-      storage_writer.AddAttributeContainer(event_data_stream)
+    return file_object
 
-      event_data.SetEventDataStreamIdentifier(event_data_stream.GetIdentifier())
-      storage_writer.AddAttributeContainer(event_data)
+  def _CreateParserMediator(self, storage_writer, file_entry=None):
+    """Creates a parser mediator.
 
-      event.SetEventDataIdentifier(event_data.GetIdentifier())
-      storage_writer.AddAttributeContainer(event)
+    Args:
+      storage_writer (StorageWriter): storage writer.
+      file_entry (Optional[dfvfs.FileEntry]): file entry object being parsed.
 
-      test_events.append((event, event_data, event_data_stream))
+    Returns:
+      ParserMediator: parser mediator.
+    """
+    parser_mediator = parsers_mediator.ParserMediator()
+    parser_mediator.SetStorageWriter(storage_writer)
 
-    mediator = analysis_mediator.AnalysisMediator(
-        session, knowledge_base_object)
-    mediator.SetStorageWriter(storage_writer)
+    if file_entry:
+      parser_mediator.SetFileEntry(file_entry)
 
-    for event, event_data, event_data_stream in test_events:
-      plugin.ExamineEvent(mediator, event, event_data, event_data_stream)
+    return parser_mediator
 
-    analysis_report = plugin.CompileReport(mediator)
-    storage_writer.AddAttributeContainer(analysis_report)
+  def _CreateStorageWriter(self):
+    """Creates a storage writer object.
 
+    Returns:
+      FakeStorageWriter: storage writer.
+    """
+    storage_writer = fake_writer.FakeStorageWriter()
+    storage_writer.Open()
     return storage_writer
 
-  def _ParseAndAnalyzeFile(
-      self, path_segments, parser, plugin, knowledge_base_values=None):
-    """Parses and analyzes a file using the parser and analysis plugin.
+  def _GetEventDataOfEvent(self, storage_writer, event):
+    """Retrieves the event data of an event.
+
+    Args:
+      storage_writer (FakeStorageWriter): storage writer.
+      event (EventObject): event.
+
+    Return:
+      EventData: event data corresponding to the event.
+    """
+    event_data_identifier = event.GetEventDataIdentifier()
+    return storage_writer.GetAttributeContainerByIdentifier(
+        events.EventData.CONTAINER_TYPE, event_data_identifier)
+
+  def _ParseFile(self, path_segments, parser, registry_find_specs=None):
+    """Parses a file with a parser and writes results to a storage writer.
 
     Args:
       path_segments (list[str]): path segments inside the test data directory.
       parser (BaseParser): parser.
-      plugin (AnalysisPlugin): plugin.
-      knowledge_base_values (Optional[dict[str, str]]): knowledge base values.
+      registry_find_specs (Optional[list[dfwinreg.FindSpec]]): Windows Registry
+          find specifications.
 
     Returns:
       FakeStorageWriter: storage writer.
 
     Raises:
       SkipTest: if the path inside the test data directory does not exist and
           the test should be skipped.
     """
-    session = sessions.Session()
-
-    knowledge_base_object = self._SetUpKnowledgeBase(
-        knowledge_base_values=knowledge_base_values)
-
-    storage_writer = self._ParseFile(
-        path_segments, parser, knowledge_base_object)
-
-    mediator = analysis_mediator.AnalysisMediator(
-        session, knowledge_base_object)
-    mediator.SetStorageWriter(storage_writer)
-
-    for event in storage_writer.GetSortedEvents():
-      event_data = None
-      event_data_identifier = event.GetEventDataIdentifier()
-      if event_data_identifier:
-        event_data = storage_writer.GetAttributeContainerByIdentifier(
-            events.EventData.CONTAINER_TYPE, event_data_identifier)
-
-      event_data_stream = None
-      if event_data:
-        event_data_stream_identifier = event_data.GetEventDataStreamIdentifier()
-        if event_data_stream_identifier:
-          event_data_stream = storage_writer.GetAttributeContainerByIdentifier(
-              events.EventDataStream.CONTAINER_TYPE,
-              event_data_stream_identifier)
+    test_file_path = self._GetTestFilePath(path_segments)
+    self._SkipIfPathNotExists(test_file_path)
 
-      plugin.ExamineEvent(mediator, event, event_data, event_data_stream)
+    path_spec = path_spec_factory.Factory.NewPathSpec(
+        dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
+    return self._ParseFileByPathSpec(
+        path_spec, parser, registry_find_specs=registry_find_specs)
 
-    analysis_report = plugin.CompileReport(mediator)
-    storage_writer.AddAttributeContainer(analysis_report)
-
-    return storage_writer
-
-  def _ParseFile(self, path_segments, parser, knowledge_base_object):
-    """Parses a file using the parser.
+  def _ParseFileByPathSpec(self, path_spec, parser, registry_find_specs=None):
+    """Parses a file with a parser and writes results to a storage writer.
 
     Args:
-      path_segments (list[str]): path segments inside the test data directory.
+      path_spec (dfvfs.PathSpec): path specification.
       parser (BaseParser): parser.
-      knowledge_base_object (KnowledgeBase): knowledge base.
+      registry_find_specs (Optional[list[dfwinreg.FindSpec]]): Windows Registry
+          find specifications.
 
     Returns:
       FakeStorageWriter: storage writer.
 
     Raises:
       SkipTest: if the path inside the test data directory does not exist and
           the test should be skipped.
     """
-    parser_mediator = parsers_mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = parsers_mediator.ParserMediator(
+        registry_find_specs=registry_find_specs)
 
-    storage_writer = fake_writer.FakeStorageWriter()
-    storage_writer.Open()
+    storage_writer = self._CreateStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
-    file_entry = self._GetTestFileEntry(path_segments)
+    file_entry = path_spec_resolver.Resolver.OpenFileEntry(path_spec)
     parser_mediator.SetFileEntry(file_entry)
 
-    event_data_stream = events.EventDataStream()
-    parser_mediator.ProduceEventDataStream(event_data_stream)
+    if file_entry:
+      event_data_stream = events.EventDataStream()
+      event_data_stream.path_spec = file_entry.path_spec
 
-    if isinstance(parser, parsers_interface.FileEntryParser):
+      parser_mediator.ProduceEventDataStream(event_data_stream)
+
+    if isinstance(parser, interface.FileEntryParser):
       parser.Parse(parser_mediator)
 
-    elif isinstance(parser, parsers_interface.FileObjectParser):
+    elif isinstance(parser, interface.FileObjectParser):
       file_object = file_entry.GetFileObject()
       parser.Parse(parser_mediator, file_object)
 
     else:
-      self.fail('Got unexpected parser type: {0!s}'.format(type(parser)))
-
-    self._ProcessEventData(knowledge_base_object, storage_writer)
+      parser_type = type(parser)
+      self.fail('Unsupported parser type: {0!s}'.format(parser_type))
 
     return storage_writer
 
-  def _ProcessEventData(
-      self, knowledge_base_object, storage_writer):
-    """Generate events from event data.
+  def CheckEventData(self, event_data, expected_event_values):
+    """Asserts that event data matches the expected values.
 
     Args:
-      knowledge_base_object (KnowledgeBase): knowledge base.
-      storage_writer (StorageWriter): storage writer.
-    """
-    event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base_object, data_location=shared_test_lib.DATA_PATH)
-
-    event_data = storage_writer.GetFirstWrittenEventData()
-    while event_data:
-      event_data_timeliner.ProcessEventData(storage_writer, event_data)
-
-      event_data = storage_writer.GetNextWrittenEventData()
+      event_data (EventData): event data to check.
+      expected_event_values (dict[str, list[str]): expected values of the event
+          data attribute values per name.
+    """
+    for name, expected_value in expected_event_values.items():
+      value = getattr(event_data, name, None)
+      if isinstance(value, dfdatetime_interface.DateTimeValues):
+        date_time_value = value.CopyToDateTimeStringISO8601()
+        if not date_time_value:
+          # Call CopyToDateTimeString to support semantic date time values.
+          date_time_value = value.CopyToDateTimeString()
+        value = date_time_value
+
+      elif isinstance(value, list) and value and isinstance(
+          value[0], dfdatetime_interface.DateTimeValues):
+        value = [date_time_value.CopyToDateTimeStringISO8601()
+                 for date_time_value in value]
+
+      error_message = (
+          'event value: "{0:s}" does not match expected value').format(name)
+      self.assertEqual(value, expected_value, error_message)
 
-  def _SetUpKnowledgeBase(self, knowledge_base_values=None):
-    """Sets up a knowledge base.
+  def CheckEventValues(self, storage_writer, event, expected_event_values):
+    """Asserts that an event and its event data matches the expected values.
 
     Args:
-      knowledge_base_values (Optional[dict[str, str]]): knowledge base values.
-
-    Returns:
-      KnowledgeBase: knowledge base.
-    """
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    if knowledge_base_values:
-      for identifier, value in knowledge_base_values.items():
-        if identifier == 'users':
-          self._SetUserAccounts(knowledge_base_object, value)
-        else:
-          knowledge_base_object.SetValue(identifier, value)
-
-    return knowledge_base_object
-
-  def _SetUserAccounts(self, knowledge_base_object, users):
-    """Sets the user accounts in the knowledge base.
-
-    Args:
-      knowledge_base_object (KnowledgeBase): used to store information about
-          users.
-      users (list[dict[str, str])): users, for example [{'name': 'me',
-        'sid': 'S-1', 'uid': '1'}]
-    """
-    for user in users:
-      identifier = user.get('sid', user.get('uid', None))
-      if not identifier:
-        continue
-
-      user_account_artifact = artifacts.UserAccountArtifact(
-          identifier=identifier, user_directory=user.get('path', None),
-          username=user.get('name', None))
-
-      knowledge_base_object.AddUserAccount(user_account_artifact)
+      storage_writer (StorageWriter): storage writer.
+      event (EventObject): event to check.
+      expected_event_values (dict[str, list[str]): expected values of the event
+          and event data attribute values per name.
+    """
+    event_data = None
+    for name, expected_value in expected_event_values.items():
+      if name == 'timestamp' and isinstance(expected_value, str):
+        posix_time = dfdatetime_posix_time.PosixTimeInMicroseconds(
+            timestamp=event.timestamp)
+        value = posix_time.CopyToDateTimeString()
+
+      elif name in ('date_time', 'timestamp', 'timestamp_desc'):
+        value = getattr(event, name, None)
+
+      else:
+        if not event_data:
+          event_data = self._GetEventDataOfEvent(storage_writer, event)
+
+        value = getattr(event_data, name, None)
+
+      if name == 'date_time' and value and isinstance(expected_value, str):
+        date_time_value = value.CopyToDateTimeStringISO8601()
+        if not date_time_value:
+          # Call CopyToDateTimeString to support semantic date time values.
+          date_time_value = value.CopyToDateTimeString()
+        value = date_time_value
+
+      error_message = (
+          'event value: "{0:s}" does not match expected value').format(name)
+      self.assertEqual(value, expected_value, error_message)
+
+  def CheckTimestamp(self, timestamp, expected_date_time):
+    """Asserts that a timestamp value matches the expected date and time.
+
+    Args:
+      timestamp (int): timestamp, which contains the number of microseconds
+          since January 1, 1970, 00:00:00 UTC.
+      expected_date_time (str): expected date and time in UTC, formatted as:
+          YYYY-MM-DD hh:mm:ss.######
+    """
+    posix_time = dfdatetime_posix_time.PosixTimeInMicroseconds(
+        timestamp=timestamp)
+    date_time = posix_time.CopyToDateTimeString()
+    self.assertEqual(date_time, expected_date_time)
```

### Comparing `plaso-20230311/tests/analysis/unique_domains_visited.py` & `plaso-20230717/tests/analysis/unique_domains_visited.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analysis/viper.py` & `plaso-20230717/tests/analysis/viper.py`

 * *Files 6% similar despite different names*

```diff
@@ -46,20 +46,22 @@
           location='C:\\WINDOWS\\system32\\evil.exe'),
       'pe_type': 'Executable (EXE)',
       'sha256_hash': _EVENT_1_HASH,
       'timestamp': '2015-01-01 17:00:00',
       'timestamp_desc': definitions.TIME_DESCRIPTION_UNKNOWN}]
 
   # pylint: disable=unused-argument
-  def _MockPost(self, url, data=None):
+  def _MockPost(self, url, data=None, timeout=None):
     """Mock function to simulate a Viper API request.
 
     Args:
       url (str): URL being requested.
-      data (dict[str, object]): simulated form data for the Viper API request.
+      data (Optional[dict[str, object]]): data for the Viper API request.
+      timeout (Optional[int]): number of seconds to wait for to establish
+          a connection to a remote machine.
 
     Returns:
       MockResponse: mocked response that simulates a real response object
           returned by the requests library from the Viper API.
     """
     sha256_hash = data.get('sha256', None)
     if sha256_hash != self._EVENT_1_HASH:
```

### Comparing `plaso-20230311/tests/analysis/virustotal.py` & `plaso-20230717/tests/analysis/virustotal.py`

 * *Files 7% similar despite different names*

```diff
@@ -32,41 +32,45 @@
     """Provided for compatibility with the requests library."""
     return
 
 
 class VirusTotalTest(test_lib.AnalysisPluginTestCase):
   """Tests for the VirusTotal analysis plugin."""
 
+  # pylint: disable=protected-access
+
   _EVENT_1_HASH = '90'
 
   _FAKE_API_KEY = '4'
 
   _TEST_EVENTS = [{
       '_parser_chain': 'pe',
       'data_type': 'pe:compilation:compilation_time',
       'path_spec': fake_path_spec.FakePathSpec(
           location='C:\\WINDOWS\\system32\\evil.exe'),
       'pe_type': 'Executable (EXE)',
       'sha256_hash': _EVENT_1_HASH,
       'timestamp': '2015-01-01 17:00:00',
       'timestamp_desc': definitions.TIME_DESCRIPTION_UNKNOWN}]
 
-  def _MockGet(self, url, params):
+  # pylint: disable=unused-argument
+  def _MockGet(self, url, params=None, timeout=None):
     """Mock function to simulate a VirusTotal API request.
 
     Args:
       url (str): URL being requested.
-      params (dict[str, object]): HTTP parameters for the VirusTotal API
-          request.
+      params (Optional[dict[str, object]]): HTTP parameters for the VirusTotal
+          API request.
+      timeout (Optional[int]): number of seconds to wait for to establish
+          a connection to a remote machine.
 
     Returns:
       MockResponse: mocked response that simulates a real response object
           returned by the requests library from the VirusTotal API.
     """
-    # pylint: disable=protected-access
     self.assertEqual(
         url, virustotal.VirusTotalAnalysisPlugin._VIRUSTOTAL_API_REPORT_URL)
 
     if params['resource'] != self._EVENT_1_HASH:
       self.fail('Unexpected parameters to request.get()')
 
     response = MockResponse()
```

### Comparing `plaso-20230311/tests/analyzers/hashers/entropy.py` & `plaso-20230717/tests/analyzers/hashers/entropy.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/hashers/manager.py` & `plaso-20230717/tests/analyzers/hashers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/hashers/md5.py` & `plaso-20230717/tests/analyzers/hashers/md5.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/hashers/sha1.py` & `plaso-20230717/tests/analyzers/hashers/sha1.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/hashers/sha256.py` & `plaso-20230717/tests/analyzers/hashers/sha256.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/hashers/test_lib.py` & `plaso-20230717/tests/analyzers/hashers/test_lib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/hashing_analyzer.py` & `plaso-20230717/tests/analyzers/hashing_analyzer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/init_imports.py` & `plaso-20230717/tests/analyzers/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/manager.py` & `plaso-20230717/tests/analyzers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/analyzers/yara_analyzer.py` & `plaso-20230717/tests/analyzers/yara_analyzer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/extraction_tool.py` & `plaso-20230717/tests/cli/extraction_tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -212,15 +212,14 @@
     """Tests the _ParseProcessingOptions function."""
     test_tool = extraction_tool.ExtractionTool()
 
     options = test_lib.TestOptions()
 
     test_tool._ParseProcessingOptions(options)
 
-  # TODO: add test for _PreprocessSources
   # TODO: add test for _ReadParserPresetsFromFile
   # TODO: add test for _SetExtractionPreferredTimeZone
 
   def testAddExtractionOptions(self):
     """Tests the AddExtractionOptions function."""
     argument_parser = argparse.ArgumentParser(
         prog='extraction_tool_test.py', description='Test argument parser.',
```

### Comparing `plaso-20230311/tests/cli/helpers/analysis_plugins.py` & `plaso-20230717/tests/cli/helpers/analysis_plugins.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/archives.py` & `plaso-20230717/tests/cli/helpers/archives.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/artifact_definitions.py` & `plaso-20230717/tests/cli/helpers/artifact_definitions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/artifact_filters.py` & `plaso-20230717/tests/cli/helpers/artifact_filters.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/bloom_analysis.py` & `plaso-20230717/tests/cli/helpers/bloom_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/codepage.py` & `plaso-20230717/tests/cli/helpers/codepage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/data_location.py` & `plaso-20230717/tests/cli/helpers/data_location.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/date_filters.py` & `plaso-20230717/tests/cli/helpers/date_filters.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/dynamic_output.py` & `plaso-20230717/tests/cli/helpers/dynamic_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/event_filters.py` & `plaso-20230717/tests/cli/helpers/event_filters.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/extraction.py` & `plaso-20230717/tests/cli/helpers/extraction.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/filter_file.py` & `plaso-20230717/tests/cli/helpers/filter_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/hashers.py` & `plaso-20230717/tests/cli/helpers/hashers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/init_imports.py` & `plaso-20230717/tests/cli/helpers/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/interface.py` & `plaso-20230717/tests/cli/helpers/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/language.py` & `plaso-20230717/tests/cli/helpers/language.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/manager.py` & `plaso-20230717/tests/cli/helpers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/nsrlsvr_analysis.py` & `plaso-20230717/tests/cli/helpers/nsrlsvr_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/opensearch_output.py` & `plaso-20230717/tests/cli/helpers/opensearch_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/opensearch_ts_output.py` & `plaso-20230717/tests/cli/helpers/opensearch_ts_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/output_modules.py` & `plaso-20230717/tests/cli/helpers/output_modules.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/parsers.py` & `plaso-20230717/tests/cli/helpers/parsers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/process_resources.py` & `plaso-20230717/tests/cli/helpers/process_resources.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/profiling.py` & `plaso-20230717/tests/cli/helpers/profiling.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/sessionize_analysis.py` & `plaso-20230717/tests/cli/helpers/sessionize_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/status_view.py` & `plaso-20230717/tests/cli/helpers/status_view.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/storage_format.py` & `plaso-20230717/tests/cli/helpers/storage_format.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/tagging_analysis.py` & `plaso-20230717/tests/cli/helpers/tagging_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/temporary_directory.py` & `plaso-20230717/tests/cli/helpers/temporary_directory.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/test_lib.py` & `plaso-20230717/tests/cli/helpers/test_lib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/vfs_backend.py` & `plaso-20230717/tests/cli/helpers/vfs_backend.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/viper_analysis.py` & `plaso-20230717/tests/cli/helpers/viper_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/virustotal_analysis.py` & `plaso-20230717/tests/cli/helpers/virustotal_analysis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/workers.py` & `plaso-20230717/tests/cli/helpers/workers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/xlsx_output.py` & `plaso-20230717/tests/cli/helpers/xlsx_output.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/helpers/yara_rules.py` & `plaso-20230717/tests/cli/helpers/yara_rules.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/image_export_tool.py` & `plaso-20230717/tests/cli/image_export_tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -269,16 +269,16 @@
         'Filters:',
         ('\tctime between 2012-05-25 15:59:00.000000 and '
          '2012-05-25 15:59:20.000000'),
         ''])
     output = output_writer.ReadOutput()
     self.assertEqual(output, expected_output)
 
-  def testProcessSourcesWithImage(self):
-    """Tests the ProcessSources function on a single partition image."""
+  def testProcessSourceWithImage(self):
+    """Tests the ProcessSource function on a single partition image."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
     test_tool = image_export_tool.ImageExportTool(output_writer=output_writer)
 
     options = test_lib.TestOptions()
@@ -287,28 +287,28 @@
     options.quiet = True
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_output = '\n'.join([
           'Export started.',
           'Extracting file entries.',
           'Export completed.',
           '',
           ''])
 
       output = output_writer.ReadOutput()
       self.assertEqual(output, expected_output)
 
-  def testProcessSourcesExtractWithDateTimeFilter(self):
-    """Tests the ProcessSources function with a date time filter."""
+  def testProcessSourceExtractWithDateTimeFilter(self):
+    """Tests the ProcessSource function with a date time filter."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['image.qcow2'])
     self._SkipIfPathNotExists(test_file_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
@@ -321,26 +321,26 @@
     options.quiet = True
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_extracted_files = sorted([
           os.path.join(temp_directory, 'a_directory'),
           os.path.join(temp_directory, 'a_directory', 'a_file'),
           os.path.join(temp_directory, 'hashes.json')])
 
       extracted_files = self._RecursiveList(temp_directory)
       self.assertEqual(sorted(extracted_files), expected_extracted_files)
 
-  def testProcessSourcesExtractWithExtensionsFilter(self):
-    """Tests the ProcessSources function with an extensions filter."""
+  def testProcessSourceExtractWithExtensionsFilter(self):
+    """Tests the ProcessSource function with an extensions filter."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['image.qcow2'])
     self._SkipIfPathNotExists(test_file_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
@@ -353,25 +353,25 @@
     options.quiet = True
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_extracted_files = sorted([
           os.path.join(temp_directory, 'passwords.txt'),
           os.path.join(temp_directory, 'hashes.json')])
 
       extracted_files = self._RecursiveList(temp_directory)
       self.assertEqual(sorted(extracted_files), expected_extracted_files)
 
-  def testProcessSourcesExtractWithNamesFilter(self):
-    """Tests the ProcessSources function with a names filter."""
+  def testProcessSourceExtractWithNamesFilter(self):
+    """Tests the ProcessSource function with a names filter."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['image.qcow2'])
     self._SkipIfPathNotExists(test_file_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
@@ -384,27 +384,27 @@
     options.quiet = False
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_extracted_files = sorted([
           os.path.join(temp_directory, 'a_directory'),
           os.path.join(temp_directory, 'a_directory', 'another_file'),
           os.path.join(temp_directory, 'hashes.json')])
 
       extracted_files = self._RecursiveList(temp_directory)
 
       self.assertEqual(sorted(extracted_files), expected_extracted_files)
 
-  def testProcessSourcesExtractWithFilter(self):
-    """Tests the ProcessSources function with a filter file."""
+  def testProcessSourceExtractWithFilter(self):
+    """Tests the ProcessSource function with a filter file."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['image.qcow2'])
     self._SkipIfPathNotExists(test_file_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
@@ -421,29 +421,29 @@
         file_object.write('/a_directory/.+_file\n')
 
       options.file_filter = filter_file
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_extracted_files = sorted([
           os.path.join(temp_directory, 'filter.txt'),
           os.path.join(temp_directory, 'a_directory'),
           os.path.join(temp_directory, 'a_directory', 'another_file'),
           os.path.join(temp_directory, 'a_directory', 'a_file'),
           os.path.join(temp_directory, 'hashes.json')])
 
       extracted_files = self._RecursiveList(temp_directory)
 
     self.assertEqual(sorted(extracted_files), expected_extracted_files)
 
-  def testProcessSourcesExtractWithArtifactsFilter(self):
-    """Tests the ProcessSources function with a artifacts filter file."""
+  def testProcessSourceExtractWithArtifactsFilter(self):
+    """Tests the ProcessSource function with a artifacts filter file."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['image.qcow2'])
     self._SkipIfPathNotExists(test_file_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
@@ -456,28 +456,28 @@
     options.artifact_filter_string = 'TestFilesImageExport'
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_extracted_files = sorted([
           os.path.join(temp_directory, 'a_directory'),
           os.path.join(temp_directory, 'a_directory', 'another_file'),
           os.path.join(temp_directory, 'a_directory', 'a_file'),
           os.path.join(temp_directory, 'hashes.json')])
 
       extracted_files = self._RecursiveList(temp_directory)
 
     self.assertEqual(sorted(extracted_files), expected_extracted_files)
 
-  def testProcessSourcesExtractWithArtifactsGroupFilter(self):
-    """Tests the ProcessSources function with a group artifacts filter file."""
+  def testProcessSourceExtractWithArtifactsGroupFilter(self):
+    """Tests the ProcessSource function with a group artifacts filter file."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['image.qcow2'])
     self._SkipIfPathNotExists(test_file_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
@@ -490,29 +490,29 @@
     options.artifact_filter_string = 'TestGroupExport'
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_extracted_files = sorted([
           os.path.join(temp_directory, 'a_directory'),
           os.path.join(temp_directory, 'a_directory', 'another_file'),
           os.path.join(temp_directory, 'a_directory', 'a_file'),
           os.path.join(temp_directory, 'passwords.txt'),
           os.path.join(temp_directory, 'hashes.json')])
 
       extracted_files = self._RecursiveList(temp_directory)
 
     self.assertEqual(sorted(extracted_files), expected_extracted_files)
 
-  def testProcessSourcesExtractWithSignaturesFilter(self):
-    """Tests the ProcessSources function with a signatures filter."""
+  def testProcessSourceExtractWithSignaturesFilter(self):
+    """Tests the ProcessSource function with a signatures filter."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['syslog_image.dd'])
     self._SkipIfPathNotExists(test_file_path)
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
@@ -525,15 +525,15 @@
     options.signature_identifiers = 'gzip'
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_extracted_files = sorted([
           os.path.join(temp_directory, 'logs'),
           os.path.join(temp_directory, 'logs', 'sys.tgz'),
           os.path.join(temp_directory, 'hashes.json')])
 
       extracted_files = self._RecursiveList(temp_directory)
@@ -557,15 +557,15 @@
     options.signature_identifiers = 'elf'
 
     with shared_test_lib.TempDirectory() as temp_directory:
       options.path = temp_directory
 
       test_tool.ParseOptions(options)
 
-      test_tool.ProcessSources()
+      test_tool.ProcessSource()
 
       expected_json_data = [{
           'sha256':
           '553c231c45eda751710eabb479d08668f70464c14e60064190a7ec206f26b5f5',
           'paths': [os.path.join('bin', 'bzcat')]
       }, {
           'sha256':
```

### Comparing `plaso-20230311/tests/cli/log2timeline_tool.py` & `plaso-20230717/tests/cli/log2timeline_tool.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/pinfo_tool.py` & `plaso-20230717/tests/cli/pinfo_tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,28 +23,14 @@
 ************************* Events generated per parser **************************
 Parser (plugin) name : Number of events
 --------------------------------------------------------------------------------
             filestat : 3 (6)
                total : 3 (38)
 --------------------------------------------------------------------------------
 
-
-******************* Timelining warnings generated per parser *******************
-Parser (plugin) name : Number of warnings
---------------------------------------------------------------------------------
-            filestat : 1 (0)
---------------------------------------------------------------------------------
-
-
-******************* Pathspecs with most timelining warnings ********************
-Number of warnings : Pathspec
---------------------------------------------------------------------------------
-             1 (0) : N/A
---------------------------------------------------------------------------------
-
 Storage files are different.
 """
 
   # TODO: add test for _CalculateStorageCounters.
   # TODO: add test for _CompareStores.
 
   def testGenerateAnalysisResultsReportAsJSON(self):
@@ -560,16 +546,16 @@
       test_tool.ParseOptions(options)
 
     # TODO: improve test coverage.
 
   def testPrintStorageInformationAsJSON(self):
     """Tests the PrintStorageInformation function with JSON output format."""
     test_filename = 'pinfo_test.plaso'
-    session_identifier = '77a17b1a-ee8c-4745-9852-8bd0e1afee80'
-    session_start_time = '2022-11-13 06:02:24.968825'
+    session_identifier = '0db86b5f-9176-4863-bf1e-9ac7ca632377'
+    session_start_time = '2023-03-27 03:47:24.091665'
 
     test_file_path = self._GetTestFilePath([test_filename])
     self._SkipIfPathNotExists(test_file_path)
 
     options = test_lib.TestOptions()
     options.storage_file = test_file_path
     options.output_format = 'json'
@@ -603,28 +589,27 @@
     self.assertIsNotNone(parsers_counter)
     self.assertEqual(parsers_counter['total'], 3)
     self.assertEqual(parsers_counter['filestat'], 3)
 
   def testPrintStorageInformationAsText(self):
     """Tests the PrintStorageInformation function with text output format."""
     test_filename = 'pinfo_test.plaso'
-    format_version = '20221023'
-    plaso_version = '20221113'
-    session_identifier = '77a17b1a-ee8c-4745-9852-8bd0e1afee80'
-    session_start_time = '2022-11-13T06:02:24.968825+00:00'
-    session_completion_time = '2022-11-13T06:02:33.777517+00:00'
+    format_version = '20230327'
+    plaso_version = '20230311'
+    session_identifier = '0db86b5f-9176-4863-bf1e-9ac7ca632377'
+    session_start_time = '2023-03-27T03:47:24.091665+00:00'
+    session_completion_time = '2023-03-27T03:47:32.596408+00:00'
 
     command_line_arguments = (
         './tools/log2timeline.py --partition=all --quiet '
         '--storage-file pinfo_test.plaso test_data/tsk_volume_system.raw')
 
     enabled_parser_names = ', '.join([
         'android_app_usage',
         'asl_log',
-        'bash_history',
         'bencode',
         'bencode/bencode_transmission',
         'bencode/bencode_utorrent',
         'binary_cookies',
         'bodyfile',
         'bsm_log',
         'chrome_cache',
@@ -639,18 +624,14 @@
         'esedb/srum',
         'esedb/user_access_logging',
         'filestat',
         'firefox_cache',
         'firefox_cache2',
         'fish_history',
         'fseventsd',
-        'gdrive_synclog',
-        'googlelog',
-        'ios_lockdownd',
-        'ios_sysdiag_log',
         'java_idx',
         'jsonl',
         'jsonl/aws_cloudtrail_log',
         'jsonl/azure_activity_log',
         'jsonl/azure_application_gateway_access_log',
         'jsonl/docker_container_config',
         'jsonl/docker_container_log',
@@ -675,31 +656,29 @@
         'pe',
         'plist',
         'plist/airport',
         'plist/apple_id',
         'plist/ios_carplay',
         'plist/ipod_device',
         'plist/launchd_plist',
+        'plist/macos_bluetooth',
         'plist/macos_software_update',
-        'plist/macosx_bluetooth',
         'plist/macosx_install_history',
         'plist/macuser',
         'plist/plist_default',
+        'plist/safari_downloads',
         'plist/safari_history',
         'plist/spotlight',
         'plist/spotlight_volume',
         'plist/time_machine',
         'pls_recall',
-        'postgresql',
         'prefetch',
         'recycle_bin',
         'recycle_bin_info2',
         'rplog',
-        'sccm',
-        'skydrive_log',
         'spotlight_storedb',
         'sqlite',
         'sqlite/android_calls',
         'sqlite/android_sms',
         'sqlite/android_webview',
         'sqlite/android_webviewcache',
         'sqlite/appusage',
@@ -734,51 +713,61 @@
         'sqlite/tango_android_tc',
         'sqlite/twitter_android',
         'sqlite/twitter_ios',
         'sqlite/windows_eventtranscript',
         'sqlite/windows_timeline',
         'sqlite/zeitgeist',
         'symantec_scanlog',
-        'syslog',
-        'syslog/cron',
-        'syslog/ssh',
         'systemd_journal',
         'text',
         'text/android_logcat',
         'text/apache_access',
         'text/apt_history',
         'text/aws_elb_access',
+        'text/bash_history',
         'text/confluence_access',
         'text/dpkg',
+        'text/gdrive_synclog',
+        'text/googlelog',
+        'text/ios_lockdownd',
         'text/ios_logd',
+        'text/ios_sysdiag_log',
         'text/mac_appfirewall_log',
         'text/mac_securityd',
         'text/mac_wifi',
         'text/popularity_contest',
+        'text/postgresql',
         'text/santa',
+        'text/sccm',
         'text/selinux',
         'text/setupapi',
         'text/skydrive_log_v1',
+        'text/skydrive_log_v2',
         'text/snort_fastlog',
         'text/sophos_av',
+        'text/syslog',
+        'text/syslog_traditional',
+        'text/viminfo',
         'text/vsftpd',
         'text/winfirewall',
         'text/winiis',
         'text/xchatlog',
         'text/xchatscrollback',
+        'text/zsh_extended_history',
         'trendmicro_url',
         'trendmicro_vd',
         'usnjrnl',
         'utmp',
         'utmpx',
-        'viminfo',
         'windefender_history',
         'winevt',
         'winevtx',
         'winjob',
+        'winpca_db0',
+        'winpca_dic',
         'winreg',
         'winreg/amcache',
         'winreg/appcompatcache',
         'winreg/bagmru',
         'winreg/bam',
         'winreg/ccleaner',
         'winreg/explorer_mountpoints2',
@@ -807,16 +796,15 @@
         'winreg/windows_timezone',
         'winreg/windows_typed_urls',
         'winreg/windows_usb_devices',
         'winreg/windows_usbstor_devices',
         'winreg/windows_version',
         'winreg/winlogon',
         'winreg/winrar_mru',
-        'winreg/winreg_default',
-        'zsh_extended_history'])
+        'winreg/winreg_default'])
 
     output_writer = test_lib.TestOutputWriter(encoding='utf-8')
 
     table_view = cli_views.ViewsFactory.GetTableView(
         cli_views.ViewsFactory.FORMAT_TYPE_CLI,
         title='Plaso Storage Information')
     table_view.AddRow(['Filename', test_filename])
@@ -836,14 +824,15 @@
     table_view.AddRow(['Completion time', session_completion_time])
     table_view.AddRow(['Product name', 'plaso'])
     table_view.AddRow(['Product version', plaso_version])
     table_view.AddRow(['Command line arguments', command_line_arguments])
     table_view.AddRow(['Parser filter expression', 'N/A'])
     table_view.AddRow(['Enabled parser and plugins', enabled_parser_names])
     table_view.AddRow(['Preferred encoding', 'UTF-8'])
+    table_view.AddRow(['Preferred time zone', 'UTC'])
     table_view.AddRow(['Debug mode', 'False'])
     table_view.AddRow(['Artifact filters', 'N/A'])
     table_view.AddRow(['Filter file', 'N/A'])
     table_view.Write(output_writer)
 
     table_view = cli_views.ViewsFactory.GetTableView(
         cli_views.ViewsFactory.FORMAT_TYPE_CLI,
```

### Comparing `plaso-20230311/tests/cli/psort_tool.py` & `plaso-20230717/tests/cli/psort_tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -276,15 +276,15 @@
     self.assertTrue(input_reader.read_called)
     self.assertEqual(TestOutputModuleMissingParameters.missing, 'foobar')
     self.assertEqual(TestOutputModuleMissingParameters.parameters, 'foobar')
 
     expected_line = (
         '2013-12-31T17:54:32+00:00,Content Modification Time,LOG,Log File,'
         '[/sbin/anacron  pid: 1234] Another one just like this (124 job run),'
-        'syslog,OS:/tmp/test/test_data/syslog,-')
+        'text/syslog_traditional,OS:/tmp/test/test_data/syslog,-')
     self.assertIn(expected_line, lines)
 
     output_manager.OutputManager.DeregisterOutput(
         TestOutputModuleMissingParameters)
     helpers_manager.ArgumentHelperManager.DeregisterHelper(
         TestOutputModuleArgumentHelper)
```

### Comparing `plaso-20230311/tests/cli/psteal_tool.py` & `plaso-20230717/tests/cli/psteal_tool.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/status_view.py` & `plaso-20230717/tests/cli/status_view.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/storage_media_tool.py` & `plaso-20230717/tests/cli/storage_media_tool.py`

 * *Files 0% similar despite different names*

```diff
@@ -59,20 +59,20 @@
     test_file_path = self._GetTestFilePath(['apfs.dmg'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_os_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
     test_raw_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_RAW, parent=test_os_path_spec)
-    test_tsk_partition_path_spec = path_spec_factory.Factory.NewPathSpec(
+    test_gpt_partition_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.PREFERRED_GPT_BACK_END, location='/p1',
         parent=test_raw_path_spec)
     test_apfs_container_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_APFS_CONTAINER, location='/',
-        parent=test_tsk_partition_path_spec)
+        parent=test_gpt_partition_path_spec)
 
     volume_system = apfs_volume_system.APFSVolumeSystem()
     volume_system.Open(test_apfs_container_path_spec)
 
     file_object = io.BytesIO()
     test_output_writer = tools.FileObjectOutputWriter(file_object)
 
@@ -272,20 +272,20 @@
     test_file_path = self._GetTestFilePath(['apfs.dmg'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_os_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
     test_raw_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_RAW, parent=test_os_path_spec)
-    test_tsk_partition_path_spec = path_spec_factory.Factory.NewPathSpec(
+    test_gpt_partition_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.PREFERRED_GPT_BACK_END, location='/p1',
         parent=test_raw_path_spec)
     test_apfs_container_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_APFS_CONTAINER, location='/',
-        parent=test_tsk_partition_path_spec)
+        parent=test_gpt_partition_path_spec)
 
     volume_system = apfs_volume_system.APFSVolumeSystem()
     volume_system.Open(test_apfs_container_path_spec)
 
     # Test selection of single volume.
     input_file_object = io.BytesIO(b'1\n')
     test_input_reader = tools.FileObjectInputReader(input_file_object)
```

### Comparing `plaso-20230311/tests/cli/test_lib.py` & `plaso-20230717/tests/cli/test_lib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/time_slices.py` & `plaso-20230717/tests/cli/time_slices.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/tool_options.py` & `plaso-20230717/tests/cli/tool_options.py`

 * *Files 4% similar despite different names*

```diff
@@ -131,15 +131,16 @@
 class OutputModuleOptionsTest(test_lib.CLIToolTestCase):
   """Tests for the output module options."""
 
   # pylint: disable=protected-access
 
   _EXPECTED_OUTPUT_TIME_ZONE_OPTION = """\
 usage: tool_options.py [--additional_fields ADDITIONAL_FIELDS]
-                       [--custom_fields CUSTOM_FIELDS] [--dynamic_time]
+                       [--custom_fields CUSTOM_FIELDS]
+                       [--custom_formatter_definitions PATH] [--dynamic_time]
                        [--output_time_zone TIME_ZONE]
 
 Test argument parser.
 
 {0:s}:
   --additional_fields ADDITIONAL_FIELDS, --additional-fields ADDITIONAL_FIELDS
                         Defines additional fields to be included in the output
@@ -151,14 +152,20 @@
                         Defines custom fields to be included in the output
                         besides the default fields. A custom field is defined
                         as "name:value". Multiple custom field names can be
                         defined as list of comma separated values. Note that
                         regular fields will are favoured above custom fields
                         with same name. Output formats that support this are:
                         dynamic, opensearch and xlsx.
+  --custom_formatter_definitions PATH, --custom-formatter-definitions PATH
+                        Path to a file containing custom event formatter
+                        definitions, which is a .yaml file. Custom event
+                        formatter definitions can be used to customize event
+                        messages and override the built-in event formatter
+                        definitions.
   --dynamic_time, --dynamic-time
                         Indicate that the output should use dynamic time.
                         Output formats that support dynamic time are: dynamic
   --output_time_zone TIME_ZONE, --output-time-zone TIME_ZONE
                         time zone of date and time values written to the
                         output, if supported by the output format. Use "list"
                         to see a list of available time zones. Output formats
```

### Comparing `plaso-20230311/tests/cli/tools.py` & `plaso-20230717/tests/cli/tools.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/cli/views.py` & `plaso-20230717/tests/cli/views.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/analyzer_result.py` & `plaso-20230717/tests/containers/analyzer_result.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/artifacts.py` & `plaso-20230717/tests/containers/artifacts.py`

 * *Files 2% similar despite different names*

```diff
@@ -148,31 +148,40 @@
 class SourceConfigurationArtifactTest(shared_test_lib.BaseTestCase):
   """Tests for the source configuration artifact."""
 
   def testGetAttributeNames(self):
     """Tests the GetAttributeNames function."""
     attribute_container = artifacts.SourceConfigurationArtifact()
 
-    expected_attribute_names = ['mount_path', 'path_spec']
+    expected_attribute_names = ['path', 'source_type']
 
     attribute_names = sorted(attribute_container.GetAttributeNames())
     self.assertEqual(attribute_names, expected_attribute_names)
 
 
 class SystemConfigurationArtifactTest(shared_test_lib.BaseTestCase):
   """Tests for the system configuration artifact."""
 
   def testGetAttributeNames(self):
     """Tests the GetAttributeNames function."""
     attribute_container = artifacts.SystemConfigurationArtifact()
 
     expected_attribute_names = [
-        'available_time_zones', 'code_page', 'hostname', 'keyboard_layout',
-        'language', 'operating_system', 'operating_system_product',
-        'operating_system_version', 'time_zone', 'user_accounts']
+        'available_time_zones',
+        'code_page',
+        'environment_variables',
+        'hostname',
+        'keyboard_layout',
+        'language',
+        'operating_system',
+        'operating_system_product',
+        'operating_system_version',
+        'path_specs',
+        'time_zone',
+        'user_accounts']
 
     attribute_names = sorted(attribute_container.GetAttributeNames())
     self.assertEqual(attribute_names, expected_attribute_names)
 
 
 class UserAccountArtifactTest(shared_test_lib.BaseTestCase):
   """Tests for the user account artifact."""
```

### Comparing `plaso-20230311/tests/containers/counts.py` & `plaso-20230717/tests/containers/counts.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/event_sources.py` & `plaso-20230717/tests/containers/event_sources.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/events.py` & `plaso-20230717/tests/containers/events.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/init_imports.py` & `plaso-20230717/tests/containers/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/plist_event.py` & `plaso-20230717/tests/containers/plist_event.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/reports.py` & `plaso-20230717/tests/containers/reports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/sessions.py` & `plaso-20230717/tests/containers/sessions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/tasks.py` & `plaso-20230717/tests/containers/tasks.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/test_lib.py` & `plaso-20230717/tests/containers/test_lib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/warnings.py` & `plaso-20230717/tests/containers/warnings.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/containers/windows_events.py` & `plaso-20230717/tests/containers/windows_events.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/data/presets.py` & `plaso-20230717/tests/data/presets.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/data/tag_linux.py` & `plaso-20230717/tests/data/tag_linux.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/data/tag_macos.py` & `plaso-20230717/tests/data/tag_macos.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/data/tag_windows.py` & `plaso-20230717/tests/data/tag_windows.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/data/test_lib.py` & `plaso-20230717/tests/data/test_lib.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,13 @@
 # -*- coding: utf-8 -*-
 """Data files related functions and classes for testing."""
 
 from plaso.analysis import mediator as analysis_mediator
 from plaso.analysis import tagging
 from plaso.containers import events
-from plaso.containers import sessions
-from plaso.engine import knowledge_base
 from plaso.lib import definitions
 from plaso.storage.fake import writer as fake_writer
 
 from tests import test_lib as shared_test_lib
 
 
 class TaggingFileTestCase(shared_test_lib.BaseTestCase):
@@ -111,34 +109,29 @@
 
     Raises:
       SkipTest: if the tag file does not exist.
     """
     tag_file_path = self._GetDataFilePath([self._TAG_FILE])
     self._SkipIfPathNotExists(tag_file_path)
 
-    session = sessions.Session()
-
     storage_writer = fake_writer.FakeStorageWriter()
     storage_writer.Open()
 
     if event_data_stream:
       storage_writer.AddAttributeContainer(event_data_stream)
       event_data_stream_identifier = event_data_stream.GetIdentifier()
       event_data.SetEventDataStreamIdentifier(event_data_stream_identifier)
 
     storage_writer.AddAttributeContainer(event_data)
     event_data_identifier = event_data.GetIdentifier()
     event.SetEventDataIdentifier(event_data_identifier)
 
     storage_writer.AddAttributeContainer(event)
 
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
-    mediator = analysis_mediator.AnalysisMediator(
-        session, knowledge_base_object)
+    mediator = analysis_mediator.AnalysisMediator()
     mediator.SetStorageWriter(storage_writer)
 
     plugin = tagging.TaggingAnalysisPlugin()
     plugin.SetAndLoadTagFile(tag_file_path)
     plugin.ExamineEvent(mediator, event, event_data, event_data_stream)
 
     analysis_report = plugin.CompileReport(mediator)
```

### Comparing `plaso-20230311/tests/end-to-end.py` & `plaso-20230717/tests/end-to-end.py`

 * *Files 3% similar despite different names*

```diff
@@ -798,14 +798,18 @@
     Args:
       test_definition_reader (TestDefinitionReader): test definition reader.
       test_definition (TestDefinition): test definition.
 
     Returns:
       bool: True if the read was successful.
     """
+    test_definition.custom_formatter_file = (
+        test_definition_reader.GetConfigValue(
+            test_definition.name, 'custom_formatter_file'))
+
     test_definition.extract_options = test_definition_reader.GetConfigValue(
         test_definition.name, 'extract_options', default=[], split_string=True)
 
     test_definition.filter_file = test_definition_reader.GetConfigValue(
         test_definition.name, 'filter_file')
 
     test_definition.logging_options = test_definition_reader.GetConfigValue(
@@ -854,14 +858,28 @@
       source_path = os.path.join(self._test_sources_path, source_path)
 
     if not os.path.exists(source_path):
       logging.error('No such source: {0:s}'.format(source_path))
       return False
 
     with TempDirectory() as temp_directory:
+      output_options = list(test_definition.output_options)
+
+      if test_definition.custom_formatter_file:
+        custom_formatter_file = test_definition.custom_formatter_file
+        if self._test_sources_path:
+          custom_formatter_file = os.path.join(
+              self._test_sources_path, custom_formatter_file)
+        temp_path = os.path.join(temp_directory, os.path.basename(
+            custom_formatter_file))
+        shutil.copyfile(custom_formatter_file, temp_path)
+
+        output_options.append('--custom-formatter-definitions={0:s}'.format(
+            temp_path))
+
       storage_file = os.path.join(
           temp_directory, '{0:s}.plaso'.format(test_definition.name))
 
       # Extract events with log2timeline.
       if not self._RunLog2Timeline(
           test_definition, temp_directory, storage_file, source_path):
         return False
@@ -876,15 +894,15 @@
         if not self._RunPinfoCompare(
             test_definition, temp_directory, storage_file):
           return False
 
       # Check if the resulting storage file can be read with psort.
       if not self._RunPsort(
           test_definition, temp_directory, storage_file,
-          output_options=test_definition.output_options):
+          output_options=output_options):
         return False
 
       # Compare output file with a reference output file.
       if test_definition.output_file and test_definition.reference_output_file:
         if not self._CompareOutputFile(test_definition, temp_directory):
           return False
 
@@ -996,14 +1014,18 @@
     Args:
       test_definition_reader (TestDefinitionReader): test definition reader.
       test_definition (TestDefinition): test definition.
 
     Returns:
       bool: True if the read was successful.
     """
+    test_definition.custom_formatter_file = (
+        test_definition_reader.GetConfigValue(
+            test_definition.name, 'custom_formatter_file'))
+
     test_definition.extract_options = test_definition_reader.GetConfigValue(
         test_definition.name, 'extract_options', default=[], split_string=True)
 
     test_definition.logging_options = test_definition_reader.GetConfigValue(
         test_definition.name, 'logging_options', default=[], split_string=True)
 
     test_definition.output_file = test_definition_reader.GetConfigValue(
@@ -1046,21 +1068,35 @@
       source_path = os.path.join(self._test_sources_path, source_path)
 
     if not os.path.exists(source_path):
       logging.error('No such source: {0:s}'.format(source_path))
       return False
 
     with TempDirectory() as temp_directory:
+      output_options = list(test_definition.output_options)
+
+      if test_definition.custom_formatter_file:
+        custom_formatter_file = test_definition.custom_formatter_file
+        if self._test_sources_path:
+          custom_formatter_file = os.path.join(
+              self._test_sources_path, custom_formatter_file)
+        temp_path = os.path.join(temp_directory, os.path.basename(
+            custom_formatter_file))
+        shutil.copyfile(custom_formatter_file, temp_path)
+
+        output_options.append('--custom-formatter-definitions={0:s}'.format(
+            temp_path))
+
       storage_file = os.path.join(
           temp_directory, '{0:s}.plaso'.format(test_definition.name))
 
       # Extract and output events with psteal.
       if not self._RunPsteal(
           test_definition, temp_directory, storage_file, source_path,
-          output_options=test_definition.output_options):
+          output_options=output_options):
         return False
 
       # Compare output file with a reference output file.
       if test_definition.output_file and test_definition.reference_output_file:
         if not self._CompareOutputFile(test_definition, temp_directory):
           return False
 
@@ -1688,14 +1724,18 @@
 
     Returns:
       bool: True if the read was successful.
     """
     test_definition.analysis_options = test_definition_reader.GetConfigValue(
         test_definition.name, 'analysis_options', default=[], split_string=True)
 
+    test_definition.custom_formatter_file = (
+        test_definition_reader.GetConfigValue(
+            test_definition.name, 'custom_formatter_file'))
+
     test_definition.logging_options = test_definition_reader.GetConfigValue(
         test_definition.name, 'logging_options', default=[], split_string=True)
 
     test_definition.output_file = test_definition_reader.GetConfigValue(
         test_definition.name, 'output_file')
 
     test_definition.output_filter = test_definition_reader.GetConfigValue(
@@ -1738,24 +1778,37 @@
 
     if not os.path.exists(source_path):
       logging.error('No such source: {0:s}'.format(source_path))
       return False
 
     with TempDirectory() as temp_directory:
       if 'backup' in test_definition.source_options:
-        temp_source_path = os.path.join(
-            temp_directory, os.path.basename(source_path))
-        shutil.copyfile(source_path, temp_source_path)
-        source_path = temp_source_path
+        temp_path = os.path.join(temp_directory, os.path.basename(source_path))
+        shutil.copyfile(source_path, temp_path)
+        source_path = temp_path
+
+      output_options = list(test_definition.output_options)
+
+      if test_definition.custom_formatter_file:
+        custom_formatter_file = test_definition.custom_formatter_file
+        if self._test_sources_path:
+          custom_formatter_file = os.path.join(
+              self._test_sources_path, custom_formatter_file)
+        temp_path = os.path.join(temp_directory, os.path.basename(
+            custom_formatter_file))
+        shutil.copyfile(custom_formatter_file, temp_path)
+
+        output_options.append('--custom-formatter-definitions={0:s}'.format(
+            temp_path))
 
       # Run psort with both analysis and output options.
       if not self._RunPsort(
           test_definition, temp_directory, source_path,
           analysis_options=test_definition.analysis_options,
-          output_options=test_definition.output_options):
+          output_options=output_options):
         return False
 
       # Compare output file with a reference output file.
       if test_definition.output_file and test_definition.reference_output_file:
         if not self._CompareOutputFile(test_definition, temp_directory):
           return False
 
@@ -1786,14 +1839,18 @@
         test_definition.name, 'analysis_options1', default=[],
         split_string=True)
 
     test_definition.analysis_options2 = test_definition_reader.GetConfigValue(
         test_definition.name, 'analysis_options2', default=[],
         split_string=True)
 
+    test_definition.custom_formatter_file = (
+        test_definition_reader.GetConfigValue(
+            test_definition.name, 'custom_formatter_file'))
+
     test_definition.logging_options = test_definition_reader.GetConfigValue(
         test_definition.name, 'logging_options', default=[], split_string=True)
 
     test_definition.output_file = test_definition_reader.GetConfigValue(
         test_definition.name, 'output_file')
 
     test_definition.output_filter = test_definition_reader.GetConfigValue(
@@ -1832,14 +1889,28 @@
       source_path = os.path.join(self._test_sources_path, source_path)
 
     if not os.path.exists(source_path):
       logging.error('No such source: {0:s}'.format(source_path))
       return False
 
     with TempDirectory() as temp_directory:
+      output_options = list(test_definition.output_options)
+
+      if test_definition.custom_formatter_file:
+        custom_formatter_file = test_definition.custom_formatter_file
+        if self._test_sources_path:
+          custom_formatter_file = os.path.join(
+              self._test_sources_path, custom_formatter_file)
+        temp_path = os.path.join(temp_directory, os.path.basename(
+            custom_formatter_file))
+        shutil.copyfile(custom_formatter_file, temp_path)
+
+        output_options.append('--custom-formatter-definitions={0:s}'.format(
+            temp_path))
+
       # Run psort with the first set of analysis options.
       if not self._RunPsort(
           test_definition, temp_directory, source_path,
           analysis_options=test_definition.analysis_options1):
         return False
 
       # Run psort with the second set of analysis options.
@@ -1847,129 +1918,30 @@
           test_definition, temp_directory, source_path,
           analysis_options=test_definition.analysis_options2):
         return False
 
       # Run psort with the output options.
       if not self._RunPsort(
           test_definition, temp_directory, source_path,
-          output_options=test_definition.output_options):
-        return False
-
-      # Compare output file with a reference output file.
-      if test_definition.output_file and test_definition.reference_output_file:
-        if not self._CompareOutputFile(test_definition, temp_directory):
-          return False
-
-    return True
-
-
-# TODO: This class is kept for backwards compatibility. For new tests use
-# AnalyzeAndOutputTestCase instead.
-class OutputTestCase(StorageFileTestCase):
-  """Output test case.
-
-  The output test case runs psort on a storage file to its various
-  output formats.
-  """
-
-  NAME = 'output'
-
-  def __init__(
-      self, tools_path, test_sources_path, test_references_path,
-      test_results_path, debug_output=False):
-    """Initializes a test case.
-
-    Args:
-      tools_path (str): path to the plaso tools.
-      test_sources_path (str): path to the test sources.
-      test_references_path (str): path to the test references.
-      test_results_path (str): path to store test results.
-      debug_output (Optional[bool]): True if debug output should be generated.
-    """
-    super(OutputTestCase, self).__init__(
-        tools_path, test_sources_path, test_references_path,
-        test_results_path, debug_output=debug_output)
-    self._InitializePsortPath()
-
-  def ReadAttributes(self, test_definition_reader, test_definition):
-    """Reads the test definition attributes into to the test definition.
-
-    Args:
-      test_definition_reader (TestDefinitionReader): test definition reader.
-      test_definition (TestDefinition): test definition.
-
-    Returns:
-      bool: True if the read was successful.
-    """
-    test_definition.logging_options = test_definition_reader.GetConfigValue(
-        test_definition.name, 'logging_options', default=[], split_string=True)
-
-    test_definition.output_file = test_definition_reader.GetConfigValue(
-        test_definition.name, 'output_file')
-
-    test_definition.output_filter = test_definition_reader.GetConfigValue(
-        test_definition.name, 'output_filter', default='')
-
-    test_definition.output_format = test_definition_reader.GetConfigValue(
-        test_definition.name, 'output_format')
-
-    test_definition.output_options = test_definition_reader.GetConfigValue(
-        test_definition.name, 'output_options', default=[], split_string=True)
-
-    test_definition.profiling_options = test_definition_reader.GetConfigValue(
-        test_definition.name, 'profiling_options', default=[],
-        split_string=True)
-
-    test_definition.reference_output_file = (
-        test_definition_reader.GetConfigValue(
-            test_definition.name, 'reference_output_file'))
-
-    test_definition.source = test_definition_reader.GetConfigValue(
-        test_definition.name, 'source')
-
-    return True
-
-  def Run(self, test_definition):
-    """Runs the test case with the parameters specified by the test definition.
-
-    Args:
-      test_definition (TestDefinition): test definition.
-
-    Returns:
-      bool: True if the test ran successfully.
-    """
-    source_path = test_definition.source
-    if self._test_sources_path:
-      source_path = os.path.join(self._test_sources_path, source_path)
-
-    if not os.path.exists(source_path):
-      logging.error('No such source: {0:s}'.format(source_path))
-      return False
-
-    with TempDirectory() as temp_directory:
-      # Run psort with the output options.
-      if not self._RunPsort(
-          test_definition, temp_directory, source_path,
-          output_options=test_definition.output_options):
+          output_options=output_options):
         return False
 
       # Compare output file with a reference output file.
       if test_definition.output_file and test_definition.reference_output_file:
         if not self._CompareOutputFile(test_definition, temp_directory):
           return False
 
     return True
 
 
 TestCasesManager.RegisterTestCases([
     AnalyzeAndOutputTestCase, ExtractAndOutputTestCase,
     ExtractAndOutputWithPstealTestCase, ExtractAndAnalyzeTestCase,
     ExtractAndTagTestCase, ImageExportTestCase,
-    MultiAnalyzeAndOutputTestCase, MultiExtractAndOutputTestCase,
-    OutputTestCase])
+    MultiAnalyzeAndOutputTestCase, MultiExtractAndOutputTestCase])
 
 
 def Main():
   """The main function."""
   argument_parser = argparse.ArgumentParser(
       description='End-to-end test launcher.', add_help=False,
       formatter_class=argparse.RawDescriptionHelpFormatter)
```

### Comparing `plaso-20230311/tests/engine/artifact_filters.py` & `plaso-20230717/tests/engine/artifact_filters.py`

 * *Files 8% similar despite different names*

```diff
@@ -14,31 +14,26 @@
 
 from dfwinreg import regf as dfwinreg_regf
 from dfwinreg import registry as dfwinreg_registry
 from dfwinreg import registry_searcher as dfwinreg_registry_searcher
 
 from plaso.containers import artifacts
 from plaso.engine import artifact_filters
-from plaso.engine import knowledge_base as knowledge_base_engine
 
 from tests import test_lib as shared_test_lib
 
 
 class ArtifactDefinitionsFiltersHelperTest(shared_test_lib.BaseTestCase):
   """Tests for artifact definitions filters helper."""
 
   # pylint: disable=protected-access
 
-  def _CreateTestArtifactDefinitionsFiltersHelper(self, knowledge_base):
+  def _CreateTestArtifactDefinitionsFiltersHelper(self):
     """Creates an artifact definitions filters helper for testing.
 
-    Args:
-      knowledge_base (KnowledgeBase): contains information from the source
-          data needed for filtering.
-
     Returns:
       ArtifactDefinitionsFiltersHelper: artifact definitions filters helper.
 
     Raises:
       SkipTest: if the path inside the test data directory does not exist and
           the test should be skipped.
     """
@@ -46,84 +41,75 @@
     reader = artifacts_reader.YamlArtifactsReader()
 
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     registry.ReadFromDirectory(reader, test_artifacts_path)
 
-    return artifact_filters.ArtifactDefinitionsFiltersHelper(
-        registry, knowledge_base)
-
-  def _CreateTestKnowledgeBaseWindows(self):
-    """Creates a knowledge base for testing Windows paths.
+    return artifact_filters.ArtifactDefinitionsFiltersHelper(registry)
 
-    Creates a knowledge base with 2 user accounts.
+  def _CreateTestUserAccounts(self):
+    """Creates user accounts for testing Windows paths.
 
     Returns:
-      KnowledgeBase: knowledge base.
+      list[UserAccountArtifact]: user accounts.
     """
-    knowledge_base = knowledge_base_engine.KnowledgeBase()
-
     test_user1 = artifacts.UserAccountArtifact(
         identifier='1000', path_separator='\\',
         user_directory='C:\\Users\\testuser1',
         username='testuser1')
-    knowledge_base.AddUserAccount(test_user1)
 
     test_user2 = artifacts.UserAccountArtifact(
         identifier='1001', path_separator='\\',
         user_directory='%SystemDrive%\\Users\\testuser2',
         username='testuser2')
-    knowledge_base.AddUserAccount(test_user2)
 
-    return knowledge_base
+    return [test_user1, test_user2]
 
   def testBuildFindSpecsWithFileSystem(self):
     """Tests the BuildFindSpecs function for file type artifacts."""
     test_file_path = self._GetTestFilePath(['System.evtx'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_file_path = self._GetTestFilePath(['testdir', 'filter_1.txt'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_file_path = self._GetTestFilePath(['testdir', 'filter_3.txt'])
     self._SkipIfPathNotExists(test_file_path)
 
-    knowledge_base = self._CreateTestKnowledgeBaseWindows()
-
     artifact_filter_names = ['TestFiles', 'TestFiles2']
-    test_filters_helper = self._CreateTestArtifactDefinitionsFiltersHelper(
-        knowledge_base)
+    test_filters_helper = self._CreateTestArtifactDefinitionsFiltersHelper()
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='SystemDrive', value='C:')
+    test_user_accounts = self._CreateTestUserAccounts()
 
     test_filters_helper.BuildFindSpecs(
-        artifact_filter_names, environment_variables=[environment_variable])
+        artifact_filter_names, environment_variables=[environment_variable],
+        user_accounts=test_user_accounts)
 
-    self.assertEqual(
-        len(test_filters_helper.included_file_system_find_specs), 16)
+    self.assertEqual(len(test_filters_helper.file_system_find_specs), 16)
     self.assertEqual(len(test_filters_helper.registry_find_specs), 0)
 
     # Last find_spec should contain the testuser2 profile path.
     location_segments = sorted([
         find_spec._location_segments
-        for find_spec in test_filters_helper.included_file_system_find_specs])
+        for find_spec in test_filters_helper.file_system_find_specs])
     path_segments = [
         'Users', 'testuser2', 'Documents', 'WindowsPowerShell', 'profile\\.ps1']
     self.assertEqual(location_segments[2], path_segments)
 
     path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location='.')
     file_system = path_spec_resolver.Resolver.OpenFileSystem(path_spec)
     searcher = file_system_searcher.FileSystemSearcher(
         file_system, path_spec)
 
     path_spec_generator = searcher.Find(
-        find_specs=test_filters_helper.included_file_system_find_specs)
+        find_specs=test_filters_helper.file_system_find_specs)
     self.assertIsNotNone(path_spec_generator)
 
     path_specs = list(path_spec_generator)
 
     # Two evtx, one symbolic link to evtx, one AUTHORS, two filter_*.txt files,
     # total 6 path specifications.
     self.assertEqual(len(path_specs), 6)
@@ -135,59 +121,53 @@
 
     test_file_path = self._GetTestFilePath(['testdir', 'filter_1.txt'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_file_path = self._GetTestFilePath(['testdir', 'filter_3.txt'])
     self._SkipIfPathNotExists(test_file_path)
 
-    knowledge_base = self._CreateTestKnowledgeBaseWindows()
-
     artifact_filter_names = ['TestGroupExtract']
-    test_filters_helper = self._CreateTestArtifactDefinitionsFiltersHelper(
-        knowledge_base)
+    test_filters_helper = self._CreateTestArtifactDefinitionsFiltersHelper()
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='SystemDrive', value='C:')
+    test_user_accounts = self._CreateTestUserAccounts()
 
     test_filters_helper.BuildFindSpecs(
-        artifact_filter_names, environment_variables=[environment_variable])
+        artifact_filter_names, environment_variables=[environment_variable],
+        user_accounts=test_user_accounts)
 
-    self.assertEqual(
-        len(test_filters_helper.included_file_system_find_specs), 16)
+    self.assertEqual(len(test_filters_helper.file_system_find_specs), 16)
     self.assertEqual(len(test_filters_helper.registry_find_specs), 0)
 
     path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location='.')
     file_system = path_spec_resolver.Resolver.OpenFileSystem(path_spec)
     searcher = file_system_searcher.FileSystemSearcher(
         file_system, path_spec)
 
     path_spec_generator = searcher.Find(
-        find_specs=test_filters_helper.included_file_system_find_specs)
+        find_specs=test_filters_helper.file_system_find_specs)
     self.assertIsNotNone(path_spec_generator)
 
     path_specs = list(path_spec_generator)
 
     # Two evtx, one symbolic link to evtx, one AUTHORS, two filter_*.txt
-    # files,
-    # total 6 path specifications.
+    # files, which total 6 path specifications.
     self.assertEqual(len(path_specs), 6)
 
   def testBuildFindSpecsWithRegistry(self):
     """Tests the BuildFindSpecs function on Windows Registry sources."""
-    knowledge_base = knowledge_base_engine.KnowledgeBase()
     artifact_filter_names = ['TestRegistry', 'TestRegistryValue']
-    test_filters_helper = self._CreateTestArtifactDefinitionsFiltersHelper(
-        knowledge_base)
+    test_filters_helper = self._CreateTestArtifactDefinitionsFiltersHelper()
 
     test_filters_helper.BuildFindSpecs(artifact_filter_names)
 
     # There should be 3 Windows Registry find specifications.
-    self.assertEqual(
-        len(test_filters_helper.included_file_system_find_specs), 0)
+    self.assertEqual(len(test_filters_helper.file_system_find_specs), 0)
     self.assertEqual(len(test_filters_helper.registry_find_specs), 3)
 
     file_entry = self._GetTestFileEntry(['SYSTEM'])
     file_object = file_entry.GetFileObject()
 
     registry_file = dfwinreg_regf.REGFWinRegistryFile(
         ascii_codepage='cp1252', emulate_virtual_keys=False)
@@ -203,17 +183,15 @@
         find_specs=test_filters_helper.registry_find_specs))
 
     self.assertIsNotNone(key_paths)
     self.assertEqual(len(key_paths), 8)
 
   def testCheckKeyCompatibility(self):
     """Tests the CheckKeyCompatibility function"""
-    knowledge_base = knowledge_base_engine.KnowledgeBase()
-    test_filter_file = self._CreateTestArtifactDefinitionsFiltersHelper(
-        knowledge_base)
+    test_filter_file = self._CreateTestArtifactDefinitionsFiltersHelper()
 
     # Compatible Key.
     key_path = 'HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control'
     compatible_key = test_filter_file.CheckKeyCompatibility(key_path)
     self.assertTrue(compatible_key)
 
     # NOT a Compatible Key.
@@ -222,17 +200,15 @@
     self.assertTrue(compatible_key)
 
   # TODO: add tests for _BuildFindSpecsFromArtifact
   # TODO: add tests for _BuildFindSpecsFromGroupName
 
   def testBuildFindSpecsFromFileSourcePath(self):
     """Tests the _BuildFindSpecsFromFileSourcePath function on file sources."""
-    knowledge_base = knowledge_base_engine.KnowledgeBase()
-    test_filter_file = self._CreateTestArtifactDefinitionsFiltersHelper(
-        knowledge_base)
+    test_filter_file = self._CreateTestArtifactDefinitionsFiltersHelper()
 
     separator = '\\'
     test_user_accounts = []
 
     # Test expansion of environment variables.
     path_entry = '%%environ_systemroot%%\\test_data\\*.evtx'
     environment_variable = [artifacts.EnvironmentVariableArtifact(
```

### Comparing `plaso-20230311/tests/engine/configurations.py` & `plaso-20230717/tests/engine/configurations.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/engine.py` & `plaso-20230717/tests/engine/engine.py`

 * *Files 14% similar despite different names*

```diff
@@ -32,20 +32,20 @@
         '/Windows/System32/config/SYSTEM', test_file_path)
 
     super(TestEngine, self).__init__()
     self._file_system = file_system_builder.file_system
     self._mount_point = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_FAKE, location='/')
 
-  def GetSourceFileSystem(self, source_path_spec, resolver_context=None):
+  def GetSourceFileSystem(self, file_system_path_spec, resolver_context=None):
     """Retrieves the file system of the source.
 
     Args:
-      source_path_spec (dfvfs.PathSpec): path specifications of the sources
-          to process.
+      file_system_path_spec (dfvfs.PathSpec): path specifications of
+          the source file system to process.
       resolver_context (dfvfs.Context): resolver context.
 
     Returns:
       tuple: containing:
 
         dfvfs.FileSystem: file system
         path.PathSpec: mount point path specification. The mount point path
@@ -74,14 +74,31 @@
       test_engine = engine.BaseEngine()
 
       test_engine._StartProfiling(None)
 
       test_engine._StartProfiling(configuration.profiling)
       test_engine._StopProfiling()
 
+  def testBuildArtifactsRegistry(self):
+    """Tests the BuildArtifactsRegistry function."""
+    test_artifacts_path = shared_test_lib.GetTestFilePath(['artifacts'])
+    self._SkipIfPathNotExists(test_artifacts_path)
+
+    test_engine = TestEngine()
+
+    self.assertIsNone(test_engine._artifacts_registry)
+
+    test_engine.BuildArtifactsRegistry(test_artifacts_path, None)
+
+    self.assertIsNotNone(test_engine._artifacts_registry)
+
+    # TODO: add test that raises BadConfigOption
+
+  # TODO: add tests for BuildCollectionFilters.
+
   def testCreateSession(self):
     """Tests the CreateSession function."""
     test_engine = engine.BaseEngine()
 
     session = test_engine.CreateSession()
     self.assertIsNotNone(session)
 
@@ -107,40 +124,36 @@
 
     self.assertIsNotNone(test_mount_point)
     self.assertIsInstance(test_mount_point, path_spec.PathSpec)
 
     with self.assertRaises(RuntimeError):
       test_engine.GetSourceFileSystem(None)
 
-  def testPreprocessSources(self):
-    """Tests the PreprocessSources function."""
+  def testPreprocessSource(self):
+    """Tests the PreprocessSource function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_file_path = self._GetTestFilePath(['SYSTEM'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_artifacts_path = shared_test_lib.GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_engine = TestEngine()
+    test_engine.BuildArtifactsRegistry(test_artifacts_path, None)
 
     source_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_FAKE, location='/')
 
-    session = test_engine.CreateSession()
-
     storage_writer = fake_writer.FakeStorageWriter()
     storage_writer.Open()
 
-    test_engine.PreprocessSources(
-        test_artifacts_path, None, [source_path_spec], session, storage_writer)
-
-    operating_system = test_engine.knowledge_base.GetValue('operating_system')
-    self.assertEqual(operating_system, 'Windows NT')
+    source_configurations = test_engine.PreprocessSource(
+        [source_path_spec], storage_writer)
 
-    test_engine.PreprocessSources(
-        test_artifacts_path, None, [None], session, storage_writer)
+    self.assertEqual(len(source_configurations), 1)
+    self.assertEqual(source_configurations[0].operating_system, 'Windows NT')
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/engine/extractors.py` & `plaso-20230717/tests/engine/extractors.py`

 * *Files 9% similar despite different names*

```diff
@@ -18,37 +18,25 @@
 from tests import test_lib as shared_test_lib
 from tests.engine import test_lib
 
 
 class EventDataExtractorTest(test_lib.EngineTestCase):
   """Tests for the event data extractor."""
 
-  def _CreateParserMediator(
-      self, storage_writer, collection_filters_helper=None,
-      file_entry=None, knowledge_base_values=None, time_zone_string='UTC'):
+  def _CreateParserMediator(self, storage_writer, file_entry=None):
     """Creates a parser mediator.
 
     Args:
       storage_writer (StorageWriter): storage writer.
-      collection_filters_helper (Optional[CollectionFiltersHelper]): collection
-          filters helper.
       file_entry (Optional[dfvfs.FileEntry]): file entry object being parsed.
-      knowledge_base_values (Optional[dict]): knowledge base values.
-      time_zone_string (Optional[str]): time zone.
 
     Returns:
       ParserMediator: parser mediator.
     """
-    knowledge_base_object = self._CreateKnowledgeBase(
-        knowledge_base_values=knowledge_base_values,
-        time_zone_string=time_zone_string)
-
-    parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object,
-        collection_filters_helper=collection_filters_helper)
+    parser_mediator = parsers_mediator.ParserMediator()
     parser_mediator.SetStorageWriter(storage_writer)
 
     if file_entry:
       parser_mediator.SetFileEntry(file_entry)
 
     return parser_mediator
 
@@ -196,15 +184,15 @@
 
       source_path_spec = path_spec_factory.Factory.NewPathSpec(
           dfvfs_definitions.TYPE_INDICATOR_OS, location=temp_directory)
 
       resolver_context = context.Context()
       test_extractor = extractors.PathSpecExtractor()
       path_specs = list(test_extractor.ExtractPathSpecs(
-          [source_path_spec], resolver_context=resolver_context))
+          source_path_spec, resolver_context=resolver_context))
 
       self.assertEqual(len(path_specs), 4)
 
   def testExtractPathSpecsFileSystemWithFindSpecs(self):
     """Tests the ExtractPathSpecs function with find specifications."""
     test_file_path = self._GetTestFilePath(['System.evtx'])
     self._SkipIfPathNotExists(test_file_path)
@@ -225,15 +213,15 @@
         dfvfs_definitions.TYPE_INDICATOR_OS, location='.')
 
     resolver_context = context.Context()
     test_extractor = extractors.PathSpecExtractor()
 
     find_specs = self._GetFindSpecs(location_expressions)
     path_specs = list(test_extractor.ExtractPathSpecs(
-        [source_path_spec], find_specs=find_specs,
+        source_path_spec, find_specs=find_specs,
         resolver_context=resolver_context))
 
     # Two files with test_data/testdir/filter_*.txt, AUTHORS,
     # test_data/System.evtx and test_data/System2.evtx and
     # a symbolic link test_data/link_to_System.evtx.
     self.assertEqual(len(path_specs), 6)
 
@@ -284,15 +272,15 @@
     source_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_TSK, location='/',
         parent=volume_path_spec)
 
     resolver_context = context.Context()
     test_extractor = extractors.PathSpecExtractor()
     path_specs = list(test_extractor.ExtractPathSpecs(
-        [source_path_spec], resolver_context=resolver_context))
+        source_path_spec, resolver_context=resolver_context))
 
     self.assertEqual(len(path_specs), 3)
 
   def testExtractPathSpecsStorageMediaImageWithFilter(self):
     """Tests the ExtractPathSpecs function on an image file with a filter."""
     location_expressions = [
         '/a_directory/.+zip',
@@ -309,15 +297,15 @@
         parent=volume_path_spec)
 
     resolver_context = context.Context()
     test_extractor = extractors.PathSpecExtractor()
 
     find_specs = self._GetFindSpecs(location_expressions)
     path_specs = list(test_extractor.ExtractPathSpecs(
-        [source_path_spec], find_specs=find_specs,
+        source_path_spec, find_specs=find_specs,
         resolver_context=resolver_context))
 
     self.assertEqual(len(path_specs), 2)
 
     paths = self._GetFilePaths(path_specs)
 
     # path_specs[0]
@@ -346,33 +334,25 @@
 
     image_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
 
     p1_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_TSK_PARTITION, location='/p1',
         part_index=2, start_offset=0x00010000, parent=image_path_spec)
-    p1_file_system_path_spec = path_spec_factory.Factory.NewPathSpec(
+    source_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_TSK, location='/',
         parent=p1_path_spec)
 
-    p2_path_spec = path_spec_factory.Factory.NewPathSpec(
-        dfvfs_definitions.TYPE_INDICATOR_TSK_PARTITION, location='/p2',
-        part_index=3, start_offset=0x00510000, parent=image_path_spec)
-    p2_file_system_path_spec = path_spec_factory.Factory.NewPathSpec(
-        dfvfs_definitions.TYPE_INDICATOR_TSK, location='/',
-        parent=p2_path_spec)
-
     test_extractor = extractors.PathSpecExtractor()
 
     resolver_context = context.Context()
     path_specs = list(test_extractor.ExtractPathSpecs(
-        [p1_file_system_path_spec, p2_file_system_path_spec],
-        resolver_context=resolver_context))
+        source_path_spec, resolver_context=resolver_context))
 
-    expected_paths_p1 = [
+    expected_paths = [
         '/$AttrDef',
         '/$BadClus',
         '/$BadClus:$Bad',
         '/$Bitmap',
         '/$Boot',
         '/$Extend',
         '/$Extend/$ObjId',
@@ -388,15 +368,30 @@
         '/$Secure',
         '/$Secure:$SDS',
         '/$UpCase',
         '/$Volume',
         '/file1.txt',
         '/file2.txt']
 
-    expected_paths_p2 = [
+    paths = self._GetFilePaths(path_specs)
+
+    self.assertEqual(len(path_specs), len(expected_paths))
+    self.assertEqual(sorted(paths), sorted(expected_paths))
+
+    p2_path_spec = path_spec_factory.Factory.NewPathSpec(
+        dfvfs_definitions.TYPE_INDICATOR_TSK_PARTITION, location='/p2',
+        part_index=3, start_offset=0x00510000, parent=image_path_spec)
+    source_path_spec = path_spec_factory.Factory.NewPathSpec(
+        dfvfs_definitions.TYPE_INDICATOR_TSK, location='/',
+        parent=p2_path_spec)
+
+    path_specs = list(test_extractor.ExtractPathSpecs(
+        source_path_spec, resolver_context=resolver_context))
+
+    expected_paths = [
         '/$AttrDef',
         '/$BadClus',
         '/$BadClus:$Bad',
         '/$Bitmap',
         '/$Boot',
         '/$Extend',
         '/$Extend/$ObjId',
@@ -413,16 +408,14 @@
         '/$Secure:$SDS',
         '/$UpCase',
         '/$Volume',
         '/file1_on_part_2.txt',
         '/file2_on_part_2.txt']
 
     paths = self._GetFilePaths(path_specs)
-    expected_paths = expected_paths_p1
-    expected_paths.extend(expected_paths_p2)
 
     self.assertEqual(len(path_specs), len(expected_paths))
     self.assertEqual(sorted(paths), sorted(expected_paths))
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/engine/filter_file.py` & `plaso-20230717/tests/engine/filter_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/path_filters.py` & `plaso-20230717/tests/engine/path_filters.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/path_helper.py` & `plaso-20230717/tests/engine/path_helper.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/process_info.py` & `plaso-20230717/tests/engine/process_info.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/processing_status.py` & `plaso-20230717/tests/engine/processing_status.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/profilers.py` & `plaso-20230717/tests/engine/profilers.py`

 * *Files 0% similar despite different names*

```diff
@@ -39,16 +39,16 @@
 
     with shared_test_lib.TempDirectory() as temp_directory:
       profiling_configuration.directory = temp_directory
 
       test_profiler = profilers.SampleFileProfiler(
           'test', profiling_configuration)
 
-      test_profiler._FILENAME_PREFIX = 'test'
-      test_profiler._FILE_HEADER = 'test'
+      setattr(test_profiler, '_FILENAME_PREFIX', 'test')
+      setattr(test_profiler, '_FILE_HEADER', 'test')
 
       test_profiler.Start()
 
       test_profiler.Stop()
 
 
 class CPUTimeProfilerTest(shared_test_lib.BaseTestCase):
```

### Comparing `plaso-20230311/tests/engine/tagging_file.py` & `plaso-20230717/tests/engine/tagging_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/timeliner.py` & `plaso-20230717/tests/engine/timeliner.py`

 * *Files 10% similar despite different names*

```diff
@@ -84,17 +84,16 @@
     event_data.SetEventDataStreamIdentifier(event_data_stream_identifier)
     storage_writer.AddAttributeContainer(event_data)
 
     return storage_writer
 
   def testGetBaseYear(self):
     """Tests the _GetBaseYear function."""
-    knowledge_base = self._CreateKnowledgeBase()
     event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base, data_location=shared_test_lib.TEST_DATA_PATH)
+        data_location=shared_test_lib.TEST_DATA_PATH)
 
     current_year = event_data_timeliner._GetCurrentYear()
 
     event_data = TestEventData1()
     event_data.value = 'MyValue'
 
     # Test with year-less log helper.
@@ -123,41 +122,39 @@
         'timelining_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # TODO: improve test coverage.
 
   def testGetCurrentYear(self):
     """Tests the _GetCurrentYear function."""
-    knowledge_base = self._CreateKnowledgeBase()
     event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base, data_location=shared_test_lib.TEST_DATA_PATH)
+        data_location=shared_test_lib.TEST_DATA_PATH)
 
     current_year = event_data_timeliner._GetCurrentYear()
     self.assertIsNotNone(current_year)
 
   def testGetEvent(self):
     """Tests the _GetEvent function."""
-    knowledge_base = self._CreateKnowledgeBase()
     event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base, data_location=shared_test_lib.TEST_DATA_PATH)
+        data_location=shared_test_lib.TEST_DATA_PATH)
 
     event_data = TestEventData1()
     event_data.value = 'MyValue'
 
     # Test a regular date and time value.
     storage_writer = self._CreateStorageWriter(event_data)
 
     date_time = dfdatetime_time_elements.TimeElementsInMicroseconds(
         time_elements_tuple=(2010, 8, 12, 20, 6, 31, 429876))
 
     # Ensure to reset the timeliner base years cache.
     event_data_timeliner._base_years = {}
 
     event = event_data_timeliner._GetEvent(
-        storage_writer, event_data, date_time, 'Test Time')
+        storage_writer, event_data, None, date_time, 'Test Time')
     self.assertIsNotNone(event)
     self.assertIsNotNone(event.date_time)
     self.assertEqual(event.date_time.year, 2010)
     self.assertEqual(event.timestamp, 1281643591429876)
 
     date_time = dfdatetime_time_elements.TimeElementsInMicroseconds(
         time_elements_tuple=(2010, 8, 12, 20, 6, 31, 429876))
@@ -168,15 +165,15 @@
     date_time = dfdatetime_time_elements.TimeElementsInMicroseconds(
         is_delta=True, time_elements_tuple=(0, 2, 29, 20, 6, 31, 429876))
 
     # Ensure to reset the timeliner base years cache.
     event_data_timeliner._base_years = {}
 
     event = event_data_timeliner._GetEvent(
-        storage_writer, event_data, date_time, 'Test Time')
+        storage_writer, event_data, None, date_time, 'Test Time')
     self.assertIsNotNone(event)
     self.assertIsNotNone(event.date_time)
     self.assertEqual(event.date_time.year, 2012)
     self.assertEqual(event.timestamp, 1330545991429876)
 
     date_time = dfdatetime_time_elements.TimeElementsInMicroseconds(
         is_delta=True, time_elements_tuple=(1, 8, 12, 20, 6, 31, 429876))
@@ -188,97 +185,95 @@
         is_delta=True, time_elements_tuple=(0, 2, 29, 20, 6, 31, 429876))
 
     # Ensure to reset the timeliner base years cache.
     event_data_timeliner._base_years = {}
 
     with self.assertRaises(ValueError):
       event_data_timeliner._GetEvent(
-          storage_writer, event_data, date_time, 'Test Time')
+          storage_writer, event_data, None, date_time, 'Test Time')
 
     # Test date time delta without a base year.
     storage_writer = self._CreateStorageWriter(event_data)
 
     date_time = dfdatetime_time_elements.TimeElementsInMicroseconds(
         time_elements_tuple=(4, 2, 29, 20, 6, 31, 429876))
 
     # Ensure to reset the timeliner base years cache.
     event_data_timeliner._base_years = {}
 
     event = event_data_timeliner._GetEvent(
-        storage_writer, event_data, date_time, 'Test Time')
+        storage_writer, event_data, None, date_time, 'Test Time')
     self.assertIsNotNone(event)
     self.assertIsNotNone(event.date_time)
     self.assertEqual(event.date_time.year, 4)
     self.assertEqual(event.timestamp, -62035818808570124)
 
   # TODO: add tests for _ProduceTimeliningWarning
   # TODO: add tests for _ReadConfigurationFile
 
   def testProcessEventData(self):
     """Tests the ProcessEventData function."""
-    knowledge_base = self._CreateKnowledgeBase()
-
     # Test creating an event.
     event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base, data_location=shared_test_lib.TEST_DATA_PATH)
+        data_location=shared_test_lib.TEST_DATA_PATH)
 
     event_data = TestEventData1()
     event_data.access_time = (
         dfdatetime_time_elements.TimeElementsInMicroseconds(
             time_elements_tuple=(2010, 8, 12, 20, 6, 31, 429876)))
     event_data.value = 'MyValue'
 
     self.assertEqual(event_data_timeliner.number_of_produced_events, 0)
 
     storage_writer = self._CreateStorageWriter(event_data)
 
-    event_data_timeliner.ProcessEventData(storage_writer, event_data)
+    event_data_timeliner.ProcessEventData(storage_writer, event_data, None)
 
     self.assertEqual(event_data_timeliner.number_of_produced_events, 1)
 
     # Test creating a placeholder event.
     event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base, data_location=shared_test_lib.TEST_DATA_PATH)
+        data_location=shared_test_lib.TEST_DATA_PATH)
 
     event_data = TestEventData1()
     event_data.value = 'MyValue'
 
     self.assertEqual(event_data_timeliner.number_of_produced_events, 0)
 
     storage_writer = self._CreateStorageWriter(event_data)
 
-    event_data_timeliner.ProcessEventData(storage_writer, event_data)
+    event_data_timeliner.ProcessEventData(storage_writer, event_data, None)
 
     self.assertEqual(event_data_timeliner.number_of_produced_events, 1)
 
     # Test creating no placeholder event.
     event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base, data_location=shared_test_lib.TEST_DATA_PATH)
+        data_location=shared_test_lib.TEST_DATA_PATH)
 
     event_data = TestEventData2()
     event_data.value = 'MyValue'
 
     self.assertEqual(event_data_timeliner.number_of_produced_events, 0)
 
     storage_writer = self._CreateStorageWriter(event_data)
 
-    event_data_timeliner.ProcessEventData(storage_writer, event_data)
+    event_data_timeliner.ProcessEventData(storage_writer, event_data, None)
 
     self.assertEqual(event_data_timeliner.number_of_produced_events, 0)
 
   def testSetPreferredTimeZone(self):
     """Tests the SetPreferredTimeZone function."""
-    knowledge_base = self._CreateKnowledgeBase()
     event_data_timeliner = timeliner.EventDataTimeliner(
-        knowledge_base, data_location=shared_test_lib.DATA_PATH)
+        data_location=shared_test_lib.DATA_PATH)
 
     event_data_timeliner.SetPreferredTimeZone('Europe/Amsterdam')
 
-    self.assertEqual(event_data_timeliner._time_zone.zone, 'Europe/Amsterdam')
+    self.assertEqual(
+        event_data_timeliner._preferred_time_zone.zone, 'Europe/Amsterdam')
 
     event_data_timeliner.SetPreferredTimeZone(None)
 
-    self.assertEqual(event_data_timeliner._time_zone.zone, 'Etc/UTC')
+    self.assertIsNone(event_data_timeliner._preferred_time_zone)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/engine/worker.py` & `plaso-20230717/tests/engine/worker.py`

 * *Files 13% similar despite different names*

```diff
@@ -8,15 +8,14 @@
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.resolver import context
 from dfvfs.path import factory as path_spec_factory
 
 from plaso.containers import events
 from plaso.containers import sessions
 from plaso.engine import configurations
-from plaso.engine import knowledge_base
 from plaso.engine import worker
 from plaso.parsers import mediator as parsers_mediator
 from plaso.storage.fake import writer as fake_writer
 
 from tests.analyzers import manager as analyzers_manager_test
 from tests import test_lib as shared_test_lib
 
@@ -72,39 +71,33 @@
     self._SkipIfPathNotExists(test_file_path)
 
     return path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
 
   def _TestProcessPathSpec(
       self, storage_writer, path_spec, expected_event_data_counts,
-      archive_types_string=None, extraction_worker=None,
-      knowledge_base_values=None):
+      archive_types_string=None, extraction_worker=None):
     """Tests processing a path specification.
 
     Args:
       storage_writer (StorageWriter): storage writer.
       path_spec (dfvfs.PathSpec): path specification.
       expected_event_data_counts (dict[str, int|list[int]]): expected counts
           of number of event data containers per data type.
       archive_types_string (Optional[str]): comma separated archive types for
           which embedded file entries should be processed.
       extraction_worker (Optional[EventExtractionWorker]): worker to process
           the path specification. If None, a new worker will be created.
-      knowledge_base_values (Optional[dict]): knowledge base values.
     """
     session = sessions.Session()
 
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    if knowledge_base_values:
-      for identifier, value in knowledge_base_values.items():
-        knowledge_base_object.SetValue(identifier, value)
-
     resolver_context = context.Context()
     parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object, resolver_context=resolver_context)
+        resolver_context=resolver_context)
+
     parser_mediator.SetStorageWriter(storage_writer)
 
     if not extraction_worker:
       configuration = configurations.ExtractionConfiguration()
       configuration.archive_types_string = archive_types_string
 
       extraction_worker = worker.EventExtractionWorker()
@@ -155,21 +148,19 @@
     # Ensure there are no events left unaccounted for.
     self.assertEqual(event_counters, collections.Counter())
 
   def testAnalyzeDataStream(self):
     """Tests the _AnalyzeDataStream function."""
     session = sessions.Session()
 
-    storage_writer = fake_writer.FakeStorageWriter()
-
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
     resolver_context = context.Context()
     parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object, resolver_context=resolver_context)
+        resolver_context=resolver_context)
+
+    storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     extraction_worker = worker.EventExtractionWorker()
 
     test_analyzer = analyzers_manager_test.TestAnalyzer()
     self.assertEqual(len(test_analyzer.GetResults()), 0)
 
@@ -197,21 +188,19 @@
     event_attribute = getattr(event_data_stream, 'test_result', None)
     self.assertEqual(event_attribute, 'is_vegetable')
 
   def testAnalyzeFileObject(self):
     """Tests the _AnalyzeFileObject function."""
     session = sessions.Session()
 
-    storage_writer = fake_writer.FakeStorageWriter()
-
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
     resolver_context = context.Context()
     parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object, resolver_context=resolver_context)
+        resolver_context=resolver_context)
+
+    storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     extraction_worker = worker.EventExtractionWorker()
 
     test_analyzer = analyzers_manager_test.TestAnalyzer()
     self.assertEqual(len(test_analyzer.GetResults()), 0)
 
@@ -258,21 +247,19 @@
     result = extraction_worker._CanSkipContentExtraction(file_entry)
     self.assertFalse(result)
 
   def testExtractContentFromDataStream(self):
     """Tests the _ExtractContentFromDataStream function."""
     session = sessions.Session()
 
-    storage_writer = fake_writer.FakeStorageWriter()
-
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
     resolver_context = context.Context()
     parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object, resolver_context=resolver_context)
+        resolver_context=resolver_context)
+
+    storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     extraction_worker = worker.EventExtractionWorker()
 
     test_analyzer = analyzers_manager_test.TestAnalyzer()
     self.assertEqual(len(test_analyzer.GetResults()), 0)
 
@@ -294,21 +281,19 @@
 
     # TODO: check results in storage writer
 
   def testExtractMetadataFromFileEntry(self):
     """Tests the _ExtractMetadataFromFileEntry function."""
     session = sessions.Session()
 
-    storage_writer = fake_writer.FakeStorageWriter()
-
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
     resolver_context = context.Context()
     parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object, resolver_context=resolver_context)
+        resolver_context=resolver_context)
+
+    storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     extraction_worker = worker.EventExtractionWorker()
 
     test_analyzer = analyzers_manager_test.TestAnalyzer()
     self.assertEqual(len(test_analyzer.GetResults()), 0)
 
@@ -330,21 +315,19 @@
 
     # TODO: check results in storage writer
 
   def testGetCompressedStreamTypes(self):
     """Tests the _GetCompressedStreamTypes function."""
     session = sessions.Session()
 
-    storage_writer = fake_writer.FakeStorageWriter()
-
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
     resolver_context = context.Context()
     parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object, resolver_context=resolver_context)
+        resolver_context=resolver_context)
+
+    storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     extraction_worker = worker.EventExtractionWorker()
 
     test_analyzer = analyzers_manager_test.TestAnalyzer()
     self.assertEqual(len(test_analyzer.GetResults()), 0)
```

### Comparing `plaso-20230311/tests/engine/yaml_filter_file.py` & `plaso-20230717/tests/engine/yaml_filter_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/engine/yaml_timeliner_file.py` & `plaso-20230717/tests/engine/yaml_timeliner_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/event_filter.py` & `plaso-20230717/tests/filters/event_filter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/expression_parser.py` & `plaso-20230717/tests/filters/expression_parser.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/expressions.py` & `plaso-20230717/tests/filters/expressions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/file_entry.py` & `plaso-20230717/tests/filters/file_entry.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/filters.py` & `plaso-20230717/tests/filters/filters.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/parser_filter.py` & `plaso-20230717/tests/filters/parser_filter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/path_filter.py` & `plaso-20230717/tests/filters/path_filter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/test_lib.py` & `plaso-20230717/tests/filters/test_lib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/filters/value_types.py` & `plaso-20230717/tests/filters/value_types.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/chrome.py` & `plaso-20230717/tests/formatters/chrome.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/chrome_preferences.py` & `plaso-20230717/tests/formatters/chrome_preferences.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/default.py` & `plaso-20230717/tests/formatters/default.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/file_system.py` & `plaso-20230717/tests/formatters/file_system.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/firefox.py` & `plaso-20230717/tests/formatters/firefox.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/init_imports.py` & `plaso-20230717/tests/formatters/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/interface.py` & `plaso-20230717/tests/formatters/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/msiecf.py` & `plaso-20230717/tests/formatters/msiecf.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/shell_items.py` & `plaso-20230717/tests/formatters/shell_items.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/test_lib.py` & `plaso-20230717/tests/formatters/test_lib.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # -*- coding: utf-8 -*-
 """Event formatter related functions and classes for testing."""
 
-from plaso.engine import knowledge_base
 from plaso.output import mediator
+from plaso.storage.fake import writer as fake_writer
 
 from tests import test_lib as shared_test_lib
 
 
 class EventFormatterTestCase(shared_test_lib.BaseTestCase):
   """The unit test case for an event formatter."""
 
@@ -16,18 +16,19 @@
     Args:
       dynamic_time (Optional[bool]): True if date and time values should be
           represented in their granularity or semantically.
 
     Returns:
       OutputMediator: output mediator.
     """
-    knowledge_base_object = knowledge_base.KnowledgeBase()
+    storage_writer = fake_writer.FakeStorageWriter()
+    storage_writer.Open()
 
     return mediator.OutputMediator(
-        knowledge_base_object, data_location=shared_test_lib.TEST_DATA_PATH,
+        storage_writer, data_location=shared_test_lib.TEST_DATA_PATH,
         dynamic_time=dynamic_time)
 
   def _TestGetFormatStringAttributeNames(
       self, event_formatter, expected_attribute_names):
     """Tests the GetFormatStringAttributeNames function.
 
     Args:
```

### Comparing `plaso-20230311/tests/formatters/winlnk.py` & `plaso-20230717/tests/formatters/winlnk.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/winprefetch.py` & `plaso-20230717/tests/formatters/winprefetch.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/winreg.py` & `plaso-20230717/tests/formatters/winreg.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/formatters/yaml_formatters_file.py` & `plaso-20230717/tests/formatters/yaml_formatters_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/helpers/language_tags.py` & `plaso-20230717/tests/helpers/language_tags.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/helpers/windows/known_folders.py` & `plaso-20230717/tests/helpers/windows/known_folders.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/helpers/windows/languages.py` & `plaso-20230717/tests/helpers/windows/languages.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/helpers/windows/resource_files.py` & `plaso-20230717/tests/helpers/windows/resource_files.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/helpers/windows/shell_folders.py` & `plaso-20230717/tests/helpers/windows/shell_folders.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/lib/bufferlib.py` & `plaso-20230717/tests/lib/bufferlib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/lib/dtfabric_helper.py` & `plaso-20230717/tests/lib/dtfabric_helper.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/lib/line_reader_file.py` & `plaso-20230717/tests/lib/line_reader_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/lib/loggers.py` & `plaso-20230717/tests/lib/loggers.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/lib/plist.py` & `plaso-20230717/tests/lib/plist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/lib/specification.py` & `plaso-20230717/tests/lib/specification.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/lib/yearless_helper.py` & `plaso-20230717/tests/lib/yearless_helper.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 
 import unittest
 
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.path import factory as path_spec_factory
 from dfvfs.resolver import resolver as path_spec_resolver
 
-from plaso.engine import knowledge_base
 from plaso.lib import yearless_helper
 from plaso.parsers import mediator as parsers_mediator
 
 from tests import test_lib as shared_test_lib
 
 
 class YearLessLogFormatHelperTest(shared_test_lib.BaseTestCase):
@@ -59,17 +58,15 @@
     test_helper._SetMonthAndYear(11, 2022)
 
     year = test_helper._GetYear()
     self.assertEqual(year, 2022)
 
   def testSetEstimatedYear(self):
     """Tests the _SetEstimatedYear function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = parsers_mediator.ParserMediator(
-        knowledge_base_object)
+    parser_mediator = parsers_mediator.ParserMediator()
 
     test_path = self._GetTestFilePath(['syslog.gz'])
     os_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location=test_path)
     gzip_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_GZIP, parent=os_path_spec)
     file_entry = path_spec_resolver.Resolver.OpenFileEntry(gzip_path_spec)
```

### Comparing `plaso-20230311/tests/multi_process/analysis_process.py` & `plaso-20230717/tests/multi_process/analysis_process.py`

 * *Files 6% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 """Tests for the multi-processing analysis process."""
 
 import os
 import time
 import unittest
 
 from plaso.analysis import interface as analysis_interface
-from plaso.containers import sessions
 from plaso.engine import configurations
 from plaso.multi_process import analysis_process
 from plaso.multi_process import plaso_queue
 from plaso.multi_process import zeromq_queue
 
 from tests import test_lib as shared_test_lib
 from tests.multi_process import test_lib
@@ -60,25 +59,25 @@
   def testInitialization(self):
     """Tests the initialization."""
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = analysis_process.AnalysisProcess(
-          None, None, None, None, configuration, name='TestAnalysis')
+          None, None, configuration, [], name='TestAnalysis')
       self.assertIsNotNone(test_process)
 
   def testGetStatus(self):
     """Tests the _GetStatus function."""
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = analysis_process.AnalysisProcess(
-          None, None, None, None, configuration, name='TestAnalysis')
+          None, None, configuration, [], name='TestAnalysis')
       status_attributes = test_process._GetStatus()
 
       self.assertIsNotNone(status_attributes)
       self.assertEqual(status_attributes['identifier'], 'TestAnalysis')
       self.assertIsNone(status_attributes['number_of_produced_reports'])
 
       # TODO: add test with analysis mediator.
@@ -90,29 +89,29 @@
     output_event_queue.Open()
 
     input_event_queue = zeromq_queue.ZeroMQPullConnectQueue(
         name='test input event queue', delay_open=True,
         port=output_event_queue.port,
         timeout_seconds=self._QUEUE_TIMEOUT)
 
-    session = sessions.Session()
     analysis_plugin = TestAnalysisPlugin()
 
     with shared_test_lib.TempDirectory() as temp_directory:
       # Set up the processed for the task storage file generated by the
       # analysis plugin.
       os.mkdir(os.path.join(temp_directory, 'processed'))
 
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = analysis_process.AnalysisProcess(
-          input_event_queue, None, session, analysis_plugin, configuration,
+          input_event_queue, analysis_plugin, configuration, [],
           name='TestAnalysis')
-      test_process._FOREMAN_STATUS_WAIT = 1
+
+      setattr(test_process, '_FOREMAN_STATUS_WAIT', 1)
 
       test_process.start()
 
       output_event_queue.PushItem(plaso_queue.QueueAbort(), block=False)
       output_event_queue.Close(abort=True)
 
       # Sleep for 1 second to allow the analysis process to terminate.
@@ -124,13 +123,13 @@
   def testSignalAbort(self):
     """Tests the SignalAbort function."""
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = analysis_process.AnalysisProcess(
-          None, None, None, None, configuration, name='TestAnalysis')
+          None, None, configuration, [], name='TestAnalysis')
       test_process.SignalAbort()
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/multi_process/base_process.py` & `plaso-20230717/tests/multi_process/base_process.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/multi_process/engine.py` & `plaso-20230717/tests/multi_process/engine.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/multi_process/extraction_engine.py` & `plaso-20230717/tests/multi_process/extraction_engine.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,66 +5,68 @@
 import collections
 import os
 import unittest
 
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.path import factory as path_spec_factory
 
-from plaso.containers import artifacts
 from plaso.containers import sessions
 from plaso.lib import definitions
 from plaso.engine import configurations
 from plaso.multi_process import extraction_engine
 from plaso.storage.sqlite import writer as sqlite_writer
 
 from tests import test_lib as shared_test_lib
 
 
 class ExtractionMultiProcessEngineTest(shared_test_lib.BaseTestCase):
   """Tests for the task-based multi-process extraction engine."""
 
-  def testProcessSources(self):
-    """Tests the PreprocessSources and ProcessSources function."""
-    artifacts_path = shared_test_lib.GetTestFilePath(['artifacts'])
-    self._SkipIfPathNotExists(artifacts_path)
+  def testProcessSource(self):
+    """Tests the PreprocessSource and ProcessSource functions."""
+    test_artifacts_path = shared_test_lib.GetTestFilePath(['artifacts'])
+    self._SkipIfPathNotExists(test_artifacts_path)
 
     test_engine = extraction_engine.ExtractionMultiProcessEngine(
         maximum_number_of_tasks=100)
+    test_engine.BuildArtifactsRegistry(test_artifacts_path, None)
 
     test_file_path = self._GetTestFilePath(['mynd.dd'])
     self._SkipIfPathNotExists(test_file_path)
 
     os_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
     source_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_TSK, location='/',
         parent=os_path_spec)
 
-    source_configuration = artifacts.SourceConfigurationArtifact(
-        path_spec=source_path_spec)
-
     session = sessions.Session()
 
-    configuration = configurations.ProcessingConfiguration()
-    configuration.data_location = shared_test_lib.DATA_PATH
-    configuration.parser_filter_expression = 'filestat'
-    configuration.task_storage_format = definitions.STORAGE_FORMAT_SQLITE
+    processing_configuration = configurations.ProcessingConfiguration()
+    processing_configuration.data_location = shared_test_lib.DATA_PATH
+    processing_configuration.parser_filter_expression = 'filestat'
+    processing_configuration.task_storage_format = (
+        definitions.STORAGE_FORMAT_SQLITE)
 
     with shared_test_lib.TempDirectory() as temp_directory:
       temp_file = os.path.join(temp_directory, 'storage.plaso')
       storage_writer = sqlite_writer.SQLiteStorageFileWriter()
       storage_writer.Open(path=temp_file)
 
       try:
-        test_engine.PreprocessSources(
-            artifacts_path, None, [source_path_spec], session, storage_writer)
+        system_configurations = test_engine.PreprocessSource(
+            [source_path_spec], storage_writer)
 
-        processing_status = test_engine.ProcessSources(
-            [source_configuration], storage_writer, session.identifier,
-            configuration, storage_file_path=temp_directory)
+        # The method is named ProcessSourceMulti because pylint 2.6.0 and
+        # later gets confused about keyword arguments when ProcessSource
+        # is used.
+        processing_status = test_engine.ProcessSourceMulti(
+            storage_writer, session.identifier, processing_configuration,
+            system_configurations, [source_path_spec],
+            storage_file_path=temp_directory)
 
         number_of_events = storage_writer.GetNumberOfAttributeContainers(
             'event')
         number_of_extraction_warnings = (
             storage_writer.GetNumberOfAttributeContainers(
                 'extraction_warning'))
         number_of_recovery_warnings = (
```

### Comparing `plaso-20230311/tests/multi_process/extraction_process.py` & `plaso-20230717/tests/multi_process/extraction_process.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """Tests for the multi-processing worker process."""
 
 import unittest
 
-from dfvfs.path import fake_path_spec
+from dfvfs.lib import definitions as dfvfs_definitions
+from dfvfs.path import factory as path_spec_factory
 
 from plaso.containers import sessions
 from plaso.containers import tasks
 from plaso.engine import configurations
 from plaso.engine import worker
 from plaso.lib import definitions
 from plaso.multi_process import extraction_process
@@ -47,35 +48,34 @@
   def testInitialization(self):
     """Tests the initialization."""
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = extraction_process.ExtractionWorkerProcess(
-          None, None, None, configuration, name='TestWorker')
+          None, configuration, [], None, name='TestWorker')
       self.assertIsNotNone(test_process)
 
   def testGetStatus(self):
     """Tests the _GetStatus function."""
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = extraction_process.ExtractionWorkerProcess(
-          None, None, None, configuration, name='TestWorker')
+          None, configuration, [], None, name='TestWorker')
       status_attributes = test_process._GetStatus()
 
       self.assertIsNotNone(status_attributes)
       self.assertEqual(status_attributes['identifier'], 'TestWorker')
       self.assertEqual(status_attributes['last_activity_timestamp'], 0.0)
 
       task_storage_writer = self._CreateStorageWriter()
-      knowledge_base = self._CreateKnowledgeBase()
       test_process._parser_mediator = self._CreateParserMediator(
-          task_storage_writer, knowledge_base)
+          task_storage_writer)
       status_attributes = test_process._GetStatus()
 
       self.assertIsNotNone(status_attributes)
       self.assertEqual(status_attributes['identifier'], 'TestWorker')
       self.assertEqual(status_attributes['last_activity_timestamp'], 0.0)
 
   def testMain(self):
@@ -90,62 +90,62 @@
         port=output_task_queue.port, timeout_seconds=self._QUEUE_TIMEOUT)
 
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = extraction_process.ExtractionWorkerProcess(
-          input_task_queue, None, None, configuration, name='TestWorker')
+          input_task_queue, configuration, [], None, name='TestWorker')
 
       test_process.start()
 
       output_task_queue.PushItem(plaso_queue.QueueAbort(), block=False)
       output_task_queue.Close(abort=True)
 
   def testProcessPathSpec(self):
     """Tests the _ProcessPathSpec function."""
+    test_file_path = self._GetTestFilePath(['testdir', 'filter_1.txt'])
+    self._SkipIfPathNotExists(test_file_path)
+
+    path_spec = path_spec_factory.Factory.NewPathSpec(
+        dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
+
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = extraction_process.ExtractionWorkerProcess(
-          None, None, None, configuration, name='TestWorker')
+          None, configuration, [], None, name='TestWorker')
 
       task_storage_writer = self._CreateStorageWriter()
-      knowledge_base = self._CreateKnowledgeBase()
-      parser_mediator = self._CreateParserMediator(
-          task_storage_writer, knowledge_base)
-
-      path_spec = fake_path_spec.FakePathSpec(location='/test/file')
+      parser_mediator = self._CreateParserMediator(task_storage_writer)
 
       extraction_worker = TestEventExtractionWorker()
       test_process._ProcessPathSpec(
           extraction_worker, parser_mediator, path_spec)
       self.assertEqual(parser_mediator._number_of_extraction_warnings, 0)
 
       test_process._ProcessPathSpec(None, parser_mediator, path_spec)
       self.assertEqual(parser_mediator._number_of_extraction_warnings, 1)
 
   def testProcessTask(self):
     """Tests the _ProcessTask function."""
     session = sessions.Session()
-    knowledge_base = self._CreateKnowledgeBase()
-
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
       configuration.task_storage_format = definitions.STORAGE_FORMAT_SQLITE
 
       test_process = extraction_process.ExtractionWorkerProcess(
-          None, None, knowledge_base, configuration, name='TestWorker')
+          None, configuration, [], None, name='TestWorker')
       test_process._extraction_worker = TestEventExtractionWorker()
 
       task_storage_writer = self._CreateStorageWriter()
       test_process._parser_mediator = self._CreateParserMediator(
-          task_storage_writer, knowledge_base)
+          task_storage_writer)
 
       task = tasks.Task(session_identifier=session.identifier)
       test_process._ProcessTask(task)
 
   def testStartAndStopProfiling(self):
     """Tests the _StartProfiling and _StopProfiling functions."""
     with shared_test_lib.TempDirectory() as temp_directory:
@@ -153,28 +153,28 @@
       configuration.profiling.directory = temp_directory
       configuration.profiling.profilers = set([
           'memory', 'parsers', 'processing', 'serializers', 'storage',
           'task_queue'])
       configuration.task_storage_path = temp_directory
 
       test_process = extraction_process.ExtractionWorkerProcess(
-          None, None, None, configuration, name='TestWorker')
+          None, configuration, [], None, name='TestWorker')
       test_process._extraction_worker = TestEventExtractionWorker()
 
       test_process._StartProfiling(None)
 
       test_process._StartProfiling(configuration.profiling)
       test_process._StopProfiling()
 
   def testSignalAbort(self):
     """Tests the SignalAbort function."""
     with shared_test_lib.TempDirectory() as temp_directory:
       configuration = configurations.ProcessingConfiguration()
       configuration.task_storage_path = temp_directory
 
       test_process = extraction_process.ExtractionWorkerProcess(
-          None, None, None, configuration, name='TestWorker')
+          None, configuration, [], None, name='TestWorker')
       test_process.SignalAbort()
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/multi_process/output_engine.py` & `plaso-20230717/tests/multi_process/output_engine.py`

 * *Files 19% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 """Tests for the output and formatting multi-processing engine."""
 
 import io
 import os
 import unittest
 
 from plaso.engine import configurations
-from plaso.engine import knowledge_base
 from plaso.lib import definitions
 from plaso.multi_process import output_engine
 from plaso.output import dynamic
 from plaso.output import interface as output_interface
 from plaso.output import mediator as output_mediator
 from plaso.storage import factory as storage_factory
 
@@ -247,147 +246,103 @@
       storage_file.AddAttributeContainer(event_data)
 
       event.SetEventDataIdentifier(event_data.GetIdentifier())
       storage_file.AddAttributeContainer(event)
 
     storage_file.Close()
 
-  def _ReadSystemConfiguration(self, path, knowledge_base_object):
-    """Reads system configuration.
-
-    The system configuration, contains information about various system
-    specific configuration data, for example the user accounts.
-
-    Args:
-      path (str): path.
-      knowledge_base_object (KnowledgeBase): is used to store the system
-          configuration.
-    """
-    storage_reader = storage_factory.StorageFactory.CreateStorageReaderForFile(
-        path)
-
-    for session_index, session in enumerate(storage_reader.GetSessions()):
-      knowledge_base_object.SetActiveSession(session.identifier)
-
-      system_configuration = storage_reader.GetAttributeContainerByIndex(
-          'system_configuration', session_index)
-      knowledge_base_object.ReadSystemConfigurationArtifact(
-          system_configuration)
-
   # TODO: add test for _ExportEvent.
 
   def testInternalExportEvents(self):
     """Tests the _ExportEvents function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
-    output_mediator_object = output_mediator.OutputMediator(
-        knowledge_base_object, data_location=shared_test_lib.TEST_DATA_PATH)
-
     formatters_directory_path = self._GetDataFilePath(['formatters'])
-    output_mediator_object.ReadMessageFormattersFromDirectory(
-        formatters_directory_path)
 
     output_module = TestOutputModule()
 
     test_engine = output_engine.OutputAndFormattingMultiProcessEngine()
 
     with shared_test_lib.TempDirectory() as temp_directory:
       temp_file = os.path.join(temp_directory, 'storage.plaso')
       self._CreateTestStorageFile(temp_file)
-      self._ReadSystemConfiguration(temp_file, knowledge_base_object)
 
       storage_reader = (
           storage_factory.StorageFactory.CreateStorageReaderForFile(temp_file))
-      for session_index, session in enumerate(storage_reader.GetSessions()):
-        knowledge_base_object.SetActiveSession(session.identifier)
 
-        system_configuration = storage_reader.GetAttributeContainerByIndex(
-            'system_configuration', session_index)
-        knowledge_base_object.ReadSystemConfigurationArtifact(
-            system_configuration)
+      output_mediator_object = output_mediator.OutputMediator(
+          storage_reader, data_location=shared_test_lib.TEST_DATA_PATH)
+      output_mediator_object.ReadMessageFormattersFromDirectory(
+          formatters_directory_path)
 
       test_engine._ExportEvents(
           storage_reader, output_module, deduplicate_events=False)
 
     self.assertEqual(len(output_module.events), 17)
     self.assertEqual(len(output_module.macb_groups), 3)
 
   def testInternalExportEventsDeduplicate(self):
     """Tests the _ExportEvents function with deduplication."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
-    output_mediator_object = output_mediator.OutputMediator(
-        knowledge_base_object, data_location=shared_test_lib.TEST_DATA_PATH)
-
     formatters_directory_path = self._GetDataFilePath(['formatters'])
-    output_mediator_object.ReadMessageFormattersFromDirectory(
-        formatters_directory_path)
 
     output_module = TestOutputModule()
 
     test_engine = output_engine.OutputAndFormattingMultiProcessEngine()
 
     with shared_test_lib.TempDirectory() as temp_directory:
       temp_file = os.path.join(temp_directory, 'storage.plaso')
       self._CreateTestStorageFile(temp_file)
-      self._ReadSystemConfiguration(temp_file, knowledge_base_object)
 
       storage_reader = (
           storage_factory.StorageFactory.CreateStorageReaderForFile(temp_file))
-      for session_index, session in enumerate(storage_reader.GetSessions()):
-        knowledge_base_object.SetActiveSession(session.identifier)
 
-        system_configuration = storage_reader.GetAttributeContainerByIndex(
-            'system_configuration', session_index)
-        knowledge_base_object.ReadSystemConfigurationArtifact(
-            system_configuration)
+      output_mediator_object = output_mediator.OutputMediator(
+          storage_reader, data_location=shared_test_lib.TEST_DATA_PATH)
+
+      output_mediator_object.ReadMessageFormattersFromDirectory(
+          formatters_directory_path)
 
       test_engine._ExportEvents(storage_reader, output_module)
 
     self.assertEqual(len(output_module.events), 15)
     self.assertEqual(len(output_module.macb_groups), 3)
 
   # TODO: add test for _FlushExportBuffer.
 
   def testExportEvents(self):
     """Tests the ExportEvents function."""
     test_file_path = self._GetTestFilePath(['psort_test.plaso'])
     self._SkipIfPathNotExists(test_file_path)
 
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-
     test_file_object = io.StringIO()
 
     storage_reader = storage_factory.StorageFactory.CreateStorageReaderForFile(
         test_file_path)
 
     output_module = dynamic.DynamicOutputModule()
     output_module._file_object = test_file_object
 
     configuration = configurations.ProcessingConfiguration()
     configuration.data_location = shared_test_lib.DATA_PATH
     configuration.preferred_language = 'en-US'
 
     test_engine = output_engine.OutputAndFormattingMultiProcessEngine()
 
-    test_engine.ExportEvents(
-        knowledge_base_object, storage_reader, output_module, configuration)
+    test_engine.ExportEvents(storage_reader, output_module, configuration)
 
     output = test_file_object.getvalue()
     lines = output.split('\n')
 
     self.assertEqual(len(lines), 22)
 
     expected_line = (
         '2014-11-18T01:15:43.000000+00:00,'
         'Content Modification Time,'
         'LOG,'
         'Log File,'
         '[---] last message repeated 5 times ---,'
-        'syslog,'
+        'text/syslog_traditional,'
         'OS:/tmp/test/test_data/syslog,'
         'repeated')
     self.assertEqual(lines[14], expected_line)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/multi_process/task_manager.py` & `plaso-20230717/tests/multi_process/task_manager.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 """This file contains tests for the task manager."""
 
 import time
 import unittest
 
+from dfvfs.lib import definitions as dfvfs_definitions
+
 from plaso.containers import tasks
 from plaso.lib import definitions
 from plaso.multi_process import task_manager
 
 from tests import test_lib as shared_test_lib
 
 
@@ -71,27 +73,40 @@
     result_task = heap.PopTask()
     self.assertEqual(len(heap), 0)
     self.assertEqual(result_task, task)
 
   def testPushTask(self):
     """Tests the PushTask function."""
     task = tasks.Task()
+    task.file_entry_type = dfvfs_definitions.FILE_ENTRY_TYPE_FILE
     task.storage_file_size = 10
 
     heap = task_manager._PendingMergeTaskHeap()
     self.assertEqual(len(heap), 0)
 
     heap.PushTask(task)
     self.assertEqual(len(heap), 1)
 
     task = tasks.Task()
+    task.file_entry_type = dfvfs_definitions.FILE_ENTRY_TYPE_FILE
     task.storage_file_size = 100
 
     heap.PushTask(task)
     self.assertEqual(len(heap), 2)
+    self.assertIsNotNone(heap._heap[0])
+    self.assertEqual(heap._heap[0][0], 10)
+
+    task = tasks.Task()
+    task.file_entry_type = dfvfs_definitions.FILE_ENTRY_TYPE_DIRECTORY
+    task.storage_file_size = 1000
+
+    heap.PushTask(task)
+    self.assertEqual(len(heap), 3)
+    self.assertIsNotNone(heap._heap[0])
+    self.assertEqual(heap._heap[0][0], -1)
 
     task = tasks.Task()
     with self.assertRaises(ValueError):
       heap.PushTask(task)
 
 
 class TaskManagerTest(shared_test_lib.BaseTestCase):
```

### Comparing `plaso-20230311/tests/multi_process/zeromq_queue.py` & `plaso-20230717/tests/multi_process/zeromq_queue.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/dynamic.py` & `plaso-20230717/tests/output/dynamic.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/formatting_helper.py` & `plaso-20230717/tests/output/formatting_helper.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/init_imports.py` & `plaso-20230717/tests/output/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/interface.py` & `plaso-20230717/tests/output/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/json_line.py` & `plaso-20230717/tests/output/json_line.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/json_out.py` & `plaso-20230717/tests/output/json_out.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/kml.py` & `plaso-20230717/tests/output/kml.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/l2t_csv.py` & `plaso-20230717/tests/output/l2t_csv.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/manager.py` & `plaso-20230717/tests/output/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/mediator.py` & `plaso-20230717/tests/output/opensearch_ts.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,115 +1,140 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the output mediator object."""
+"""Tests for the OpenSearchTimesketch output module."""
 
 import unittest
 
-from plaso.containers import artifacts
-from plaso.engine import knowledge_base
+from unittest.mock import MagicMock
+
+from dfvfs.path import fake_path_spec
+
 from plaso.lib import definitions
-from plaso.output import mediator
+from plaso.output import opensearch_ts
+from plaso.output import shared_opensearch
 
-from tests.containers import test_lib as containers_test_lib
 from tests.output import test_lib
+from tests.containers import test_lib as containers_test_lib
+
+
+class TestOpenSearchTimesketchOutputModule(
+    opensearch_ts.OpenSearchTimesketchOutputModule):
+  """OpenSearchsearch output module for testing."""
 
+  def _Connect(self):
+    """Connects to an OpenSearch server."""
+    self._client = MagicMock()
 
-class OutputMediatorTest(test_lib.OutputModuleTestCase):
-  """Tests for the output mediator object."""
+
+class OpenSearchTimesketchOutputModuleTest(test_lib.OutputModuleTestCase):
+  """Tests for the OpenSearchTimesketch output module."""
 
   # pylint: disable=protected-access
 
   _TEST_EVENTS = [
-      {'data_type': 'test:event',
+      {'a_binary_field': b'binary',
+       'data_type': 'syslog:line',
        'filename': 'log/syslog.1',
        'hostname': 'ubuntu',
+       'my_number': 123,
+       'some_additional_foo': True,
+       'path_spec': fake_path_spec.FakePathSpec(
+           location='log/syslog.1'),
        'text': (
            'Reporter <CRON> PID: 8442 (pam_unix(cron:session): session\n '
            'closed for user root)'),
-       'timestamp': '2012-06-27 18:17:01',
-       'timestamp_desc': definitions.TIME_DESCRIPTION_METADATA_MODIFICATION,
-       'username': 'root'}]
+       'timestamp': '2012-06-27 18:17:01+00:00',
+       'timestamp_desc': definitions.TIME_DESCRIPTION_WRITTEN}]
+
+  def testFlushEvents(self):
+    """Tests the _FlushEvents function.
+
+    Raises:
+      SkipTest: if opensearch-py is missing.
+    """
+    if shared_opensearch.opensearchpy is None:
+      raise unittest.SkipTest('missing opensearch-py')
+
+    output_mediator = self._CreateOutputMediator()
+
+    formatters_directory_path = self._GetDataFilePath(['formatters'])
+    output_mediator.ReadMessageFormattersFromDirectory(
+        formatters_directory_path)
+
+    output_module = TestOpenSearchTimesketchOutputModule()
 
-  def setUp(self):
-    """Makes preparations before running an individual test."""
-    self._knowledge_base = knowledge_base.KnowledgeBase()
+    output_module._Connect()
+    output_module._CreateIndexIfNotExists('test', {})
 
-    hostname_artifact = artifacts.HostnameArtifact(name='myhost')
-    self._knowledge_base.SetHostname(hostname_artifact)
+    event, event_data, event_data_stream = (
+        containers_test_lib.CreateEventFromValues(self._TEST_EVENTS[0]))
 
-  # TODO: add tests for _GetWinevtRcDatabaseReader
+    # TODO: add test for event_tag.
+    field_values = output_module._GetFieldValues(
+        output_mediator, event, event_data, event_data_stream, None)
 
-  def testReadMessageFormattersFile(self):
-    """Tests the _ReadMessageFormattersFile function."""
-    test_file_path = self._GetTestFilePath(['formatters', 'format_test.yaml'])
-    self._SkipIfPathNotExists(test_file_path)
+    output_module._WriteFieldValues(output_mediator, field_values)
 
-    output_mediator = mediator.OutputMediator(self._knowledge_base, None)
+    self.assertEqual(len(output_module._event_documents), 2)
+    self.assertEqual(output_module._number_of_buffered_events, 1)
 
-    output_mediator._ReadMessageFormattersFile(test_file_path)
-    self.assertEqual(len(output_mediator._message_formatters), 2)
+    output_module._FlushEvents()
 
-  # TODO: add tests for _ReadSourceMappings
+    self.assertEqual(len(output_module._event_documents), 0)
+    self.assertEqual(output_module._number_of_buffered_events, 0)
 
-  # TODO: add tests for GetDisplayNameForPathSpec
+  def testWriteFieldValues(self):
+    """Tests the _WriteFieldValues function.
 
-  def testGetHostname(self):
-    """Tests the GetHostname function."""
-    output_mediator = mediator.OutputMediator(self._knowledge_base, None)
+    Raises:
+      SkipTest: if opensearch-py is missing.
+    """
+    if shared_opensearch.opensearchpy is None:
+      raise unittest.SkipTest('missing opensearch-py')
 
-    _, event_data, _ = containers_test_lib.CreateEventFromValues(
-        self._TEST_EVENTS[0])
+    output_mediator = self._CreateOutputMediator()
 
-    hostname = output_mediator.GetHostname(event_data)
-    self.assertEqual(hostname, 'ubuntu')
+    formatters_directory_path = self._GetDataFilePath(['formatters'])
+    output_mediator.ReadMessageFormattersFromDirectory(
+        formatters_directory_path)
 
-  def testGetMACBRepresentation(self):
-    """Tests the GetMACBRepresentation function."""
-    output_mediator = mediator.OutputMediator(self._knowledge_base, None)
+    output_module = TestOpenSearchTimesketchOutputModule()
 
-    event, event_data, _ = containers_test_lib.CreateEventFromValues(
-        self._TEST_EVENTS[0])
-    macb_representation = output_mediator.GetMACBRepresentation(
-        event, event_data)
-    self.assertEqual(macb_representation, '..C.')
+    output_module._Connect()
+    output_module._CreateIndexIfNotExists('test', {})
 
-  # TODO: add tests for GetMACBRepresentationFromDescriptions
-  # TODO: add tests for GetMessageFormatter
-  # TODO: add tests for GetRelativePathForPathSpec
+    self.assertEqual(len(output_module._event_documents), 0)
+    self.assertEqual(output_module._number_of_buffered_events, 0)
 
-  def testGetUsername(self):
-    """Tests the GetUsername function."""
-    output_mediator = mediator.OutputMediator(self._knowledge_base, None)
+    event, event_data, event_data_stream = (
+        containers_test_lib.CreateEventFromValues(self._TEST_EVENTS[0]))
 
-    _, event_data, _ = containers_test_lib.CreateEventFromValues(
-        self._TEST_EVENTS[0])
-    username = output_mediator.GetUsername(event_data)
-    self.assertEqual(username, 'root')
+    # TODO: add test for event_tag.
+    field_values = output_module._GetFieldValues(
+        output_mediator, event, event_data, event_data_stream, None)
 
-  # TODO: add tests for GetWindowsEventMessage
+    output_module._WriteFieldValues(output_mediator, field_values)
 
-  def testReadMessageFormattersFromDirectory(self):
-    """Tests the ReadMessageFormattersFromDirectory function."""
-    test_directory_path = self._GetTestFilePath(['formatters'])
-    self._SkipIfPathNotExists(test_directory_path)
+    self.assertEqual(len(output_module._event_documents), 2)
+    self.assertEqual(output_module._number_of_buffered_events, 1)
 
-    output_mediator = mediator.OutputMediator(self._knowledge_base, None)
+  def testWriteHeader(self):
+    """Tests the WriteHeader function.
 
-    output_mediator.ReadMessageFormattersFromDirectory(test_directory_path)
-    self.assertEqual(len(output_mediator._message_formatters), 2)
+    Raises:
+      SkipTest: if opensearch-py is missing.
+    """
+    if shared_opensearch.opensearchpy is None:
+      raise unittest.SkipTest('missing opensearch-py')
 
-  def testReadMessageFormattersFromFile(self):
-    """Tests the ReadMessageFormattersFromFile function."""
-    test_file_path = self._GetTestFilePath(['formatters', 'format_test.yaml'])
-    self._SkipIfPathNotExists(test_file_path)
+    output_mediator = self._CreateOutputMediator()
+    output_module = TestOpenSearchTimesketchOutputModule()
 
-    output_mediator = mediator.OutputMediator(self._knowledge_base, None)
+    self.assertIsNone(output_module._client)
 
-    output_mediator.ReadMessageFormattersFromFile(test_file_path)
-    self.assertEqual(len(output_mediator._message_formatters), 2)
+    output_module.WriteHeader(output_mediator)
 
-  # TODO: add tests for SetPreferredLanguageIdentifier
-  # TODO: add tests for SetTimezone
+    self.assertIsNotNone(output_module._client)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/output/null.py` & `plaso-20230717/tests/output/null.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/opensearch.py` & `plaso-20230717/tests/output/opensearch.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/opensearch_ts.py` & `plaso-20230717/tests/output/shared_opensearch.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,36 +1,48 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the OpenSearchTimesketch output module."""
+"""Tests for the shared functionality for OpenSearch output modules."""
 
 import unittest
 
 from unittest.mock import MagicMock
 
 from dfvfs.path import fake_path_spec
 
+from plaso.containers import events
 from plaso.lib import definitions
-from plaso.output import opensearch_ts
 from plaso.output import shared_opensearch
 
-from tests.output import test_lib
 from tests.containers import test_lib as containers_test_lib
+from tests.output import test_lib
 
 
-class TestOpenSearchTimesketchOutputModule(
-    opensearch_ts.OpenSearchTimesketchOutputModule):
-  """OpenSearchsearch output module for testing."""
+class TestOpenSearchOutputModule(
+    shared_opensearch.SharedOpenSearchOutputModule):
+  """OpenSearch output module for testing."""
 
   def _Connect(self):
     """Connects to an OpenSearch server."""
     self._client = MagicMock()
 
+  # pylint: disable=unused-argument
+
+  def _WriteFieldValues(self, output_mediator, field_values):
+    """Writes field values to the output.
+
+    Args:
+      output_mediator (OutputMediator): mediates interactions between output
+          modules and other components, such as storage and dfVFS.
+      field_values (dict[str, str]): output field values per name.
+    """
+    return
+
 
-class OpenSearchTimesketchOutputModuleTest(test_lib.OutputModuleTestCase):
-  """Tests for the OpenSearchTimesketch output module."""
+class SharedOpenSearchOutputModuleTest(test_lib.OutputModuleTestCase):
+  """Tests the shared functionality for OpenSearch output modules."""
 
   # pylint: disable=protected-access
 
   _TEST_EVENTS = [
       {'a_binary_field': b'binary',
        'data_type': 'syslog:line',
        'filename': 'log/syslog.1',
@@ -41,100 +53,154 @@
            location='log/syslog.1'),
        'text': (
            'Reporter <CRON> PID: 8442 (pam_unix(cron:session): session\n '
            'closed for user root)'),
        'timestamp': '2012-06-27 18:17:01+00:00',
        'timestamp_desc': definitions.TIME_DESCRIPTION_WRITTEN}]
 
-  def testFlushEvents(self):
-    """Tests the _FlushEvents function.
+  def testConnect(self):
+    """Tests the _Connect function.
 
     Raises:
       SkipTest: if opensearch-py is missing.
     """
     if shared_opensearch.opensearchpy is None:
       raise unittest.SkipTest('missing opensearch-py')
 
-    output_mediator = self._CreateOutputMediator()
-
-    formatters_directory_path = self._GetDataFilePath(['formatters'])
-    output_mediator.ReadMessageFormattersFromDirectory(
-        formatters_directory_path)
+    output_module = TestOpenSearchOutputModule()
 
-    output_module = TestOpenSearchTimesketchOutputModule()
+    self.assertIsNone(output_module._client)
 
     output_module._Connect()
-    output_module._CreateIndexIfNotExists('test', {})
-
-    event, event_data, event_data_stream = (
-        containers_test_lib.CreateEventFromValues(self._TEST_EVENTS[0]))
 
-    # TODO: add test for event_tag.
-    field_values = output_module._GetFieldValues(
-        output_mediator, event, event_data, event_data_stream, None)
-
-    output_module._WriteFieldValues(output_mediator, field_values)
+    self.assertIsNotNone(output_module._client)
 
-    self.assertEqual(len(output_module._event_documents), 2)
-    self.assertEqual(output_module._number_of_buffered_events, 1)
+  def testCreateIndexIfNotExists(self):
+    """Tests the _CreateIndexIfNotExists function.
+    Raises:
+      SkipTest: if opensearch-py is missing.
+    """
+    if shared_opensearch.opensearchpy is None:
+      raise unittest.SkipTest('missing opensearch-py')
 
-    output_module._FlushEvents()
+    output_module = TestOpenSearchOutputModule()
 
-    self.assertEqual(len(output_module._event_documents), 0)
-    self.assertEqual(output_module._number_of_buffered_events, 0)
+    output_module._Connect()
+    output_module._CreateIndexIfNotExists('test', {})
 
-  def testWriteFieldValues(self):
-    """Tests the _WriteFieldValues function.
+  def testClose(self):
+    """Tests the Close function.
 
     Raises:
       SkipTest: if opensearch-py is missing.
     """
     if shared_opensearch.opensearchpy is None:
       raise unittest.SkipTest('missing opensearch-py')
 
+    output_module = TestOpenSearchOutputModule()
+
+    output_module._Connect()
+
+    self.assertIsNotNone(output_module._client)
+
+    output_module.Close()
+
+    self.assertIsNone(output_module._client)
+
+  def testGetFieldValues(self):
+    """Tests the _GetFieldValues function."""
     output_mediator = self._CreateOutputMediator()
 
     formatters_directory_path = self._GetDataFilePath(['formatters'])
     output_mediator.ReadMessageFormattersFromDirectory(
         formatters_directory_path)
 
-    output_module = TestOpenSearchTimesketchOutputModule()
-
-    output_module._Connect()
-    output_module._CreateIndexIfNotExists('test', {})
-
-    self.assertEqual(len(output_module._event_documents), 0)
-    self.assertEqual(output_module._number_of_buffered_events, 0)
+    output_module = TestOpenSearchOutputModule()
 
     event, event_data, event_data_stream = (
         containers_test_lib.CreateEventFromValues(self._TEST_EVENTS[0]))
 
-    # TODO: add test for event_tag.
+    event_tag = events.EventTag()
+    event_tag.AddLabel('Test')
+
+    expected_field_values = {
+        'a_binary_field': 'binary',
+        'data_type': 'syslog:line',
+        'datetime': '2012-06-27T18:17:01.000000+00:00',
+        'display_name': 'FAKE:log/syslog.1',
+        'filename': 'log/syslog.1',
+        'hostname': 'ubuntu',
+        'message': '[',
+        'my_number': 123,
+        'path_spec': (
+            '{"__type__": "PathSpec", "location": "log/syslog.1", '
+            '"type_indicator": "FAKE"}'),
+        'some_additional_foo': True,
+        'source_long': 'Log File',
+        'source_short': 'LOG',
+        'tag': ['Test'],
+        'text': ('Reporter <CRON> PID: 8442 (pam_unix(cron:session): '
+                 'session\n closed for user root)'),
+        'timestamp': 1340821021000000,
+        'timestamp_desc': 'Content Modification Time'}
+
     field_values = output_module._GetFieldValues(
-        output_mediator, event, event_data, event_data_stream, None)
+        output_mediator, event, event_data, event_data_stream, event_tag)
 
-    output_module._WriteFieldValues(output_mediator, field_values)
+    self.assertEqual(field_values, expected_field_values)
 
-    self.assertEqual(len(output_module._event_documents), 2)
-    self.assertEqual(output_module._number_of_buffered_events, 1)
+  def testSetFlushInterval(self):
+    """Tests the SetFlushInterval function."""
+    output_module = TestOpenSearchOutputModule()
 
-  def testWriteHeader(self):
-    """Tests the WriteHeader function.
+    self.assertEqual(
+        output_module._flush_interval, output_module._DEFAULT_FLUSH_INTERVAL)
 
-    Raises:
-      SkipTest: if opensearch-py is missing.
-    """
-    if shared_opensearch.opensearchpy is None:
-      raise unittest.SkipTest('missing opensearch-py')
+    output_module.SetFlushInterval(1234)
 
-    output_mediator = self._CreateOutputMediator()
-    output_module = TestOpenSearchTimesketchOutputModule()
+    self.assertEqual(output_module._flush_interval, 1234)
 
-    self.assertIsNone(output_module._client)
+  def testSetIndexName(self):
+    """Tests the SetIndexName function."""
+    output_module = TestOpenSearchOutputModule()
 
-    output_module.WriteHeader(output_mediator)
+    self.assertIsNone(output_module._index_name)
 
-    self.assertIsNotNone(output_module._client)
+    output_module.SetIndexName('test_index')
+
+    self.assertEqual(output_module._index_name, 'test_index')
+
+  def testSetPassword(self):
+    """Tests the SetPassword function."""
+    output_module = TestOpenSearchOutputModule()
+
+    self.assertIsNone(output_module._password)
+
+    output_module.SetPassword('test_password')
+
+    self.assertEqual(output_module._password, 'test_password')
+
+  def testSetServerInformation(self):
+    """Tests the SetServerInformation function."""
+    output_module = TestOpenSearchOutputModule()
+
+    self.assertIsNone(output_module._host)
+    self.assertIsNone(output_module._port)
+
+    output_module.SetServerInformation('127.0.0.1', 1234)
+
+    self.assertEqual(output_module._host, '127.0.0.1')
+    self.assertEqual(output_module._port, 1234)
+
+  def testSetUsername(self):
+    """Tests the SetUsername function."""
+    output_module = TestOpenSearchOutputModule()
+
+    self.assertIsNone(output_module._username)
+
+    output_module.SetUsername('test_username')
+
+    self.assertEqual(output_module._username, 'test_username')
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/output/rawpy.py` & `plaso-20230717/tests/output/rawpy.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/shared_json.py` & `plaso-20230717/tests/output/shared_json.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/test_lib.py` & `plaso-20230717/tests/output/test_lib.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # -*- coding: utf-8 -*-
 """Output related functions and classes for testing."""
 
-from plaso.engine import knowledge_base
 from plaso.output import mediator
+from plaso.storage.fake import writer as fake_writer
 
 from tests import test_lib as shared_test_lib
 
 
 class OutputModuleTestCase(shared_test_lib.BaseTestCase):
   """The unit test case for a output module."""
 
@@ -16,12 +16,13 @@
     Args:
       dynamic_time (Optional[bool]): True if date and time values should be
           represented in their granularity or semantically.
 
     Returns:
       OutputMediator: output mediator.
     """
-    knowledge_base_object = knowledge_base.KnowledgeBase()
+    storage_writer = fake_writer.FakeStorageWriter()
+    storage_writer.Open()
 
     return mediator.OutputMediator(
-        knowledge_base_object, data_location=shared_test_lib.TEST_DATA_PATH,
+        storage_writer, data_location=shared_test_lib.TEST_DATA_PATH,
         dynamic_time=dynamic_time)
```

### Comparing `plaso-20230311/tests/output/text_file.py` & `plaso-20230717/tests/output/text_file.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/tln.py` & `plaso-20230717/tests/output/tln.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/output/winevt_rc.py` & `plaso-20230717/tests/output/winevt_rc.py`

 * *Files 4% similar despite different names*

```diff
@@ -41,15 +41,15 @@
 
   def testGetWinevtRcDatabaseMessageString(self):
     """Tests the _GetWinevtRcDatabaseMessageString function."""
     database_path = self._GetTestFilePath(['winevt-rc.db'])
     self._SkipIfPathNotExists(database_path)
 
     test_helper = winevt_rc.WinevtResourcesHelper(
-        None, shared_test_lib.TEST_DATA_PATH, 0x00000409, {})
+        None, shared_test_lib.TEST_DATA_PATH, 0x00000409)
 
     expected_message_string = (
         'Your computer has detected that the IP address {0:s} for the Network '
         'Card with network address {2:s} is already in use on the network. '
         'Your computer will automatically attempt to obtain a different '
         'address.')
 
@@ -59,15 +59,15 @@
 
   def testGetMessageString(self):
     """Tests the GetMessageString function."""
     database_path = self._GetTestFilePath(['winevt-rc.db'])
     self._SkipIfPathNotExists(database_path)
 
     test_helper = winevt_rc.WinevtResourcesHelper(
-        None, shared_test_lib.TEST_DATA_PATH, 0x00000409, {})
+        None, shared_test_lib.TEST_DATA_PATH, 0x00000409)
 
     expected_message_string = (
         'Your computer has detected that the IP address {0:s} for the Network '
         'Card with network address {2:s} is already in use on the network. '
         'Your computer will automatically attempt to obtain a different '
         'address.')
```

### Comparing `plaso-20230311/tests/output/xlsx.py` & `plaso-20230717/tests/output/xlsx.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/android_app_usage.py` & `plaso-20230717/tests/parsers/android_app_usage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/asl.py` & `plaso-20230717/tests/parsers/asl.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/bencode_parser.py` & `plaso-20230717/tests/parsers/bencode_parser.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/bencode_plugins/transmission.py` & `plaso-20230717/tests/parsers/bencode_plugins/transmission.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/bencode_plugins/utorrent.py` & `plaso-20230717/tests/parsers/bencode_plugins/utorrent.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/bodyfile.py` & `plaso-20230717/tests/parsers/bodyfile.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/bsm.py` & `plaso-20230717/tests/parsers/bsm.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/chrome_cache.py` & `plaso-20230717/tests/parsers/networkminer.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,43 +1,51 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the Chrome Cache files parser."""
+"""Tests for the NetworkMiner fileinfos parser."""
 
 import unittest
 
-from plaso.parsers import chrome_cache
+from plaso.parsers import networkminer
 
 from tests.parsers import test_lib
 
 
-class ChromeCacheParserTest(test_lib.ParserTestCase):
-  """Tests for the Chrome Cache files parser."""
+class NetworkMinerUnitTest(test_lib.ParserTestCase):
+  """Tests for the NetworkMiner fileinfos parser."""
 
   def testParse(self):
     """Tests the Parse function."""
-    parser = chrome_cache.ChromeCacheParser()
-    storage_writer = self._ParseFile(['chrome_cache', 'index'], parser)
+    parser = networkminer.NetworkMinerParser()
+    storage_writer = self._ParseFile(
+        ['networkminer.pcap.FileInfos.csv'], parser)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 217)
+    self.assertEqual(number_of_event_data, 4)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'creation_time': '2014-04-30T16:44:36.226091+00:00',
-        'data_type': 'chrome:cache:entry',
-        'original_url': (
-            'https://s.ytimg.com/yts/imgbin/player-common-vfliLfqPT.webp')}
+        'data_type': 'networkminer:fileinfos:file',
+        'destination_ip': '192.168.151.130',
+        'destination_port': 'TCP 48304',
+        'file_details': 'travelocity.com/',
+        'file_md5': 'abdb151dfd5775c05b47c0f4ea1cd3d7',
+        'file_size': '98 500 B',
+        'file_path': 'D:\\case-export\\AssembledFiles\\index.html',
+        'filename': 'index.html',
+        'source_ip': '111.123.124.11',
+        'source_port': 'TCP 80',
+        'written_time': '2007-12-17T04:32:30.399052+00:00'}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/chrome_preferences.py` & `plaso-20230717/tests/parsers/chrome_preferences.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/cookie_plugins/ganalytics.py` & `plaso-20230717/tests/parsers/cookie_plugins/ganalytics.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 
 class GoogleAnalyticsPluginTest(sqlite_plugins_test_lib.SQLitePluginTestCase):
   """Tests for the Google Analytics plugin."""
 
   def testParsingFirefox29CookieDatabase(self):
     """Tests the Process function on a Firefox 29 cookie database file."""
-    plugin = firefox_cookies.FirefoxCookiePlugin()
+    plugin = firefox_cookies.FirefoxCookie2Plugin()
     storage_writer = self._ParseDatabaseFileWithPlugin(
         ['firefox_cookies.sqlite'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
     self.assertEqual(number_of_event_data, 105)
```

### Comparing `plaso-20230311/tests/parsers/cookie_plugins/manager.py` & `plaso-20230717/tests/parsers/cookie_plugins/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/cups_ipp.py` & `plaso-20230717/tests/parsers/cups_ipp.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/custom_destinations.py` & `plaso-20230717/tests/parsers/custom_destinations.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/czip.py` & `plaso-20230717/tests/parsers/czip.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/czip_plugins/oxml.py` & `plaso-20230717/tests/parsers/czip_plugins/oxml.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/dsv_parser.py` & `plaso-20230717/tests/parsers/dsv_parser.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/esedb.py` & `plaso-20230717/tests/parsers/esedb.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/esedb_plugins/file_history.py` & `plaso-20230717/tests/parsers/esedb_plugins/file_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/esedb_plugins/msie_webcache.py` & `plaso-20230717/tests/parsers/esedb_plugins/msie_webcache.py`

 * *Files 22% similar despite different names*

```diff
@@ -67,15 +67,15 @@
     """Tests the Process function on database with a PartitionsEx table."""
     plugin = msie_webcache.MsieWebCacheESEDBPlugin()
     storage_writer = self._ParseESEDBFileWithPlugin(
         ['PartitionsEx-WebCacheV01.dat'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 978)
+    self.assertEqual(number_of_event_data, 1143)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 3)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
@@ -94,13 +94,46 @@
             '[HTTP/1.1 200; content-length: 726; content-type: image/svg+xml; '
             'x-cache: TCP_HIT; x-msedge-ref: Ref A: 3CD5FCBC8EAD4E0A80FA41A62'
             'FBC8CCC Ref B: PRAEDGE0910 Ref C: 2019-12-16T20:55:28Z; date: '
             'Mon, 16 Dec 2019 20:55:28 GMT]'),
         'synchronization_count': 0,
         'url': 'https://www.bing.com/rs/3R/kD/ic/878ca0cd/b83d57c0.svg'}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 199)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 211)
+    self.CheckEventData(event_data, expected_event_values)
+
+  def testProcessOnDatabaseWithCookiesExTable(self):
+    """Tests the Process function on database with a CookiesEx table."""
+    plugin = msie_webcache.MsieWebCacheESEDBPlugin()
+    storage_writer = self._ParseESEDBFileWithPlugin(
+        ['WebCacheV01_cookies.dat'], plugin)
+
+    number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
+        'event_data')
+    self.assertEqual(number_of_event_data, 276)
+
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'extraction_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'recovery_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    expected_event_values = {
+            'cookie_hash': '5b4342ed6e2b0ae16f7e2c4c',
+            'cookie_name': 'abid',
+            'cookie_value': 'fcc450d1-8674-1bd3-4074-a240cff5c5b1',
+            'cookie_value_raw': (
+                '66636334353064312d383637342d316264332d343037342d6132343063666'
+                '6356335623100'),
+            'data_type': 'msie:webcache:cookie',
+            'entry_identifier': 13,
+            'flags': 0x80082401,
+            'request_domain': 'com.associates-amazon' }
+
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 69)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/esedb_plugins/srum.py` & `plaso-20230717/tests/parsers/esedb_plugins/srum.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/esedb_plugins/user_access_logging.py` & `plaso-20230717/tests/parsers/esedb_plugins/user_access_logging.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/filestat.py` & `plaso-20230717/tests/parsers/filestat.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/firefox_cache.py` & `plaso-20230717/tests/parsers/firefox_cache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/fish_history.py` & `plaso-20230717/tests/parsers/fish_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/fseventsd.py` & `plaso-20230717/tests/parsers/fseventsd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/init_imports.py` & `plaso-20230717/tests/parsers/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/interface.py` & `plaso-20230717/tests/parsers/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/java_idx.py` & `plaso-20230717/tests/parsers/java_idx.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/aws_cloudtrail_log.py` & `plaso-20230717/tests/parsers/jsonl_plugins/aws_cloudtrail_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/azure_activity_log.py` & `plaso-20230717/tests/parsers/jsonl_plugins/azure_activity_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/azure_application_gateway_log.py` & `plaso-20230717/tests/parsers/jsonl_plugins/azure_application_gateway_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/docker_container_config.py` & `plaso-20230717/tests/parsers/jsonl_plugins/docker_container_config.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/docker_container_log.py` & `plaso-20230717/tests/parsers/jsonl_plugins/docker_container_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/docker_layer_config.py` & `plaso-20230717/tests/parsers/jsonl_plugins/docker_layer_config.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/gcp_log.py` & `plaso-20230717/tests/parsers/jsonl_plugins/gcp_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/ios_app_privacy.py` & `plaso-20230717/tests/parsers/jsonl_plugins/ios_app_privacy.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/microsoft365_audit_log.py` & `plaso-20230717/tests/parsers/jsonl_plugins/microsoft365_audit_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/jsonl_plugins/test_lib.py` & `plaso-20230717/tests/parsers/esedb_plugins/test_lib.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,73 +1,65 @@
 # -*- coding: utf-8 -*-
-"""JSON-L parser plugin related functions and classes for testing."""
-
-import json
-
-from dfvfs.helpers import text_file
+"""ESEDB plugin related functions and classes for testing."""
 
 from plaso.containers import events
+from plaso.parsers import esedb
 from plaso.parsers import mediator as parsers_mediator
 
 from tests.parsers import test_lib
 
 
-class JSONLPluginTestCase(test_lib.ParserTestCase):
-  """JSON-L parser plugin test case."""
+class ESEDBPluginTestCase(test_lib.ParserTestCase):
+  """ESE database-based plugin test case."""
 
-  def _ParseJSONLFileWithPlugin(
-      self, path_segments, plugin, knowledge_base_values=None,
-      time_zone_string=None):
-    """Parses a file as an JSON-L log file and returns an event generator.
+  def _ParseESEDBFileWithPlugin(self, path_segments, plugin):
+    """Parses a file as an ESE database file and returns an event generator.
 
-    This method will first test if a JSON-L log file has the required format
-    using plugin.CheckRequiredFormat() and then extracts events using
+    This method will first test if an ESE database contains the required tables
+    using plugin.CheckRequiredTables() and then extracts events using
     plugin.Process().
 
     Args:
       path_segments (list[str]): path segments inside the test data directory.
-      plugin (JSONLPlugin): JSON-L log file plugin.
-      knowledge_base_values (Optional[dict[str, object]]): knowledge base
-          values.
-      time_zone_string (Optional[str]): time zone.
+      plugin (ESEDBPlugin): ESE database plugin.
 
     Returns:
       FakeStorageWriter: storage writer.
 
     Raises:
       SkipTest: if the path inside the test data directory does not exist and
           the test should be skipped.
     """
-    # TODO: move knowledge base time_zone_string into knowledge_base_values.
-    knowledge_base_object = self._CreateKnowledgeBase(
-        knowledge_base_values=knowledge_base_values,
-        time_zone_string=time_zone_string)
-
-    parser_mediator = parsers_mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = parsers_mediator.ParserMediator()
 
     storage_writer = self._CreateStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     file_entry = self._GetTestFileEntry(path_segments)
     parser_mediator.SetFileEntry(file_entry)
 
     if file_entry:
       event_data_stream = events.EventDataStream()
       event_data_stream.path_spec = file_entry.path_spec
 
       parser_mediator.ProduceEventDataStream(event_data_stream)
 
     # AppendToParserChain needs to be run after SetFileEntry.
-    parser_mediator.AppendToParserChain('jsonl')
+    parser_mediator.AppendToParserChain('esedb')
 
     file_object = file_entry.GetFileObject()
-    text_file_object = text_file.TextFile(file_object)
 
-    line = text_file_object.readline()
-    json_dict = json.loads(line)
+    database = esedb.ESEDatabase()
+    database.Open(file_object)
 
-    required_format = plugin.CheckRequiredFormat(json_dict)
-    self.assertTrue(required_format)
+    try:
+      required_tables_exist = plugin.CheckRequiredTables(database)
+      self.assertTrue(required_tables_exist)
+
+      cache = esedb.ESEDBCache()
+      plugin.UpdateChainAndProcess(
+          parser_mediator, cache=cache, database=database)
 
-    plugin.UpdateChainAndProcess(parser_mediator, file_object=file_object)
+    finally:
+      database.Close()
 
     return storage_writer
```

### Comparing `plaso-20230311/tests/parsers/locate.py` & `plaso-20230717/tests/parsers/locate.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/macos_keychain.py` & `plaso-20230717/tests/parsers/macos_keychain.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/manager.py` & `plaso-20230717/tests/parsers/manager.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/mcafeeav.py` & `plaso-20230717/tests/parsers/mcafeeav.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/mediator.py` & `plaso-20230717/tests/parsers/mediator.py`

 * *Files 16% similar despite different names*

```diff
@@ -5,33 +5,40 @@
 import unittest
 
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.path import factory as path_spec_factory
 from dfvfs.resolver import resolver as path_spec_resolver
 
 from plaso.containers import events
-from plaso.engine import knowledge_base
 from plaso.parsers import mediator
 from plaso.storage.fake import writer as fake_writer
 
 from tests.parsers import test_lib
 
 
 class ParsersMediatorTest(test_lib.ParserTestCase):
   """Tests for the parsers mediator."""
 
   # pylint: disable=protected-access
 
   # TODO: add tests for AppendToParserChain.
   # TODO: add tests for ClearParserChain.
 
+  def testGetCodePage(self):
+    """Tests the GetCodePage function."""
+    parser_mediator = mediator.ParserMediator()
+
+    code_page = parser_mediator.GetCodePage()
+    self.assertEqual(code_page, 'cp1252')
+
+    # TODO: improve test coverage.
+
   def testGetDisplayName(self):
     """Tests the GetDisplayName function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     with self.assertRaises(ValueError):
       parser_mediator.GetDisplayName(file_entry=None)
 
@@ -76,16 +83,15 @@
 
     self.assertEqual(display_name, 'VSS2:TSK:/syslog.gz')
 
     # TODO: add test with relative path.
 
   def testGetDisplayNameForPathSpec(self):
     """Tests the GetDisplayNameForPathSpec function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     test_file_path = self._GetTestFilePath(['syslog.gz'])
     self._SkipIfPathNotExists(test_file_path)
 
@@ -94,42 +100,48 @@
 
     expected_display_name = 'OS:{0:s}'.format(test_file_path)
     display_name = parser_mediator.GetDisplayNameForPathSpec(os_path_spec)
     self.assertEqual(display_name, expected_display_name)
 
   def testGetFileEntry(self):
     """Tests the GetFileEntry function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     file_entry = parser_mediator.GetFileEntry()
     self.assertIsNone(file_entry)
 
   def testGetFilename(self):
     """Tests the GetFilename function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     filename = parser_mediator.GetFilename()
     self.assertIsNone(filename)
 
+  def testGetLanguageTag(self):
+    """Tests the GetLanguageTag function."""
+    parser_mediator = mediator.ParserMediator()
+
+    language_tag = parser_mediator.GetLanguageTag()
+    self.assertEqual(language_tag, 'en-us')
+
+    # TODO: improve test coverage.
+
   # TODO: add tests for GetParserChain.
   # TODO: add tests for GetRelativePathForPathSpec.
   # TODO: add tests for PopFromParserChain.
 
   def testProduceEventData(self):
     """Tests the ProduceEventData method."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     storage_writer.Open()
 
     event_data_stream = events.EventDataStream()
@@ -154,16 +166,15 @@
     self.assertEqual(number_of_warnings, 0)
 
   # TODO: add tests for ProduceEventDataStream.
   # TODO: add tests for ProduceEventSource.
 
   def testProduceExtractionWarning(self):
     """Tests the ProduceExtractionWarning method."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     storage_writer.Open()
 
     parser_mediator.ProduceExtractionWarning('test')
@@ -174,16 +185,15 @@
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
   def testProduceRecoveryWarning(self):
     """Tests the ProduceRecoveryWarning method."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     storage_writer.Open()
 
     parser_mediator.ProduceRecoveryWarning('test')
@@ -194,46 +204,42 @@
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 1)
 
   def testResetFileEntry(self):
     """Tests the ResetFileEntry function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     parser_mediator.ResetFileEntry()
 
   def testSetFileEntry(self):
     """Tests the SetFileEntry function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     parser_mediator.SetFileEntry(None)
 
   def testSetStorageWriter(self):
     """Tests the SetStorageWriter function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     parser_mediator.SetStorageWriter(None)
 
   def testSignalAbort(self):
     """Tests the SignalAbort function."""
-    knowledge_base_object = knowledge_base.KnowledgeBase()
-    parser_mediator = mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = mediator.ParserMediator()
 
     storage_writer = fake_writer.FakeStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     parser_mediator.SignalAbort()
```

### Comparing `plaso-20230311/tests/parsers/msiecf.py` & `plaso-20230717/tests/parsers/msiecf.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/networkminer.py` & `plaso-20230717/tests/parsers/sqlite_plugins/imessage.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,51 +1,47 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the NetworkMiner fileinfos parser."""
+"""Tests for the iMessage plugin."""
 
 import unittest
 
-from plaso.parsers import networkminer
+from plaso.parsers.sqlite_plugins import imessage
 
-from tests.parsers import test_lib
+from tests.parsers.sqlite_plugins import test_lib
 
 
-class NetworkMinerUnitTest(test_lib.ParserTestCase):
-  """Tests for the NetworkMiner fileinfos parser."""
+class IMessageTest(test_lib.SQLitePluginTestCase):
+  """Tests for the iMessage database plugin."""
 
-  def testParse(self):
-    """Tests the Parse function."""
-    parser = networkminer.NetworkMinerParser()
-    storage_writer = self._ParseFile(
-        ['networkminer.pcap.FileInfos.csv'], parser)
+  def testProcess(self):
+    """Test the Process function on a iMessage chat.db file."""
+    plugin = imessage.IMessagePlugin()
+    storage_writer = self._ParseDatabaseFileWithPlugin(
+        ['imessage_chat.db'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 4)
+    self.assertEqual(number_of_event_data, 10)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'data_type': 'networkminer:fileinfos:file',
-        'destination_ip': '192.168.151.130',
-        'destination_port': 'TCP 48304',
-        'file_details': 'travelocity.com/',
-        'file_md5': 'abdb151dfd5775c05b47c0f4ea1cd3d7',
-        'file_size': '98 500 B',
-        'file_path': 'D:\\case-export\\AssembledFiles\\index.html',
-        'filename': 'index.html',
-        'source_ip': '111.123.124.11',
-        'source_port': 'TCP 80',
-        'written_time': '2007-12-17T04:32:30.399052+00:00'}
+        'creation_time': '2015-11-30T10:48:40.000000+00:00',
+        'data_type': 'imessage:event:chat',
+        'imessage_id': 'xxxxxx2015@icloud.com',
+        'message_type': 0,
+        'read_receipt': 1,
+        'service': 'iMessage',
+        'text': 'Did you try to send me a message?'}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 7)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/ntfs.py` & `plaso-20230717/tests/parsers/ntfs.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/olecf.py` & `plaso-20230717/tests/parsers/olecf.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/olecf_plugins/automatic_destinations.py` & `plaso-20230717/tests/parsers/olecf_plugins/automatic_destinations.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/olecf_plugins/default.py` & `plaso-20230717/tests/parsers/olecf_plugins/default.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/olecf_plugins/summary.py` & `plaso-20230717/tests/parsers/olecf_plugins/summary.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/opera.py` & `plaso-20230717/tests/parsers/opera.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/pe.py` & `plaso-20230717/tests/parsers/pe.py`

 * *Files 2% similar despite different names*

```diff
@@ -96,17 +96,15 @@
     self.CheckEventData(event_data, expected_event_values)
 
   def testParseFileObjectOnResourceFile(self):
     """Tests the ParseFileObject on a resource Dynamic Link Library file."""
     test_file_path = self._GetTestFilePath(['wrc-test-wevt_template.dll'])
     self._SkipIfPathNotExists(test_file_path)
 
-    knowledge_base_object = self._CreateKnowledgeBase()
-
-    parser_mediator = parsers_mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = parsers_mediator.ParserMediator()
 
     test_event_provider = artifacts.WindowsEventLogMessageFileArtifact()
     parser_mediator._extract_winevt_resources = True
     parser_mediator._windows_event_log_providers_per_path = {
         os.path.dirname(test_file_path).lower(): {
             'wrc-test-wevt_template.dll': test_event_provider}}
```

### Comparing `plaso-20230311/tests/parsers/plist.py` & `plaso-20230717/tests/parsers/plist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/airport.py` & `plaso-20230717/tests/parsers/plist_plugins/airport.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/apple_account.py` & `plaso-20230717/tests/parsers/plist_plugins/apple_account.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/bluetooth.py` & `plaso-20230717/tests/parsers/plist_plugins/bluetooth.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/default.py` & `plaso-20230717/tests/parsers/plist_plugins/default.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/install_history.py` & `plaso-20230717/tests/parsers/plist_plugins/install_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/interface.py` & `plaso-20230717/tests/parsers/plist_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/ios_carplay.py` & `plaso-20230717/tests/parsers/plist_plugins/ios_carplay.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/ipod.py` & `plaso-20230717/tests/parsers/plist_plugins/ipod.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/launchd.py` & `plaso-20230717/tests/parsers/plist_plugins/launchd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/macos_user.py` & `plaso-20230717/tests/parsers/plist_plugins/macos_user.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/safari_downloads.py` & `plaso-20230717/tests/parsers/plist_plugins/safari_downloads.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/safari_history.py` & `plaso-20230717/tests/parsers/plist_plugins/safari_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/software_update.py` & `plaso-20230717/tests/parsers/plist_plugins/software_update.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/spotlight_searched_terms.py` & `plaso-20230717/tests/parsers/plist_plugins/spotlight_searched_terms.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/spotlight_volume.py` & `plaso-20230717/tests/parsers/plist_plugins/spotlight_volume.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/plist_plugins/time_machine.py` & `plaso-20230717/tests/parsers/plist_plugins/time_machine.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/pls_recall.py` & `plaso-20230717/tests/parsers/pls_recall.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/presets.py` & `plaso-20230717/tests/parsers/presets.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/recycler.py` & `plaso-20230717/tests/parsers/recycler.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/safari_cookies.py` & `plaso-20230717/tests/parsers/safari_cookies.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/spotlight_storedb.py` & `plaso-20230717/tests/parsers/utmp.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,94 +1,81 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the Apple Spotlight store database parser."""
+"""Parser test for utmp files."""
 
 import unittest
 
-from plaso.parsers import spotlight_storedb
+from plaso.parsers import utmp
 
 from tests.parsers import test_lib
 
 
-class SpotlightStoreDatabaseParserTest(test_lib.ParserTestCase):
-  """Tests for the Apple Spotlight store database parser."""
+class UtmpParserTest(test_lib.ParserTestCase):
+  """The unit test for utmp parser."""
 
-  def testParse(self):
-    """Tests the Parse function."""
-    parser = spotlight_storedb.SpotlightStoreDatabaseParser()
-    storage_writer = self._ParseFile(['store.db'], parser)
+  def testParseUtmpFile(self):
+    """Tests the Parse function on a utmp file."""
+    parser = utmp.UtmpParser()
+    storage_writer = self._ParseFile(['utmp'], parser)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 193192)
+    self.assertEqual(number_of_event_data, 14)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'added_time': '2013-06-04T20:53:10.000000+00:00',
-        'attribute_change_time': None,
-        'content_creation_time': '2009-08-23T23:24:01.000000+00:00',
-        'content_modification_time': '2013-06-04T20:53:10.000000+00:00',
-        'content_type': 'com.apple.icns',
-        'creation_time': '2009-08-23T23:24:01.000000+00:00',
-        'data_type': 'spotlight:metadata_item',
-        'downloaded_time': None,
-        'file_name': 'CIJCanoScan9000F.icns',
-        'file_system_identifier': 41322,
-        'kind': 'Apple icon image',
-        'modification_time': '2013-06-04T20:53:10.000000+00:00',
-        'parent_file_system_identifier': 41320,
-        'purchase_time': None,
-        'snapshot_times': None,
-        'update_time': '2015-09-19T18:06:32.552596+00:00',
-        'used_times': None}
+        'data_type': 'linux:utmp:event',
+        'exit_status': 0,
+        'hostname': 'localhost',
+        'ip_address': '0.0.0.0',
+        'pid': 1115,
+        'terminal_identifier': 52,
+        'terminal': 'tty4',
+        'type': 6,
+        'username': 'LOGIN',
+        'written_time': '2013-12-13T14:45:09.000000+00:00'}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 3)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 2)
     self.CheckEventData(event_data, expected_event_values)
 
-  def testParseLZ4CompressedPage(self):
-    """Tests the Parse function on a file with a LZ4 compressed page."""
-    parser = spotlight_storedb.SpotlightStoreDatabaseParser()
-    storage_writer = self._ParseFile(['859631-store.db'], parser)
+  def testParseWtmpFile(self):
+    """Tests the Parse function on a wtmp file."""
+    parser = utmp.UtmpParser()
+    storage_writer = self._ParseFile(['wtmp.1'], parser)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 1848)
+    self.assertEqual(number_of_event_data, 4)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'added_time': None,
-        'attribute_change_time': None,
-        'content_creation_time': None,
-        'content_modification_time': None,
-        'content_type': None,
-        'creation_time': None,
-        'data_type': 'spotlight:metadata_item',
-        'downloaded_time': None,
-        'file_name': None,
-        'file_system_identifier': None,
-        'kind': None,
-        'modification_time': None,
-        'purchase_time': None,
-        'snapshot_times': None,
-        'update_time': '2019-09-17T09:22:07.536585+00:00',
-        'used_times': None}
+        'data_type': 'linux:utmp:event',
+        'exit_status': 0,
+        'hostname': '10.10.122.1',
+        'ip_address': '10.10.122.1',
+        'pid': 20060,
+        'terminal': 'pts/32',
+        'terminal_identifier': 842084211,
+        'type': 7,
+        'username': 'userA',
+        'written_time': '2011-12-01T17:36:38.432935+00:00'}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/sqlite.py` & `plaso-20230717/tests/parsers/sqlite.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/android_calls.py` & `plaso-20230717/tests/parsers/sqlite_plugins/android_calls.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/android_hangouts.py` & `plaso-20230717/tests/parsers/sqlite_plugins/android_hangouts.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/android_sms.py` & `plaso-20230717/tests/parsers/sqlite_plugins/android_sms.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/android_tango.py` & `plaso-20230717/tests/parsers/sqlite_plugins/android_tango.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/android_twitter.py` & `plaso-20230717/tests/parsers/sqlite_plugins/android_twitter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/android_webview.py` & `plaso-20230717/tests/parsers/sqlite_plugins/android_webview.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/android_webviewcache.py` & `plaso-20230717/tests/parsers/sqlite_plugins/android_webviewcache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/chrome_autofill.py` & `plaso-20230717/tests/parsers/sqlite_plugins/chrome_autofill.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/chrome_cookies.py` & `plaso-20230717/tests/parsers/sqlite_plugins/chrome_cookies.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/chrome_extension_activity.py` & `plaso-20230717/tests/parsers/sqlite_plugins/chrome_extension_activity.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/chrome_history.py` & `plaso-20230717/tests/parsers/sqlite_plugins/chrome_history.py`

 * *Files 6% similar despite different names*

```diff
@@ -34,14 +34,15 @@
     expected_event_values = {
         'data_type': 'chrome:history:page_visited',
         'last_visited_time': '2011-04-07T12:03:11.000000+00:00',
         'page_transition_type': 0,
         'title': 'Ubuntu Start Page',
         'typed_count': 0,
         'url': 'http://start.ubuntu.com/10.04/Google/',
+        'visit_count': 4,
         'visit_source': 3}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
     # Check the first file downloaded entry.
     expected_event_values = {
@@ -84,14 +85,15 @@
         'generate-specimens.sh')
 
     expected_event_values = {
         'data_type': 'chrome:history:page_visited',
         'last_visited_time': '2018-01-21T14:09:53.885478+00:00',
         'title': '',
         'typed_count': 0,
+        'visit_count': 1,
         'url': expected_url}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
     # Check the file downloaded entry.
     expected_event_values = {
@@ -132,14 +134,15 @@
         'generate-specimens.sh')
 
     expected_event_values = {
         'data_type': 'chrome:history:page_visited',
         'last_visited_time': '2018-01-21T14:09:27.315765+00:00',
         'title': '',
         'typed_count': 0,
+        'visit_count': 1,
         'url': expected_url}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
     # Check the file downloaded entry.
     expected_event_values = {
@@ -180,14 +183,15 @@
         'generate-specimens.sh')
 
     expected_event_values = {
         'data_type': 'chrome:history:page_visited',
         'last_visited_time': '2018-01-21T14:08:52.037692+00:00',
         'title': '',
         'typed_count': 0,
+        'visit_count': 1,
         'url': expected_url}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
     # Check the file downloaded entry.
     expected_event_values = {
@@ -230,14 +234,15 @@
         'generate-specimens.sh')
 
     expected_event_values = {
         'data_type': 'chrome:history:page_visited',
         'last_visited_time': '2018-01-21T14:08:52.037692+00:00',
         'title': '',
         'typed_count': 0,
+        'visit_count': 1,
         'url': expected_url}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
     # Check the file downloaded entry.
     expected_event_values = {
```

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/dropbox.py` & `plaso-20230717/tests/parsers/sqlite_plugins/dropbox.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/firefox_cookies.py` & `plaso-20230717/tests/parsers/text_plugins/macos_appfirewall.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,49 +1,66 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the Firefox cookie database plugin."""
+"""Tests for the MacOS Application firewall log file text parser plugin."""
 
 import unittest
 
-from plaso.parsers.sqlite_plugins import firefox_cookies
+from plaso.parsers.text_plugins import macos_appfirewall
 
-from tests.parsers.sqlite_plugins import test_lib
+from tests.parsers.text_plugins import test_lib
 
 
-class FirefoxCookiesPluginTest(test_lib.SQLitePluginTestCase):
-  """Tests for the Firefox cookie database plugin."""
+class MacOSAppFirewallTextPluginTest(test_lib.TextPluginTestCase):
+  """Tests for the MacOS Application firewall log file text parser plugin."""
 
   def testProcess(self):
-    """Tests the Process function on a Firefox 29 cookie database file."""
-    plugin = firefox_cookies.FirefoxCookiePlugin()
-    storage_writer = self._ParseDatabaseFileWithPlugin(
-        ['firefox_cookies.sqlite'], plugin)
+    """Tests the Process function."""
+    plugin = macos_appfirewall.MacOSAppFirewallTextPlugin()
+    storage_writer = self._ParseTextFileWithPlugin(['appfirewall.log'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 105)
+    self.assertEqual(number_of_event_data, 47)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
+    # Note that added_time contains a date time delta.
     expected_event_values = {
-        'access_time': '2013-10-30T21:56:03.997686+00:00',
-        'cookie_name': '__utma',
-        'creation_time': '2013-10-30T21:56:03.992499+00:00',
-        'data_type': 'firefox:cookie:entry',
-        'expiration_time': '2015-10-30T21:56:03+00:00',
-        'host': 's.greenqloud.com',
-        'httponly': False,
-        'secure': False,
-        'url': 'http://s.greenqloud.com/'}
+        'action': 'Allow TCP LISTEN  (in:0 out:1)',
+        'added_time': '0000-11-29T22:17:30+00:00',
+        'agent': 'socketfilterfw[87]',
+        'computer_name': 'DarkTemplar-2.local',
+        'data_type': 'macos:appfirewall_log:entry',
+        'process_name': 'Spotify',
+        'status': 'Info'}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 13)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 38)
+    self.CheckEventData(event_data, expected_event_values)
+
+    # Check repeated lines.
+    expected_event_values['added_time'] = '0000-11-29T22:18:29+00:00'
+
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 39)
+    self.CheckEventData(event_data, expected_event_values)
+
+    # Check year change.
+    expected_event_values = {
+        'action': 'Allow TCP LISTEN  (in:0 out:1)',
+        'added_time': '0001-01-01T01:13:23+00:00',
+        'agent': 'socketfilterfw[87]',
+        'computer_name': 'DarkTemplar-2.local',
+        'data_type': 'macos:appfirewall_log:entry',
+        'process_name': 'Notify',
+        'status': 'Info'}
+
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 46)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/firefox_downloads.py` & `plaso-20230717/tests/parsers/sqlite_plugins/firefox_downloads.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/firefox_history.py` & `plaso-20230717/tests/parsers/sqlite_plugins/firefox_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/gdrive.py` & `plaso-20230717/tests/parsers/sqlite_plugins/gdrive.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/imessage.py` & `plaso-20230717/tests/parsers/sqlite_plugins/macos_tcc.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,47 +1,45 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the iMessage plugin."""
+"""Tests for the MacOS TCC plugin."""
 
 import unittest
 
-from plaso.parsers.sqlite_plugins import imessage
+from plaso.parsers.sqlite_plugins import macos_tcc
 
 from tests.parsers.sqlite_plugins import test_lib
 
 
-class IMessageTest(test_lib.SQLitePluginTestCase):
-  """Tests for the iMessage database plugin."""
+class MacOSTCCPluginTest(test_lib.SQLitePluginTestCase):
+  """Tests for the MacOS TCC plugin."""
 
   def testProcess(self):
-    """Test the Process function on a iMessage chat.db file."""
-    plugin = imessage.IMessagePlugin()
-    storage_writer = self._ParseDatabaseFileWithPlugin(
-        ['imessage_chat.db'], plugin)
+    """Tests the Process function on a MacOS TCC file."""
+    plugin = macos_tcc.MacOSTCCPlugin()
+    storage_writer = self._ParseDatabaseFileWithPlugin(['TCC-test.db'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 10)
+    self.assertEqual(number_of_event_data, 21)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'creation_time': '2015-11-30T10:48:40.000000+00:00',
-        'data_type': 'imessage:event:chat',
-        'imessage_id': 'xxxxxx2015@icloud.com',
-        'message_type': 0,
-        'read_receipt': 1,
-        'service': 'iMessage',
-        'text': 'Did you try to send me a message?'}
+        'allowed': 1,
+        'client': 'com.apple.weather',
+        'data_type': 'macos:tcc_entry',
+        'modification_time': '2020-05-29T12:09:51+00:00',
+        'prompt_count': 1,
+        'service': 'kTCCServiceUbiquity'}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 7)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/interface.py` & `plaso-20230717/tests/parsers/sqlite_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/ios_kik.py` & `plaso-20230717/tests/parsers/sqlite_plugins/ios_kik.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/ios_netusage.py` & `plaso-20230717/tests/parsers/sqlite_plugins/ios_netusage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/ios_powerlog.py` & `plaso-20230717/tests/parsers/sqlite_plugins/ios_powerlog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/ios_screentime.py` & `plaso-20230717/tests/parsers/sqlite_plugins/ios_screentime.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/ios_twitter.py` & `plaso-20230717/tests/parsers/sqlite_plugins/ios_twitter.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/kodi.py` & `plaso-20230717/tests/parsers/sqlite_plugins/kodi.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/ls_quarantine.py` & `plaso-20230717/tests/parsers/sqlite_plugins/ls_quarantine.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/mackeeper_cache.py` & `plaso-20230717/tests/parsers/sqlite_plugins/mackeeper_cache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/macos_appusage.py` & `plaso-20230717/tests/parsers/sqlite_plugins/macos_appusage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/macos_document_versions.py` & `plaso-20230717/tests/parsers/sqlite_plugins/macos_document_versions.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/macos_knowledgec.py` & `plaso-20230717/tests/parsers/sqlite_plugins/macos_knowledgec.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/macos_notes.py` & `plaso-20230717/tests/parsers/sqlite_plugins/macos_notes.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/macos_notification_center.py` & `plaso-20230717/tests/parsers/sqlite_plugins/macos_notification_center.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/macos_tcc.py` & `plaso-20230717/tests/parsers/sqlite_plugins/ios_datausage.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,45 +1,54 @@
-#!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the MacOS TCC plugin."""
+"""Tests for the SQLite parser plugin for iOS datausage database files."""
 
 import unittest
 
-from plaso.parsers.sqlite_plugins import macos_tcc
+from plaso.parsers.sqlite_plugins import ios_datausage
 
 from tests.parsers.sqlite_plugins import test_lib
 
 
-class MacOSTCCPluginTest(test_lib.SQLitePluginTestCase):
-  """Tests for the MacOS TCC plugin."""
+class IOSDataUsagePluginTest(test_lib.SQLitePluginTestCase):
+  """Tests for the SQLite parser plugin for iOS data database files."""
 
   def testProcess(self):
-    """Tests the Process function on a MacOS TCC file."""
-    plugin = macos_tcc.MacOSTCCPlugin()
-    storage_writer = self._ParseDatabaseFileWithPlugin(['TCC-test.db'], plugin)
+    """Test the Process function."""
+    plugin = ios_datausage.IOSDatausagePlugin()
+    storage_writer = self._ParseDatabaseFileWithPlugin(
+        ['DataUsage.sqlite'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 21)
+    self.assertEqual(number_of_event_data, 887)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
-        'recovery_warning')
-    self.assertEqual(number_of_warnings, 0)
-
     expected_event_values = {
-        'allowed': 1,
-        'client': 'com.apple.weather',
-        'data_type': 'macos:tcc_entry',
-        'modification_time': '2020-05-29T12:09:51+00:00',
-        'prompt_count': 1,
-        'service': 'kTCCServiceUbiquity'}
+        'bundle_identifier': None,
+        'process_name': 'CumulativeUsageTracker',
+        'start_time': '2023-04-11T14:45:15.450549+00:00',
+        'wifi_in': 0,
+        'wifi_out': 0,
+        'wireless_wan_in': 1185814689,
+        'wireless_wan_out': 150}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
+    expected_event_values = {
+        'bundle_identifier': 'com.apple.MobileSMS',
+        'process_name': 'mDNSResponder/com.apple.MobileSMS',
+        'start_time': '2023-05-15T20:58:15.839447+00:00',
+        'wifi_in': 0,
+        'wifi_out': 0,
+        'wireless_wan_in': 4498,
+        'wireless_wan_out': 1408}
+
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 332)
+    self.CheckEventData(event_data, expected_event_values)
+
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/safari.py` & `plaso-20230717/tests/parsers/sqlite_plugins/safari.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/skype.py` & `plaso-20230717/tests/parsers/sqlite_plugins/skype.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/windows_eventtranscript.py` & `plaso-20230717/tests/parsers/sqlite_plugins/windows_eventtranscript.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/windows_timeline.py` & `plaso-20230717/tests/parsers/sqlite_plugins/windows_timeline.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/sqlite_plugins/zeitgeist.py` & `plaso-20230717/tests/parsers/sqlite_plugins/zeitgeist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/symantec.py` & `plaso-20230717/tests/parsers/symantec.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/systemd_journal.py` & `plaso-20230717/tests/parsers/systemd_journal.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_parser.py` & `plaso-20230717/tests/parsers/text_parser.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/android_logcat.py` & `plaso-20230717/tests/parsers/text_plugins/android_logcat.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/apache_access.py` & `plaso-20230717/tests/parsers/text_plugins/apache_access.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/apt_history.py` & `plaso-20230717/tests/parsers/text_plugins/apt_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/aws_elb_access.py` & `plaso-20230717/tests/parsers/text_plugins/aws_elb_access.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/bash_history.py` & `plaso-20230717/tests/parsers/text_plugins/bash_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/confluence_access.py` & `plaso-20230717/tests/parsers/text_plugins/confluence_access.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/dpkg.py` & `plaso-20230717/tests/parsers/text_plugins/dpkg.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/gdrive_synclog.py` & `plaso-20230717/tests/parsers/text_plugins/gdrive_synclog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/google_logging.py` & `plaso-20230717/tests/parsers/text_plugins/google_logging.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/iis.py` & `plaso-20230717/tests/parsers/text_plugins/iis.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/interface.py` & `plaso-20230717/tests/parsers/text_plugins/interface.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/ios_lockdownd.py` & `plaso-20230717/tests/parsers/text_plugins/ios_lockdownd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/ios_logd.py` & `plaso-20230717/tests/parsers/text_plugins/ios_logd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/ios_sysdiag_log.py` & `plaso-20230717/tests/parsers/text_plugins/ios_sysdiag_log.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/macos_appfirewall.py` & `plaso-20230717/tests/parsers/text_plugins/vsftpd.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,66 +1,45 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the MacOS Application firewall log file text parser plugin."""
+"""Tests for the vsftpd log file text parser plugin."""
 
 import unittest
 
-from plaso.parsers.text_plugins import macos_appfirewall
+from plaso.parsers.text_plugins import vsftpd
 
 from tests.parsers.text_plugins import test_lib
 
 
-class MacOSAppFirewallTextPluginTest(test_lib.TextPluginTestCase):
-  """Tests for the MacOS Application firewall log file text parser plugin."""
+class VsftpdLogTextPluginText(test_lib.TextPluginTestCase):
+  """Tests for the vsftpd log file text parser plugin."""
 
   def testProcess(self):
     """Tests the Process function."""
-    plugin = macos_appfirewall.MacOSAppFirewallTextPlugin()
-    storage_writer = self._ParseTextFileWithPlugin(['appfirewall.log'], plugin)
+    plugin = vsftpd.VsftpdLogTextPlugin()
+    storage_writer = self._ParseTextFileWithPlugin(['vsftpd.log'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 47)
+    self.assertEqual(number_of_event_data, 25)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    # Note that added_time contains a date time delta.
     expected_event_values = {
-        'action': 'Allow TCP LISTEN  (in:0 out:1)',
-        'added_time': '0000-11-29T22:17:30+00:00',
-        'agent': 'socketfilterfw[87]',
-        'computer_name': 'DarkTemplar-2.local',
-        'data_type': 'macos:appfirewall_log:entry',
-        'process_name': 'Spotify',
-        'status': 'Info'}
+        'added_time': '2016-06-10T14:24:19',
+        'data_type': 'vsftpd:log',
+        'text': (
+            '[pid 3] [jean] OK DOWNLOAD: Client "192.168.1.7", '
+            '"/home/jean/trains/how-thomas-the-tank-engine-works-1.jpg", '
+            '49283 bytes, 931.38Kbyte/sec')}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 38)
-    self.CheckEventData(event_data, expected_event_values)
-
-    # Check repeated lines.
-    expected_event_values['added_time'] = '0000-11-29T22:18:29+00:00'
-
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 39)
-    self.CheckEventData(event_data, expected_event_values)
-
-    # Check year change.
-    expected_event_values = {
-        'action': 'Allow TCP LISTEN  (in:0 out:1)',
-        'added_time': '0001-01-01T01:13:23+00:00',
-        'agent': 'socketfilterfw[87]',
-        'computer_name': 'DarkTemplar-2.local',
-        'data_type': 'macos:appfirewall_log:entry',
-        'process_name': 'Notify',
-        'status': 'Info'}
-
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 46)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 12)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/text_plugins/macos_securityd.py` & `plaso-20230717/tests/parsers/text_plugins/macos_securityd.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/macos_wifi.py` & `plaso-20230717/tests/parsers/text_plugins/macos_wifi.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/popcontest.py` & `plaso-20230717/tests/parsers/text_plugins/popcontest.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/postgresql.py` & `plaso-20230717/tests/parsers/text_plugins/postgresql.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/santa.py` & `plaso-20230717/tests/parsers/text_plugins/santa.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/sccm.py` & `plaso-20230717/tests/parsers/text_plugins/sccm.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/selinux.py` & `plaso-20230717/tests/parsers/text_plugins/selinux.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/setupapi.py` & `plaso-20230717/tests/parsers/text_plugins/setupapi.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/skydrivelog.py` & `plaso-20230717/tests/parsers/text_plugins/skydrivelog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/snort_fastlog.py` & `plaso-20230717/tests/parsers/text_plugins/snort_fastlog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/sophos_av.py` & `plaso-20230717/tests/parsers/text_plugins/sophos_av.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/syslog.py` & `plaso-20230717/tests/parsers/text_plugins/syslog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/test_lib.py` & `plaso-20230717/tests/parsers/text_plugins/test_lib.py`

 * *Files 26% similar despite different names*

```diff
@@ -7,43 +7,33 @@
 
 from tests.parsers import test_lib
 
 
 class TextPluginTestCase(test_lib.ParserTestCase):
   """Text parser plugin test case."""
 
-  def _ParseTextFileWithPlugin(
-      self, path_segments, plugin, knowledge_base_values=None,
-      time_zone_string='UTC'):
+  def _ParseTextFileWithPlugin(self, path_segments, plugin):
     """Parses a file as a text log file and returns an event generator.
 
     This method will first test if a text log file has the required format
     using plugin.CheckRequiredFormat() and then extracts events using
     plugin.Process().
 
     Args:
       path_segments (list[str]): path segments inside the test data directory.
       plugin (TextPlugin): text log file plugin.
-      knowledge_base_values (Optional[dict[str, object]]): knowledge base
-          values.
-      time_zone_string (Optional[str]): time zone.
 
     Returns:
       FakeStorageWriter: storage writer.
 
     Raises:
       SkipTest: if the path inside the test data directory does not exist and
           the test should be skipped.
     """
-    # TODO: move knowledge base time_zone_string into knowledge_base_values.
-    knowledge_base_object = self._CreateKnowledgeBase(
-        knowledge_base_values=knowledge_base_values,
-        time_zone_string=time_zone_string)
-
-    parser_mediator = parsers_mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = parsers_mediator.ParserMediator()
 
     storage_writer = self._CreateStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     file_entry = self._GetTestFileEntry(path_segments)
     parser_mediator.SetFileEntry(file_entry)
 
@@ -52,17 +42,20 @@
       event_data_stream.path_spec = file_entry.path_spec
 
       parser_mediator.ProduceEventDataStream(event_data_stream)
 
     # AppendToParserChain needs to be run after SetFileEntry.
     parser_mediator.AppendToParserChain('text')
 
+    encoding = plugin.ENCODING
+    if not encoding:
+      encoding = parser_mediator.GetCodePage()
+
     file_object = file_entry.GetFileObject()
-    text_reader = text_parser.EncodedTextReader(
-        file_object, encoding=plugin.ENCODING or parser_mediator.codepage)
+    text_reader = text_parser.EncodedTextReader(file_object, encoding=encoding)
 
     text_reader.ReadLines()
 
     required_format = plugin.CheckRequiredFormat(parser_mediator, text_reader)
     self.assertTrue(required_format)
 
     plugin.UpdateChainAndProcess(parser_mediator, file_object=file_object)
```

### Comparing `plaso-20230311/tests/parsers/text_plugins/viminfo.py` & `plaso-20230717/tests/parsers/text_plugins/viminfo.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/vsftpd.py` & `plaso-20230717/tests/parsers/text_plugins/winfirewall.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,45 +1,51 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the vsftpd log file text parser plugin."""
+"""Tests for the Windows firewall log text parser plugin."""
 
 import unittest
 
-from plaso.parsers.text_plugins import vsftpd
+from plaso.parsers.text_plugins import winfirewall
 
 from tests.parsers.text_plugins import test_lib
 
 
-class VsftpdLogTextPluginText(test_lib.TextPluginTestCase):
-  """Tests for the vsftpd log file text parser plugin."""
+class WinFirewallLogTextPluginTest(test_lib.TextPluginTestCase):
+  """Tests for the Windows firewall log text parser plugin."""
 
   def testProcess(self):
     """Tests the Process function."""
-    plugin = vsftpd.VsftpdLogTextPlugin()
-    storage_writer = self._ParseTextFileWithPlugin(['vsftpd.log'], plugin)
+    plugin = winfirewall.WinFirewallLogTextPlugin()
+    storage_writer = self._ParseTextFileWithPlugin(
+        ['windows_firewall.log'], plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 25)
+    self.assertEqual(number_of_event_data, 15)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'added_time': '2016-06-10T14:24:19',
-        'data_type': 'vsftpd:log',
-        'text': (
-            '[pid 3] [jean] OK DOWNLOAD: Client "192.168.1.7", '
-            '"/home/jean/trains/how-thomas-the-tank-engine-works-1.jpg", '
-            '49283 bytes, 931.38Kbyte/sec')}
+        'data_type': 'windows:firewall_log:entry',
+        'destination_ip': '123.156.78.90',
+        'destination_port': 1774,
+        'last_written_time': '2005-04-11T08:06:26',
+        'source_ip': '123.45.78.90',
+        'source_port': 80,
+        'packet_size': 576,
+        'tcp_ack': 987654321,
+        'tcp_flags': 'A',
+        'tcp_sequence_number': 123456789,
+        'tcp_window_size': 12345}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 12)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 7)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/text_plugins/winfirewall.py` & `plaso-20230717/tests/parsers/chrome_cache.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,51 +1,70 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the Windows firewall log text parser plugin."""
+"""Tests for the Chrome Cache files parser."""
 
 import unittest
 
-from plaso.parsers.text_plugins import winfirewall
+from plaso.parsers import chrome_cache
 
-from tests.parsers.text_plugins import test_lib
+from tests.parsers import test_lib
 
 
-class WinFirewallLogTextPluginTest(test_lib.TextPluginTestCase):
-  """Tests for the Windows firewall log text parser plugin."""
+class ChromeCacheParserTest(test_lib.ParserTestCase):
+  """Tests for the Chrome Cache files parser."""
 
-  def testProcess(self):
-    """Tests the Process function."""
-    plugin = winfirewall.WinFirewallLogTextPlugin()
-    storage_writer = self._ParseTextFileWithPlugin(
-        ['windows_firewall.log'], plugin)
+  def testParse(self):
+    """Tests the Parse function."""
+    parser = chrome_cache.ChromeCacheParser()
+    storage_writer = self._ParseFile(['chrome_cache', 'index'], parser)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 15)
+    self.assertEqual(number_of_event_data, 217)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'data_type': 'windows:firewall_log:entry',
-        'destination_ip': '123.156.78.90',
-        'destination_port': 1774,
-        'last_written_time': '2005-04-11T08:06:26',
-        'source_ip': '123.45.78.90',
-        'source_port': 80,
-        'packet_size': 576,
-        'tcp_ack': 987654321,
-        'tcp_flags': 'A',
-        'tcp_sequence_number': 123456789,
-        'tcp_window_size': 12345}
+        'creation_time': '2014-04-30T16:44:36.226091+00:00',
+        'data_type': 'chrome:cache:entry',
+        'original_url': (
+            'https://s.ytimg.com/yts/imgbin/player-common-vfliLfqPT.webp')}
 
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 7)
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
+    self.CheckEventData(event_data, expected_event_values)
+
+  def testParseWithVersion3(self):
+    """Tests the Parse function with version 3 Chrome Cache."""
+    parser = chrome_cache.ChromeCacheParser()
+    storage_writer = self._ParseFile(['chrome_cache_v3', 'index'], parser)
+
+    number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
+        'event_data')
+    self.assertEqual(number_of_event_data, 862)
+
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'extraction_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'recovery_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    expected_event_values = {
+        'creation_time': '2023-06-20T22:38:46.862881+00:00',
+        'data_type': 'chrome:cache:entry',
+        'original_url': ('https://m.media-amazon.com/images/'
+            'G/01/gno/sprites/nav-sprite-global-1x-reorg-privacy'
+            '._CB587940754_.png')}
+
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/text_plugins/xchatlog.py` & `plaso-20230717/tests/parsers/text_plugins/xchatlog.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/xchatscrollback.py` & `plaso-20230717/tests/parsers/text_plugins/xchatscrollback.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/text_plugins/zsh_extended_history.py` & `plaso-20230717/tests/parsers/text_plugins/zsh_extended_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/trendmicroav.py` & `plaso-20230717/tests/parsers/trendmicroav.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/utmp.py` & `plaso-20230717/tests/parsers/wincc.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,81 +1,76 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Parser test for utmp files."""
+"""Tests the for bodyfile parser."""
 
 import unittest
 
-from plaso.parsers import utmp
+from plaso.parsers import wincc
 
 from tests.parsers import test_lib
 
 
-class UtmpParserTest(test_lib.ParserTestCase):
-  """The unit test for utmp parser."""
-
-  def testParseUtmpFile(self):
-    """Tests the Parse function on a utmp file."""
-    parser = utmp.UtmpParser()
-    storage_writer = self._ParseFile(['utmp'], parser)
+class SIMATICTest(test_lib.ParserTestCase):
+  """Tests for the SIMATIC S7 logs parser."""
 
+  def testParse(self):
+    """Tests the Parse function."""
+    parser = wincc.SIMATICLogParser()
+    storage_writer = self._ParseFile(
+        ['wincc_simatic_s7_proto_suite.log'], parser)
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 14)
+    self.assertEqual(number_of_event_data, 284)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'data_type': 'linux:utmp:event',
-        'exit_status': 0,
-        'hostname': 'localhost',
-        'ip_address': '0.0.0.0',
-        'pid': 1115,
-        'terminal_identifier': 52,
-        'terminal': 'tty4',
-        'type': 6,
-        'username': 'LOGIN',
-        'written_time': '2013-12-13T14:45:09.000000+00:00'}
-
+        'data_type': 'wincc:simatic_s7:entry',
+        'creation_time': '2019-05-27T10:05:43+00:00',
+        'body': ('419 INFO     | LogFileCount  : 3')
+    }
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 2)
     self.CheckEventData(event_data, expected_event_values)
 
-  def testParseWtmpFile(self):
-    """Tests the Parse function on a wtmp file."""
-    parser = utmp.UtmpParser()
-    storage_writer = self._ParseFile(['wtmp.1'], parser)
 
+class WinCCSyslogTest(test_lib.ParserTestCase):
+  """Tests for the Wincc sys logs parser."""
+
+  def testParse(self):
+    """Tests the Parse function."""
+    parser = wincc.WinCCSysLogParser()
+    storage_writer = self._ParseFile(
+        ['wincc_sys.log'], parser)
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
-    self.assertEqual(number_of_event_data, 4)
+    self.assertEqual(number_of_event_data, 768)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'data_type': 'linux:utmp:event',
-        'exit_status': 0,
-        'hostname': '10.10.122.1',
-        'ip_address': '10.10.122.1',
-        'pid': 20060,
-        'terminal': 'pts/32',
-        'terminal_identifier': 842084211,
-        'type': 7,
-        'username': 'userA',
-        'written_time': '2011-12-01T17:36:38.432935+00:00'}
-
-    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
+        'data_type': 'wincc:sys_log:entry',
+        'log_identifier': 2303,
+        'creation_time': '2019-05-27T10:10:04.712',
+        'event_number': 1012301,
+        'log_hostname': 'BMS001',
+        'source_device': 'CCWriteArchiveServer',
+        'body': ('[(null) 224]failed to insert into MSARCLONG with '
+                 '0x80004005(#0 \'2019-05-27 08:10:03.602\') MSG_STATE_COME')
+    }
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 2)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/utmpx.py` & `plaso-20230717/tests/parsers/utmpx.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/windefender_history.py` & `plaso-20230717/tests/parsers/windefender_history.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winevt.py` & `plaso-20230717/tests/parsers/winevt.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winevtx.py` & `plaso-20230717/tests/parsers/winevtx.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winjob.py` & `plaso-20230717/tests/parsers/winjob.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winlnk.py` & `plaso-20230717/tests/parsers/winlnk.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winprefetch.py` & `plaso-20230717/tests/parsers/winprefetch.py`

 * *Files 2% similar despite different names*

```diff
@@ -340,14 +340,58 @@
         'device_path': '\\VOLUME{01d08edc0cbccaad-3e0d2d25}',
         'origin': 'BYTECODEGENERATOR.EXE-C1E9BCE6.pf',
         'serial_number': 0x3e0d2d25}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
+  def testParse30Variant1Compressed(self):
+    """Tests the Parse function on a compressed version 30 variant 1 file."""
+    parser = winprefetch.WinPrefetchParser()
+    storage_writer = self._ParseFile(['ONEDRIVE.EXE-7E152375.pf'], parser)
+
+    number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
+        'event_data')
+    self.assertEqual(number_of_event_data, 2)
+
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'extraction_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'recovery_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    # Check the prefetch execution event data.
+    expected_event_values = {
+        'data_type': 'windows:prefetch:execution',
+        'executable': 'ONEDRIVE.EXE',
+        'last_run_time': '2015-05-14T22:11:05.4852771+00:00',
+        'prefetch_hash': 0x7e152375,
+        'previous_run_times': [
+            '2015-05-14T22:10:28.6747101+00:00'],
+        'run_count': 2,
+        'version': 30}
+
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 1)
+    self.CheckEventData(event_data, expected_event_values)
+
+    self.assertEqual(len(event_data.mapped_files), 134)
+
+    # Check the volume creation event data.
+    expected_event_values = {
+        'creation_time': '2015-05-15T06:54:55.1392941+00:00',
+        'data_type': 'windows:volume:creation',
+        'device_path': '\\VOLUME{01d08edc0cbccaad-3e0d2d25}',
+        'origin': 'ONEDRIVE.EXE-7E152375.pf',
+        'serial_number': 0x3e0d2d25}
+
+    event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
+    self.CheckEventData(event_data, expected_event_values)
+
   def testParse30Variant2Compressed(self):
     """Tests the Parse function on a compressed version 30 variant 2 file."""
     parser = winprefetch.WinPrefetchParser()
     storage_writer = self._ParseFile(['NOTEPAD.EXE-D8414F97.pf'], parser)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
```

### Comparing `plaso-20230311/tests/parsers/winreg_parser.py` & `plaso-20230717/tests/parsers/winreg_parser.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 
 import unittest
 
 from artifacts import reader as artifacts_reader
 from artifacts import registry as artifacts_registry
 
 from plaso.engine import artifact_filters
-from plaso.engine import knowledge_base as knowledge_base_engine
 from plaso.parsers import winreg_parser
 # Register all plugins.
 from plaso.parsers import winreg_plugins  # pylint: disable=unused-import
 
 from tests.parsers import test_lib
 
 
@@ -140,31 +139,29 @@
   def testParseSystemWithArtifactFilters(self):
     """Tests the Parse function on a SYSTEM file with artifact filters."""
     artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(artifacts_path)
 
     parser = winreg_parser.WinRegistryParser()
     parser.EnablePlugins(parser.ALL_PLUGINS)
-    knowledge_base = knowledge_base_engine.KnowledgeBase()
 
     artifact_filter_names = ['TestRegistryKey', 'TestRegistryValue']
     registry = artifacts_registry.ArtifactDefinitionsRegistry()
     reader = artifacts_reader.YamlArtifactsReader()
 
     registry.ReadFromDirectory(reader, artifacts_path)
 
     artifacts_filters_helper = (
-        artifact_filters.ArtifactDefinitionsFiltersHelper(
-            registry, knowledge_base))
+        artifact_filters.ArtifactDefinitionsFiltersHelper(registry))
 
-    artifacts_filters_helper.BuildFindSpecs(
-        artifact_filter_names, environment_variables=None)
+    artifacts_filters_helper.BuildFindSpecs(artifact_filter_names)
 
     storage_writer = self._ParseFile(
-        ['SYSTEM'], parser, collection_filters_helper=artifacts_filters_helper)
+        ['SYSTEM'], parser,
+        registry_find_specs=artifacts_filters_helper.registry_find_specs)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
     self.assertEqual(number_of_event_data, 3535)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'extraction_warning')
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/amcache.py` & `plaso-20230717/tests/parsers/winreg_plugins/amcache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/appcompatcache.py` & `plaso-20230717/tests/parsers/winreg_plugins/appcompatcache.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/bagmru.py` & `plaso-20230717/tests/parsers/winreg_plugins/bagmru.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/bam.py` & `plaso-20230717/tests/parsers/winreg_plugins/bam.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/ccleaner.py` & `plaso-20230717/tests/parsers/winreg_plugins/ccleaner.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/default.py` & `plaso-20230717/tests/parsers/winreg_plugins/winrar.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,74 +1,72 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the default Windows Registry plugin."""
+"""Tests for the WinRAR Windows Registry plugin."""
 
 import unittest
 
 from dfdatetime import filetime as dfdatetime_filetime
 from dfwinreg import definitions as dfwinreg_definitions
 from dfwinreg import fake as dfwinreg_fake
 
-from plaso.parsers.winreg_plugins import default
+from plaso.parsers.winreg_plugins import winrar
 
 from tests.parsers.winreg_plugins import test_lib
 
 
-class TestDefaultRegistry(test_lib.RegistryPluginTestCase):
-  """Tests for the default Windows Registry plugin."""
+class WinRARHistoryPluginTest(test_lib.RegistryPluginTestCase):
+  """Tests for the WinRAR history Windows Registry plugin."""
 
   def _CreateTestKey(self, key_path, time_string):
-    """Creates Registry keys and values for testing.
+    """Creates WinRAR history Registry keys and values for testing.
 
     Args:
       key_path (str): Windows Registry key path.
       time_string (str): key last written date and time.
 
     Returns:
       dfwinreg.WinRegistryKey: a Windows Registry key.
     """
     filetime = dfdatetime_filetime.Filetime()
     filetime.CopyFromDateTimeString(time_string)
     registry_key = dfwinreg_fake.FakeWinRegistryKey(
-        'TimeZoneInformation', key_path=key_path,
-        last_written_time=filetime.timestamp, offset=1456)
+        'ArcHistory', key_path=key_path, last_written_time=filetime.timestamp,
+        offset=1456)
 
-    value_data = 'acb'.encode('utf_16_le')
+    value_data = 'C:\\Downloads\\The Sleeping Dragon CD1.iso'.encode(
+        'utf_16_le')
     registry_value = dfwinreg_fake.FakeWinRegistryValue(
-        'MRUList', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
-        offset=123)
-    registry_key.AddValue(registry_value)
-
-    value_data = 'Some random text here'.encode('utf_16_le')
-    registry_value = dfwinreg_fake.FakeWinRegistryValue(
-        'a', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
+        '0', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
         offset=1892)
     registry_key.AddValue(registry_value)
 
-    value_data = 'c:/evil.exe'.encode('utf_16_le')
+    value_data = 'C:\\Downloads\\plaso-static.rar'.encode('utf_16_le')
     registry_value = dfwinreg_fake.FakeWinRegistryValue(
-        'b', data=value_data, data_type=dfwinreg_definitions.REG_BINARY,
+        '1', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
         offset=612)
     registry_key.AddValue(registry_value)
 
-    value_data = 'C:/looks_legit.exe'.encode('utf_16_le')
-    registry_value = dfwinreg_fake.FakeWinRegistryValue(
-        'c', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
-        offset=1001)
-    registry_key.AddValue(registry_value)
-
     return registry_key
 
+  def testFilters(self):
+    """Tests the FILTERS class attribute."""
+    plugin = winrar.WinRARHistoryPlugin()
+
+    key_path = 'HKEY_CURRENT_USER\\Software\\WinRAR\\ArcHistory'
+    self._AssertFiltersOnKeyPath(plugin, key_path)
+
+    self._AssertNotFiltersOnKeyPath(plugin, 'HKEY_LOCAL_MACHINE\\Bogus')
+
   def testProcess(self):
     """Tests the Process function."""
-    key_path = '\\Microsoft\\Some Windows\\InterestingApp\\MRU'
+    key_path = 'HKEY_CURRENT_USER\\Software\\WinRAR\\ArcHistory'
     time_string = '2012-08-28 09:23:49.002031'
     registry_key = self._CreateTestKey(key_path, time_string)
 
-    plugin = default.DefaultPlugin()
+    plugin = winrar.WinRARHistoryPlugin()
     storage_writer = self._ParseKeyWithPlugin(registry_key, plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
     self.assertEqual(number_of_event_data, 1)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
@@ -76,22 +74,20 @@
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'data_type': 'windows:registry:key_value',
+        'data_type': 'winrar:history',
+        'entries': (
+            '0: C:\\Downloads\\The Sleeping Dragon CD1.iso '
+            '1: C:\\Downloads\\plaso-static.rar'),
         'key_path': key_path,
-        'last_written_time': '2012-08-28T09:23:49.0020310+00:00',
-        'values': (
-            'MRUList: [REG_SZ] acb '
-            'a: [REG_SZ] Some random text here '
-            'b: [REG_BINARY] (22 bytes) '
-            'c: [REG_SZ] C:/looks_legit.exe')}
+        'last_written_time': '2012-08-28T09:23:49.0020310+00:00'}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/interface.py` & `plaso-20230717/tests/parsers/winreg_plugins/interface.py`

 * *Files 2% similar despite different names*

```diff
@@ -212,18 +212,17 @@
     value_data = b'o\x00n\x00e\x00'
     registry_value = dfwinreg_fake.FakeWinRegistryValue(
         'a', data=value_data, data_type=dfwinreg_definitions.REG_SZ)
     registry_key.AddValue(registry_value)
 
     plugin = interface.WindowsRegistryPlugin()
 
-    expected_value_dict = {
-        'a': '[REG_SZ] one',
-        'MRUList': '[REG_BINARY] (2 bytes)'}
+    expected_value_tuples = [
+        ('MRUList', 'REG_BINARY', '(2 bytes)'),
+        ('a', 'REG_SZ', 'one')]
 
-    values_dict = plugin._GetValuesFromKey(parser_mediator, registry_key)
-    self.assertEqual(
-        sorted(values_dict.items()), sorted(expected_value_dict.items()))
+    value_tuples = plugin._GetValuesFromKey(parser_mediator, registry_key)
+    self.assertEqual(sorted(value_tuples), expected_value_tuples)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/lfu.py` & `plaso-20230717/tests/parsers/winreg_plugins/lfu.py`

 * *Files 11% similar despite different names*

```diff
@@ -125,29 +125,27 @@
         'key_path': key_path,
         'last_written_time': '2012-08-31T20:45:29.0000000+00:00',
         'value': 'autocheck autochk *'}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
-    expected_values = (
-        'CriticalSectionTimeout: [REG_SZ] 2592000 '
-        'ExcludeFromKnownDlls: [REG_MULTI_SZ] [] '
-        'GlobalFlag: [REG_SZ] 0 '
-        'HeapDeCommitFreeBlockThreshold: [REG_SZ] 0 '
-        'HeapDeCommitTotalFreeThreshold: [REG_SZ] 0 '
-        'HeapSegmentCommit: [REG_SZ] 0 '
-        'HeapSegmentReserve: [REG_SZ] 0 '
-        'NumberOfInitialSessions: [REG_SZ] 2')
-
     expected_event_values = {
         'data_type': 'windows:registry:key_value',
         'key_path': key_path,
         'last_written_time': '2012-08-31T20:45:29.0000000+00:00',
-        'values': expected_values}
+        'values': [
+            ('CriticalSectionTimeout', 'REG_SZ', '2592000'),
+            ('ExcludeFromKnownDlls', 'REG_MULTI_SZ', '[]'),
+            ('GlobalFlag', 'REG_SZ', '0'),
+            ('HeapDeCommitFreeBlockThreshold', 'REG_SZ', '0'),
+            ('HeapDeCommitTotalFreeThreshold', 'REG_SZ', '0'),
+            ('HeapSegmentCommit', 'REG_SZ', '0'),
+            ('HeapSegmentReserve', 'REG_SZ', '0'),
+            ('NumberOfInitialSessions', 'REG_SZ', '2')]}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 1)
     self.CheckEventData(event_data, expected_event_values)
 
 
 class BootVerificationPluginTest(test_lib.RegistryPluginTestCase):
   """Tests for the LFU BootVerification Windows Registry plugin."""
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/mountpoints.py` & `plaso-20230717/tests/parsers/winreg_plugins/mountpoints.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/mrulist.py` & `plaso-20230717/tests/parsers/winreg_plugins/mrulist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/mrulistex.py` & `plaso-20230717/tests/parsers/winreg_plugins/mrulistex.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/msie_zones.py` & `plaso-20230717/tests/parsers/winreg_plugins/msie_zones.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/network_drives.py` & `plaso-20230717/tests/parsers/winreg_plugins/network_drives.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/networks.py` & `plaso-20230717/tests/parsers/winreg_plugins/networks.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/officemru.py` & `plaso-20230717/tests/parsers/winreg_plugins/officemru.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/outlook.py` & `plaso-20230717/tests/parsers/winreg_plugins/outlook.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/programscache.py` & `plaso-20230717/tests/parsers/winreg_plugins/programscache.py`

 * *Files 7% similar despite different names*

```diff
@@ -101,20 +101,20 @@
     self.CheckEventData(event_data, expected_event_values)
 
     # The Windows Registry key event.
     expected_event_values = {
         'data_type': 'windows:registry:key_value',
         'key_path': key_path,
         'last_written_time': '2009-08-04T15:22:18.4196250+00:00',
-        'values': (
-            'Favorites: [REG_BINARY] (55 bytes) '
-            'FavoritesChanges: [REG_DWORD_LE] 1 '
-            'FavoritesResolve: [REG_BINARY] (8 bytes) '
-            'StartMenu_Balloon_Time: [REG_BINARY] (8 bytes) '
-            'StartMenu_Start_Time: [REG_BINARY] (8 bytes)')}
+        'values': [
+            ('StartMenu_Start_Time', 'REG_BINARY', '(8 bytes)'),
+            ('FavoritesResolve', 'REG_BINARY', '(8 bytes)'),
+            ('Favorites', 'REG_BINARY', '(55 bytes)'),
+            ('FavoritesChanges', 'REG_DWORD_LE', '1'),
+            ('StartMenu_Balloon_Time', 'REG_BINARY', '(8 bytes)')]}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 26)
     self.CheckEventData(event_data, expected_event_values)
 
   def testProcessStartPage2(self):
     """Tests the Process function on a StartPage2 key."""
     test_file_entry = self._GetTestFileEntry(['NTUSER-WIN7.DAT'])
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/run.py` & `plaso-20230717/tests/parsers/winreg_plugins/run.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/sam_users.py` & `plaso-20230717/tests/parsers/winreg_plugins/sam_users.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/services.py` & `plaso-20230717/tests/parsers/winreg_plugins/services.py`

 * *Files 3% similar despite different names*

```diff
@@ -104,28 +104,27 @@
         'extraction_warning')
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    expected_values = (
-        'DisplayName: [REG_SZ] Test Driver '
-        'DriverPackageId: [REG_SZ] testdriver.inf_x86_neutral_dd39b6b0a45226c4 '
-        'Group: [REG_SZ] Pnp Filter')
-
     expected_event_values = {
         'data_type': 'windows:registry:service',
         'error_control': 1,
         'image_path': 'C:\\Dell\\testdriver.sys',
         'key_path': key_path,
         'last_written_time': '2012-08-28T09:23:49.0020310+00:00',
         'service_type': 2,
         'start_type': 2,
-        'values': expected_values}
+        'values': [
+            ('Group', 'REG_SZ', 'Pnp Filter'),
+            ('DisplayName', 'REG_SZ', 'Test Driver'),
+            ('DriverPackageId', 'REG_SZ',
+             'testdriver.inf_x86_neutral_dd39b6b0a45226c4')]}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
   def testProcessFile(self):
     """Tests the Process function on a key in a file."""
     test_file_entry = self._GetTestFileEntry(['SYSTEM'])
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/shutdown.py` & `plaso-20230717/tests/parsers/winreg_plugins/shutdown.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/task_scheduler.py` & `plaso-20230717/tests/parsers/winreg_plugins/task_scheduler.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/terminal_server.py` & `plaso-20230717/tests/parsers/winreg_plugins/terminal_server.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/test_lib.py` & `plaso-20230717/tests/parsers/winreg_plugins/test_lib.py`

 * *Files 14% similar despite different names*

```diff
@@ -100,41 +100,32 @@
 
     win_registry = dfwinreg_registry.WinRegistry()
     key_path_prefix = win_registry.GetRegistryFileMapping(registry_file)
     win_registry.MapFile(key_path_prefix, registry_file)
 
     return win_registry
 
-  def _ParseKeyWithPlugin(
-      self, registry_key, plugin, file_entry=None, knowledge_base_values=None,
-      time_zone_string='UTC'):
+  def _ParseKeyWithPlugin(self, registry_key, plugin, file_entry=None):
     """Parses a key within a Windows Registry file using the plugin.
 
     Args:
       registry_key (dfwinreg.WinRegistryKey): Windows Registry Key.
       plugin (WindowsRegistryPlugin): Windows Registry plugin.
       file_entry (Optional[dfvfs.FileEntry]): file entry.
-      knowledge_base_values (Optional[dict[str, str]]): knowledge base values.
-      time_zone_string (Optional[str]): time zone.
 
     Returns:
       FakeStorageWriter: storage writer.
 
     Raises:
       SkipTest: if the path inside the test data directory does not exist and
           the test should be skipped.
     """
     self.assertIsNotNone(registry_key)
 
-    # TODO: move knowledge base time_zone_string into knowledge_base_values.
-    knowledge_base_object = self._CreateKnowledgeBase(
-        knowledge_base_values=knowledge_base_values,
-        time_zone_string=time_zone_string)
-
-    parser_mediator = parsers_mediator.ParserMediator(knowledge_base_object)
+    parser_mediator = parsers_mediator.ParserMediator()
 
     storage_writer = self._CreateStorageWriter()
     parser_mediator.SetStorageWriter(storage_writer)
 
     parser_mediator.SetFileEntry(file_entry)
 
     if file_entry:
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/timezone.py` & `plaso-20230717/tests/parsers/winreg_plugins/timezone.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/typedurls.py` & `plaso-20230717/tests/parsers/winreg_plugins/typedurls.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/usb.py` & `plaso-20230717/tests/parsers/winreg_plugins/usb.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/usbstor.py` & `plaso-20230717/tests/parsers/winreg_plugins/usbstor.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/userassist.py` & `plaso-20230717/tests/parsers/winreg_plugins/userassist.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/windows_version.py` & `plaso-20230717/tests/parsers/winreg_plugins/windows_version.py`

 * *Files 2% similar despite different names*

```diff
@@ -133,19 +133,19 @@
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
     expected_event_values = {
         'data_type': 'windows:registry:key_value',
         'key_path': key_path,
         'last_written_time': '2012-08-31T20:09:55.1235210+00:00',
-        'values': (
-            'CSDVersion: [REG_SZ] Service Pack 1 '
-            'CurrentVersion: [REG_SZ] 5.1 '
-            'ProductName: [REG_SZ] MyTestOS '
-            'RegisteredOwner: [REG_SZ] A Concerned Citizen')}
+        'values': [
+            ('CSDVersion', 'REG_SZ', 'Service Pack 1'),
+            ('CurrentVersion', 'REG_SZ', '5.1'),
+            ('ProductName', 'REG_SZ', 'MyTestOS'),
+            ('RegisteredOwner', 'REG_SZ', 'A Concerned Citizen')]}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 1)
     self.CheckEventData(event_data, expected_event_values)
 
   def testProcessFile(self):
     """Tests the Process function on a Windows Registry file."""
     test_file_entry = self._GetTestFileEntry(['SOFTWARE-RunTests'])
```

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/winlogon.py` & `plaso-20230717/tests/parsers/winreg_plugins/winlogon.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/parsers/winreg_plugins/winrar.py` & `plaso-20230717/tests/parsers/winreg_plugins/default.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,72 +1,74 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
-"""Tests for the WinRAR Windows Registry plugin."""
+"""Tests for the default Windows Registry plugin."""
 
 import unittest
 
 from dfdatetime import filetime as dfdatetime_filetime
 from dfwinreg import definitions as dfwinreg_definitions
 from dfwinreg import fake as dfwinreg_fake
 
-from plaso.parsers.winreg_plugins import winrar
+from plaso.parsers.winreg_plugins import default
 
 from tests.parsers.winreg_plugins import test_lib
 
 
-class WinRARHistoryPluginTest(test_lib.RegistryPluginTestCase):
-  """Tests for the WinRAR history Windows Registry plugin."""
+class TestDefaultRegistry(test_lib.RegistryPluginTestCase):
+  """Tests for the default Windows Registry plugin."""
 
   def _CreateTestKey(self, key_path, time_string):
-    """Creates WinRAR history Registry keys and values for testing.
+    """Creates Registry keys and values for testing.
 
     Args:
       key_path (str): Windows Registry key path.
       time_string (str): key last written date and time.
 
     Returns:
       dfwinreg.WinRegistryKey: a Windows Registry key.
     """
     filetime = dfdatetime_filetime.Filetime()
     filetime.CopyFromDateTimeString(time_string)
     registry_key = dfwinreg_fake.FakeWinRegistryKey(
-        'ArcHistory', key_path=key_path, last_written_time=filetime.timestamp,
-        offset=1456)
+        'TimeZoneInformation', key_path=key_path,
+        last_written_time=filetime.timestamp, offset=1456)
 
-    value_data = 'C:\\Downloads\\The Sleeping Dragon CD1.iso'.encode(
-        'utf_16_le')
+    value_data = 'acb'.encode('utf_16_le')
     registry_value = dfwinreg_fake.FakeWinRegistryValue(
-        '0', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
+        'MRUList', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
+        offset=123)
+    registry_key.AddValue(registry_value)
+
+    value_data = 'Some random text here'.encode('utf_16_le')
+    registry_value = dfwinreg_fake.FakeWinRegistryValue(
+        'a', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
         offset=1892)
     registry_key.AddValue(registry_value)
 
-    value_data = 'C:\\Downloads\\plaso-static.rar'.encode('utf_16_le')
+    value_data = 'c:/evil.exe'.encode('utf_16_le')
     registry_value = dfwinreg_fake.FakeWinRegistryValue(
-        '1', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
+        'b', data=value_data, data_type=dfwinreg_definitions.REG_BINARY,
         offset=612)
     registry_key.AddValue(registry_value)
 
-    return registry_key
-
-  def testFilters(self):
-    """Tests the FILTERS class attribute."""
-    plugin = winrar.WinRARHistoryPlugin()
-
-    key_path = 'HKEY_CURRENT_USER\\Software\\WinRAR\\ArcHistory'
-    self._AssertFiltersOnKeyPath(plugin, key_path)
+    value_data = 'C:/looks_legit.exe'.encode('utf_16_le')
+    registry_value = dfwinreg_fake.FakeWinRegistryValue(
+        'c', data=value_data, data_type=dfwinreg_definitions.REG_SZ,
+        offset=1001)
+    registry_key.AddValue(registry_value)
 
-    self._AssertNotFiltersOnKeyPath(plugin, 'HKEY_LOCAL_MACHINE\\Bogus')
+    return registry_key
 
   def testProcess(self):
     """Tests the Process function."""
-    key_path = 'HKEY_CURRENT_USER\\Software\\WinRAR\\ArcHistory'
+    key_path = '\\Microsoft\\Some Windows\\InterestingApp\\MRU'
     time_string = '2012-08-28 09:23:49.002031'
     registry_key = self._CreateTestKey(key_path, time_string)
 
-    plugin = winrar.WinRARHistoryPlugin()
+    plugin = default.DefaultPlugin()
     storage_writer = self._ParseKeyWithPlugin(registry_key, plugin)
 
     number_of_event_data = storage_writer.GetNumberOfAttributeContainers(
         'event_data')
     self.assertEqual(number_of_event_data, 1)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
@@ -74,20 +76,22 @@
     self.assertEqual(number_of_warnings, 0)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'recovery_warning')
     self.assertEqual(number_of_warnings, 0)
 
     expected_event_values = {
-        'data_type': 'winrar:history',
-        'entries': (
-            '0: C:\\Downloads\\The Sleeping Dragon CD1.iso '
-            '1: C:\\Downloads\\plaso-static.rar'),
+        'data_type': 'windows:registry:key_value',
         'key_path': key_path,
-        'last_written_time': '2012-08-28T09:23:49.0020310+00:00'}
+        'last_written_time': '2012-08-28T09:23:49.0020310+00:00',
+        'values': [
+            ('MRUList', 'REG_SZ', 'acb'),
+            ('a', 'REG_SZ', 'Some random text here'),
+            ('b', 'REG_BINARY', '(22 bytes)'),
+            ('c', 'REG_SZ', 'C:/looks_legit.exe')]}
 
     event_data = storage_writer.GetAttributeContainerByIndex('event_data', 0)
     self.CheckEventData(event_data, expected_event_values)
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/parsers/winrestore.py` & `plaso-20230717/tests/parsers/winrestore.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/preprocessors/init_imports.py` & `plaso-20230717/tests/preprocessors/init_imports.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/preprocessors/linux.py` & `plaso-20230717/tests/preprocessors/linux.py`

 * *Files 4% similar despite different names*

```diff
@@ -24,16 +24,15 @@
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = linux.LinuxHostnamePlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    hostname = test_mediator.knowledge_base.GetHostname()
-    self.assertEqual(hostname, 'plaso.kiddaland.net')
+    self.assertEqual(test_mediator.hostname.name, 'plaso.kiddaland.net')
 
 
 class LinuxDistributionPluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Linux distribution plugin."""
 
   _FILE_DATA = b'Fedora release 26 (Twenty Six)\n'
 
@@ -44,16 +43,15 @@
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = linux.LinuxDistributionPlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    system_product = test_mediator.knowledge_base.GetValue(
-        'operating_system_product')
+    system_product = test_mediator.GetValue('operating_system_product')
     self.assertEqual(system_product, 'Fedora release 26 (Twenty Six)')
 
 
 class LinuxIssueFilePluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Linux issue file plugin."""
 
   _FILE_DATA = b"""\
@@ -68,16 +66,15 @@
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = linux.LinuxIssueFilePlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    system_product = test_mediator.knowledge_base.GetValue(
-        'operating_system_product')
+    system_product = test_mediator.GetValue('operating_system_product')
     self.assertEqual(system_product, 'Debian GNU/Linux 5.0')
 
 
 class LinuxStandardBaseReleasePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Linux standard base (LSB) release plugin."""
 
@@ -94,54 +91,52 @@
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = linux.LinuxStandardBaseReleasePlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    system_product = test_mediator.knowledge_base.GetValue(
-        'operating_system_product')
+    system_product = test_mediator.GetValue('operating_system_product')
     self.assertEqual(system_product, 'Ubuntu 14.04 LTS')
 
 
 class LinuxSystemdOperatingSystemPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Linux operating system release plugin."""
 
-  _FILE_DATA = b"""\
-NAME=Fedora
-VERSION="26 (Workstation Edition)"
-ID=fedora
-VERSION_ID=26
-PRETTY_NAME="Fedora 26 (Workstation Edition)"
-ANSI_COLOR="0;34"
-CPE_NAME="cpe:/o:fedoraproject:fedora:26"
-HOME_URL="https://fedoraproject.org/"
-BUG_REPORT_URL="https://bugzilla.redhat.com/"
-REDHAT_BUGZILLA_PRODUCT="Fedora"
-REDHAT_BUGZILLA_PRODUCT_VERSION=26
-REDHAT_SUPPORT_PRODUCT="Fedora"
-REDHAT_SUPPORT_PRODUCT_VERSION=26
-PRIVACY_POLICY_URL=https://fedoraproject.org/wiki/Legal:PrivacyPolicy
-VARIANT="Workstation Edition"
-VARIANT_ID=workstation"""
+  _FILE_DATA = (
+      b'NAME=Fedora\n'
+      b'VERSION="26 (Workstation Edition)"\n'
+      b'ID=fedora\n'
+      b'VERSION_ID=26\n'
+      b'PRETTY_NAME="Fedora 26 (Workstation Edition)"\n'
+      b'ANSI_COLOR="0;34"\n'
+      b'CPE_NAME="cpe:/o:fedoraproject:fedora:26"\n'
+      b'HOME_URL="https://fedoraproject.org/"\n'
+      b'BUG_REPORT_URL="https://bugzilla.redhat.com/"\n'
+      b'REDHAT_BUGZILLA_PRODUCT="Fedora"\n'
+      b'REDHAT_BUGZILLA_PRODUCT_VERSION=26\n'
+      b'REDHAT_SUPPORT_PRODUCT="Fedora"\n'
+      b'REDHAT_SUPPORT_PRODUCT_VERSION=26\n'
+      b'PRIVACY_POLICY_URL=https://fedoraproject.org/wiki/Legal:PrivacyPolicy\n'
+      b'VARIANT="Workstation Edition"\n'
+      b'VARIANT_ID=workstation\n')
 
   def testParseFileData(self):
     """Tests the _ParseFileData function."""
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile('/etc/os-release', self._FILE_DATA)
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = linux.LinuxSystemdOperatingSystemPlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    system_product = test_mediator.knowledge_base.GetValue(
-        'operating_system_product')
+    system_product = test_mediator.GetValue('operating_system_product')
     self.assertEqual(system_product, 'Fedora 26 (Workstation Edition)')
 
 
 class LinuxTimeZonePluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Linux time zone plugin."""
 
   def testParseFileEntryWithLink(self):
@@ -158,16 +153,15 @@
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    self.assertEqual(
-        test_mediator.knowledge_base.timezone.zone, 'Europe/Zurich')
+    self.assertEqual(test_mediator.time_zone.zone, 'Europe/Zurich')
 
   def testParseFileEntryWithBogusLink(self):
     """Tests the _ParseFileEntry function on a bogus symbolic link."""
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddSymbolicLink(
         '/etc/localtime', '/usr/share/zoneinfo/Bogus')
 
@@ -179,18 +173,18 @@
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
-    self.assertEqual(test_mediator.knowledge_base.timezone.zone, 'UTC')
+    self.assertIsNone(test_mediator.time_zone)
 
   def testParseFileEntryWithTZif(self):
-    """Tests the _ParseFileEntry function on a timezone information file."""
+    """Tests the _ParseFileEntry function on a time zone information file."""
     test_file_path = self._GetTestFilePath(['localtime.tzif'])
     self._SkipIfPathNotExists(test_file_path)
 
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFileReadData('/etc/localtime', test_file_path)
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
@@ -201,15 +195,15 @@
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    self.assertEqual(test_mediator.knowledge_base.timezone.zone, 'CET')
+    self.assertEqual(test_mediator.time_zone.zone, 'CET')
 
   def testParseFileEntryWithBogusTZif(self):
     """Tests the _ParseFileEntry function on a bogus TZif file."""
     test_file_path = self._GetTestFilePath(['syslog'])
     self._SkipIfPathNotExists(test_file_path)
 
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
@@ -223,15 +217,15 @@
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
-    self.assertEqual(test_mediator.knowledge_base.timezone.zone, 'UTC')
+    self.assertIsNone(test_mediator.time_zone)
 
 
 class LinuxUserAccountsPluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Linux user accounts plugin."""
 
   _FILE_DATA = (
       b'root:x:0:0:root:/root:/bin/bash\n'
@@ -253,27 +247,27 @@
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile('/etc/passwd', self._FILE_DATA)
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    users = sorted(
-        test_mediator.knowledge_base.user_accounts,
-        key=lambda user_account: user_account.identifier)
-    self.assertEqual(len(users), 13)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'user_account')
+    self.assertEqual(number_of_artifacts, 13)
 
-    user_account = users[4]
+    user_account = storage_writer.GetAttributeContainerByIndex(
+       'user_account', 11)
 
     self.assertEqual(user_account.identifier, '14')
     self.assertEqual(user_account.group_identifier, '50')
     self.assertEqual(user_account.user_directory, '/var/ftp')
     self.assertEqual(user_account.username, 'ftp')
     self.assertEqual(user_account.shell, '/sbin/nologin')
 
@@ -282,144 +276,144 @@
     file_system_builder.AddFile(
         '/etc/passwd', b'error:99:99:Nobody:/home/error:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with empty username.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b':x:99:99:Nobody:/home/error:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with empty user identifier.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b'error:x::99:Nobody:/home/error:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with non UTF-8 username.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b'er\xbfor:x:99:99:Nobody:/home/error:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with non UTF-8 user identifier.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b'error:x:\xbf9:99:Nobody:/home/error:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with non UTF-8 group identifier.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b'error:x:99:\xbf9:Nobody:/home/error:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with non UTF-8 full name.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b'error:x:99:99:Nob\xbfdy:/home/error:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with non UTF-8 user directory.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b'error:x:99:99:Nobody:/home/er\xbfor:/sbin/nologin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
     # Test on /etc/passwd with non UTF-8 shell.
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/etc/passwd', b'error:x:99:99:Nobody:/home/error:/sbin/nol\xbfgin\n')
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = linux.LinuxUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, storage_writer, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+       file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
 
 if __name__ == '__main__':
```

### Comparing `plaso-20230311/tests/preprocessors/macos.py` & `plaso-20230717/tests/preprocessors/macos.py`

 * *Files 3% similar despite different names*

```diff
@@ -52,16 +52,15 @@
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = macos.MacOSHostnamePlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    hostname = test_mediator.knowledge_base.GetHostname()
-    self.assertEqual(hostname, 'Plaso\'s Mac mini')
+    self.assertEqual(test_mediator.hostname.name, 'Plaso\'s Mac mini')
 
 
 class MacOSKeyboardLayoutPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the MacOS keyboard layout plugin."""
 
   def testParsePlistKeyValue(self):
@@ -75,15 +74,15 @@
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = macos.MacOSKeyboardLayoutPlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    keyboard_layout = test_mediator.knowledge_base.GetValue('keyboard_layout')
+    keyboard_layout = test_mediator.GetValue('keyboard_layout')
     self.assertEqual(keyboard_layout, 'US')
 
 
 class MacOSSystemVersionPluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the MacOS system version information plugin."""
 
   _FILE_DATA = (
@@ -114,15 +113,15 @@
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     plugin = macos.MacOSSystemVersionPlugin()
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, None, plugin)
 
-    build = test_mediator.knowledge_base.GetValue('operating_system_version')
+    build = test_mediator.GetValue('operating_system_version')
     self.assertEqual(build, '10.9.2')
 
 
 class MacOSTimeZonePluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the MacOS time zone plugin."""
 
   def testParseFileEntryWithLink(self):
@@ -139,16 +138,15 @@
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    self.assertEqual(
-        test_mediator.knowledge_base.timezone.zone, 'Europe/Amsterdam')
+    self.assertEqual(test_mediator.time_zone.zone, 'Europe/Amsterdam')
 
   def testParseFileEntryWithBogusLink(self):
     """Tests the _ParseFileEntry function a bogus symbolic link."""
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddSymbolicLink(
         '/private/etc/localtime', '/usr/share/zoneinfo/Bogus')
 
@@ -160,15 +158,15 @@
     test_mediator = self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
-    self.assertEqual(test_mediator.knowledge_base.timezone.zone, 'UTC')
+    self.assertIsNone(test_mediator.time_zone)
 
 
 class MacOSUserAccountsPluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the MacOS user accounts plugin."""
 
   # pylint: disable=protected-access
 
@@ -183,27 +181,27 @@
         test_file_path)
 
     mount_point = fake_path_spec.FakePathSpec(location='/')
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = macos.MacOSUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
+    self._RunPreprocessorPluginOnFileSystem(
         file_system_builder.file_system, mount_point, storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    users = sorted(
-        test_mediator.knowledge_base.user_accounts,
-        key=lambda user_account: user_account.identifier)
-    self.assertEqual(len(users), 1)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'user_account')
+    self.assertEqual(number_of_artifacts, 1)
 
-    user_account = users[0]
+    user_account = storage_writer.GetAttributeContainerByIndex(
+       'user_account', 0)
 
     self.assertEqual(user_account.identifier, '-2')
     self.assertEqual(user_account.full_name, 'Unprivileged User')
     self.assertEqual(user_account.user_directory, '/var/empty')
     self.assertEqual(user_account.username, 'nobody')
 
   def testRunWithTruncatedFile(self):
```

### Comparing `plaso-20230311/tests/preprocessors/manager.py` & `plaso-20230717/tests/preprocessors/manager.py`

 * *Files 17% similar despite different names*

```diff
@@ -3,33 +3,31 @@
 """Tests for the preprocess plugins manager."""
 
 import unittest
 
 from artifacts import reader as artifacts_reader
 from artifacts import registry as artifacts_registry
 
-from plaso.engine import knowledge_base as knowledge_base_library
 from plaso.preprocessors import interface
 from plaso.preprocessors import manager
 
 from tests import test_lib as shared_test_lib
 
 
 class TestArtifactPreprocessorPlugin(interface.ArtifactPreprocessorPlugin):
   """Test artifact preprocessor plugin."""
 
   ARTIFACT_DEFINITION_NAME = 'TestArtifactDefinition'
 
 
   # pylint: disable=unused-argument
-  def ParseValueData(self, knowledge_base, value_data):
+  def ParseValueData(self, value_data):
     """Parses artifact value data for a preprocessing attribute.
 
     Args:
-      knowledge_base (KnowledgeBase): to fill with preprocessing information.
       value_data (object): artifact value data.
     """
     return
 
 
 class PreprocessPluginsManagerTest(shared_test_lib.BaseTestCase):
   """Tests for the preprocess plugins manager."""
@@ -41,21 +39,17 @@
     artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(artifacts_path)
 
     registry = artifacts_registry.ArtifactDefinitionsRegistry()
     reader = artifacts_reader.YamlArtifactsReader()
     registry.ReadFromDirectory(reader, artifacts_path)
 
-    knowledge_base_object = knowledge_base_library.KnowledgeBase()
-
-    _ = knowledge_base_object
-
     # TODO: implement.
     # manager.PreprocessPluginsManager.CollectFromFileSystem(
-    #     registry, knowledge_base_object, None, None)
+    #     registry, None, None)
 
   # TODO: add tests for CollectFromWindowsRegistry
   # TODO: add tests for GetNames
 
   def testRegistrationPlugin(self):
     """Tests RegisterPlugin and DeregisterPlugin functions."""
     number_of_plugins = len(manager.PreprocessPluginsManager._plugins)
```

### Comparing `plaso-20230311/tests/preprocessors/test_lib.py` & `plaso-20230717/tests/preprocessors/test_lib.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,16 +7,14 @@
 from dfvfs.helpers import file_system_searcher
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.path import factory as path_spec_factory
 from dfwinreg import registry as dfwinreg_registry
 from dfwinreg import registry_searcher
 
 from plaso.containers import artifacts
-from plaso.containers import sessions
-from plaso.engine import knowledge_base
 from plaso.preprocessors import manager
 from plaso.preprocessors import mediator
 from plaso.storage.fake import writer as fake_writer
 
 from tests import test_lib as shared_test_lib
 
 
@@ -56,18 +54,15 @@
     Return:
       PreprocessMediator: preprocess mediator.
     """
     artifact_definition = self._artifacts_registry.GetDefinitionByName(
         plugin.ARTIFACT_DEFINITION_NAME)
     self.assertIsNotNone(artifact_definition)
 
-    session = sessions.Session()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     searcher = file_system_searcher.FileSystemSearcher(file_system, mount_point)
 
     plugin.Collect(test_mediator, artifact_definition, searcher, file_system)
 
     return test_mediator
 
@@ -93,18 +88,15 @@
         case_sensitive=False, name='SystemRoot', value='C:\\Windows')
 
     registry_file_reader = manager.FileSystemWinRegistryFileReader(
         file_system, mount_point, environment_variables=[environment_variable])
     win_registry = dfwinreg_registry.WinRegistry(
         registry_file_reader=registry_file_reader)
 
-    session = sessions.Session()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     searcher = registry_searcher.WinRegistrySearcher(win_registry)
 
     plugin.Collect(test_mediator, artifact_definition, searcher)
 
     return test_mediator
```

### Comparing `plaso-20230311/tests/preprocessors/windows.py` & `plaso-20230717/tests/preprocessors/windows.py`

 * *Files 11% similar despite different names*

```diff
@@ -5,100 +5,106 @@
 import unittest
 
 from dfvfs.helpers import fake_file_system_builder
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.path import factory as path_spec_factory
 
 from plaso.containers import artifacts
-from plaso.containers import sessions
-from plaso.engine import knowledge_base
 from plaso.preprocessors import mediator
 from plaso.preprocessors import windows
 
 from tests.preprocessors import test_lib
 
 
 class WindowsAllUsersAppDataKnowledgeBasePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the allusersdata knowledge base value plugin."""
 
+  # pylint: disable=protected-access
+
   def testCollect(self):
     """Tests the Collect function."""
     plugin = windows.WindowsAllUsersAppDataKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'allusersappdata')
-    self.assertIsNone(environment_variable)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 0)
 
   def testCollectWithAllUsersProfile(self):
     """Tests the Collect function with the %AllUsersProfile% variable."""
     plugin = windows.WindowsAllUsersAppDataKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='allusersprofile',
         value='C:\\Documents and Settings\\All Users')
 
-    test_mediator.knowledge_base.AddEnvironmentVariable(environment_variable)
+    test_mediator._environment_variables['ALLUSERSPROFILE'] = (
+        environment_variable)
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'allusersappdata')
+    # The %AllUsersAppData% environment variable is derived from
+    # the %AllUsersProfile% environment variable.
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
+
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'allusersappdata')
     self.assertEqual(
         environment_variable.value,
         'C:\\Documents and Settings\\All Users\\Application Data')
 
   def testCollectWithProgramData(self):
     """Tests the Collect function with the %ProgramData% variable."""
     plugin = windows.WindowsAllUsersAppDataKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='programdata',
         value='%SystemDrive%\\ProgramData')
 
-    test_mediator.knowledge_base.AddEnvironmentVariable(environment_variable)
+    test_mediator._environment_variables['PROGRAMDATA'] = environment_variable
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'allusersappdata')
+    # The %AllUsersAppData% environment variable is derived from
+    # the %ProgramData% environment variable.
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
+
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'allusersappdata')
     self.assertEqual(environment_variable.value, '%SystemDrive%\\ProgramData')
 
 
 class WindowsAllUsersProfileEnvironmentVariablePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the %AllUsersProfile% environment variable plugin."""
 
@@ -106,103 +112,104 @@
     """Tests the _ParseValueData function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsAllUsersProfileEnvironmentVariablePlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'AllUsersProfile')
-    self.assertIsNone(environment_variable)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 0)
 
 
 class WindowsAllUsersAppProfileKnowledgeBasePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the allusersprofile knowledge base value plugin."""
 
+  # pylint: disable=protected-access
+
   def testCollect(self):
     """Tests the Collect function."""
     plugin = windows.WindowsAllUsersAppProfileKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'allusersprofile')
-    self.assertIsNone(environment_variable)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 0)
 
   def testCollectWithAllUsersProfile(self):
     """Tests the Collect function with the %AllUsersProfile% variable."""
     plugin = windows.WindowsAllUsersAppProfileKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='allusersprofile',
         value='C:\\Documents and Settings\\All Users')
 
-    test_mediator.knowledge_base.AddEnvironmentVariable(environment_variable)
+    test_mediator._environment_variables['ALLUSERSPROFILE'] = (
+        environment_variable)
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'allusersprofile')
-    self.assertIsNotNone(environment_variable)
-    self.assertEqual(
-        environment_variable.value, 'C:\\Documents and Settings\\All Users')
+    # The %AllUsersProfile% environment variable is already set in
+    # the knowledge base and should not be created.
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 0)
 
   def testCollectWithProgramData(self):
     """Tests the Collect function with the %ProgramData% variable."""
     plugin = windows.WindowsAllUsersAppProfileKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='programdata',
         value='%SystemDrive%\\ProgramData')
 
-    test_mediator.knowledge_base.AddEnvironmentVariable(environment_variable)
+    test_mediator._environment_variables['PROGRAMDATA'] = environment_variable
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'allusersprofile')
+    # The %AllUsersProfile% environment variable is derived from
+    # the %ProgramData% environment variable.
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
+
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'allusersprofile')
     self.assertEqual(environment_variable.value, '%SystemDrive%\\ProgramData')
 
 
 class WindowsAvailableTimeZonesPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows available time zones plugin."""
 
@@ -210,97 +217,98 @@
     """Tests the _ParseKey function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsAvailableTimeZonesPlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    available_time_zones = sorted(
-        test_mediator.knowledge_base.available_time_zones,
-        key=lambda time_zone: time_zone.name)
-    self.assertIsNotNone(available_time_zones)
-    self.assertEqual(len(available_time_zones), 101)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'time_zone')
+    self.assertEqual(number_of_artifacts, 101)
+
+    available_time_zone = storage_writer.GetAttributeContainerByIndex(
+       'time_zone', 7)
 
-    self.assertEqual(available_time_zones[0].name, 'AUS Central Standard Time')
+    self.assertEqual(available_time_zone.name, 'AUS Central Standard Time')
 
 
-class WindowsCodepagePluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
-  """Tests for the Windows codepage plugin."""
+class WindowsCodePagePluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
+  """Tests for the Windows code page plugin."""
 
   def testParseValueData(self):
     """Tests the _ParseValueData function."""
     test_file_path = self._GetTestFilePath(['SYSTEM'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
-    plugin = windows.WindowsCodepagePlugin()
+    plugin = windows.WindowsCodePagePlugin()
     test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSystem(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    self.assertEqual(test_mediator.knowledge_base.codepage, 'cp1252')
+    self.assertEqual(test_mediator.code_page, 'cp1252')
 
 
 class WindowsEventLogPublishersPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows Event Log publishers plugin."""
 
   def testParseValueData(self):
     """Tests the _ParseValueData function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsEventLogPublishersPlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    windows_eventlog_providers = (
-        test_mediator.knowledge_base.GetWindowsEventLogProviders())
-    self.assertEqual(len(windows_eventlog_providers), 438)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'windows_eventlog_provider')
+    self.assertEqual(number_of_artifacts, 438)
 
 
 class WindowsEventLogSourcesPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows Event Log sources plugin."""
 
   def testParseValueData(self):
     """Tests the _ParseValueData function."""
     test_file_path = self._GetTestFilePath(['SYSTEM'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsEventLogSourcesPlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSystem(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSystem(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    windows_eventlog_providers = (
-        test_mediator.knowledge_base.GetWindowsEventLogProviders())
-    self.assertEqual(len(windows_eventlog_providers), 374)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'windows_eventlog_provider')
+    self.assertEqual(number_of_artifacts, 374)
 
 
 class WindowsHostnamePluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows hostname plugin."""
 
   # pylint: disable=protected-access
 
@@ -315,16 +323,15 @@
     test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSystem(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    hostname = test_mediator.knowledge_base.GetHostname()
-    self.assertEqual(hostname, 'WKS-WIN732BITA')
+    self.assertEqual(test_mediator.hostname.name, 'WKS-WIN732BITA')
 
     value_data = ['MyHost', '']
     plugin._ParseValueData(test_mediator, value_data)
 
 
 class WindowsLanguagePlugin(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows language plugin."""
@@ -340,15 +347,15 @@
     test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSystem(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    self.assertEqual(test_mediator.knowledge_base.language, 'en-US')
+    self.assertEqual(test_mediator.language, 'en-US')
 
 
 class WindowsMountedDevicesPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows mounted devices plugin."""
 
   # pylint: disable=protected-access
@@ -390,129 +397,141 @@
     """Tests the _ParseValueData function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsProgramDataEnvironmentVariablePlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'ProgramData')
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
+
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'programdata')
     self.assertEqual(environment_variable.value, '%SystemDrive%\\ProgramData')
 
 
 class WindowsProgramDataKnowledgeBasePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the programdata knowledge base value plugin."""
 
+  # pylint: disable=protected-access
+
   def testCollect(self):
     """Tests the Collect function."""
     plugin = windows.WindowsProgramDataKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'programdata')
-    self.assertIsNone(environment_variable)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 0)
 
   def testCollectWithAllUsersProfile(self):
     """Tests the Collect function with the %AllUsersProfile% variable."""
     plugin = windows.WindowsProgramDataKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='allusersprofile',
         value='C:\\Documents and Settings\\All Users')
 
-    test_mediator.knowledge_base.AddEnvironmentVariable(environment_variable)
+    test_mediator._environment_variables['ALLUSERSPROFILE'] = (
+        environment_variable)
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'programdata')
+    # The %ProgramData% environment variable is derived from
+    # the %AllUsersProfile% environment variable.
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
+
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'programdata')
     self.assertEqual(
         environment_variable.value, 'C:\\Documents and Settings\\All Users')
 
   def testCollectWithProgramData(self):
     """Tests the Collect function with the %ProgramData% variable."""
     plugin = windows.WindowsProgramDataKnowledgeBasePlugin()
 
-    session = sessions.Session()
     storage_writer = self._CreateTestStorageWriter()
-    test_knowledge_base = knowledge_base.KnowledgeBase()
-    test_mediator = mediator.PreprocessMediator(
-        session, storage_writer, test_knowledge_base)
+    test_mediator = mediator.PreprocessMediator(storage_writer)
 
     environment_variable = artifacts.EnvironmentVariableArtifact(
         case_sensitive=False, name='programdata',
         value='%SystemDrive%\\ProgramData')
 
-    test_mediator.knowledge_base.AddEnvironmentVariable(environment_variable)
+    test_mediator._environment_variables['PROGRAMDATA'] = environment_variable
 
     plugin.Collect(test_mediator)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'programdata')
-    self.assertIsNotNone(environment_variable)
-    self.assertEqual(environment_variable.value, '%SystemDrive%\\ProgramData')
+    # The %ProgramData% environment variable is already set in
+    # the knowledge base and should not be created.
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 0)
 
 
 class WindowsProgramFilesEnvironmentVariablePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the %ProgramFiles% environment variable plugin."""
 
   def testParseValueData(self):
     """Tests the _ParseValueData function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsProgramFilesEnvironmentVariablePlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'ProgramFiles')
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
+
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'programfiles')
     self.assertEqual(environment_variable.value, 'C:\\Program Files')
 
 
 class WindowsProgramFilesX86EnvironmentVariablePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the %ProgramFilesX86% environment variable plugin."""
 
@@ -520,26 +539,26 @@
     """Tests the _ParseValueData function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsProgramFilesX86EnvironmentVariablePlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'ProgramFilesX86')
     # The test SOFTWARE Registry file does not contain a value for
     # the Program Files X86 path.
-    self.assertIsNone(environment_variable)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 0)
 
 
 class WindowsSystemRootEnvironmentVariablePluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the %SystemRoot% environment variable plugin."""
 
   _FILE_DATA = b'regf'
@@ -549,21 +568,31 @@
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/Windows/System32/config/SYSTEM', self._FILE_DATA)
 
     mount_point = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_FAKE, location='/')
 
+    storage_writer = self._CreateTestStorageWriter()
     plugin = windows.WindowsSystemRootEnvironmentVariablePlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, None, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+        file_system_builder.file_system, mount_point, storage_writer, plugin)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'SystemRoot')
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'preprocessing_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
+
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'systemroot')
     self.assertEqual(environment_variable.value, '\\Windows')
 
 
 class WindowsServicesAndDriversPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows service (and driver) configurations plugin."""
 
@@ -602,16 +631,15 @@
     test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    system_product = test_mediator.knowledge_base.GetValue(
-        'operating_system_product')
+    system_product = test_mediator.GetValue('operating_system_product')
     self.assertEqual(system_product, 'Windows 7 Ultimate')
 
 
 class WindowsSystemVersionPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the system version information plugin."""
 
@@ -626,16 +654,15 @@
     test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    system_version = test_mediator.knowledge_base.GetValue(
-        'operating_system_version')
+    system_version = test_mediator.GetValue('operating_system_version')
     self.assertEqual(system_version, '6.1')
 
 
 class WindowsTimeZonePluginTest(test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the time zone plugin."""
 
   def testParseValueData(self):
@@ -651,16 +678,15 @@
 
     # Unable to map: "@tzres.dll,-112" to time zone with error: Unsupported
     # time zone: @tzres.dll,-112
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 1)
 
-    self.assertEqual(
-        test_mediator.knowledge_base.timezone.zone, 'America/New_York')
+    self.assertEqual(test_mediator.time_zone.zone, 'America/New_York')
 
 
 class WindowsUserAccountsPluginTest(
     test_lib.ArtifactPreprocessorPluginTestCase):
   """Tests for the Windows user accounts artifacts mapping."""
 
   # pylint: disable=protected-access
@@ -669,28 +695,27 @@
     """Tests the _ParseKey function."""
     test_file_path = self._GetTestFilePath(['SOFTWARE'])
     self._SkipIfPathNotExists(test_file_path)
 
     storage_writer = self._CreateTestStorageWriter()
 
     plugin = windows.WindowsUserAccountsPlugin()
-    test_mediator = self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
+    self._RunPreprocessorPluginOnWindowsRegistryValueSoftware(
         storage_writer, plugin)
 
     number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
         'preprocessing_warning')
     self.assertEqual(number_of_warnings, 0)
 
-    user_accounts = sorted(
-        test_mediator.knowledge_base.user_accounts,
-        key=lambda user_account: user_account.identifier)
-    self.assertIsNotNone(user_accounts)
-    self.assertEqual(len(user_accounts), 11)
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'user_account')
+    self.assertEqual(number_of_artifacts, 11)
 
-    user_account = user_accounts[9]
+    user_account = storage_writer.GetAttributeContainerByIndex(
+       'user_account', 9)
 
     expected_sid = 'S-1-5-21-2036804247-3058324640-2116585241-1114'
     self.assertEqual(user_account.identifier, expected_sid)
     self.assertEqual(user_account.username, 'rsydow')
     self.assertEqual(user_account.user_directory, 'C:\\Users\\rsydow')
 
 
@@ -705,19 +730,29 @@
     file_system_builder = fake_file_system_builder.FakeFileSystemBuilder()
     file_system_builder.AddFile(
         '/Windows/System32/config/SYSTEM', self._FILE_DATA)
 
     mount_point = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_FAKE, location='/')
 
+    storage_writer = self._CreateTestStorageWriter()
     plugin = windows.WindowsWinDirEnvironmentVariablePlugin()
-    test_mediator = self._RunPreprocessorPluginOnFileSystem(
-        file_system_builder.file_system, mount_point, None, plugin)
+    self._RunPreprocessorPluginOnFileSystem(
+        file_system_builder.file_system, mount_point, storage_writer, plugin)
+
+    number_of_warnings = storage_writer.GetNumberOfAttributeContainers(
+        'preprocessing_warning')
+    self.assertEqual(number_of_warnings, 0)
+
+    number_of_artifacts = storage_writer.GetNumberOfAttributeContainers(
+        'environment_variable')
+    self.assertEqual(number_of_artifacts, 1)
 
-    environment_variable = test_mediator.knowledge_base.GetEnvironmentVariable(
-        'WinDir')
+    environment_variable = storage_writer.GetAttributeContainerByIndex(
+        'environment_variable', 0)
     self.assertIsNotNone(environment_variable)
+    self.assertEqual(environment_variable.name, 'windir')
     self.assertEqual(environment_variable.value, '\\Windows')
 
 
 if __name__ == '__main__':
   unittest.main()
```

### Comparing `plaso-20230311/tests/serializer/json_serializer.py` & `plaso-20230717/tests/serializer/json_serializer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/single_process/extraction_engine.py` & `plaso-20230717/tests/single_process/extraction_engine.py`

 * *Files 7% similar despite different names*

```diff
@@ -5,65 +5,58 @@
 import collections
 import unittest
 
 from dfvfs.lib import definitions as dfvfs_definitions
 from dfvfs.path import factory as path_spec_factory
 from dfvfs.resolver import context
 
-from plaso.containers import artifacts
-from plaso.containers import sessions
 from plaso.engine import configurations
 from plaso.single_process import extraction_engine
 from plaso.storage.fake import writer as fake_writer
 
 from tests import test_lib as shared_test_lib
 
 
 class SingleProcessEngineTest(shared_test_lib.BaseTestCase):
   """Tests for the single process engine object."""
 
   # pylint: disable=protected-access
 
-  def testProcessSources(self):
-    """Tests the ProcessSources function."""
+  def testProcessSource(self):
+    """Tests the PreprocessSource and ProcessSource functions."""
     test_artifacts_path = self._GetTestFilePath(['artifacts'])
     self._SkipIfPathNotExists(test_artifacts_path)
 
     test_file_path = self._GetTestFilePath(['mynd.dd'])
     self._SkipIfPathNotExists(test_file_path)
 
     test_engine = extraction_engine.SingleProcessEngine()
+    test_engine.BuildArtifactsRegistry(test_artifacts_path, None)
     resolver_context = context.Context()
 
     os_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_OS, location=test_file_path)
     source_path_spec = path_spec_factory.Factory.NewPathSpec(
         dfvfs_definitions.TYPE_INDICATOR_TSK, location='/',
         parent=os_path_spec)
 
-    source_configuration = artifacts.SourceConfigurationArtifact(
-        path_spec=source_path_spec)
-
-    session = sessions.Session()
-
-    configuration = configurations.ProcessingConfiguration()
-    configuration.data_location = shared_test_lib.DATA_PATH
-    configuration.parser_filter_expression = 'filestat'
+    processing_configuration = configurations.ProcessingConfiguration()
+    processing_configuration.data_location = shared_test_lib.DATA_PATH
+    processing_configuration.parser_filter_expression = 'filestat'
 
     storage_writer = fake_writer.FakeStorageWriter()
     storage_writer.Open()
 
     try:
-      test_engine.PreprocessSources(
-          test_artifacts_path, None, [source_path_spec], session,
-          storage_writer)
-
-      processing_status = test_engine.ProcessSources(
-          [source_configuration], storage_writer, resolver_context,
-          configuration)
+      system_configurations = test_engine.PreprocessSource(
+          [source_path_spec], storage_writer)
+
+      processing_status = test_engine.ProcessSource(
+          storage_writer, resolver_context, processing_configuration,
+          system_configurations, [source_path_spec])
 
       number_of_events = storage_writer.GetNumberOfAttributeContainers('event')
       number_of_extraction_warnings = (
           storage_writer.GetNumberOfAttributeContainers(
               'extraction_warning'))
       number_of_recovery_warnings = (
           storage_writer.GetNumberOfAttributeContainers(
```

### Comparing `plaso-20230311/tests/storage/factory.py` & `plaso-20230717/tests/storage/factory.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/fake/event_heap.py` & `plaso-20230717/tests/storage/fake/event_heap.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/fake/writer.py` & `plaso-20230717/tests/storage/fake/writer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/reader.py` & `plaso-20230717/tests/storage/reader.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/redis/reader.py` & `plaso-20230717/tests/storage/redis/reader.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/redis/redis_store.py` & `plaso-20230717/tests/storage/redis/redis_store.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/sqlite/reader.py` & `plaso-20230717/tests/storage/sqlite/reader.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/sqlite/sqlite_file.py` & `plaso-20230717/tests/storage/sqlite/sqlite_file.py`

 * *Files 0% similar despite different names*

```diff
@@ -106,15 +106,15 @@
         with self.assertRaises(IOError):
           test_store._CreateAttributeContainerTable(
               event_data_stream.CONTAINER_TYPE)
 
       finally:
         test_store.Close()
 
-  # TODO: add tests for _CreatetAttributeContainerFromRow
+  # TODO: add tests for _CreateAttributeContainerFromRow
   # TODO: add tests for _DeserializeAttributeContainer
 
   def testGetAttributeContainersWithFilter(self):
     """Tests the _GetAttributeContainersWithFilter function."""
     event_data_stream = events.EventDataStream()
     event_data_stream.md5_hash = '8f0bf95a7959baad9666b21a7feed79d'
```

### Comparing `plaso-20230311/tests/storage/sqlite/writer.py` & `plaso-20230717/tests/storage/sqlite/writer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/test_lib.py` & `plaso-20230717/tests/storage/test_lib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/storage/writer.py` & `plaso-20230717/tests/storage/writer.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tests/test_lib.py` & `plaso-20230717/tests/test_lib.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tools/image_export.py` & `plaso-20230717/tools/image_export.py`

 * *Files 4% similar despite different names*

```diff
@@ -55,15 +55,15 @@
   if not tool.has_filters:
     logging.warning('No filter defined exporting all files.')
 
   # TODO: print more status information like PrintOptions.
   tool.PrintFilterCollection()
 
   try:
-    tool.ProcessSources()
+    tool.ProcessSource()
 
   # Writing to stdout and stderr will raise BrokenPipeError if it
   # receives a SIGPIPE.
   except BrokenPipeError:
     pass
 
   except (KeyboardInterrupt, errors.UserAbort):
@@ -72,15 +72,15 @@
 
   except errors.BadConfigOption as exception:
     logging.warning(exception)
     return False
 
   except errors.SourceScannerError as exception:
     logging.warning((
-        'Unable to scan for a supported filesystem with error: {0!s}\n'
+        'Unable to scan for a supported file system with error: {0!s}\n'
         'Most likely the image format is not supported by the '
         'tool.').format(exception))
     return False
 
   return True
```

### Comparing `plaso-20230311/tools/log2timeline.py` & `plaso-20230717/tools/log2timeline.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tools/pinfo.py` & `plaso-20230717/tools/pinfo.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tools/psort.py` & `plaso-20230717/tools/psort.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tools/psteal.py` & `plaso-20230717/tools/psteal.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/tox.ini` & `plaso-20230717/tox.ini`

 * *Files 26% similar despite different names*

```diff
@@ -14,31 +14,15 @@
     -rrequirements.txt
     -rtest_requirements.txt
     coverage: coverage
 commands =
     py3{7,8,9,10,11}: ./run_tests.py
     coverage: coverage erase
     coverage: coverage run --source=plaso --omit="*_test*,*__init__*,*test_lib*" run_tests.py
-
-[testenv:codecov]
-skip_install = True
-passenv =
-    CFLAGS
-    CPPFLAGS
-    GITHUB_ACTION
-    GITHUB_HEAD_REF
-    GITHUB_REF
-    GITHUB_REPOSITORY
-    GITHUB_RUN_ID
-    GITHUB_SHA
-    LDFLAGS
-deps =
-    codecov < 2.1.10
-commands =
-    codecov
+    coverage: coverage xml
 
 [testenv:docs]
 usedevelop = True
 deps =
     -rdocs/requirements.txt
 commands =
     sphinx-build -b html -d build/doctrees docs dist/docs
@@ -52,15 +36,15 @@
     CPPFLAGS
     LDFLAGS
 setenv =
     PYTHONPATH = {toxinidir}
 deps =
     -rrequirements.txt
     -rtest_requirements.txt
-    pylint >= 2.14.0, < 2.15.0
+    pylint >= 2.17.0, < 2.18.0
     yamllint >= 1.26.0
 commands =
     pylint --version
     yamllint -v
     # Ignore setup.py for now due to:
     # setup.py:15:0: E0001: Cannot import 'distutils.command.bdist_msi' due to
     # syntax error 'expected an indented block (<unknown>, line 347)' (syntax-error)
```

### Comparing `plaso-20230311/utils/build_docker.sh` & `plaso-20230717/utils/build_docker.sh`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/check_dependencies.py` & `plaso-20230717/utils/check_dependencies.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/dependencies.py` & `plaso-20230717/utils/dependencies.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/export_event_data.py` & `plaso-20230717/utils/export_event_data.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/export_supported_formats.py` & `plaso-20230717/utils/export_supported_formats.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/generate_windows_time_zones.py` & `plaso-20230717/utils/generate_windows_time_zones.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/plot_cpu_usage.py` & `plaso-20230717/utils/plot_cpu_usage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/plot_memory_usage.py` & `plaso-20230717/utils/plot_memory_usage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/plot_storage.py` & `plaso-20230717/utils/plot_storage.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/plot_task_queue.py` & `plaso-20230717/utils/plot_task_queue.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/plot_tasks.py` & `plaso-20230717/utils/plot_tasks.py`

 * *Files identical despite different names*

### Comparing `plaso-20230311/utils/update_release.sh` & `plaso-20230717/utils/update_release.sh`

 * *Files identical despite different names*

